<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="research-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PeerJ</journal-id>
<journal-id journal-id-type="iso-abbrev">PeerJ</journal-id>
<journal-id journal-id-type="publisher-id">peerj</journal-id>
<journal-id journal-id-type="pmc">peerj</journal-id>
<journal-title-group>
<journal-title>PeerJ</journal-title>
</journal-title-group>
<issn pub-type="epub">2167-8359</issn>
<publisher>
<publisher-name>PeerJ Inc.</publisher-name>
<publisher-loc>San Diego, USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">32704450</article-id>
<article-id pub-id-type="pmc">7346860</article-id>
<article-id pub-id-type="publisher-id">9470</article-id>
<article-id pub-id-type="doi">10.7717/peerj.9470</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Bioinformatics</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Computational Biology</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Data Mining and Machine Learning</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Data Science</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Predicting the effect of variants on splicing using Convolutional Neural Networks</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" id="author-1">
<name>
<surname>Thanapattheerakul</surname>
<given-names>Thanyathorn</given-names>
</name>
<xref ref-type="aff" rid="aff-1">1</xref>
</contrib>
<contrib contrib-type="author" id="author-2">
<name>
<surname>Engchuan</surname>
<given-names>Worrawat</given-names>
</name>
<xref ref-type="aff" rid="aff-2">2</xref>
<xref ref-type="aff" rid="aff-3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes" id="author-3">
<name>
<surname>Chan</surname>
<given-names>Jonathan H.</given-names>
</name>
<email>jonathan@sit.kmutt.ac.th</email>
<xref ref-type="aff" rid="aff-1">1</xref>
<xref ref-type="aff" rid="aff-4">4</xref>
</contrib>
<aff id="aff-1"><label>1</label><institution>School of Information Technology, King Mongkut’s University of Technology Thonburi</institution>, <city>Bangkok</city>, <country>Thailand</country></aff>
<aff id="aff-2"><label>2</label><institution>Genetics and Genome Biology, The Hospital for Sick Children</institution>, <city>Toronto</city>, <state>Ontario</state>, <country>Canada</country></aff>
<aff id="aff-3"><label>3</label><institution>The Centre for Applied Genomics, The Hospital of Sick Children</institution>, <city>Toronto</city>, <state>Ontario</state>, <country>Canada</country></aff>
<aff id="aff-4"><label>4</label><institution> IC2-DLab, School of Information Technology, King Mongkut’s University of Technology Thonburi</institution>, <state>Bangkok</state>, <country>Thailand</country></aff>
</contrib-group>
<contrib-group>
<contrib contrib-type="editor">
<name>
<surname>Piccolo</surname>
<given-names>Stephen</given-names>
</name>
</contrib>
</contrib-group>
<pub-date date-type="pub" iso-8601-date="2020-07-06" pub-type="epub">
<day>6</day>
<month>7</month>
<year iso-8601-date="2020">2020</year>
</pub-date>
<pub-date pub-type="collection">
<year>2020</year>
</pub-date>
<volume>8</volume>
<elocation-id>e9470</elocation-id>
<history>
<date date-type="received" iso-8601-date="2019-11-25">
<day>25</day>
<month>11</month>
<year iso-8601-date="2019">2019</year>
</date>
<date date-type="accepted" iso-8601-date="2020-06-11">
<day>11</day>
<month>6</month>
<year iso-8601-date="2020">2020</year>
</date>
</history>
<permissions>
<copyright-statement>©2020 Thanapattheerakul et al.</copyright-statement>
<copyright-year>2020</copyright-year>
<copyright-holder>Thanapattheerakul et al.</copyright-holder>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ) and either DOI or URL of the article must be cited.</license-p>
</license>
</permissions>
<self-uri xlink:href="https://peerj.com/articles/9470"></self-uri>
<abstract>
<p>Mutations that cause an error in the splicing of a messenger RNA (mRNA) can lead to diseases in humans. Various computational models have been developed to recognize the sequence pattern of the splice sites. In recent studies, Convolutional Neural Network (CNN) architectures were shown to outperform other existing models in predicting the splice sites. However, an insufficient effort has been put into extending the CNN model to predict the effect of the genomic variants on the splicing of mRNAs. This study proposes a framework to elaborate on the utility of CNNs to assess the effect of splice variants on the identification of potential disease-causing variants that disrupt the RNA splicing process. Five models, including three CNN-based and two non-CNN machine learning based, were trained and compared using two existing splice site datasets, Genome Wide Human splice sites (GWH) and a dataset provided at the Deep Learning and Artificial Intelligence winter school 2018 (DLAI). The donor sites were also used to test on the HSplice tool to evaluate the predictive models. To improve the effectiveness of predictive models, two datasets were combined. The CNN model with four convolutional layers showed the best splice site prediction performance with an AUPRC of 93.4% and 88.8% for donor and acceptor sites, respectively. The effects of variants on splicing were estimated by applying the best model on variant data from the ClinVar database. Based on the estimation, the framework could effectively differentiate pathogenic variants from the benign variants (<italic>p</italic> = 5.9 × 10<sup>−7</sup>). These promising results support that the proposed framework could be applied in future genetic studies to identify disease causing loci involving the splicing mechanism. The datasets and Python scripts used in this study are available on the GitHub repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/smiile8888/rna-splice-sites-recognition">https://github.com/smiile8888/rna-splice-sites-recognition</ext-link>.</p>
</abstract>
<kwd-group kwd-group-type="author">
<kwd>Splice site</kwd>
<kwd>Convolutional neural networks</kwd>
<kwd>Deep learning</kwd>
<kwd>RNA Splice Sites</kwd>
<kwd>Binding sites</kwd>
<kwd>Splicing events</kwd>
<kwd>Genomic variants</kwd>
</kwd-group>
<funding-group>
<award-group id="fund-1">
<funding-source>King Mongkut’s University of Technology Thonburi</funding-source>
</award-group>
<award-group id="fund-2">
<funding-source>Canada-ASEAN Scholarships and Educational Exchanges for Development (SEED)</funding-source>
</award-group>
<funding-statement>This work was supported by the Petchra Pra Jom Klao Master scholarship from King Mongkut’s University of Technology Thonburi, and the Canada-ASEAN Scholarships and Educational Exchanges for Development (SEED) funded by the Canadian Government. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
</article-meta>
</front>
<body>
<sec sec-type="intro">
<title>Introduction</title>
<p>RNA splicing, a process exclusive to eukaryotic cells, is a post-transcriptional modification of a protein-coding messenger RNA (mRNA). This process is carried out by a complex of small nuclear RNA (snRNA) and protein, known as a spliceosome, which binds to the splice site on a pre-mRNA to fold, clip and rejoin the pre-mRNA. The intronic sequence is then eliminated, and the remaining exonic sequences are joined. The whole process is referred to as RNA splicing (<xref ref-type="bibr" rid="ref-5">Faustino &amp; Cooper, 2003</xref>). A single pre-mRNA can be encoded to multiple proteins by a mechanism called alternative splicing, where the pre-mRNA is modified by incorporating different sets of the exons. This mechanism allows the eukaryotic genome to store more information economically but requires precise regulation. In humans, errors in splicing or mis-splicing have been shown to underlie many diseases, including heart disease, dementia, and autism spectrum disorder (ASD) (<xref ref-type="bibr" rid="ref-23">Scotti &amp; Swanson, 2016</xref>). Specifically, a mis-splicing of LDB3 regulated by RBM20 leads to the development of heart disease (<xref ref-type="bibr" rid="ref-33">Zhu et al., 2017</xref>; <xref ref-type="bibr" rid="ref-21">Rexiati, Sun &amp; Guo, 2018</xref>), and mutations in MAPT can cause an increase in the splicing of its exon that leads to frontotemporal dementia with Parkinsonism (<xref ref-type="bibr" rid="ref-3">Buée et al., 2000</xref>). More complex conditions like schizophrenia and autism spectrum disorder (ASD) have also been linked to mis-splicing caused by single nucleotide variations (SNVs) (<xref ref-type="bibr" rid="ref-20">Reble, Dineen &amp; Barr, 2018</xref>).</p>
<p>Many studies have used position-weight-matrix (PWM) to recognize the sequence pattern of DNA/RNA binding sites, including splice sites (<xref ref-type="bibr" rid="ref-27">Stormo, 2000</xref>). Knowing the sequence pattern and binding specificity makes it possible to assess the effect of SNVs on the binding affinity at the sequence level (<xref ref-type="bibr" rid="ref-4">Desmet et al., 2010</xref>). Although PWM is powerful and easy to interpret, it can capture only a simple sequence pattern; for more complex sequence patterns, a more advanced method is required. Over the past few years, whole genome sequencing data have been increasingly deposited in public databases due to the advances in sequencing technology and lowered costs (<xref ref-type="bibr" rid="ref-26">Stephens et al., 2015</xref>; <xref ref-type="bibr" rid="ref-13">Lek et al , 2016</xref>). The enormous amount of publicly available data has allowed more analytic methods to emerge, with some being improved versions of existing techniques and some being novelties.</p>
<p>Recently, machine learning (ML) and deep learning (DL) have been applied to solve problems in many fields with astonishing results, especially for applications in the computer vision field (<xref ref-type="bibr" rid="ref-11">LeCun, Bengio &amp; Hinton, 2015</xref>). It has also been adopted in biomedical research (<xref ref-type="bibr" rid="ref-29">Wainberg et al., 2018</xref>). Support Vector Machines (SVMs) and Random Forest (RF) are the most popular of traditional ML techniques. <xref ref-type="bibr" rid="ref-24">Sonnenburg et al. (2007)</xref> proposed the SVM with a weighted degree kernel to recognize splice sites. Various SVM- and RF-based tools, for example, HSplice (<xref ref-type="bibr" rid="ref-16">Meher et al., 2016</xref>) and MaLDoSS (<xref ref-type="bibr" rid="ref-15">Meher, Sahu &amp; Rao, 2016</xref>), have been made available in the public domain for the prediction of donor splice sites in many species, including <italic>Homo sapiens, Bos taurus, Danio rerio,</italic> and <italic>Caenorhabditis elegans.</italic> Convolutional neural networks (CNNs) have been leveraged to identify the sequence motifs of the binding sites in the human genome. DeepSEA and DeepBind are CNN-based algorithms designed to capture the sequence specificity of DNA/RNA binding proteins and assess the impact of SNVs on the binding sites (<xref ref-type="bibr" rid="ref-1">Alipanahi et al., 2015</xref>; <xref ref-type="bibr" rid="ref-32">Zhou &amp; Troyanskaya, 2015</xref>). SpliceRover, a CNN-based tool for splice site prediction, demonstrated improved performance compared to conventional SVMs (i.e., linear SVM and SVM with a weighted degree kernel) and the deep belief network (i.e., restricted Boltzmann machine (RBM)) on different splice site datasets (<xref ref-type="bibr" rid="ref-34">Zuallaert et al., 2018</xref>). Recurrent Neural Network (RNN) and its variants, such as Long Short-Term Memory (LSTM), have also been adopted to solve classification problems on DNA and RNA sequences. Quang and Xie proposed a hybrid convolutional and recurrent deep neural network to predict the transcription factor binding sites. They made use of a CNN to capture the features in the sequences, while a RNN learned the relationship among those features. Their comparison results with DeepSEA showed that using a hybrid model improves the performance by more than 50% over using CNN alone (<xref ref-type="bibr" rid="ref-19">Quang &amp; Xie, 2016</xref>).</p>
<p>Although deep learning techniques have shown superior performance over other methods, no framework has been built to extend the model to estimate the effect of genomic variants located near the splice sites. Therefore, a framework is proposed here to predict the effects of such variants on splicing events, in the hopes of identifying the variants causing disease through disruption of the splicing mechanism.</p>
<sec>
<title>Framework</title>
<p>The framework covers two parts: (1) training a model for splice site prediction; and (2) estimating the effect of variants on splicing. In particular, the pipeline used in this study involved the comparison of deep learning and traditional machine learning models to recognize sequence patterns of the splice sites on two datasets. Then the model with the best performance in distinguishing the actual splice sites from the negative sequences was used to estimate the effect of the point mutation on the splice site (referred here as ‘splice variant’ or ‘variant’). The overall workflow of this framework is shown in <xref ref-type="fig" rid="fig-1">Fig. 1</xref>.</p>
<p>The model preparation starts from data gathering and preprocessing, followed by modeling and validation of the model with unseen data. Data gathering and preprocessing are essential steps because the quality and quantity of the data directly affect the performance of the model. The preprocessing step involves the conversion of raw data into a compatible format as the input of the model. The model can be based on traditional machine learning algorithms, deep learning techniques, or other algorithms that give a probabilistic prediction. The probabilistic prediction is required to calculate a score for the splice variants.</p>
<fig id="fig-1" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.7717/peerj.9470/fig-1</object-id>
<label>Figure 1</label>
<caption>
<title>Overall workflow of the proposed variant scoring framework.</title>
</caption>
<graphic xlink:href="peerj-08-9470-g001"></graphic>
</fig>
<p>The second part is to estimate the effect of the splice variant by using the pre-trained model from the previous step. For each variant, a reference (major allele) and an alternative (minor allele) sequence of splice sites where the variant is located was obtained, then the model was applied on the obtained sequences to give a probability of being a splice site. If the variant affected the splice site in some way, it was inferred that the probabilistic prediction on the reference sequence was higher than the one with an alternative variant. The variants affecting the splice sites could result in mis-splicing and be disease-causing if an important gene is disrupted. A score for each pair of sequences was calculated by taking the difference between the probabilistic prediction of reference and alternative sequences.</p>
</sec>
</sec>
<sec sec-type="materials|methods">
<title>Materials &amp; Methods</title>
<sec>
<title>Dataset</title>
<p>As mentioned earlier, two datasets were used in this work. The first one is called Genome-Wide Human splice sites (GWH), which was obtained from a 2007 paper by <xref ref-type="bibr" rid="ref-24">Sonnenburg et al. (2007)</xref>. The splice site data were retrieved by processing the Expressed-Sequence Tags (ESTs) and cDNA data available in commonly used databases (<xref ref-type="bibr" rid="ref-24">Sonnenburg et al., 2007</xref>). The GWH data is an imbalanced case-control dataset where cases or positive sequences are confirmed sequences of being spliced sites, and controls or negative sequences are other sequences with spliced-site core dinucleotide at the center position of the sequences. For donor sites, there are 1,484,844 sequences of negative data, while 80,515 sequences are positive data. Similarly, 1,374,182 sequences of acceptor sites are negative data, while 79,250 sequences are positive data. Each sequence has a length of 398 nucleotides (nt) with core dinucleotides, GT for donor sites and AG for acceptor sites, in the middle of the sequence. Specifically, the dimer of donor sites is at the position of 201 and 202, while 198 and 199 are the position of the dimer in acceptor sites.</p>
<p>The second dataset is called DLAI. It was a dataset provided in the competition track of the First Deep Learning and Artificial Intelligence Winter School (DLAI1) (<ext-link ext-link-type="uri" xlink:href="https://deeplearningandaiwinterschool.github.io/dlai1.html">https://deeplearningandaiwinterschool.github.io/dlai1.html</ext-link>). The dataset was prepared by obtaining transcript data from the curated RefSeq database (hg19). Many of the splicing signals are found within ±50 nt window from the splice site based on the average absolute weighted contribution score (wcs) (<xref ref-type="bibr" rid="ref-34">Zuallaert et al., 2018</xref>); however, the majority is mainly within ±20 nt window of the splice sites. Thus, sequences of ±20 nt window from the splice site were extracted. This was done to reduce noise from extending the window for too far and also to speed up the training process. The negative sequences were defined as non-splice site sequences (40 nt) containing core dinucleotides. The negative donor sequences have a GT dimer at position 20 and 21, while the acceptor negative sequences have an AG dimer at position 19 and 20. Unlike the GWH dataset, this is a balanced dataset which contains 223,143 sequences of the donor, and 220,034 sequences of the acceptor. Even though the preparation of the two datasets was different, overlapping levels of positive sequences between the two were very high, as 74% of donor and 75% of acceptor sites of GWH data were found in the DLAI data. On the other hand, the negative sequences rarely overlapped between both datasets, as only 1% of donor and 2% of acceptor sites from the GWH data were found in the DLAI data.</p>
<p>The splice variant data was gathered from the ClinVar database. The ClinVar is a clinical variant database, which contains both copy number variations (CNVs) and single nucleotide variations (SNVs). All the variants were classified into different groups based on their pathogenicity level by manual validation and/or computational method following the American College of Medical Genetics and Genomics (ACMG) guidelines for Mendelian disorder variant interpretation (<xref ref-type="bibr" rid="ref-10">Landrum et al., 2014</xref>). The SNVs belonging to benign, likely benign, likely pathogenic, and pathogenic groups were obtained to validate the model in the second part of the framework. The pathogenic variants are genomic variants with evidence reported that they cause a disease. To evaluate the performance of the model, the splicing effect scores estimated by the model SNVs were compared between pathogenic (pathogenic + likely pathogenic; <italic>n</italic> = 801 and <italic>n</italic> = 356, for donor and acceptor, respectively) and benign (benign + likely benign; <italic>n</italic> = 11,200 and <italic>n</italic> = 10,944, for donor and acceptor, respectively) variants. Only variants located within 20 base pairs (bp) from splice sites were obtained along with their respective splice site sequences (40 bp of length with splice junction at the center of the sequence).</p>
</sec>
<sec>
<title>Methodology</title>
<p>This section describes a case study applied to the proposed framework, including the process of building predictive models and predicting the effect of splice variants.</p>
<sec>
<title>Data Preprocessing</title>
<p>The predictive models used in the study are based on deep learning and traditional machine learning techniques. The input of these models requires a numerical matrix representing pixels in a black and white or a grayscale image. Thus, the input sequences have to be transformed into a matrix format. A DNA sequence is a string composed of four letters: A, C, G, and T. These correspond to the vectors [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], and [0, 0, 0, 1], respectively. Therefore, each sequence is represented as a <italic>N</italic> × 4 matrix, where <italic>N</italic> is the length of the input DNA sequence, and 4 is the number of different nucleotides. <xref ref-type="fig" rid="fig-2">Figure 2</xref> illustrates an input DNA sequence and the corresponding matrix. This transformation technique is called one-hot encoding.</p>
<fig id="fig-2" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.7717/peerj.9470/fig-2</object-id>
<label>Figure 2</label>
<caption>
<title>DNA Sequence converted into a binary matrix.</title>
<p>(A) A DNA sequence transformed into a binary matrix. (B) The DNA sequence represented as an image.</p>
</caption>
<graphic xlink:href="peerj-08-9470-g002"></graphic>
</fig>
</sec>
<sec>
<title>Modeling</title>
<p>To recognize splice sites, any model that can give a probabilistic prediction can be applied. In this study, a comparison of deep learning, to traditional machine learning algorithms—convolutional neural networks (CNNs), and a hybrid CNN with LSTM, to support vector machine (SVM) and random forest (RF)—is provided.</p>
<p>The NNs are designed for representation of high-level abstraction in the data. Typically, NNs consist of an input layer, hidden layers, and an output layer, each consisting of a number of neurons or nodes. Each neuron is a processing unit with different parameters or weights. The input layer propagates the data through the network, yielding intermediate results using an activation function at each hidden layer. The output layer results in a final prediction. For more complex models, a nonlinear function, e.g., Rectified Linear Unit (ReLU) (<xref ref-type="bibr" rid="ref-17">Nair &amp; Hinton, 2010</xref>) and softmax, is applied to activate neurons in each layer so that they are able to represent a non linear relationship. Over the past few years, the ReLU has been applied to activate neurons in hidden layers. It is the simplest nonlinear activation function, which outputs 0 if the input is less than or equal 0, and outputs raw output, otherwise. In classification problems, softmax is commonly used as an activation function in the last layer to generate a probability of each class. In supervised learning, NNs learn from the annotated training data by adjusting the weights based on a loss function. The loss function represents the difference between the predictions from the network and the annotated labels. Besides traditional NNs, convolutional neural networks (CNNs) have been proposed and shown to outperform traditional NNs in image recognition, including classifying images, detecting objects, and recognizing faces. CNN is a variation of NNs that consists of at least one convolutional layer in the NNs. The convolutional layer has filters that slide over the sequence and detect patterns. Here, weights are stored within a filter to be shared over different positions. Typically, the convolutional layer is followed by a pooling layer, which helps to reduce dimensionality and map features independently. The most common approach used in the pooling layer is Max-pooling, which uses a maximum value representing the area of the specified filter. Overfitting is the main issue when NNs have many layers, resulting in high performance in training data but poor performance on unseen data. Neuron dropout is a common technique used to avoid the over-fitting issue by randomly deactivating some neurons from the network which helps to reduces independent learning among neurons (<xref ref-type="bibr" rid="ref-25">Srivastava et al., 2014</xref>).</p>
<p>Another variation of NNs is recurrent neural networks (RNNs). The RNN has an internal loop to maintain a cell state of extracted information. Instead of processing the whole sequence in a single step, it processes the sequence by iterating through the sequence elements and allowing information relative to what it has processed to persist. The information stored in the internal state allows the network to exhibit dynamic temporal or spatial behavior (<xref ref-type="bibr" rid="ref-22">Schuster &amp; Paliwal, 1997</xref>). Although the RNN should theoretically be able to relate previous information to the present extracted information, in practice, as the sequence grows, it becomes unable to learn to connect the information. Connections between past and present information are called “long-term dependencies.” Long Short-Term Memory networks (LSTMs) have been introduced to solve this problem (<xref ref-type="bibr" rid="ref-2">Bengio, Simard &amp; Frasconi, 1994</xref>; <xref ref-type="bibr" rid="ref-7">Hochreiter &amp; Schmidhuber, 1997</xref>). The LSTM is the variant of RNN that is capable of learning long-term dependencies. It is able to add or remove information to the internal cell states. The amounts of information to be added or removed are carefully regulated by structures called gates. A bi-directional LSTM is a variant of standard LSTM that combines two LSTMs, where each takes a sequence in a different direction; for example, in sequential data, one moves from left to right, and the other moves right to left.</p>
<p>Machine learning techniques like SVMs and RFs are known to be excellent for classification tasks. In the bioinformatics field, SVMs and RFs have been applied to predict splice sites. They both gave a promising performance as reported in papers by Sonnenburg, Lee and Yoon (<xref ref-type="bibr" rid="ref-24">Sonnenburg et al., 2007</xref>; <xref ref-type="bibr" rid="ref-12">Lee &amp; Yoon, 2015</xref>).</p>
<p>In this case study, five models were used: two CNN-based models, the CNN with bidirectional LSTM model, the SVM model, and the RF model, to distinguish the positive and negative sequences. The CNN-based models include the model for the sequence length of 40 nucleotides from SpliceRover (<xref ref-type="bibr" rid="ref-34">Zuallaert et al., 2018</xref>) and the other one from our preliminary study (<xref ref-type="bibr" rid="ref-28">Thanapattheerakul et al., 2018</xref>). These models are called CNN_3 and CNN_4 as the number represents the number of convolutional layers in the model. The hybrid CNN with bidirectional LSTM, the architecture of which was derived from DanQ (<xref ref-type="bibr" rid="ref-19">Quang &amp; Xie, 2016</xref>), is called CNN_LSTM. The bi-directional LSTM is integrated with a CNN at the last layer before being connected to the fully connected layer. All architectures and hyperparameters of CNN and CNN with LSTM models are shown in <xref ref-type="table" rid="table-1">Tables 1</xref> and <xref ref-type="table" rid="table-2">2</xref>, respectively. For SVM and RF, the recommended default hyperparameters were used.</p>
</sec>
<sec>
<title>Model Comparison</title>
<p>To evaluate the different models, 5-fold cross-validation was performed on the DLAI data. The DLAI was used because it is a balanced dataset containing the most up-to-date sequences. When comparing to the other datasets, it is the smallest one, but it was sufficient to train models, so the training time was reduced. The 5-fold cross-validation was done by the traditional cross-validation approach that resamples the data into five portions. In each iteration, four portions are used as a training data to fit the model, while the rest is used as a hold-out to evaluate the model. The model is then discarded and re-declared in the next iteration. As an additional comparison of the developed CNN models to the traditional machine learning approach, an existing web-based tool termed HSplice (<xref ref-type="bibr" rid="ref-16">Meher et al., 2016</xref>) was used. This tool is available for prediction of human donor splice sites only, and it is available at <ext-link ext-link-type="uri" xlink:href="http://cabgrid.res.in:8080/HSplice">http://cabgrid.res.in:8080/HSplice</ext-link>. Prior to using the HSplice tool, the donor sites needed to be shortened from 40 bp to 15 bp (−8 to +7 from splice junction). The output of the tool was the prediction probability of the given sequence being a splice site. For a direct comparison with this work, the prediction probability was used to calculate the area under precision and recall curve (AUPRC) and area under the receiver operating characteristic (AUROC). To obtain precision and recall, the same procedure was used to convert the probability of each sequence to a binary class output, using a threshold of 0.5; if the probability was greater than 0.5, it was classified as splice site, otherwise it was a nonsplice site.</p>
<table-wrap id="table-1" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.7717/peerj.9470/table-1</object-id>
<label>Table 1</label>
<caption>
<title>CNN-based architecture details.</title>
<p>The details of the architecture of CNN_3, CNN_4, and CNN_LSTM are described. Both CNN_3 and CNN_4 are CNN-based architecture, but they are different in the number of layers and the filter in each layer. The CNN_LSTM is a hybrid CNN with bi-directional LSTM.</p>
</caption>
<alternatives>
<graphic xlink:href="peerj-08-9470-g004"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col span="1"/>
<col span="1"/>
<col span="1"/>
</colgroup>
<thead>
<tr>
<th colspan="1" rowspan="1">
<bold>Name</bold>
</th>
<th align="center" colspan="2" rowspan="1">
<bold>Architectures</bold>
</th>
</tr>
<tr>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1">
<bold>Layers</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Details</bold>
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="1" rowspan="11">CNN_3</td>
<td colspan="1" rowspan="1">conv2D layer 1</td>
<td colspan="1" rowspan="1">70 filters of size (9,4)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dropout layer 1</td>
<td colspan="1" rowspan="1"><italic>p</italic> = 0.2</td>
</tr>
<tr>
<td colspan="1" rowspan="1">conv2D layer 2</td>
<td colspan="1" rowspan="1">100 filters of size (7,1)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">maxpool layer 1</td>
<td colspan="1" rowspan="1">pool size (2,1)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dropout layer 2</td>
<td colspan="1" rowspan="1"><italic>p</italic> = 0.2</td>
</tr>
<tr>
<td colspan="1" rowspan="1">conv2D layer 3</td>
<td colspan="1" rowspan="1">150 filters of size (7,1)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">maxpool layer 2</td>
<td colspan="1" rowspan="1">pool size (2,1)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dropout layer 3</td>
<td colspan="1" rowspan="1"><italic>p</italic> = 0.2</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dense layer 1</td>
<td colspan="1" rowspan="1">512 neurons</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dropout layer 4</td>
<td colspan="1" rowspan="1"><italic>p</italic> = 0.2</td>
</tr>
<tr>
<td colspan="1" rowspan="1">softmax layer</td>
<td colspan="1" rowspan="1">2 outputs</td>
</tr>
<tr>
<td colspan="1" rowspan="13">CNN_4</td>
<td colspan="1" rowspan="1">conv2D layer 1</td>
<td colspan="1" rowspan="1">70 filters of size (3,4)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dropout layer 1</td>
<td colspan="1" rowspan="1"><italic>p</italic> = 0.2</td>
</tr>
<tr>
<td colspan="1" rowspan="1">conv2D layer 2</td>
<td colspan="1" rowspan="1">100 filters of size (3,1)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dropout layer 2</td>
<td colspan="1" rowspan="1"><italic>p</italic> = 0.2</td>
</tr>
<tr>
<td colspan="1" rowspan="1">conv2D layer 3</td>
<td colspan="1" rowspan="1">100 filters of size (3,1)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">maxpool layer 1</td>
<td colspan="1" rowspan="1">pool size (2,1)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dropout layer 3</td>
<td colspan="1" rowspan="1"><italic>p</italic> = 0.2</td>
</tr>
<tr>
<td colspan="1" rowspan="1">conv2D layer 4</td>
<td colspan="1" rowspan="1">200 filters of size (3,1)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">maxpool layer 2</td>
<td colspan="1" rowspan="1">pool size (2,1)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dropout layer 4</td>
<td colspan="1" rowspan="1"><italic>p</italic> = 0.2</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dense layer 1</td>
<td colspan="1" rowspan="1">512 neurons</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dropout layer 5</td>
<td colspan="1" rowspan="1"><italic>p</italic> = 0.2</td>
</tr>
<tr>
<td colspan="1" rowspan="1">softmax layer</td>
<td colspan="1" rowspan="1">2 outputs</td>
</tr>
<tr>
<td colspan="1" rowspan="7">CNN_LSTM</td>
<td colspan="1" rowspan="1">conv1D layer 1</td>
<td colspan="1" rowspan="1">320 filters of length 26</td>
</tr>
<tr>
<td colspan="1" rowspan="1">maxpool layer 1</td>
<td colspan="1" rowspan="1">pool size (13)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dropout layer 1</td>
<td colspan="1" rowspan="1"><italic>p</italic> = 0.2</td>
</tr>
<tr>
<td colspan="1" rowspan="1">bidirectional LSTM layer 1</td>
<td colspan="1" rowspan="1">320 output dimension</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dropout layer 2</td>
<td colspan="1" rowspan="1"><italic>p</italic> = 0.5</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Dense layer 1</td>
<td colspan="1" rowspan="1">925 neurons</td>
</tr>
<tr>
<td colspan="1" rowspan="1">softmax layer</td>
<td colspan="1" rowspan="1">2 outputs</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec>
<title>Testing effect of imbalanced data</title>
<p>To maximize statistical power, the two datasets, GWH and DLAI, were combined to increase the number of positive and negative sequences. The sequences from GWH were trimmed down from 398 nt to 40 nt to match with the ones from DLAI. Although the combined dataset was much more comprehensive, it became imbalanced. For donor sites, there were 230,208 positive sequences and 1,669,934 negative sequences. For acceptor sites, there were 226,436 positive sequences and 1,558,077 negative sequences. The combined dataset was used to test the effect of imbalanced data in order to utilize the model performance. Since the positive data is in the minority, 80% of the positive data was randomly selected. Also, subsets of negative data were then picked to construct different datasets where the ratio of positive to negative data was restricted at 1:1, 1:3, 1:5, and 1:7. The CNN_3 and CNN_4 models were then validated by performing 5-fold cross-validation using these subsets of positive and negative sequences. Furthermore, after training on the different subsets, each model was tested on the remaining 20% of positive data and the rest of the negative data. As an additional comparison, 20% of the donor site test set was randomly selected to test on the CNN models and HSplice tool.</p>
<table-wrap id="table-2" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.7717/peerj.9470/table-2</object-id>
<label>Table 2</label>
<caption>
<title>CNN-based hyperparameter details.</title>
<p>The hyperparameters set applied for CNN_3, CNN_4, and CNN_LSTM.</p>
</caption>
<alternatives>
<graphic xlink:href="peerj-08-9470-g005"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
</colgroup>
<thead>
<tr>
<th colspan="1" rowspan="1">
<bold>Optimizer</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Loss function</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Epoch</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Batch size</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Start learning rate</bold>
</th>
<th colspan="1" rowspan="1">
<bold># Steps per learning rate decay</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Learning rate decay scheduling</bold>
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="1" rowspan="1">SGD with Nesterov momentum 0.9</td>
<td colspan="1" rowspan="1">Categorical cross-entropy</td>
<td colspan="1" rowspan="1">30</td>
<td colspan="1" rowspan="1">64</td>
<td colspan="1" rowspan="1">0.05</td>
<td colspan="1" rowspan="1">5</td>
<td colspan="1" rowspan="1">Yes</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec>
<title>Testing effect of window sizes</title>
<p>Another factor that could affect the model performance is window size or input sequence length. To compare the effect of window size, the CNN_4 model was performed on the GWH dataset with five different sequence lengths: 40 nt, 80 nt, 160 nt, 240 nt, and 398 nt. The subset of the GWH dataset with a 1:7 ratio of positive to negative sequencing from the previous step was used in 5-fold cross-validation.</p>
</sec>
<sec>
<title>Predicting variant effect</title>
<p>To predict the effects of variants, the CNN_4 model was used on the combined dataset with a 1:7 ratio of positive to negative sequences. This dataset was used since it contains the most up-to-date data (DLAI dataset) and a bigger negative set. This model was tested on the splice variants from the ClinVar database. The effects of variants on splicing were estimated by making a probabilistic prediction of whether splicing would occur on the sequence with the presence and the absence of an alternative allele. Then, the variant was scored by taking the difference between the two predictions using the formula below as suggested by a previous study of the effect of variants on transcription factor binding site (<xref ref-type="bibr" rid="ref-32">Zhou &amp; Troyanskaya, 2015</xref>): <disp-formula id="NONUM-d2e542"><alternatives><graphic mime-subtype="png" mimetype="image" orientation="portrait" position="float" xlink:href="peerj-08-9470-e001.jpg"></graphic><tex-math id="M1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{eqnarray*}Score \left( {m}_{i} \right) =\log \nolimits 10( \frac{PM \left( ref \right) }{PM \left( alt \right) } ) \end{eqnarray*}\end{document}</tex-math><mml:math id="mml-NONUM-d2e542"><mml:mstyle displaystyle="true"><mml:mi>S</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo class="qopname"> log</mml:mo><mml:mn>10</mml:mn><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mi>M</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>M</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac></mml:mfenced></mml:mrow></mml:mstyle></mml:math></alternatives></disp-formula>
</p>
<p>where <italic>Score</italic>(<italic>m</italic><sub><italic>i</italic></sub>) is a score of variant or mutation, <italic>PM</italic>(<italic>ref</italic>) is a probability of a reference sequence being a splice site (<italic>reference sequence:</italic> sequence with the absence of an alternative allele), and <italic>PM</italic>(<italic>alt</italic>) is the probability of an alternative sequence being a splice site (<italic>alternative sequence:</italic> sequence with the presence of an alternative allele).</p>
<p>The splice variant effect prediction was obtained from the dbscSNV database, used to compare with the prediction from the proposed method. The dbscSNV is a comprehensive database that stores splicing effect score (ada_score) of human SNVs located in the splicing regions, i.e., 3 to +8 from donor sites and −12 to +2 from acceptor sites (<xref ref-type="bibr" rid="ref-9">Jian, Boerwinkle &amp; Liu, 2014</xref>). The ada_score is a prediction score (in the range of 0 to 1) of variants causing splicing disruption and leading to disease computed using AdaBoost model (<xref ref-type="bibr" rid="ref-9">Jian, Boerwinkle &amp; Liu, 2014</xref>). It was compared to the score predicted by the proposed method based on how well they distinguished benign and pathogenic variants.</p>
</sec>
</sec>
<sec>
<title>Computational setup</title>
<p>All experiments of CNN- and RF-based models were conducted on Google Colaboratory (<ext-link ext-link-type="uri" xlink:href="https://colab.research.google.com/">https://colab.research.google.com/</ext-link>). The backend was run with Python 3 and a GPU hardware accelerator. Due to the time limitation (12 h per session for the freely available resource) on Google Colaboratory, the SVM-based model was run on a local laptop without GPU (Intel Core i5-3230M CPU @ 2.60 GHz, x64-based Windows OS, 8 GB of RAM, 256 GB SSD). Pandas (<xref ref-type="bibr" rid="ref-14">McKinney, 2010</xref>) and NumPy (<xref ref-type="bibr" rid="ref-18">Oliphant, 2006</xref>; <xref ref-type="bibr" rid="ref-30">VanDer Walt, Colbert &amp; Varoquaux, 2011</xref>) were used in the processes of data preparation and representation. The ggplot2 R package (<xref ref-type="bibr" rid="ref-31">Wickham, 2009</xref>) and matplotlib (<xref ref-type="bibr" rid="ref-8">Hunter, 2007</xref>) were used for data and result visualization, including graphic generation. Keras (<ext-link ext-link-type="uri" xlink:href="https://keras.io/">https://keras.io/</ext-link>) with TensorFlow was used for model construction, training and testing.</p>
</sec>
</sec>
<sec sec-type="results">
<title>Results</title>
<sec>
<title>Comparison between deep learning and traditional machine learning approaches</title>
<p>The first set of results is a comparison between CNNs, CNN_LSTM, SVM, and RF in splice site prediction performance assessed by 5-fold cross-validation on the DLAI dataset only, which is a balanced dataset. Moreover, for donor sites, HSplice, a donor site prediction tool, was used as a benchmark in the comparison. Here, several evaluation metrics are reported, including precision, recall, AUPRC, and AUROC. <xref ref-type="table" rid="table-3">Table 3</xref> shows the performance on the 5-fold cross-validation and the average training time, which was also obtained from 5-fold cross-validation of all models. The CNN-based models performed significantly better than SVM and RF models regarding the AUPRC (One-sided Welch’s <italic>t</italic>-test <italic>p</italic> = 6 ×10<sup>−12</sup> and <italic>p</italic> = 4. 8 ×10<sup>−15</sup>, for SVM and RF, respectively). Among the CNN-based models, CNN_3 and CNN_4 outperformed the CNN_LSTM (One-sided Welch’s <italic>t</italic>-test <italic>p</italic> = 1. 4 ×10<sup>−5</sup>), while no significant difference in performance between the CNN_3 and CNN_4 models was found (One-sided Welch’s <italic>t</italic>-test <italic>p</italic> = 0.54). Besides the superior performance, the training times of CNN_3 and CNN_4 (average runtime was 12 min per fold) were also faster than CNN_LSTM (average runtime was 25 min per fold). Therefore, only CNN_3 and CNN_4 were applied for further analysis.</p>
<table-wrap id="table-3" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.7717/peerj.9470/table-3</object-id>
<label>Table 3</label>
<caption>
<title>The performance of five predictive models.</title>
<p>The average AUPRC, precision, recall, AUROC, and the average training time of the five predictive models from 5-fold cross-validation are described. For the donor sites, the HSplice tool was used as a benchmark.</p>
</caption>
<alternatives>
<graphic xlink:href="peerj-08-9470-g006"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
</colgroup>
<thead>
<tr>
<th colspan="1" rowspan="1">
<bold>Site</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Model</bold>
</th>
<th align="center" colspan="2" rowspan="1">
<bold>AUPRC</bold>
</th>
<th align="center" colspan="2" rowspan="1">
<bold>Precision</bold>
</th>
<th align="center" colspan="2" rowspan="1">
<bold>Recall</bold>
</th>
<th align="center" colspan="2" rowspan="1">
<bold>AUROC</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Runtime</bold>
<bold>(Colab)</bold>
</th>
</tr>
<tr>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1">
<bold>mean</bold>
</th>
<th colspan="1" rowspan="1">
<bold>SD</bold>
</th>
<th colspan="1" rowspan="1">
<bold>mean</bold>
</th>
<th colspan="1" rowspan="1">
<bold>SD</bold>
</th>
<th colspan="1" rowspan="1">
<bold>mean</bold>
</th>
<th colspan="1" rowspan="1">
<bold>SD</bold>
</th>
<th colspan="1" rowspan="1">
<bold>mean</bold>
</th>
<th colspan="1" rowspan="1">
<bold>SD</bold>
</th>
<th colspan="1" rowspan="1"></th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="1" rowspan="6">Donor</td>
<td colspan="1" rowspan="1">CNN_3</td>
<td colspan="1" rowspan="1">
<bold>0.986</bold>
</td>
<td colspan="1" rowspan="1">0.0005</td>
<td colspan="1" rowspan="1">0.936</td>
<td colspan="1" rowspan="1">0.0013</td>
<td colspan="1" rowspan="1">0.979</td>
<td colspan="1" rowspan="1">0.0009</td>
<td colspan="1" rowspan="1">
<bold>0.989</bold>
</td>
<td colspan="1" rowspan="1">0.0003</td>
<td colspan="1" rowspan="1">12 m</td>
</tr>
<tr>
<td colspan="1" rowspan="1">CNN_4</td>
<td colspan="1" rowspan="1">
<bold>0.986</bold>
</td>
<td colspan="1" rowspan="1">0.0002</td>
<td colspan="1" rowspan="1">0.930</td>
<td colspan="1" rowspan="1">0.0015</td>
<td colspan="1" rowspan="1">
<bold>0.982</bold>
</td>
<td colspan="1" rowspan="1">0.0010</td>
<td colspan="1" rowspan="1">
<bold>0.989</bold>
</td>
<td colspan="1" rowspan="1">0.0001</td>
<td colspan="1" rowspan="1">12 m</td>
</tr>
<tr>
<td colspan="1" rowspan="1">CNN_LSTM</td>
<td colspan="1" rowspan="1">0.983</td>
<td colspan="1" rowspan="1">0.0004</td>
<td colspan="1" rowspan="1">0.932</td>
<td colspan="1" rowspan="1">0.0003</td>
<td colspan="1" rowspan="1">0.975</td>
<td colspan="1" rowspan="1">0.0013</td>
<td colspan="1" rowspan="1">0.986</td>
<td colspan="1" rowspan="1">0.0002</td>
<td colspan="1" rowspan="1">25 m</td>
</tr>
<tr>
<td colspan="1" rowspan="1">SVM</td>
<td colspan="1" rowspan="1">0.923</td>
<td colspan="1" rowspan="1">0.0007</td>
<td colspan="1" rowspan="1">0.937</td>
<td colspan="1" rowspan="1">0.0007</td>
<td colspan="1" rowspan="1">0.968</td>
<td colspan="1" rowspan="1">0.0012</td>
<td colspan="1" rowspan="1">0.952</td>
<td colspan="1" rowspan="1">0.0006</td>
<td colspan="1" rowspan="1">2 hr<xref ref-type="fn" rid="table-3fn1"><sup>a</sup></xref></td>
</tr>
<tr>
<td colspan="1" rowspan="1">RF</td>
<td colspan="1" rowspan="1">0.913</td>
<td colspan="1" rowspan="1">0.0004</td>
<td colspan="1" rowspan="1">
<bold>0.939</bold>
</td>
<td colspan="1" rowspan="1">0.0006</td>
<td colspan="1" rowspan="1">0.942</td>
<td colspan="1" rowspan="1">0.0007</td>
<td colspan="1" rowspan="1">0.940</td>
<td colspan="1" rowspan="1">0.0002</td>
<td colspan="1" rowspan="1">11 s</td>
</tr>
<tr>
<td colspan="1" rowspan="1">HSplice</td>
<td align="center" colspan="2" rowspan="1">0.968</td>
<td align="center" colspan="2" rowspan="1">0.928</td>
<td align="center" colspan="2" rowspan="1">0.936</td>
<td align="center" colspan="2" rowspan="1">0.975</td>
<td colspan="1" rowspan="1">N/A</td>
</tr>
<tr>
<td colspan="1" rowspan="5">Acceptor</td>
<td colspan="1" rowspan="1">CNN_3</td>
<td colspan="1" rowspan="1">
<bold>0.979</bold>
</td>
<td colspan="1" rowspan="1">0.0003</td>
<td colspan="1" rowspan="1">0.910</td>
<td colspan="1" rowspan="1">0.0028</td>
<td colspan="1" rowspan="1">0.968</td>
<td colspan="1" rowspan="1">0.0027</td>
<td colspan="1" rowspan="1">
<bold>0.982</bold>
</td>
<td colspan="1" rowspan="1">0.0004</td>
<td colspan="1" rowspan="1">12 m</td>
</tr>
<tr>
<td colspan="1" rowspan="1">CNN_4</td>
<td colspan="1" rowspan="1">
<bold>0.979</bold>
</td>
<td colspan="1" rowspan="1">0.0008</td>
<td colspan="1" rowspan="1">0.905</td>
<td colspan="1" rowspan="1">0.0030</td>
<td colspan="1" rowspan="1">
<bold>0.973</bold>
</td>
<td colspan="1" rowspan="1">0.0012</td>
<td colspan="1" rowspan="1">
<bold>0.982</bold>
</td>
<td colspan="1" rowspan="1">0.0006</td>
<td colspan="1" rowspan="1">12 m</td>
</tr>
<tr>
<td colspan="1" rowspan="1">CNN_LSTM</td>
<td colspan="1" rowspan="1">0.975</td>
<td colspan="1" rowspan="1">0.0008</td>
<td colspan="1" rowspan="1">0.914</td>
<td colspan="1" rowspan="1">0.0020</td>
<td colspan="1" rowspan="1">0.960</td>
<td colspan="1" rowspan="1">0.0013</td>
<td colspan="1" rowspan="1">0.979</td>
<td colspan="1" rowspan="1">0.0006</td>
<td colspan="1" rowspan="1">25 m</td>
</tr>
<tr>
<td colspan="1" rowspan="1">SVM</td>
<td colspan="1" rowspan="1">0.893</td>
<td colspan="1" rowspan="1">0.0017</td>
<td colspan="1" rowspan="1">
<bold>0.915</bold>
</td>
<td colspan="1" rowspan="1">0.0018</td>
<td colspan="1" rowspan="1">0.948</td>
<td colspan="1" rowspan="1">0.0013</td>
<td colspan="1" rowspan="1">0.930</td>
<td colspan="1" rowspan="1">0.0013</td>
<td colspan="1" rowspan="1">2.30 hr<xref ref-type="fn" rid="table-3fn1"><sup>a</sup></xref></td>
</tr>
<tr>
<td colspan="1" rowspan="1">RF</td>
<td colspan="1" rowspan="1">0.866</td>
<td colspan="1" rowspan="1">0.0009</td>
<td colspan="1" rowspan="1">0.910</td>
<td colspan="1" rowspan="1">0.0011</td>
<td colspan="1" rowspan="1">0.893</td>
<td colspan="1" rowspan="1">0.0020</td>
<td colspan="1" rowspan="1">0.902</td>
<td colspan="1" rowspan="1">0.0010</td>
<td colspan="1" rowspan="1">11 s</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="table-3fn">
<p>
<bold>Notes.</bold>
</p>
</fn>
<fn id="table-3fn1">
<label>a</label>
<p>The SVM-based model was run on a local laptop without GPU (Intel Core i5-3230M CPU 2.60 GHz, x64-based Windows OS, 8 GB of RAM, 256 GB SSD).</p>
</fn>
<fn id="table-3fn2">
<p>Bold styling emphasizes the highest values regarding the evaluation metrics used in the study.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec>
<title>Effect of imbalanced data</title>
<p>According to the results shown in <xref ref-type="table" rid="table-4">Table 4</xref>, the performance tends to decrease when the ratio of positive to negative data is increased. As shown, the models trained on the 1:1 gave the highest evaluation metrics, while the models trained on 1:7 gave the lowest in both donor and acceptor sites. However, the results shown in <xref ref-type="table" rid="table-5">Table 5</xref> suggest that using balanced data (1:1) for training resulted in over-fitting of the positive data where the model failed to classify negative data in the testing step. It can be concluded that validating the models on the balanced data may result in an overestimation of the performance. Between the two CNN-based models, the CNN_4 outperformed CNN_3, in both donor and acceptor sites, based on the highest AUPRC in the testing step. Recall, precision, and Matthews Correlation Coefficient (MCC) were used as tiebreakers. In addition, the comparison between CNN models and the existing HSplice tool was reported in <xref ref-type="table" rid="table-6">Table 6</xref>.</p>
<table-wrap id="table-4" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.7717/peerj.9470/table-4</object-id>
<label>Table 4</label>
<caption>
<title>The performance of CNN_3 and CNN_4 on the combined dataset.</title>
<p>The training performance on the combined dataset with different ratios collected from 5-fold cross-validation are described.</p>
</caption>
<alternatives>
<graphic xlink:href="peerj-08-9470-g007"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
</colgroup>
<thead>
<tr>
<th colspan="1" rowspan="1">
<bold>Site</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Ratio</bold>
</th>
<th align="center" colspan="8" rowspan="1">
<bold>Model</bold>
</th>
</tr>
<tr>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1"></th>
<th align="center" colspan="4" rowspan="1">
<bold>CNN_3</bold>
</th>
<th align="center" colspan="4" rowspan="1">
<bold>CNN_4</bold>
</th>
</tr>
<tr>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1">
<bold>AUPRC</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Precision</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Recall</bold>
</th>
<th colspan="1" rowspan="1">
<bold>MCC</bold>
</th>
<th colspan="1" rowspan="1">
<bold>AUPRC</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Precision</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Recall</bold>
</th>
<th colspan="1" rowspan="1">
<bold>MCC</bold>
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="1" rowspan="4">Donor</td>
<td colspan="1" rowspan="1">1:1</td>
<td colspan="1" rowspan="1">
<bold>0.987</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.944</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.969</bold>
</td>
<td colspan="1" rowspan="1">0.841</td>
<td colspan="1" rowspan="1">
<bold>0.988</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.940</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.973</bold>
</td>
<td colspan="1" rowspan="1">0.846</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1:3</td>
<td colspan="1" rowspan="1">0.969</td>
<td colspan="1" rowspan="1">0.911</td>
<td colspan="1" rowspan="1">0.939</td>
<td colspan="1" rowspan="1">
<bold>0.899</bold>
</td>
<td colspan="1" rowspan="1">0.970</td>
<td colspan="1" rowspan="1">0.900</td>
<td colspan="1" rowspan="1">0.949</td>
<td colspan="1" rowspan="1">
<bold>0.898</bold>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1:5</td>
<td colspan="1" rowspan="1">0.954</td>
<td colspan="1" rowspan="1">0.892</td>
<td colspan="1" rowspan="1">0.912</td>
<td colspan="1" rowspan="1">0.882</td>
<td colspan="1" rowspan="1">0.954</td>
<td colspan="1" rowspan="1">0.875</td>
<td colspan="1" rowspan="1">0.931</td>
<td colspan="1" rowspan="1">0.882</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1:7</td>
<td colspan="1" rowspan="1">0.940</td>
<td colspan="1" rowspan="1">0.878</td>
<td colspan="1" rowspan="1">0.886</td>
<td colspan="1" rowspan="1">0.865</td>
<td colspan="1" rowspan="1">0.940</td>
<td colspan="1" rowspan="1">0.854</td>
<td colspan="1" rowspan="1">0.915</td>
<td colspan="1" rowspan="1">0.866</td>
</tr>
<tr>
<td colspan="1" rowspan="4">Acceptor</td>
<td colspan="1" rowspan="1">1:1</td>
<td colspan="1" rowspan="1">
<bold>0.972</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.902</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.949</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.846</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.973</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.898</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.954</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.847</bold>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1:3</td>
<td colspan="1" rowspan="1">0.933</td>
<td colspan="1" rowspan="1">0.850</td>
<td colspan="1" rowspan="1">0.894</td>
<td colspan="1" rowspan="1">0.827</td>
<td colspan="1" rowspan="1">0.935</td>
<td colspan="1" rowspan="1">0.839</td>
<td colspan="1" rowspan="1">0.907</td>
<td colspan="1" rowspan="1">0.828</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1:5</td>
<td colspan="1" rowspan="1">0.903</td>
<td colspan="1" rowspan="1">0.820</td>
<td colspan="1" rowspan="1">0.851</td>
<td colspan="1" rowspan="1">0.802</td>
<td colspan="1" rowspan="1">0.904</td>
<td colspan="1" rowspan="1">0.806</td>
<td colspan="1" rowspan="1">0.870</td>
<td colspan="1" rowspan="1">0.806</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1:7</td>
<td colspan="1" rowspan="1">0.877</td>
<td colspan="1" rowspan="1">0.804</td>
<td colspan="1" rowspan="1">0.811</td>
<td colspan="1" rowspan="1">0.780</td>
<td colspan="1" rowspan="1">0.878</td>
<td colspan="1" rowspan="1">0.788</td>
<td colspan="1" rowspan="1">0.835</td>
<td colspan="1" rowspan="1">0.783</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="table-4fn">
<p>
<bold>Notes.</bold>
</p>
</fn>
<fn id="table-4fn1">
<p>Bold styling emphasizes the highest values regarding the evaluation metrics used in the study.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table-5" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.7717/peerj.9470/table-5</object-id>
<label>Table 5</label>
<caption>
<title>The testing results of CNN_3 and CNN_4 performed on the combined dataset.</title>
<p>The testing results performed on the hold-out data.</p>
</caption>
<alternatives>
<graphic xlink:href="peerj-08-9470-g008"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
</colgroup>
<thead>
<tr>
<th colspan="1" rowspan="1">
<bold>Site</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Ratio</bold>
</th>
<th align="center" colspan="8" rowspan="1">
<bold>Model</bold>
</th>
</tr>
<tr>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1"></th>
<th align="center" colspan="4" rowspan="1">
<bold>CNN_3</bold>
</th>
<th align="center" colspan="4" rowspan="1">
<bold>CNN_4</bold>
</th>
</tr>
<tr>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1">
<bold>AUPRC</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Precision</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Recall</bold>
</th>
<th colspan="1" rowspan="1">
<bold>MCC</bold>
</th>
<th colspan="1" rowspan="1">
<bold>AUPRC</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Precision</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Recall</bold>
</th>
<th colspan="1" rowspan="1">
<bold>MCC</bold>
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="1" rowspan="4">Donor</td>
<td colspan="1" rowspan="1">1:1</td>
<td colspan="1" rowspan="1">0.801</td>
<td colspan="1" rowspan="1">0.394</td>
<td colspan="1" rowspan="1">
<bold>0.963</bold>
</td>
<td colspan="1" rowspan="1">0.600</td>
<td colspan="1" rowspan="1">0.802</td>
<td colspan="1" rowspan="1">0.387</td>
<td colspan="1" rowspan="1">
<bold>0.964</bold>
</td>
<td colspan="1" rowspan="1">0.595</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1:3</td>
<td colspan="1" rowspan="1">0.847</td>
<td colspan="1" rowspan="1">0.619</td>
<td colspan="1" rowspan="1">0.917</td>
<td colspan="1" rowspan="1">0.741</td>
<td colspan="1" rowspan="1">0.848</td>
<td colspan="1" rowspan="1">0.566</td>
<td colspan="1" rowspan="1">0.940</td>
<td colspan="1" rowspan="1">0.716</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1:5</td>
<td colspan="1" rowspan="1">0.887</td>
<td colspan="1" rowspan="1">0.758</td>
<td colspan="1" rowspan="1">0.885</td>
<td colspan="1" rowspan="1">0.807</td>
<td colspan="1" rowspan="1">0.887</td>
<td colspan="1" rowspan="1">0.705</td>
<td colspan="1" rowspan="1">0.921</td>
<td colspan="1" rowspan="1">0.792</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1:7</td>
<td colspan="1" rowspan="1">
<bold>0.934</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.888</bold>
</td>
<td colspan="1" rowspan="1">0.850</td>
<td colspan="1" rowspan="1">
<bold>0.854</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.934</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.852</bold>
</td>
<td colspan="1" rowspan="1">0.901</td>
<td colspan="1" rowspan="1">
<bold>0.860</bold>
</td>
</tr>
<tr>
<td colspan="1" rowspan="4">Acceptor</td>
<td colspan="1" rowspan="1">1:1</td>
<td colspan="1" rowspan="1">0.674</td>
<td colspan="1" rowspan="1">0.277</td>
<td colspan="1" rowspan="1">
<bold>0.933</bold>
</td>
<td colspan="1" rowspan="1">0.487</td>
<td colspan="1" rowspan="1">0.679</td>
<td colspan="1" rowspan="1">0.266</td>
<td colspan="1" rowspan="1">
<bold>0.941</bold>
</td>
<td colspan="1" rowspan="1">0.475</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1:3</td>
<td colspan="1" rowspan="1">0.734</td>
<td colspan="1" rowspan="1">0.475</td>
<td colspan="1" rowspan="1">0.871</td>
<td colspan="1" rowspan="1">0.623</td>
<td colspan="1" rowspan="1">0.738</td>
<td colspan="1" rowspan="1">0.463</td>
<td colspan="1" rowspan="1">0.881</td>
<td colspan="1" rowspan="1">0.618</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1:5</td>
<td colspan="1" rowspan="1">0.801</td>
<td colspan="1" rowspan="1">0.675</td>
<td colspan="1" rowspan="1">0.804</td>
<td colspan="1" rowspan="1">0.717</td>
<td colspan="1" rowspan="1">0.802</td>
<td colspan="1" rowspan="1">0.631</td>
<td colspan="1" rowspan="1">0.845</td>
<td colspan="1" rowspan="1">0.709</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1:7</td>
<td colspan="1" rowspan="1">
<bold>0.886</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.850</bold>
</td>
<td colspan="1" rowspan="1">0.761</td>
<td colspan="1" rowspan="1">
<bold>0.776</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.888</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.828</bold>
</td>
<td colspan="1" rowspan="1">0.805</td>
<td colspan="1" rowspan="1">
<bold>0.788</bold>
</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="table-5fn">
<p>
<bold>Notes.</bold>
</p>
</fn>
<fn id="table-5fn1">
<p>Bold styling emphasizes the highest values regarding the evaluation metrics used in the study.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="table-6" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.7717/peerj.9470/table-6</object-id>
<label>Table 6</label>
<caption>
<title>The testing results of CNN_3, CNN_4, and HSplice performed on the donor sites of the combined dataset.</title>
<p>The testing results performed on 20% of each hold-out set of the donor sites.</p>
</caption>
<alternatives>
<graphic xlink:href="peerj-08-9470-g009"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
</colgroup>
<thead>
<tr>
<th colspan="1" rowspan="1">
<bold>Site</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Evaluation Metrics</bold>
</th>
<th colspan="1" rowspan="2" valign="top">
<bold>Model</bold>
</th>
<th align="center" colspan="4" rowspan="1">
<bold>Ratio</bold>
</th>
</tr>
<tr>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1">
<bold>1:1</bold>
</th>
<th colspan="1" rowspan="1">
<bold>1:3</bold>
</th>
<th colspan="1" rowspan="1">
<bold>1:5</bold>
</th>
<th colspan="1" rowspan="1">
<bold>1:7</bold>
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="1" rowspan="12">Donor</td>
<td colspan="1" rowspan="3">
<bold>AUPRC</bold>
</td>
<td colspan="1" rowspan="1">CNN_3</td>
<td colspan="1" rowspan="1">0.795</td>
<td colspan="1" rowspan="1">0.846</td>
<td colspan="1" rowspan="1">0.891</td>
<td colspan="1" rowspan="1">
<bold>
<italic>0.935</italic>
</bold>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">CNN_4</td>
<td colspan="1" rowspan="1">
<bold>0.798</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.847</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.892</bold>
</td>
<td colspan="1" rowspan="1">0.934</td>
</tr>
<tr>
<td colspan="1" rowspan="1">HSplice</td>
<td colspan="1" rowspan="1">0.551</td>
<td colspan="1" rowspan="1">0.527</td>
<td colspan="1" rowspan="1">0.686</td>
<td colspan="1" rowspan="1">0.594</td>
</tr>
<tr>
<td colspan="1" rowspan="3">
<bold>Precision</bold>
</td>
<td colspan="1" rowspan="1">CNN_3</td>
<td colspan="1" rowspan="1">
<bold>0.394</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.615</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.760</bold>
</td>
<td colspan="1" rowspan="1">
<bold>
<italic>0.889</italic>
</bold>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">CNN_4</td>
<td colspan="1" rowspan="1">0.387</td>
<td colspan="1" rowspan="1">0.561</td>
<td colspan="1" rowspan="1">0.708</td>
<td colspan="1" rowspan="1">0.850</td>
</tr>
<tr>
<td colspan="1" rowspan="1">HSplice</td>
<td colspan="1" rowspan="1">0.290</td>
<td colspan="1" rowspan="1">0.327</td>
<td colspan="1" rowspan="1">0.443</td>
<td colspan="1" rowspan="1">0.539</td>
</tr>
<tr>
<td colspan="1" rowspan="3">
<bold>Recall</bold>
</td>
<td colspan="1" rowspan="1">CNN_3</td>
<td colspan="1" rowspan="1">0.960</td>
<td colspan="1" rowspan="1">0.919</td>
<td colspan="1" rowspan="1">0.888</td>
<td colspan="1" rowspan="1">0.854</td>
</tr>
<tr>
<td colspan="1" rowspan="1">CNN_4</td>
<td colspan="1" rowspan="1">
<bold>
<italic>0.962</italic>
</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.940</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.922</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.903</bold>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">HSplice</td>
<td colspan="1" rowspan="1">0.927</td>
<td colspan="1" rowspan="1">0.813</td>
<td colspan="1" rowspan="1">0.909</td>
<td colspan="1" rowspan="1">0.660</td>
</tr>
<tr>
<td colspan="1" rowspan="3">
<bold>MCC</bold>
</td>
<td colspan="1" rowspan="1">CNN_3</td>
<td colspan="1" rowspan="1">
<bold>0.599</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.740</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.810</bold>
</td>
<td colspan="1" rowspan="1">0.856</td>
</tr>
<tr>
<td colspan="1" rowspan="1">CNN_4</td>
<td colspan="1" rowspan="1">0.594</td>
<td colspan="1" rowspan="1">0.713</td>
<td colspan="1" rowspan="1">0.795</td>
<td colspan="1" rowspan="1">
<bold>
<italic>0.861</italic>
</bold>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">HSplice</td>
<td colspan="1" rowspan="1">0.496</td>
<td colspan="1" rowspan="1">0.487</td>
<td colspan="1" rowspan="1">0.606</td>
<td colspan="1" rowspan="1">0.542</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="table-6fn">
<p>
<bold>Notes.</bold>
</p>
</fn>
<fn id="table-6fn1">
<p>Bold styling emphasizes the highest values regarding the evaluation metrics used in the study.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec>
<title>Effect of window sizes</title>
<p>As shown in <xref ref-type="table" rid="table-6">Tables 6</xref> and <xref ref-type="table" rid="table-7">7</xref>, the results of both training and testing show the same trend that using a sequence length of 398 nt performs better than other lengths. From <xref ref-type="table" rid="table-7">Table 7</xref>, according to the AUPRC, considering donor sites, using 398nt does not cause the model to perform significantly differently from using 160 nt and 240 nt (one-sided Welch’s <italic>t</italic>-test <italic>p</italic> = 0.1 and <italic>p</italic> = 0.39), while using 40 nt cannot beat other window sizes (one-sided Welch’s <italic>t</italic>-test <italic>p</italic> = 9. 4 ×10<sup>−4</sup>, <italic>p</italic> = 3 ×10<sup>−6</sup>, <italic>p</italic> = 4. 8 ×10<sup>−7</sup>, and <italic>p</italic> = 3. 7 ×10<sup>−7</sup>, for 80 nt, 160 nt, 240 nt, and 398 nt, respectively). Similarly, for acceptor sites, using 40 nt is insufficient when compared to other window sizes (one-sided Welch’s <italic>t</italic>-test <italic>p</italic> = 2. 8 ×10<sup>−7</sup>, <italic>p</italic> = 1. 2 ×10<sup>−9</sup>, <italic>p</italic> = 1. 8 ×10<sup>−10</sup>, and <italic>p</italic> = 2. 1 ×10<sup>−10</sup>, for 80 nt, 160 nt, 240, and 398 nt, respectively).</p>
<table-wrap id="table-7" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.7717/peerj.9470/table-7</object-id>
<label>Table 7</label>
<caption>
<title>The training performance of CNN_4 on the GWH dataset with different window sizes.</title>
<p>The training performance on the GWH dataset with different window sizes were collected from 5-fold cross-validation. The average values of each evaluation matrix are shown.</p>
</caption>
<alternatives>
<graphic xlink:href="peerj-08-9470-g010"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
</colgroup>
<thead>
<tr>
<th colspan="1" rowspan="1">
<bold>Site</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Window size (nt)</bold>
</th>
<th align="center" colspan="4" rowspan="1">
<bold>Model</bold>
</th>
</tr>
<tr>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1"></th>
<th align="center" colspan="4" rowspan="1">
<bold>CNN_4</bold>
</th>
</tr>
<tr>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1">
<bold>AUPRC</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Precision</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Recall</bold>
</th>
<th colspan="1" rowspan="1">
<bold>MCC</bold>
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="1" rowspan="5">Donor</td>
<td colspan="1" rowspan="1">40</td>
<td colspan="1" rowspan="1">0.924</td>
<td colspan="1" rowspan="1">0.848</td>
<td colspan="1" rowspan="1">0.890</td>
<td colspan="1" rowspan="1">0.849</td>
</tr>
<tr>
<td colspan="1" rowspan="1">80</td>
<td colspan="1" rowspan="1">0.933</td>
<td colspan="1" rowspan="1">0.871</td>
<td colspan="1" rowspan="1">0.894</td>
<td colspan="1" rowspan="1">0.866</td>
</tr>
<tr>
<td colspan="1" rowspan="1">160</td>
<td colspan="1" rowspan="1">0.948</td>
<td colspan="1" rowspan="1">0.886</td>
<td colspan="1" rowspan="1">0.908</td>
<td colspan="1" rowspan="1">0.882</td>
</tr>
<tr>
<td colspan="1" rowspan="1">240</td>
<td colspan="1" rowspan="1">
<bold>0.951</bold>
</td>
<td colspan="1" rowspan="1">0.888</td>
<td colspan="1" rowspan="1">0.916</td>
<td colspan="1" rowspan="1">0.888</td>
</tr>
<tr>
<td colspan="1" rowspan="1">398</td>
<td colspan="1" rowspan="1">
<bold>0.951</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.888</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.918</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.889</bold>
</td>
</tr>
<tr>
<td colspan="1" rowspan="5">Acceptor</td>
<td colspan="1" rowspan="1">40</td>
<td colspan="1" rowspan="1">0.846</td>
<td colspan="1" rowspan="1">0.774</td>
<td colspan="1" rowspan="1">0.788</td>
<td colspan="1" rowspan="1">0.749</td>
</tr>
<tr>
<td colspan="1" rowspan="1">80</td>
<td colspan="1" rowspan="1">0.890</td>
<td colspan="1" rowspan="1">0.818</td>
<td colspan="1" rowspan="1">0.834</td>
<td colspan="1" rowspan="1">0.801</td>
</tr>
<tr>
<td colspan="1" rowspan="1">160</td>
<td colspan="1" rowspan="1">0.922</td>
<td colspan="1" rowspan="1">0.856</td>
<td colspan="1" rowspan="1">0.860</td>
<td colspan="1" rowspan="1">0.838</td>
</tr>
<tr>
<td colspan="1" rowspan="1">240</td>
<td colspan="1" rowspan="1">0.933</td>
<td colspan="1" rowspan="1">0.880</td>
<td colspan="1" rowspan="1">0.870</td>
<td colspan="1" rowspan="1">0.857</td>
</tr>
<tr>
<td colspan="1" rowspan="1">398</td>
<td colspan="1" rowspan="1">
<bold>0.938</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.886</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.880</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.867</bold>
</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="table-7fn">
<p>
<bold>Notes.</bold>
</p>
</fn>
<fn id="table-7fn1">
<p>Bold styling emphasizes the highest values regarding the evaluation metrics used in the study.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>When it comes to testing, the model trained on 398 nt gave the best results for both donor and acceptor sites, as shown in <xref ref-type="table" rid="table-8">Table 8</xref>. However, for donor sites, using 240 nt is not significantly different from using 398 nt as one-sided Welch’s <italic>t</italic>-test <italic>p</italic> = 0.37.</p>
<table-wrap id="table-8" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.7717/peerj.9470/table-8</object-id>
<label>Table 8</label>
<caption>
<title>The testing performance of the CNN_4 on the GWH dataset with different window sizes.</title>
<p>The testing results of the CNN_4 performed on the hold-out data with different window sizes.</p>
</caption>
<alternatives>
<graphic xlink:href="peerj-08-9470-g011"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
<col span="1"/>
</colgroup>
<thead>
<tr>
<th colspan="1" rowspan="1">
<bold>Site</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Window size (nt)</bold>
</th>
<th align="center" colspan="4" rowspan="1">
<bold>Model</bold>
</th>
</tr>
<tr>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1"></th>
<th align="center" colspan="4" rowspan="1">
<bold>CNN_4</bold>
</th>
</tr>
<tr>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1"></th>
<th colspan="1" rowspan="1">
<bold>AUPRC</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Precision</bold>
</th>
<th colspan="1" rowspan="1">
<bold>Recall</bold>
</th>
<th colspan="1" rowspan="1">
<bold>MCC</bold>
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="1" rowspan="5">Donor</td>
<td colspan="1" rowspan="1">40</td>
<td colspan="1" rowspan="1">0.922</td>
<td colspan="1" rowspan="1">0.846</td>
<td colspan="1" rowspan="1">0.882</td>
<td colspan="1" rowspan="1">0.844</td>
</tr>
<tr>
<td colspan="1" rowspan="1">80</td>
<td colspan="1" rowspan="1">0.931</td>
<td colspan="1" rowspan="1">0.868</td>
<td colspan="1" rowspan="1">0.886</td>
<td colspan="1" rowspan="1">0.859</td>
</tr>
<tr>
<td colspan="1" rowspan="1">160</td>
<td colspan="1" rowspan="1">0.945</td>
<td colspan="1" rowspan="1">0.884</td>
<td colspan="1" rowspan="1">0.901</td>
<td colspan="1" rowspan="1">0.877</td>
</tr>
<tr>
<td colspan="1" rowspan="1">240</td>
<td colspan="1" rowspan="1">
<bold>0.950</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.887</bold>
</td>
<td colspan="1" rowspan="1">0.910</td>
<td colspan="1" rowspan="1">0.883</td>
</tr>
<tr>
<td colspan="1" rowspan="1">398</td>
<td colspan="1" rowspan="1">
<bold>0.950</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.887</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.912</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.885</bold>
</td>
</tr>
<tr>
<td colspan="1" rowspan="5">Acceptor</td>
<td colspan="1" rowspan="1">40</td>
<td colspan="1" rowspan="1">0.840</td>
<td colspan="1" rowspan="1">0.762</td>
<td colspan="1" rowspan="1">0.786</td>
<td colspan="1" rowspan="1">0.741</td>
</tr>
<tr>
<td colspan="1" rowspan="1">80</td>
<td colspan="1" rowspan="1">0.887</td>
<td colspan="1" rowspan="1">0.813</td>
<td colspan="1" rowspan="1">0.831</td>
<td colspan="1" rowspan="1">0.796</td>
</tr>
<tr>
<td colspan="1" rowspan="1">160</td>
<td colspan="1" rowspan="1">0.919</td>
<td colspan="1" rowspan="1">0.854</td>
<td colspan="1" rowspan="1">0.858</td>
<td colspan="1" rowspan="1">0.834</td>
</tr>
<tr>
<td colspan="1" rowspan="1">240</td>
<td colspan="1" rowspan="1">0.932</td>
<td colspan="1" rowspan="1">0.878</td>
<td colspan="1" rowspan="1">0.867</td>
<td colspan="1" rowspan="1">0.855</td>
</tr>
<tr>
<td colspan="1" rowspan="1">398</td>
<td colspan="1" rowspan="1">
<bold>0.937</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.883</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.878</bold>
</td>
<td colspan="1" rowspan="1">
<bold>0.863</bold>
</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="table-8fn">
<p>
<bold>Notes.</bold>
</p>
</fn>
<fn id="table-8fn1">
<p>Bold styling emphasizes the highest values regarding the evaluation metrics used in the study.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec>
<title>Variant effect prediction</title>
<p>As mentioned earlier, the best CNN-based model, or CNN_4 from the previous step, was used to predict the effect of variants on splicing events. Only variants on splice sites with a splicing probability of reference sequences over 80% were taken into account. There remained only 16,600 benign variants (9,361 in donor and 7,239 in acceptor) and 833 pathogenic variants (628 in donor and 205 in acceptor). The result shows that pathogenic variants significantly reduced the probability of sequences being splice sites compared to benign variants (one-sided Welch’s <italic>t</italic>-test <italic>p</italic> = 5. 9 ×10<sup>−6</sup> and <italic>p</italic> = 1. 6 ×10<sup>−10</sup>, for donor and acceptor sites, as shown in <xref ref-type="fig" rid="fig-3">Figs. 3A</xref> and <xref ref-type="fig" rid="fig-3">3B</xref>, respectively). The effects of variants were further investigated in each position relative to the splice sites (<xref ref-type="fig" rid="fig-3">Figs. 3C</xref> and <xref ref-type="fig" rid="fig-3">3D</xref>). It was shown that, for donor sites (see <xref ref-type="fig" rid="fig-3">Fig. 3C</xref>), the model detected effects of variants on splicing within 5 bp around the splice site (15th-20th positions). However, for acceptor sites (see <xref ref-type="fig" rid="fig-3">Fig. 3D</xref>), this range was extended further but still within 15 bp around the splice site (5th-36th positions).</p>
<fig id="fig-3" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.7717/peerj.9470/fig-3</object-id>
<label>Figure 3</label>
<caption>
<title>Variant effect prediction result.</title>
<p>(A) Distribution of donor score of benign and pathogenic variants. (B) Distribution of acceptor score of benign and pathogenic variants. (C) Distribution of donor score of variant at each position. (D) Distribution of acceptor score of variant at each position.</p>
</caption>
<graphic xlink:href="peerj-08-9470-g003"></graphic>
</fig>
<p><xref ref-type="table" rid="table-9">Table 9</xref> shows the <italic>p</italic>-value of a one-sided Welch’s <italic>t</italic>-test comparing the score obtained from the CNN_4 and the ada_score from the dbscSNV database. In general, CNN_4 is able to differentiate the pathogenic and benign variants as the one-sided Welch’s <italic>t</italic>-test <italic>p</italic> &lt; 0.05 for both donor and acceptor sites. However, the ada_score yields lower <italic>p</italic>-values for both donor and acceptor sites meaning that the score from the dbscSNV better differentiates the benign and pathogenic variants.</p>
<table-wrap id="table-9" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.7717/peerj.9470/table-9</object-id>
<label>Table 9</label>
<caption>
<title>The <italic>p</italic>-value of one-sided Welch’s <italic>t</italic>-test comparing between the score obtained from the CNN_4 and the ada_score from the dbscSNV database.</title>
<p>The <italic>p</italic>-value shows the comparison between the effectiveness of the CNN_4 model when predicting the effect of variants and the splicing variant scores (ada_score) from the dbscSNV database.</p>
</caption>
<alternatives>
<graphic xlink:href="peerj-08-9470-g012"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col span="1"/>
<col span="1"/>
<col span="1"/>
</colgroup>
<thead>
<tr>
<th colspan="1" rowspan="1">
<bold>Site</bold>
</th>
<th colspan="1" rowspan="1">
<bold>CNN_4</bold>
</th>
<th colspan="1" rowspan="1">
<bold>dbscSNV</bold>
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="1" rowspan="1">Donor</td>
<td colspan="1" rowspan="1">1.7 × 10<sup>−2</sup></td>
<td colspan="1" rowspan="1">5 × 10<sup>−6</sup></td>
</tr>
<tr>
<td colspan="1" rowspan="1">Acceptor</td>
<td colspan="1" rowspan="1">3.2 × 10<sup>−2</sup></td>
<td colspan="1" rowspan="1">4.3 × 10<sup>−3</sup></td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
</sec>
<sec sec-type="discussion">
<title>Discussion</title>
<p>CNN models provided significantly better performance than the traditional machine learning approaches (see <xref ref-type="table" rid="table-3">Tables 3</xref> and <xref ref-type="table" rid="table-6">6</xref>). Based on the comparison of donor sites to the existing HSplice tool, it is clear that constructing additional features for classification using domain knowledge can provide reasonably good performance despite using only a window size of 15 nt. However, the CNN models significantly improved performance by automatically extracting more useful features than the aforementioned feature engineering process. Among CNN-based models, the models containing CNN layers alone outperformed the hybrid CNN with bi-directional LSTM. This could be because the hybrid model contains only one layer of CNN. The performance could improve or be better than CNN alone if more CNN layers are added. Even though CNN models successfully recognized the sequence patterns of the actual splice sites, there is still room for improvement. The recall of two CNN models with different complexities was very high, but their precision was not at a comparable level. As a result, the models were not as good for predicting the negative sequences. Comparing the predicting performance on the unseen data between donor and acceptor sites, the performance of acceptor site prediction was not as good as of that the donor sites. This contradicts previous studies asserting that acceptor sites are far less variable and should be easier to predict when compared to donor sites (<xref ref-type="bibr" rid="ref-6">Garg &amp; Green, 2007</xref>). The limited performance in predicting negative sequences as well as acceptor sites could be caused by the limitation of the input sequence size in existing data (40 bp). In fact, more information could be fed to the model if longer sequences were used, as this study showed that the optimal performance occurs when a model is trained on input sequences of size 398 bp. However, the donor sites can perform similarly well when using 240 bp of the input sequences. For the effect of imbalanced data, according to the results shown in <xref ref-type="table" rid="table-4">Table 4</xref>, training a model using balanced data (1:1) tends to cause overfitting. This may be due to the fact that the data with a 1:1 ratio does not represent the actual scenario; there is much more negative data than positive data in the human genome. It is also possible that the negative data is not enough when trying to balance the dataset by randomly using a smaller set of negative data. It seems as though the imbalanced data does not affect the model as when more negative data is added to train the model, it actually improved the performance of the model. This also applies to the traditional machine learning approach as shown in <xref ref-type="table" rid="table-6">Table 6</xref>. The effectiveness of HSplice increases when the ratio of positive and negative increases. This may also be because of the fact that DL techniques, especially CNNs, can potentially extract features and learn by themselves to address imbalanced data. However, interpretable models are still on-going in research areas.</p>
<p>Variant effect prediction based on the CNN model showed that the proposed framework with the CNN_4 model was able to differentiate the pathogenic splice variants from the benign splice variants. When comparing the obtained scores with the ada_score from dbscSNV database, the obtained scores for both donor and acceptor sites were not better than the ada_score in terms of the difference between benign and pathogenic variants. It could be because the dbscSNV database directly studied the variant effect on splice sites. The model was trained using variant data with given labels, while the CNN_4 model was trained by using splice sequences. Also, the dbscSNV used additional features on top of the mRNA sequences. Specifically, they used conservation scores (i.e., PhyloP46way_placental and PhyloP46way_primate) (<xref ref-type="bibr" rid="ref-9">Jian, Boerwinkle &amp; Liu, 2014</xref>). Moreover, there is some overlap between their training dataset and the ClinVar database; thus, the performance observed could be due to over-fitting. Even though the CNN_4 model did not yield better results, it was able to predict a wider range of splice variants’ locations, i.e., ±20 at both donor and acceptor sites, unlike the dbscSNV which can only predict −3 to +8 at donor sites and −12 to +2 at acceptor sites. Only a small set of variants could be tested here as the model was trained on a sequence of length 40 bp. Based on the prediction performance comparison of difference sequence lengths, it would be better to extend the length of splice site sequences to train the model, so that not only the performance might be improved but the effect of variants located further could also be assessed.</p>
<p>Future work will address the limitations of the current study. In addition, an even larger amount of data will be collected, especially negative data, to provide a more comprehensive dataset. This includes longer sequences and different preprocessing techniques, e.g., shifting the core-dinucleotides to different positions, and using two or more nucleotides for encoding the sequence instead of using one nucleotide as shown in this study, which would help to make more robust models. Also, the conservation scores can be added as an additional feature for the splice variants to improve the model performance. In addition, to facilitate other researchers who may be interested to pursue the effect of sequence length in more depth, the pseudocode of splice site and variant data preparation have been included on GitHub for open access; however, the domain knowledge is needed to finalize a validated dataset and it is also a time-consuming process.</p>
</sec>
<sec sec-type="conclusions">
<title>Conclusions</title>
<p>This study provided a framework for predicting the effects of variants on splice sites. A case study was demonstrated by applying the framework with two datasets. These datasets were combined to improve the power of the predictive model. Multiple measures were used to compare the performance of different models. CNN models outperformed traditional machine learning models with average AUPRC of 93% for donor sites and 88% for acceptor sites. The best model was the CNN model with four convolutional layers, which then used to analyze genetic variant data from the ClinVar database. It showed promising results in distinguishing pathogenic variants from the benign. A few limitations found in the current study were discussed and will be further addressed in a future study. The GitHub repository for this study has been created, including the Python scripts and the datasets used in this study (see <ext-link ext-link-type="uri" xlink:href="https://github.com/smiile8888/rna-splice-sites-recognition">https://github.com/smiile8888/rna-splice-sites-recognition</ext-link>). However, the GWH dataset was not included because it has been published by <xref ref-type="bibr" rid="ref-12">Lee &amp; Yoon (2015</xref>: <ext-link ext-link-type="uri" xlink:href="https://dl.acm.org/doi/10.5555/3045118.3045382">https://dl.acm.org/doi/10.5555/3045118.3045382</ext-link>).</p>
</sec>
</body>
<back>
<ack>
<p>The authors would like to thank Rena Lu, Ryan Chang, Nicola Lawford, Mark Chignell, and Dunja Matic for proofreading this work as well as Jaturong Kongmanee for proofreading the methodology section.</p>
</ack>
<sec sec-type="additional-information">
<title>Additional Information and Declarations</title>
<fn-group content-type="competing-interests">
<title>Competing Interests</title>
<fn fn-type="COI-statement" id="conflict-1">
<p>The authors declare there are no competing interests.</p>
</fn>
</fn-group>
<fn-group content-type="author-contributions">
<title>Author Contributions</title>
<fn fn-type="con" id="contribution-1">
<p><xref ref-type="contrib" rid="author-1">Thanyathorn Thanapattheerakul</xref> and <xref ref-type="contrib" rid="author-2">Worrawat Engchuan</xref> conceived and designed the experiments, performed the experiments, analyzed the data, prepared figures and/or tables, authored or reviewed drafts of the paper, and approved the final draft.</p>
</fn>
<fn fn-type="con" id="contribution-3">
<p><xref ref-type="contrib" rid="author-3">Jonathan H. Chan</xref> conceived and designed the experiments, authored or reviewed drafts of the paper, and approved the final draft.</p>
</fn>
</fn-group>
<fn-group content-type="other">
<title>Data Availability</title>
<fn id="addinfo-1">
<p>The following information was supplied regarding data availability:</p>
<p>Data and code are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/smiile8888/rna-splice-sites-recognition">https://github.com/smiile8888/rna-splice-sites-recognition</ext-link>.</p>
</fn>
</fn-group>
</sec>
<ref-list content-type="authoryear">
<title>References</title>
<ref id="ref-1">
<label>Alipanahi et al. (2015)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Alipanahi</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Delong</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Weirauch</surname>
<given-names>MT</given-names>
</name>
<name>
<surname>Frey</surname>
<given-names>BJ</given-names>
</name>
</person-group>
<year>2015</year>
<article-title>Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</article-title>
<source/>Nature Biotechnology
          <volume>33</volume>
<fpage>831</fpage>
<lpage>838</lpage>
<pub-id pub-id-type="doi">10.1038/nbt.3300</pub-id>
</element-citation>
</ref>
<ref id="ref-2">
<label>Bengio, Simard &amp; Frasconi (1994)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bengio</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Simard</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Frasconi</surname>
<given-names>P</given-names>
</name>
</person-group>
<year>1994</year>
<article-title>Learning long-term dependencies with gradient descent is difficult</article-title>
<source/>IEEE Transactions on Neural Networks
          <volume>5</volume>
<fpage>157</fpage>
<lpage>166</lpage>
<pub-id pub-id-type="doi">10.1109/72.279181</pub-id>
<pub-id pub-id-type="pmid">18267787</pub-id>
</element-citation>
</ref>
<ref id="ref-3">
<label>Buée et al. (2000)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Buée</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Bussière</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Buée-Scherrer</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Delacourte</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Hof</surname>
<given-names>PR</given-names>
</name>
</person-group>
<year>2000</year>
<article-title>Tau protein isoforms, phosphorylation and role in neurodegenerative disorders</article-title>
<source/>Brain Research Reviews
          <volume>33</volume>
<fpage>95</fpage>
<lpage>130</lpage>
<pub-id pub-id-type="doi">10.1016/S0165-0173(00)00019-9</pub-id>
<pub-id pub-id-type="pmid">10967355</pub-id>
</element-citation>
</ref>
<ref id="ref-4">
<label>Desmet et al. (2010)</label>
<element-citation publication-type="other">
<person-group person-group-type="author">
<name>
<surname>Desmet</surname>
<given-names>F-O</given-names>
</name>
<name>
<surname>Hamroun</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Collod-Béroud</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Claustres</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Béroud</surname>
<given-names>C</given-names>
</name>
</person-group>
<year>2010</year>
<article-title>Bioinformatics identification of splice site signals and prediction of mutation effects</article-title>
</element-citation>
</ref>
<ref id="ref-5">
<label>Faustino &amp; Cooper (2003)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Faustino</surname>
<given-names>NA</given-names>
</name>
<name>
<surname>Cooper</surname>
<given-names>TA</given-names>
</name>
</person-group>
<year>2003</year>
<article-title>Pre-mRNA splicing and human disease</article-title>
<source/>Genes and Development
          <volume>17</volume>
<fpage>419</fpage>
<lpage>437</lpage>
<pub-id pub-id-type="doi">10.1101/gad.1048803</pub-id>
<pub-id pub-id-type="pmid">12600935</pub-id>
</element-citation>
</ref>
<ref id="ref-6">
<label>Garg &amp; Green (2007)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Garg</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Green</surname>
<given-names>P</given-names>
</name>
</person-group>
<article-title>Differing patterns of selection in alternative and constitutive splice sites</article-title>
<source/>Genome Research
          <volume>17</volume>
<fpage>1015</fpage>
<lpage>1022</lpage>
<year>2007</year>
<pub-id pub-id-type="doi">10.1101/gr.6347907</pub-id>
<pub-id pub-id-type="pmid">17556528</pub-id>
</element-citation>
</ref>
<ref id="ref-7">
<label>Hochreiter &amp; Schmidhuber (1997)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hochreiter</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Schmidhuber</surname>
<given-names>J</given-names>
</name>
</person-group>
<year>1997</year>
<article-title>Long short-term memory</article-title>
<source/>Neural Computation
          <volume>9</volume>
<fpage>1735</fpage>
<lpage>1780</lpage>
<pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
<pub-id pub-id-type="pmid">9377276</pub-id>
</element-citation>
</ref>
<ref id="ref-8">
<label>Hunter (2007)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hunter</surname>
<given-names>JD</given-names>
</name>
</person-group>
<year>2007</year>
<article-title>Matplotlib: a 2D graphics environment</article-title>
<source/>Computing in Science and Engineering
          <volume>9</volume>
<fpage>99</fpage>
<lpage>104</lpage>
<pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id>
</element-citation>
</ref>
<ref id="ref-9">
<label>Jian, Boerwinkle &amp; Liu (2014)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jian</surname>
<given-names>X</given-names>
</name>
<name>
<surname>Boerwinkle</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>X</given-names>
</name>
</person-group>
<year>2014</year>
<article-title>In silico prediction of splice-altering single nucleotide variants in the human genome</article-title>
<source/>Nucleic Acids Research
          <volume>42</volume>
<fpage>13534</fpage>
<lpage>13544</lpage>
<pub-id pub-id-type="doi">10.1093/nar/gku1206</pub-id>
<pub-id pub-id-type="pmid">25416802</pub-id>
</element-citation>
</ref>
<ref id="ref-10">
<label>Landrum et al. (2014)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Landrum</surname>
<given-names>MJ</given-names>
</name>
<name>
<surname>Lee</surname>
<given-names>JM</given-names>
</name>
<name>
<surname>Riley</surname>
<given-names>GR</given-names>
</name>
<name>
<surname>Jang</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Rubinstein</surname>
<given-names>WS</given-names>
</name>
<name>
<surname>Church</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Maglott</surname>
<given-names>DR</given-names>
</name>
</person-group>
<year>2014</year>
<article-title>ClinVar: public archive of relationships among sequence variation and human phenotype</article-title>
<source/>Nucleic Acids Research
          <volume>42</volume>
<pub-id pub-id-type="doi">10.1093/nar/gkt1113</pub-id>
</element-citation>
</ref>
<ref id="ref-11">
<label>LeCun, Bengio &amp; Hinton (2015)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>LeCun</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Bengio</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Hinton</surname>
<given-names>G</given-names>
</name>
</person-group>
<year>2015</year>
<article-title>Deep learning</article-title>
<source/>Nature
          <volume>521</volume>
<fpage>436</fpage>
<lpage>444</lpage>
<pub-id pub-id-type="doi">10.1038/nature14539</pub-id>
<pub-id pub-id-type="pmid">26017442</pub-id>
</element-citation>
</ref>
<ref id="ref-12">
<label>Lee &amp; Yoon (2015)</label>
<element-citation publication-type="confproc">
<person-group person-group-type="author">
<name>
<surname>Lee</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Yoon</surname>
<given-names>S</given-names>
</name>
</person-group>
<year>2015</year>
<article-title>Boosted categorical restricted Boltzmann machine for computational prediction of splice junctions</article-title>
<conf-name>International conference on machine learning</conf-name>
</element-citation>
</ref>
<ref id="ref-13">
<label>Lek et al., (2016)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lek</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Karczewski</surname>
<given-names>KJ</given-names>
</name>
<name>
<surname>Minikel</surname>
<given-names>EV</given-names>
</name>
<name>
<surname>Samocha</surname>
<given-names>KE</given-names>
</name>
<name>
<surname>Banks</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Fennell</surname>
<given-names>T</given-names>
</name>
<name>
<surname>O’Donnell-Luria</surname>
<given-names>AH</given-names>
</name>
<name>
<surname>Ware</surname>
<given-names>JS</given-names>
</name>
<name>
<surname>Hill</surname>
<given-names>AJ</given-names>
</name>
<name>
<surname>Cummings</surname>
<given-names>BB</given-names>
</name>
<name>
<surname>Tukiainen</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Birnbaum</surname>
<given-names>DP</given-names>
</name>
<name>
<surname>Kosmicki</surname>
<given-names>JA</given-names>
</name>
<name>
<surname>Duncan</surname>
<given-names>LE</given-names>
</name>
<name>
<surname>Estrada</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Zhao</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Zou</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Pierce-Hoffman</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Berghout</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Cooper</surname>
<given-names>DN</given-names>
</name>
<name>
<surname>Deflaux</surname>
<given-names>N</given-names>
</name>
<name>
<surname>DePristo</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Do</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Flannick</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Fromer</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Gauthier</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Goldstein</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Gupta</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Howrigan</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Kiezun</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Kurki</surname>
<given-names>MI</given-names>
</name>
<name>
<surname>Moonshine</surname>
<given-names>AL</given-names>
</name>
<name>
<surname>Natarajan</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Orozco</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Peloso</surname>
<given-names>GM</given-names>
</name>
<name>
<surname>Poplin</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Rivas</surname>
<given-names>MA</given-names>
</name>
<name>
<surname>Ruano-Rubio</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Rose</surname>
<given-names>SA</given-names>
</name>
<name>
<surname>Ruderfer</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Shakir</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Stenson</surname>
<given-names>PD</given-names>
</name>
<name>
<surname>Stevens</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Thomas</surname>
<given-names>BP</given-names>
</name>
<name>
<surname>Tiao</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Tusie-Luna</surname>
<given-names>MT</given-names>
</name>
<name>
<surname>Weisburd</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Won</surname>
<given-names>HH</given-names>
</name>
<name>
<surname>Yu</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Altshuler</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Ardissino</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Boehnke</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Danesh</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Donnelly</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Elosua</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Florez</surname>
<given-names>JC</given-names>
</name>
<name>
<surname>Gabriel</surname>
<given-names>SB</given-names>
</name>
<name>
<surname>Getz</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Glatt</surname>
<given-names>SJ</given-names>
</name>
<name>
<surname>Hultman</surname>
<given-names>CM</given-names>
</name>
<name>
<surname>Kathiresan</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Laakso</surname>
<given-names>M</given-names>
</name>
<name>
<surname>McCarroll</surname>
<given-names>S</given-names>
</name>
<name>
<surname>McCarthy</surname>
<given-names>MI</given-names>
</name>
<name>
<surname>McGovern</surname>
<given-names>D</given-names>
</name>
<name>
<surname>McPherson</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Neale</surname>
<given-names>BM</given-names>
</name>
<name>
<surname>Palotie</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Purcell</surname>
<given-names>SM</given-names>
</name>
<name>
<surname>Saleheen</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Scharf</surname>
<given-names>JM</given-names>
</name>
<name>
<surname>Sklar</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Sullivan</surname>
<given-names>PF</given-names>
</name>
<name>
<surname>Tuomilehto</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Tsuang</surname>
<given-names>MT</given-names>
</name>
<name>
<surname>Watkins</surname>
<given-names>HC</given-names>
</name>
<name>
<surname>Wilson</surname>
<given-names>JG</given-names>
</name>
<name>
<surname>Daly</surname>
<given-names>MJ</given-names>
</name>
<name>
<surname>MacArthur</surname>
<given-names>DG</given-names>
</name>
<name>
<surname>Abboud</surname>
<given-names>HE</given-names>
</name>
<name>
<surname>Abecasis</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Aguilar-Salinas</surname>
<given-names>CA</given-names>
</name>
<name>
<surname>Arellano-Campos</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Atzmon</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Aukrust</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Barr</surname>
<given-names>CL</given-names>
</name>
<name>
<surname>Bell</surname>
<given-names>GI</given-names>
</name>
<name>
<surname>Bergen</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Bjørkhaug</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Blangero</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Bowden</surname>
<given-names>DW</given-names>
</name>
<name>
<surname>Budman</surname>
<given-names>CL</given-names>
</name>
<name>
<surname>Burtt</surname>
<given-names>NP</given-names>
</name>
<name>
<surname>Centeno-Cruz</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Chambers</surname>
<given-names>JC</given-names>
</name>
<name>
<surname>Chambert</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Clarke</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Collins</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Coppola</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Córdova</surname>
<given-names>EJ</given-names>
</name>
<name>
<surname>Cortes</surname>
<given-names>ML</given-names>
</name>
<name>
<surname>Cox</surname>
<given-names>NJ</given-names>
</name>
<name>
<surname>Duggirala</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Farrall</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Fernandez-Lopez</surname>
<given-names>JC</given-names>
</name>
<name>
<surname>Fontanillas</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Frayling</surname>
<given-names>TM</given-names>
</name>
<name>
<surname>Freimer</surname>
<given-names>NB</given-names>
</name>
<name>
<surname>Fuchsberger</surname>
<given-names>C</given-names>
</name>
<name>
<surname>García-Ortiz</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Goel</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Gómez-Vázquez</surname>
<given-names>MJ</given-names>
</name>
<name>
<surname>González-Villalpando</surname>
<given-names>ME</given-names>
</name>
<name>
<surname>González-Villalpando</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Grados</surname>
<given-names>MA</given-names>
</name>
<name>
<surname>Groop</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Haiman</surname>
<given-names>CA</given-names>
</name>
<name>
<surname>Hanis</surname>
<given-names>CL</given-names>
</name>
<name>
<surname>Hattersley</surname>
<given-names>AT</given-names>
</name>
<name>
<surname>Henderson</surname>
<given-names>BE</given-names>
</name>
<name>
<surname>Hopewell</surname>
<given-names>JC</given-names>
</name>
<name>
<surname>Huerta-Chagoya</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Islas-Andrade</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Jacobs</surname>
<given-names>SB</given-names>
</name>
<name>
<surname>Jalilzadeh</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Jenkinson</surname>
<given-names>CP</given-names>
</name>
<name>
<surname>Moran</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Jiménez-Morale</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Kähler</surname>
<given-names>A</given-names>
</name>
<name>
<surname>King</surname>
<given-names>RA</given-names>
</name>
<name>
<surname>Kirov</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Kooner</surname>
<given-names>JS</given-names>
</name>
<name>
<surname>Kyriakou</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Lee</surname>
<given-names>JY</given-names>
</name>
<name>
<surname>Lehman</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Lyon</surname>
<given-names>G</given-names>
</name>
<name>
<surname>MacMahon</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Magnusson</surname>
<given-names>PK</given-names>
</name>
<name>
<surname>Mahajan</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Marrugat</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Martínez-Hernández</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Mathews</surname>
<given-names>CA</given-names>
</name>
<name>
<surname>McVean</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Meigs</surname>
<given-names>JB</given-names>
</name>
<name>
<surname>Meitinger</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Mendoza-Caamal</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Mercader</surname>
<given-names>JM</given-names>
</name>
<name>
<surname>Mohlke</surname>
<given-names>KL</given-names>
</name>
<name>
<surname>Moreno-Macías</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Morris</surname>
<given-names>AP</given-names>
</name>
<name>
<surname>Najmi</surname>
<given-names>LA</given-names>
</name>
<name>
<surname>Njølstad</surname>
<given-names>PR</given-names>
</name>
<name>
<surname>O’Donovan</surname>
<given-names>MC</given-names>
</name>
<name>
<surname>Ordóñez-Sánchez</surname>
<given-names>ML</given-names>
</name>
<name>
<surname>Owen</surname>
<given-names>MJ</given-names>
</name>
<name>
<surname>Park</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Pauls</surname>
<given-names>DL</given-names>
</name>
<name>
<surname>Posthuma</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Revilla-Monsalve</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Riba</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Ripke</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Rodríguez-Guillén</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Rodríguez-Torres</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Sandor</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Seielstad</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Sladek</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Soberón</surname>
<given-names>X</given-names>
</name>
<name>
<surname>Spector</surname>
<given-names>TD</given-names>
</name>
<name>
<surname>Tai</surname>
<given-names>SE</given-names>
</name>
<name>
<surname>Teslovich</surname>
<given-names>TM</given-names>
</name>
<name>
<surname>Walford</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Wilkens</surname>
<given-names>LR</given-names>
</name>
<name>
<surname>Williams</surname>
<given-names>AL</given-names>
</name>
</person-group>
<year>2016</year>
<article-title>Analysis of protein-coding genetic variation in 60, 706 humans</article-title>
<source/>Nature
          <volume>536</volume>
<fpage>285</fpage>
<lpage>291</lpage>
<pub-id pub-id-type="doi">10.1038/nature19057</pub-id>
<pub-id pub-id-type="pmid">27535533</pub-id>
</element-citation>
</ref>
<ref id="ref-14">
<label>McKinney (2010)</label>
<element-citation publication-type="confproc">
<person-group person-group-type="author">
<name>
<surname>McKinney</surname>
<given-names>W</given-names>
</name>
</person-group>
<year>2010</year>
<article-title>Data structures for statistical computing in Python</article-title>
<conf-name>Proceedings of the 9th Python in science conference</conf-name>
<volume>5</volume>
<fpage>1</fpage>
<lpage>56</lpage>
<pub-id pub-id-type="doi">10.1192/bjp.111.479.1009-a</pub-id>
</element-citation>
</ref>
<ref id="ref-15">
<label>Meher, Sahu &amp; Rao (2016)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Meher</surname>
<given-names>PK</given-names>
</name>
<name>
<surname>Sahu</surname>
<given-names>TK</given-names>
</name>
<name>
<surname>Rao</surname>
<given-names>AR</given-names>
</name>
</person-group>
<year>2016</year>
<article-title>Prediction of donor splice sites using random forest with a new sequence encoding approach</article-title>
<source/>BioData Mining
          <volume>9</volume>
<fpage>4</fpage>
<lpage>1</lpage>
<pub-id pub-id-type="doi">10.1186/s13040-016-0086-4</pub-id>
<pub-id pub-id-type="pmid">26807151</pub-id>
</element-citation>
</ref>
<ref id="ref-16">
<label>Meher et al. (2016)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Meher</surname>
<given-names>PK</given-names>
</name>
<name>
<surname>Sahu</surname>
<given-names>TK</given-names>
</name>
<name>
<surname>Rao</surname>
<given-names>AR</given-names>
</name>
<name>
<surname>Wahi</surname>
<given-names>SD</given-names>
</name>
</person-group>
<year>2016</year>
<article-title>Identification of donor splice sites using support vector machine: a computational approach based on positional, compositional and dependency features</article-title>
<volume>11</volume>
<fpage>16</fpage>
<pub-id pub-id-type="doi">10.1186/s13015-016-0078-4</pub-id>
</element-citation>
</ref>
<ref id="ref-17">
<label>Nair &amp; Hinton (2010)</label>
<element-citation publication-type="other">
<person-group person-group-type="author">
<name>
<surname>Nair</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Hinton</surname>
<given-names>GE</given-names>
</name>
</person-group>
<year>2010</year>
<article-title>Rectified linear units improve restricted Boltzmann machines</article-title>
</element-citation>
</ref>
<ref id="ref-18">
<label>Oliphant (2006)</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Oliphant</surname>
<given-names>TE</given-names>
</name>
</person-group>
<year>2006</year>
<source/>A guide to numpy
        </element-citation>
</ref>
<ref id="ref-19">
<label>Quang &amp; Xie (2016)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Quang</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Xie</surname>
<given-names>X</given-names>
</name>
</person-group>
<year>2016</year>
<article-title>DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences</article-title>
<source/>Nucleic Acids Research
          <volume>44</volume>
<fpage>e107</fpage>
<lpage>e107</lpage>
<pub-id pub-id-type="doi">10.1093/nar/gkw226</pub-id>
<pub-id pub-id-type="pmid">27084946</pub-id>
</element-citation>
</ref>
<ref id="ref-20">
<label>Reble, Dineen &amp; Barr (2018)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Reble</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Dineen</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Barr</surname>
<given-names>CL</given-names>
</name>
</person-group>
<year>2018</year>
<article-title>The contribution of alternative splicing to genetic risk for psychiatric disorders</article-title>
<source/>Genes, Brain and Behavior
          <volume>17</volume>
<pub-id pub-id-type="doi">10.1111/gbb.12430</pub-id>
</element-citation>
</ref>
<ref id="ref-21">
<label>Rexiati, Sun &amp; Guo (2018)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rexiati</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Sun</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Guo</surname>
<given-names>W</given-names>
</name>
</person-group>
<year>2018</year>
<article-title>Muscle-specific mis-splicing and heart disease exemplified by RBM20</article-title>
<source/>Gene
          <volume>9</volume>
<issue>18</issue>
<pub-id pub-id-type="doi">10.3390/genes9010018</pub-id>
</element-citation>
</ref>
<ref id="ref-22">
<label>Schuster &amp; Paliwal (1997)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Schuster</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Paliwal</surname>
<given-names>KK</given-names>
</name>
</person-group>
<year>1997</year>
<article-title>Bidirectional recurrent neural networks</article-title>
<source/>IEEE Transactions on Signal Processing
          <volume>45</volume>
<fpage>2673</fpage>
<lpage>2681</lpage>
<pub-id pub-id-type="doi">10.1109/78.650093</pub-id>
</element-citation>
</ref>
<ref id="ref-23">
<label>Scotti &amp; Swanson (2016)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Scotti</surname>
<given-names>MM</given-names>
</name>
<name>
<surname>Swanson</surname>
<given-names>MS</given-names>
</name>
</person-group>
<year>2016</year>
<article-title>RNA mis-splicing in disease</article-title>
<source/>Nature Reviews Genetics
          <volume>17</volume>
<fpage>19</fpage>
<lpage>32</lpage>
<pub-id pub-id-type="doi">10.1038/nrg.2015.3</pub-id>
</element-citation>
</ref>
<ref id="ref-24">
<label>Sonnenburg et al. (2007)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Sonnenburg</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Schweikert</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Philips</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Behr</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Rätsch</surname>
<given-names>G</given-names>
</name>
</person-group>
<year>2007</year>
<article-title>Accurate splice site prediction using support vector machines</article-title>
<source/>BMC Bioinformatics
          <pub-id pub-id-type="doi">10.1186/1471-2105-8-S10-S7</pub-id>
</element-citation>
</ref>
<ref id="ref-25">
<label>Srivastava et al. (2014)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Srivastava</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Hinton</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Krizhevsky</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Salakhutdinov</surname>
<given-names>R</given-names>
</name>
</person-group>
<year>2014</year>
<article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
<source/>Journal of Machine Learning Research
          <volume>15</volume>
<fpage>1929</fpage>
<lpage>1958</lpage>
</element-citation>
</ref>
<ref id="ref-26">
<label>Stephens et al. (2015)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stephens</surname>
<given-names>ZD</given-names>
</name>
<name>
<surname>Lee</surname>
<given-names>SY</given-names>
</name>
<name>
<surname>Faghri</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Campbell</surname>
<given-names>RH</given-names>
</name>
<name>
<surname>Zhai</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Efron</surname>
<given-names>MJ</given-names>
</name>
<name>
<surname>Iyer</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Schatz</surname>
<given-names>MC</given-names>
</name>
<name>
<surname>Sinha</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Robinson</surname>
<given-names>GE</given-names>
</name>
</person-group>
<year>2015</year>
<article-title>Big data: astronomical or Genomical?</article-title>
<source/>PLOS Biology
          <volume>13</volume>
<elocation-id>e1002195</elocation-id>
<pub-id pub-id-type="doi">10.1371/journal.pbio.1002195</pub-id>
<pub-id pub-id-type="pmid">26151137</pub-id>
</element-citation>
</ref>
<ref id="ref-27">
<label>Stormo (2000)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stormo</surname>
<given-names>GD</given-names>
</name>
</person-group>
<year>2000</year>
<article-title>DNA binding sites: representation and discovery</article-title>
<source/>Bioinformatics
          <volume>16</volume>
<fpage>16</fpage>
<lpage>23</lpage>
<pub-id pub-id-type="doi">10.1093/bioinformatics/16.1.16</pub-id>
<pub-id pub-id-type="pmid">10812473</pub-id>
</element-citation>
</ref>
<ref id="ref-28">
<label>Thanapattheerakul et al. (2018)</label>
<element-citation publication-type="data">
<person-group person-group-type="author">
<name>
<surname>Thanapattheerakul</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Engchuan</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Merico</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Doungpan</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Hashimoto</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Chan</surname>
<given-names>J</given-names>
</name>
</person-group>
<year>2018</year>
<data-title>RNA splice sites classification using convolutional neural network models</data-title>
<uri xlink:href="http://site.ieee.org/thailand-cis/files/2018/11/JSCI6-Paper-5.pdf">http://site.ieee.org/thailand-cis/files/2018/11/JSCI6-Paper-5.pdf</uri>
<date-in-citation content-type="access-date" iso-8601-date="2019-01-14">14 January 2019</date-in-citation>
</element-citation>
</ref>
<ref id="ref-29">
<label>Wainberg et al. (2018)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wainberg</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Merico</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Delong</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Frey</surname>
<given-names>BJ</given-names>
</name>
</person-group>
<year>2018</year>
<article-title>Deep learning in biomedicine</article-title>
<source/>Nature Biotechnology
          <volume>36</volume>
<fpage>829</fpage>
<lpage>838</lpage>
<pub-id pub-id-type="doi">10.1038/nbt.4233</pub-id>
</element-citation>
</ref>
<ref id="ref-30">
<label>VanDer Walt, Colbert &amp; Varoquaux (2011)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>VanDer Walt</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Colbert</surname>
<given-names>SC</given-names>
</name>
<name>
<surname>Varoquaux</surname>
<given-names>G</given-names>
</name>
</person-group>
<year>2011</year>
<article-title>The NumPy array: a structure for efficient numerical computation</article-title>
<source/>Computing in Science and Engineering
          <volume>13</volume>
<fpage>22</fpage>
<lpage>30</lpage>
<pub-id pub-id-type="doi">10.1109/MCSE.2011.37</pub-id>
</element-citation>
</ref>
<ref id="ref-31">
<label>Wickham (2009)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wickham</surname>
<given-names>H</given-names>
</name>
</person-group>
<year>2009</year>
<article-title>ggplot2: elegant graphics for data analysis - hadley wickham - google books</article-title>
<volume>10</volume>
<issue>2019</issue>
</element-citation>
</ref>
<ref id="ref-32">
<label>Zhou &amp; Troyanskaya (2015)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhou</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Troyanskaya</surname>
<given-names>OG</given-names>
</name>
</person-group>
<year>2015</year>
<article-title>Predicting effects of noncoding variants with deep learning–based sequence model</article-title>
<source/>Nature Methods
          <volume>12</volume>
<fpage>931</fpage>
<lpage>934</lpage>
<pub-id pub-id-type="doi">10.1038/nmeth.3547</pub-id>
<pub-id pub-id-type="pmid">26301843</pub-id>
</element-citation>
</ref>
<ref id="ref-33">
<label>Zhu et al. (2017)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhu</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Yin</surname>
<given-names>Z</given-names>
</name>
<name>
<surname>Tan</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Guo</surname>
<given-names>W</given-names>
</name>
</person-group>
<year>2017</year>
<article-title>Insulin regulates titin pre-mRNA splicing through the PI3K-Akt-mTOR kinase axis in a RBM20-dependent manner</article-title>
<source/>Biochimica et Biophysica Acta (BBA) - Molecular Basis of Disease
          <volume>1863</volume>
<fpage>2363</fpage>
<lpage>2371</lpage>
<pub-id pub-id-type="doi">10.1016/J.BBADIS.2017.06.023</pub-id>
<pub-id pub-id-type="pmid">28676430</pub-id>
</element-citation>
</ref>
<ref id="ref-34">
<label>Zuallaert et al. (2018)</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zuallaert</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Godin</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Kim</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Soete</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Saeys</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>De Neve</surname>
<given-names>W</given-names>
</name>
</person-group>
<year>2018</year>
<article-title>SpliceRover: interpretable convolutional neural networks for improved splice site prediction</article-title>
<source/>Bioinformatics
          <volume>34</volume>
<fpage>4180</fpage>
<lpage>4188</lpage>
<pub-id pub-id-type="doi">10.1093/bioinformatics/bty497</pub-id>
<pub-id pub-id-type="pmid">29931149</pub-id>
</element-citation>
</ref>
</ref-list>
</back>
</article>
</pmc-articleset>