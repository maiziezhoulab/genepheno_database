<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="research-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">Appl Netw Sci</journal-id>
<journal-id journal-id-type="iso-abbrev">Appl Netw Sci</journal-id>
<journal-title-group>
<journal-title>Applied Network Science</journal-title>
</journal-title-group>
<issn pub-type="epub">2364-8228</issn>
<publisher>
<publisher-name>Springer International Publishing</publisher-name>
<publisher-loc>Cham</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">30839816</article-id>
<article-id pub-id-type="pmc">6214326</article-id>
<article-id pub-id-type="publisher-id">93</article-id>
<article-id pub-id-type="doi">10.1007/s41109-018-0093-0</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Applications of node-based resilience graph theoretic framework to clustering autism spectrum disorders phenotypes</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Matta</surname>
<given-names>John</given-names>
</name>
<address>
<email>jmatta@siue.edu</email>
</address>
<xref ref-type="aff" rid="Aff1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zhao</surname>
<given-names>Junya</given-names>
</name>
<address>
<email>Junya009@live.missouristate.edu</email>
</address>
<xref ref-type="aff" rid="Aff2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ercal</surname>
<given-names>Gunes</given-names>
</name>
<address>
<email>gercal@siue.edu</email>
</address>
<xref ref-type="aff" rid="Aff1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Obafemi-Ajayi</surname>
<given-names>Tayo</given-names>
</name>
<address>
<email>tayoobafemiajayi@missouristate.edu</email>
</address>
<xref ref-type="aff" rid="Aff3">3</xref>
</contrib>
<aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0816 4489</institution-id><institution-id institution-id-type="GRID">grid.263857.d</institution-id><institution>Department of Computer Science, Southern Illinois University Edwardsville, </institution></institution-wrap>Edwardsville, IL USA </aff>
<aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0745 8995</institution-id><institution-id institution-id-type="GRID">grid.260126.1</institution-id><institution>Department of Computer Science, Missouri State University, </institution></institution-wrap>Springfield, MO USA </aff>
<aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0745 8995</institution-id><institution-id institution-id-type="GRID">grid.260126.1</institution-id><institution>Engineering Program, Missouri State University, </institution></institution-wrap>Springfield, MO USA </aff>
</contrib-group>
<pub-date pub-type="epub">
<day>29</day>
<month>8</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="pmc-release">
<day>29</day>
<month>8</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="ppub">
<year>2018</year>
</pub-date>
<volume>3</volume>
<issue>1</issue>
<elocation-id>38</elocation-id>
<history>
<date date-type="received">
<day>3</day>
<month>4</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>8</day>
<month>8</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>© The Author(s) 2018</copyright-statement>
<license license-type="OpenAccess">
<license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</license-p>
</license>
</permissions>
<abstract id="Abs1">
<p>With the growing ubiquity of data in network form, clustering in the context of a network, represented as a graph, has become increasingly important. Clustering is a very useful data exploratory machine learning tool that allows us to make better sense of heterogeneous data by grouping data with similar attributes based on some criteria. This paper investigates the application of a novel graph theoretic clustering method, Node-Based Resilience clustering (NBR-Clust), to address the heterogeneity of Autism Spectrum Disorder (ASD) and identify meaningful subgroups. The hypothesis is that analysis of these subgroups would reveal relevant biomarkers that would provide a better understanding of ASD phenotypic heterogeneity useful for further ASD studies. We address appropriate graph constructions suited for representing the ASD phenotype data. The sample population is drawn from a very large rigorous dataset: Simons Simplex Collection (SSC). Analysis of the results performed using graph quality measures, internal cluster validation measures, and clinical analysis outcome demonstrate the potential usefulness of resilience measure clustering for biomedical datasets. We also conduct feature extraction analysis to characterize relevant biomarkers that delineate the resulting subgroups. The optimal results obtained favored predominantly a 5-cluster configuration.</p>
<sec>
<title>Electronic supplementary material</title>
<p>The online version of this article (10.1007/s41109-018-0093-0) contains supplementary material, which is available to authorized users.</p>
</sec>
</abstract>
<kwd-group xml:lang="en">
<title>Keywords</title>
<kwd>Graph theory</kwd>
<kwd>Clustering</kwd>
<kwd>Autism spectrum disorders</kwd>
<kwd>Resilience measures</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta>
<meta-name>issue-copyright-statement</meta-name>
<meta-value>© The Author(s) 2018</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="Sec1" sec-type="introduction">
<title>Introduction</title>
<p>Clustering comprises a prolific research area for data exploration and knowledge discovery applications with a great variety of approaches. With the growing ubiquity of data in network form, clustering in the context of a network represented as a graph has become increasingly important. In graph theory contexts, clustering involves finding a k-partitioning of the vertices of a graph. The concepts and properties of graph theory make it very convenient to describe clustering problems by means of graphs (<xref ref-type="bibr" rid="CR61">Xu and Wunsch II 2009</xref>). Nodes <italic>V</italic>={<italic>v</italic><sub><italic>i</italic></sub>,<italic>i</italic>=1,…,<italic>N</italic>} of a weighted graph <italic>G</italic> correspond to <italic>N</italic> data points in the pattern space, and edges <italic>E</italic>={<italic>e</italic><sub><italic>ij</italic></sub>,<italic>i</italic>,<italic>j</italic>∈<italic>V</italic>,<italic>i</italic>≠<italic>j</italic>} reflect the proximities between each pair of data points. Use of graph theoretic clustering techniques is not restricted to cases where the data is inherently graph-based. They have also been shown to be effective on other types of data by transforming the data to a graph form using an appropriate graph representation (<xref ref-type="bibr" rid="CR4">Alpert et al. 1999</xref>). Brugere et al. (<xref ref-type="bibr" rid="CR15">2018</xref>) provide an in depth overview regarding creating networks from data as well as examples of network structure inference in diverse fields such as computational biology, neuroscience, epidemiology, ecology, and mobile device technology.</p>
<p>There are many benefits to converting data to a network representation as networks are an excellent way of representing complex relationships. The following benefits are highlighted and discussed in details in Ref. (<xref ref-type="bibr" rid="CR15">Brugere et al. 2018</xref>). Networks aid in uncovering the higher-order structure emerging from dyadic relationships. They are also useful in exploring the heterogeneity that exists among individual entities. Diverse measures can be applied in interpreting and/or evaluating network representations such as density, degree distribution, clustering coefficient, centralities, etc. Networks are interpretable models for further analysis and hypothesis generation. Many useful tools also exist for network analysis that can be used across domains. Thus, networks provide a common language through which biological researchers can communicate with computer scientists. Graph based methods aid ease of visualization of analysis, a natural co-occurrence of network representation. Given a dataset, the main challenge usually lies in determining which particular network will be the most useful representation to provide meaningful inference.</p>
<p>There are various successful examples of the use of graphs in analyzing biological and health-related data. Pan et al. (<xref ref-type="bibr" rid="CR53">2018</xref>) converted gene expression data to an appropriate graph representation and computed <italic>betweenness centrality</italic> (a graph-theoretic measure) to find important regulator genes in tumors. Their study is a useful motivation for the current work, which also uses betweenness centrality in a heuristic to find important data points. Dale et al. (<xref ref-type="bibr" rid="CR21">2018</xref>) employed graph clustering techniques to gene expression data to identify genes potentially related to powdery mildew disease resistance in grapevines. Alves et al. (<xref ref-type="bibr" rid="CR5">2018</xref>) applied graph clustering and graph theoretic measures (degree distribution, average clustering coefficient, and average short path length) to evaluate the effects of an antibody on chick embryos. The specific application of classification of human traits and diseases in patient networks using graph analysis is conducted for a variety of medical applications including pathological narcissism in (<xref ref-type="bibr" rid="CR54">Pierro et al. 2018</xref>), dark personality traits in (<xref ref-type="bibr" rid="CR40">Marcus et al. 2018</xref>), post-traumatic stress disorder in (<xref ref-type="bibr" rid="CR6">Akiki et al. 2018</xref>), and inflammatory bowel diseases in (<xref ref-type="bibr" rid="CR1">Abbas et al. 2018</xref>).</p>
<p>This paper investigates the application of graph theoretic clustering on analysis of clinical data relating to Autism Spectrum Disorder (ASD) phenotypes. Clinical data, such as in ASD, is commonly characterized by significant heterogeneity, high dimensionality, complexity in structure and mixture of variables, disparate data sources, and missing data. There is a critical need to identify and validate more homogeneous subgroups as well as learn the distinct features (biomarkers) associated with the subgroups. This work significantly extends preliminary results presented in (<xref ref-type="bibr" rid="CR43">Matta et al. 2017</xref>) on clustering ASD phenotype data using our <italic>node-based resilience</italic> clustering framework (NBR-Clust) (<xref ref-type="bibr" rid="CR44">Matta et al. 2016</xref>; <xref ref-type="bibr" rid="CR13">Borwey et al. 2015</xref>). NBR-Clust is unique in its focus on critical attack sets of <italic>nodes</italic>
<italic>S</italic>⊂<italic>V</italic> whose removal disconnects the network into multiple components that form the basis of resultant clusters. Due to natural properties of sparse node-cuts, the NBR-Clust approach is useful not only for traditional clustering scenarios where the number of clusters may be unknown a priori, but also for clustering in the presence of outliers or noise, and/or overlapping nodes (<xref ref-type="bibr" rid="CR44">Matta et al. 2016</xref>; <xref ref-type="bibr" rid="CR13">Borwey et al. 2015</xref>). In (<xref ref-type="bibr" rid="CR44">Matta et al. 2016</xref>), we generalized the usefulness of node-based resilience measures for clustering, particularly when the number of clusters is not known a priori. We conducted an in-depth comparative analysis using existing known resilience measures such as integrity, toughness, tenacity, and scattering number as well as a parametrized version of vertex attack tolerance (VAT). The results obtained demonstrated the effectiveness of VAT and integrity over the other methods in clustering the datasets with high accuracy. Additionally, integrity was likely to cluster datasets in one step, and tenacity was useful for giving an upper bound to cluster number determination.</p>
<p>In this work, we conduct a systematic exploration of application of NBR measures to delineate heterogeneous ASD data into more meaningful subgroups using a sample population drawn from the Simons Simplex Collection (<xref ref-type="bibr" rid="CR25">Fischbach and Lord 2010</xref>). We investigate three NBR measures (VAT, Integrity and Tenacity) along with multiple graph constructions to determine appropriate representations for the ASD phenotype data. We also employ feature extraction techniques to determine a potential set of ASD phenotype biomarkers that discriminate the resulting subgroups. A varied set of statistical methods is applied to validate and interpret the clinical significance of the results.</p>
</sec>
<sec id="Sec2">
<title>Autism spectrum disorders</title>
<p>ASDs are childhood neurodevelopmental disorders diagnosed on the basis of behavioral assessments of social, communicative, and repetitive symptoms (Association et al. <xref ref-type="bibr" rid="CR9">2013</xref>). Although ASD is behaviorally distinctive and reliably identified by experienced clinicians, it is clinically and genetically extremely heterogeneous (<xref ref-type="bibr" rid="CR46">Miles 2011</xref>). Children with ASD exhibit a wide diversity in type, number, and severity of social deficits, behaviors, and communicative and cognitive difficulties, which are assumed to reflect multiple etiologic origins (<xref ref-type="bibr" rid="CR22">Eaves et al. 1994</xref>). Given the increase in ASD prevalence (<xref ref-type="bibr" rid="CR10">Autism and Developmental Disabilities Monitoring Network Surveillance Year 2010 Principal Investigators 2014</xref>) and the corresponding increasing associated economic burden (<xref ref-type="bibr" rid="CR34">Lavelle et al. 2014</xref>), there is a need for automated approaches to detect more homogeneous subgroups of patients, and more importantly for biomarkers (biologically based phenotypes) to inform tailored intervention and improved outcomes. Biomarkers are useful to index diagnostic status or risk, demonstrate engagement of specific biological systems, and provide more rapid assessment of change than traditional measures based on clinical observation and caregiver report (<xref ref-type="bibr" rid="CR45">McPartland 2016</xref>). In the unsupervised learning context, biomarkers can be regarded as significant features that characterize a subgroup (or cluster). Thus, the problem of inferring meaningful biomarkers translates to unsupervised learning of discriminant features. A better understanding of heterogeneity in autism itself, based on scientifically rigorous approaches centered on systematic evaluation of the clinical and research utility of the phenotypic and genotypic markers (<xref ref-type="bibr" rid="CR27">Georgiades et al. 2013</xref>), would generate useful information for the study of etiology, diagnosis, treatment and prognosis of the disorder.</p>
<p>There have been varied cluster analysis approaches on ASD phenotype/clinical data over the past two decades. Prior to DSM-5 (Association et al. <xref ref-type="bibr" rid="CR9">2013</xref>), some of these approaches (<xref ref-type="bibr" rid="CR58">Stevens et al. 2000</xref>; <xref ref-type="bibr" rid="CR31">Ingram et al. 2008</xref>; <xref ref-type="bibr" rid="CR19">Cuccaro et al. 2012</xref>) focused on exploring empirical subgroups that aligned with pre-defined subgroups (such as ASD DSM-IV subtypes) or illuminated some knowledge on etiologically distinct subgroups i.e. which behavioral and physical phenotypes will most likely subdivide ASD. Since the introduction of the DSM-5, emphasis is placed on the spectrum of autism i.e. on a severity gradient under the diagnostic umbrella of Autism Spectrum Disorder. According to Georgiades et al. (<xref ref-type="bibr" rid="CR27">2013</xref>), the task of categorizing the clinical heterogeneity in children with autism is still of critical importance, regardless of how the DSM changes its definition. Hence, there have been even more studies (<xref ref-type="bibr" rid="CR28">Georgiades et al. 2013</xref>; <xref ref-type="bibr" rid="CR52">Ousley and Cermak 2014</xref>; <xref ref-type="bibr" rid="CR59">Veatch et al. 2014</xref>; <xref ref-type="bibr" rid="CR50">Obafemi-Ajayi et al. 2015</xref>; <xref ref-type="bibr" rid="CR3">Al-Jabery et al. 2016</xref>; <xref ref-type="bibr" rid="CR48">Nguyen et al. 2018</xref>) that attempt to better classify the ASD heterogeneity under DSM-5 using a varied set of ASD phenotype data. Some ASD studies (<xref ref-type="bibr" rid="CR17">Chaste et al. 2015</xref>) suggest that attempts to stratify children based on phenotype will not increase the power of ASD genetic discovery studies. This is possibly true when the methods are limited by a very restricted set of phenotyping variables (diagnosis, IQ, age at first words, ASD severity, insistence sameness, and symptom profiles) and do not account for possible outliers in the dataset. Spencer et al. (<xref ref-type="bibr" rid="CR57">2018</xref>) demonstrated that ASD phenotype subgroups could aid discovery of novel ASD genes. It is important to employ clustering methods that simultaneously identify and remove possible outliers that could be skewing the results and add pertinent and relevant phenotype ingredients that may uncover meaningful subtypes. Ultimately, the validity of any subgrouping paradigm depends on whether the ASD subgroups actually uncover/expose some biologic or genetic variation, which can be used to predict prognosis, recurrence risks or treatment responses. Hence, in this work, we also apply rigorous statistical analysis to validate the significance of the results as well as guide the optimal clustering configuration selection.</p>
</sec>
<sec id="Sec3">
<title>Clustering framework</title>
<sec id="Sec4">
<title>NBR-Clust Algorithm</title>
<p>Node-based resilience measures compute a critical attack set of nodes <italic>S</italic>⊂<italic>V</italic> whose removal disconnects the network with relative severity. Given a node-based resilience measure, NBR-Clust conducts robust clustering by using the set of components that result from the removal of the computed critical attack set as a basis for the set of clusters. We explore the following three node-based resilience measures in this work: vertex attack tolerance (VAT), integrity, and tenacity.</p>
<p>The VAT of an undirected, connected graph G = (V, E) is denoted <italic>τ</italic>(<italic>G</italic>) and defined as (<xref ref-type="bibr" rid="CR24">Ercal 2014</xref>; <xref ref-type="bibr" rid="CR42">Matta et al. 2017</xref>) 
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \tau(G) = \min_{S \subset V, S \neq \emptyset} \left\{\frac{|S|}{|V-S-C_{max}(V-S)|+1} \right\}  $$ \end{document}</tex-math><mml:math id="M2"><mml:mi>τ</mml:mi><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>min</mml:mo></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mo>⊂</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>≠</mml:mo><mml:mi>∅</mml:mi></mml:mrow></mml:munder><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:mi>S</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">max</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><graphic position="anchor" xlink:href="41109_2018_93_Article_Equ1.gif"></graphic></alternatives></disp-formula></p>
<p>where <italic>S</italic> is an attack set and <italic>C</italic><sub><italic>max</italic></sub>(<italic>V</italic>−<italic>S</italic>) is the largest connected component in <italic>V</italic>−<italic>S</italic>.</p>
<p>Normalized integrity (<xref ref-type="bibr" rid="CR11">Barefoot et al. 1987</xref>) is defined as 
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ I(G) = \min_{S \subset V} \left\{ \frac{|S| + C_{max}(V-S)}{|V|} \right\}.  $$ \end{document}</tex-math><mml:math id="M4"><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>min</mml:mo></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mo>⊂</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">max</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>V</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mi>.</mml:mi></mml:math><graphic position="anchor" xlink:href="41109_2018_93_Article_Equ2.gif"></graphic></alternatives></disp-formula></p>
<p>Tenacity (<xref ref-type="bibr" rid="CR18">Cozzens et al. 1995</xref>) is defined as 
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ T(G) = \min_{S \subset V}\left\{\frac{|S|+C_{max}(V-S)}{\omega (V-S)}\right\},  $$ \end{document}</tex-math><mml:math id="M6"><mml:mi>T</mml:mi><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>min</mml:mo></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mo>⊂</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">max</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>ω</mml:mi><mml:mo>(</mml:mo><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic position="anchor" xlink:href="41109_2018_93_Article_Equ3.gif"></graphic></alternatives></disp-formula></p>
<p>where <italic>ω</italic>(<italic>V</italic>−<italic>S</italic>) is the number of connected components in <italic>V</italic>−<italic>S</italic>.</p>
<p>Traditional clustering usually ensures assignment of all nodes to a specific cluster. In complex datasets, some nodes could be outliers (nodes that don’t really belong to a specific cluster) or overlapping nodes (i.e. nodes that could be assigned to more than one cluster). In these scenarios, the critical attack set may be used to determine outliers or overlap data points(<xref ref-type="bibr" rid="CR44">Matta et al. 2016</xref>; <xref ref-type="bibr" rid="CR13">Borwey et al. 2015</xref>). In this work, we consider both the traditional complete clustering scenario where all critical attack nodes are reassigned to cluster-components, as well as the non-traditional situation where the critical attack set is removed from the base clusters (i.e. without node reassignment). Given that we are clustering phenotype data that could involve some errors from the data collection process, outliers would imply potential erroneous data points. Removal of these outliers may result in better defined clusters. Overlap nodes could also be a pertinent feature, like in biological networks when proteins are classified to different clusters to reflect their multiple functions. However, the concept of overlap nodes is not clearly defined for medical data. We plan to explore this concept further in future work.</p>
<p>The NBR-Clust algorithm consists of four main phases: 
<list list-type="simple"><list-item><label>i)</label><p>Transform point data into a graph G;</p></list-item><list-item><label>ii)</label><p>Approximate resilience measure of graph, R(G), with acceptable accuracy, and return the candidate attack set S whose removal results in some number of candidate groupings (components C);</p></list-item><list-item><label>iii)</label><p>Perform a node-assignment strategy that assigns each node of S to a component C from step ii;</p></list-item><list-item><label>iv)</label><p>If more clusters are desired, choose the component with the lowest resilience measure and divide it into additional components using steps ii and iii. If fewer clusters are desired, join components with the greatest number of adjacent edges. The dividing and combining can continue until a desired number of clusters is obtained.</p></list-item></list></p>
<p>The VAT-Clust, Integrity-Clust, and Tenacity-Clust algorithms (<xref ref-type="bibr" rid="CR13">Borwey et al. 2015</xref>; <xref ref-type="bibr" rid="CR44">Matta et al. 2016</xref>) utilize a heuristic known as Greedy-betweenness centrality (Greedy-BC). The <italic>betweenness centrality</italic> of a node is the ratio of shortest paths that include that node to the total number of shortest paths. High betweenness centrality is a measure of the importance of a node, as it implies that the node is more likely to be part of a path used when traversing the graph. The Greedy-BC heuristic estimates candidate attack sets by repeatedly taking the highest betweenness node, removing it from the network, taking the next highest betweenness node, removing it from the network, etc. Matta (<xref ref-type="bibr" rid="CR41">2017</xref>); Matta et al. (<xref ref-type="bibr" rid="CR42">2017</xref>) demonstrated that Greedy-BC approximates VAT, integrity and tenacity with acceptable accuracy. We implemented the NBR-Clust framework using weighted betweenness centrality computations (<xref ref-type="bibr" rid="CR14">Brandes 2001</xref>).</p>
<p>In the NBR-Clust method, if there is a desired number of clusters <italic>k</italic> for the output clustering configuration, a regrouping or hierarchical (<xref ref-type="bibr" rid="CR13">Borwey et al. 2015</xref>) algorithm can be applied to attain this. None of the three clustering algorithms are guaranteed to output an exact <italic>k</italic> number of clusters. When more clusters are produced than desired, we regroup clusters by finding the pair of current components C1 and C2 that maximizes the normalized cut quantity: E(C1,C2)/(C1*C2), where E(C1,C2) is the number of edges between C1 and C2 and C1*C2 is the product of the number of nodes in C1 and the number of nodes in C2. C1 and C2 are combined into one cluster. Regrouping of clusters is repeated until the desired number of clusters is obtained. If the algorithm outputs fewer clusters than desired, then the hierarchical approach (<xref ref-type="bibr" rid="CR13">Borwey et al. 2015</xref>) is applied to split the clusters till the specified number of clusters is achieved.</p>
</sec>
<sec id="Sec5">
<title>Data preprocessing</title>
<p>Given that the sample was drawn from a rigorous data collection (Simons Simplex Collection (<xref ref-type="bibr" rid="CR25">Fischbach and Lord 2010</xref>), it contained very few missing values, approximately 0.1% missing values. Majority of the missing values were localized in two features, out of a total of 36 features. To impute missing values for these two attributes we used a standard regression, computed in Matlab, on the remaining 34 attributes to determine likely values. For other features that had very few missing values (0.002<italic>%</italic>), the mean of the remaining values for the specific feature was used.</p>
<p>Feature selection is commonly used for selecting a small subset of features for building a learning model with good generalization performance (<xref ref-type="bibr" rid="CR32">Guyon and Elisseeff 2003</xref>). Usually, the task of a feature selection algorithm is to prune the feature space by eliminating as many irrelevant and redundant features as possible and thus reducing the dimensionality of the dataset. In the dataset used, the number of features is relatively small compared to the number of examples. We apply the correlation filter algorithm introduced in (<xref ref-type="bibr" rid="CR49">Obafemi-Ajayi et al. 2017</xref>) to exclude highly correlated features from the subsequent analysis. The filter algorithm automatically identifies and filters highly correlated features using pairwise Pearson correlation function based on a user defined threshold value. In this work, we investigate the effect of applying the correlation filter prior to clustering vs. simply using the entire set of features.</p>
</sec>
<sec id="Sec6">
<title>Graph representations</title>
<p>To apply the NBR-Clust framework on our dataset, we first convert the data into a k-nearest neighbor (kNN) graph <italic>G</italic>. In a kNN graph <italic>G</italic><sub><italic>k</italic></sub>, vertices <italic>u</italic> and <italic>v</italic> have an edge between them if <italic>v</italic> is amongst the <italic>k</italic> closest vertices to <italic>u</italic> with respect to the distance metric considered. While any distance metric may be used to determine nearness of neighbors, we use the <italic>n</italic>-dimensional Euclidean distance following normalization of the feature space, where <italic>n</italic> is the number of features considered.</p>
<p>In both (<xref ref-type="bibr" rid="CR44">Matta et al. 2016</xref>; <xref ref-type="bibr" rid="CR20">Cukierski and Foran 2008</xref>) evidence is presented in favor of minimal connectivity (min-conn) parameter <italic>k</italic> in the construction of kNN graph <italic>G</italic><sub><italic>k</italic></sub>. Min-conn <italic>k</italic> implies choosing the minimal <italic>k</italic> such that <inline-formula id="IEq1"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\phantom {\dot {i}\!}\: \forall \;k' \ge k \; \forall _{(u, v \in V)} \; \exists \text { \textit {u-v} path in} G_{k'}$\end{document}</tex-math><mml:math id="M8"><mml:mspace width="2.22144pt"></mml:mspace><mml:mo>∀</mml:mo><mml:mspace width="2.77626pt"></mml:mspace><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>≥</mml:mo><mml:mi>k</mml:mi><mml:mspace width="2.77626pt"></mml:mspace><mml:msub><mml:mrow><mml:mo>∀</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mspace width="2.77626pt"></mml:mspace><mml:mo>∃</mml:mo><mml:mtext>u-v path in</mml:mtext><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq1.gif"></inline-graphic></alternatives></inline-formula>. Additional information may be revealed at different levels of connectivity. A graph where parameter <italic>k</italic> is above connectivity contains more information in the form of additional edges. If nodes that should be clustered together are near to each other, edges are more likely to be added within potential clusters than between them. This will make it easier to identify clusters, and may give better clustering results than graphs where <italic>k</italic> is at minimum connectivity. The cost of using additional information is increased time and complexity.</p>
<p>We consider three different connectivity settings for <italic>k</italic> in the kNN graph construction: min-conn, min-conn+1, and min-conn+2.</p>
</sec>
<sec id="Sec7">
<title>Determining optimal clustering configuration</title>
<p>We applied a holistic approach in determining the most optimal set of results per resilience measure (VAT, Integrity, and Tenacity) using three main criteria: internal cluster validation indices (ICVIs), graph quality measures, and distribution of resulting clusters. Clustering configurations that resulted in clusters with very few nodes (i.e. less than 10) were discarded, given that we had a total of 2680 nodes to cluster. Highly un-skewed clustering configurations tend to bias the cluster validation indices.</p>
<p>An internal cluster validation index determines the optimal clustering solution most appropriate for the input dataset based on two measurement criteria: Compactness and Separateness (<xref ref-type="bibr" rid="CR33">Kovács et al. 2005</xref>). Compactness measures how close the members of each cluster are to each other. Separateness measures how separated the clusters are from each other. The optimal cluster configuration should yield clusters that are compact and well separated. We explored the application of nine commonly used ICVIs (Liu et al. <xref ref-type="bibr" rid="CR35">2010</xref>, <xref ref-type="bibr" rid="CR36">2013</xref>; Aggarwal and Reddy <xref ref-type="bibr" rid="CR2">2013</xref>) (Silhouette index (SI), Davies-Bouldin (DB) index, Dunn’s index, Xie-Beni index (XB), Calinski-Harabasz (CH) index, I index (I), SD validity index (SD), S_Dbw validity index (S_Dbw), and Clustering Validation index based on Nearest Neighbors (CVNN)) on the clustering results to measure the goodness of the clusters. The metrics are described fully in (Liu et al. <xref ref-type="bibr" rid="CR35">2010</xref>, <xref ref-type="bibr" rid="CR36">2013</xref>) and were implemented following their guidelines. We applied a large number of ICVIs to attain a more robust decision, given multiple studies (<xref ref-type="bibr" rid="CR16">Brun et al. 2007</xref>; <xref ref-type="bibr" rid="CR60">Vendramin et al. 2010</xref>; <xref ref-type="bibr" rid="CR7">Arbelaitz et al. 2013</xref>; <xref ref-type="bibr" rid="CR36">Liu et al. 2013</xref>) that demonstrate the diversity in range of results chosen by different indices. The optimal number of clusters is determined based on the majority vote of the validation indices along with the graph validation measures. A summary of these internal validation metrics utilized in this work for selecting the optimal clustering configuration is presented in Table <xref ref-type="table" rid="Tab1">1</xref>. The notations and definitions employed are similar to those presented in (<xref ref-type="bibr" rid="CR36">Liu et al. 2013</xref>).
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Summary of internal cluster validation used to determine optimal clustering configuration</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Validation Metric</th><th align="left">Mathematical Description</th><th align="left">Optimal Value</th></tr></thead><tbody><tr><td align="left">Silhouette index (SI)</td><td align="left"><inline-formula id="IEq2"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\frac {1}{k}{\sum \nolimits }_{i}^{}\bigg \{\frac {1}{n_{i}}{\sum \nolimits }_{x \in C_{i}}^{}\frac {b(x)-a(x)}{\max _{x}[b(x),a(x)]}\bigg \}$\end{document}</tex-math><mml:math id="M10"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow></mml:mrow></mml:msubsup><mml:mstyle mathsize="2.03em"><mml:mfenced close="" open="{" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:mi>b</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:munder><mml:mo>[</mml:mo><mml:mi>b</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>]</mml:mo></mml:mrow></mml:mfrac><mml:mstyle mathsize="2.03em"><mml:mfenced close="" open="}" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq2.gif"></inline-graphic></alternatives></inline-formula> where</td><td align="left">Max</td></tr><tr><td align="left"></td><td align="left"><inline-formula id="IEq3"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$a(x) = \frac {1}{n_{i} - 1} {\sum \nolimits }_{y \in c_{i}, y \neq x} d(x,y)$\end{document}</tex-math><mml:math id="M12"><mml:mi>a</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>≠</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq3.gif"></inline-graphic></alternatives></inline-formula> and</td><td align="left"></td></tr><tr><td align="left"></td><td align="left">
<inline-formula id="IEq4"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$b(x) = min_{j, j\neq i}\bigg [ \frac {1}{n_{j}} {\sum \nolimits }_{y \in C_{j}} d(x,y) \bigg ]$\end{document}</tex-math><mml:math id="M14"><mml:mi>b</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">mi</mml:mtext><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mstyle mathsize="2.03em"><mml:mfenced close="" open="[" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo><mml:mstyle mathsize="2.03em"><mml:mfenced close="" open="]" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq4.gif"></inline-graphic></alternatives></inline-formula>
</td><td align="left"></td></tr><tr><td align="left">Calinski-Harabasz index (CH)</td><td align="left">
<inline-formula id="IEq5"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\frac {{\sum \nolimits }_{i}^{}n_{i}d^{2}(c_{i},c)/(k-1)}{{\sum \nolimits }_{i}^{}{\sum \nolimits }_{x \in C_{i}}^{}d^{2}(x,c_{i})/(N-k)}$\end{document}</tex-math><mml:math id="M16"><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq5.gif"></inline-graphic></alternatives></inline-formula>
</td><td align="left">Max</td></tr><tr><td align="left">Davies-Bouldin index (DB)</td><td align="left">
<inline-formula id="IEq6"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\frac {1}{k}\sum _{i}\max _{j, j \neq i} \bigg [ \frac {\frac {1}{n_{i}}\sum _{x \in C_{i}}d(x,c_{i}) + \frac {1}{n_{j}}\sum _{x \in C_{j}}d(x, c_{j})}{d(c_{i},c_{j})}\bigg ]$\end{document}</tex-math><mml:math id="M18"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mstyle mathsize="2.03em"><mml:mfenced close="" open="[" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle><mml:mfrac><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mstyle mathsize="2.03em"><mml:mfenced close="" open="]" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq6.gif"></inline-graphic></alternatives></inline-formula>
</td><td align="left">Min</td></tr><tr><td align="left">Dunn’s index</td><td align="left">
<inline-formula id="IEq7"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\min _{i}\bigg [\min _{j}\frac {\min _{x \in C_{i}, y \in C_{j}}d(x,y)}{\max _{k} \{\max _{x,y \in C_{k}} d(x,y) \}}\bigg ]$\end{document}</tex-math><mml:math id="M20"><mml:munder><mml:mrow><mml:mo>min</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mstyle mathsize="2.03em"><mml:mfenced close="" open="[" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle><mml:munder><mml:mrow><mml:mo>min</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:munder><mml:mrow><mml:mo>min</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mo>{</mml:mo><mml:munder><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mfrac><mml:mstyle mathsize="2.03em"><mml:mfenced close="" open="]" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq7.gif"></inline-graphic></alternatives></inline-formula>
</td><td align="left">Max</td></tr><tr><td align="left">Xie-Beni index (XB)</td><td align="left">
<inline-formula id="IEq8"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\frac {\sum _{i}\sum _{x \in C_{i}}d^{2}(x,c_{i})} { N \min _{i,j \neq i}d^{2}(c_{i},c_{j})}$\end{document}</tex-math><mml:math id="M22"><mml:mfrac><mml:mrow><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:munder><mml:mrow><mml:mo>min</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq8.gif"></inline-graphic></alternatives></inline-formula>
</td><td align="left">Min</td></tr><tr><td align="left">SD validity index (SD)</td><td align="left"><italic>D</italic><italic>i</italic><italic>s</italic>(<italic>k</italic><sub><italic>max</italic></sub>)<italic>S</italic><italic>c</italic><italic>a</italic><italic>t</italic>(<italic>k</italic>)+<italic>D</italic><italic>i</italic><italic>s</italic>(<italic>k</italic>) where</td><td align="left">Min</td></tr><tr><td align="left"></td><td align="left"><inline-formula id="IEq9"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$Scat(k) = \frac {1}{k}\sum _{i}||\sigma (C_{i})|| / ||\sigma (D)||$\end{document}</tex-math><mml:math id="M24"><mml:mtext mathvariant="italic">Scat</mml:mtext><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mo>/</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mo>)</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq9.gif"></inline-graphic></alternatives></inline-formula> and</td><td align="left"></td></tr><tr><td align="left"></td><td align="left">
<inline-formula id="IEq10"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$Dis(k) = \frac {\max _{i,j}d(c_{i},c_{j})}{\min _{i,j}d(c_{i},c_{j})}\sum _{i}\Big [\sum _{j}d(c_{i},c_{j})\Big ]^{-1}$\end{document}</tex-math><mml:math id="M26"><mml:mtext mathvariant="italic">Dis</mml:mtext><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mo>min</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mstyle mathsize="1.61em"><mml:mfenced close="" open="[" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:msup><mml:mrow><mml:mstyle mathsize="1.61em"><mml:mfenced close="" open="]" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq10.gif"></inline-graphic></alternatives></inline-formula>
</td><td align="left"></td></tr><tr><td align="left">S_Dbw validity Index (SD_Dbw)</td><td align="left"><italic>S</italic><italic>c</italic><italic>a</italic><italic>t</italic>(<italic>k</italic>)+<italic>D</italic><italic>e</italic><italic>n</italic><italic>s</italic>_<italic>b</italic><italic>w</italic>(<italic>k</italic>) where</td><td align="left">Min</td></tr><tr><td align="left"></td><td align="left">
<inline-formula id="IEq11"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$Dens\_bw(k) = \frac {1}{k(k-1)} \sum \limits _{i} \bigg [ \sum \limits _{j, j \neq i} \frac {\sum \limits _{x \in C_{i} \cup C_{j}}f(x, u_{ij})}{max \big \{ \sum \limits _{x \in C_{i}}f(x,c_{i}),\sum \limits _{x \in C_{j}}f(x,c_{j}) \big \}} \bigg ]$\end{document}</tex-math><mml:math id="M28"><mml:mtext mathvariant="italic">Dens_bw</mml:mtext><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mstyle mathsize="2.03em"><mml:mfenced close="" open="[" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ij</mml:mtext></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">max</mml:mtext><mml:mstyle mathsize="1.19em"><mml:mfenced close="" open="{" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mstyle mathsize="1.19em"><mml:mfenced close="" open="}" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle></mml:mrow></mml:mfrac><mml:mstyle mathsize="2.03em"><mml:mfenced close="" open="]" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq11.gif"></inline-graphic></alternatives></inline-formula>
</td><td align="left"></td></tr><tr><td align="left"><italic>I</italic> index</td><td align="left">
<inline-formula id="IEq12"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\bigg [\frac {\sum _{x \in D}d(x,c)}{k \sum _{i}\sum _{x \in C_{i}}d(x,c_{i})}\max _{i,j}d(c_{i},c_{j})\bigg ]^{p}$\end{document}</tex-math><mml:math id="M30"><mml:mstyle mathsize="2.03em"><mml:mfenced close="" open="[" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle><mml:mfrac><mml:mrow><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:msup><mml:mrow><mml:mstyle mathsize="2.03em"><mml:mfenced close="" open="]" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq12.gif"></inline-graphic></alternatives></inline-formula>
</td><td align="left">Max</td></tr><tr><td align="left">CVNN index</td><td align="left"><inline-formula id="IEq13"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$ \frac {Sep(k,NN)}{\max \limits _{k}SEP(k,NN)} + \frac {Com(k)}{\max \limits _{k}Com(k)} $\end{document}</tex-math><mml:math id="M32"><mml:mfrac><mml:mrow><mml:mtext mathvariant="italic">Sep</mml:mtext><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mtext mathvariant="italic">NN</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mtext mathvariant="italic">SEP</mml:mtext><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mtext mathvariant="italic">NN</mml:mtext><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mtext mathvariant="italic">Com</mml:mtext><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mtext mathvariant="italic">Com</mml:mtext><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq13.gif"></inline-graphic></alternatives></inline-formula> where</td><td align="left">Min</td></tr><tr><td align="left"></td><td align="left"><inline-formula id="IEq14"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$Com(k) = \sum _{i}\Big [\frac {2}{n_{i}(n_{i}-1)}\sum \limits _{x,y \in C_{i}}d(x,y)\Big ]$\end{document}</tex-math><mml:math id="M34"><mml:mtext mathvariant="italic">Com</mml:mtext><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mstyle mathsize="1.61em"><mml:mfenced close="" open="[" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo><mml:mstyle mathsize="1.61em"><mml:mfenced close="" open="]" separators=""><mml:mrow></mml:mrow></mml:mfenced></mml:mstyle></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq14.gif"></inline-graphic></alternatives></inline-formula> and</td><td align="left"></td></tr><tr><td align="left"></td><td align="left"><inline-formula id="IEq15"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$Sep(k,NN) = \max _{i}(\frac {1}{n_{i}}\sum _{j}^{n_{i}}\frac {q_{j}}{NN})$\end{document}</tex-math><mml:math id="M36"><mml:mtext mathvariant="italic">Sep</mml:mtext><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mtext mathvariant="italic">NN</mml:mtext><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">NN</mml:mtext></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="41109_2018_93_Article_IEq15.gif"></inline-graphic></alternatives></inline-formula> where</td><td align="left"></td></tr><tr><td align="left"></td><td align="left"><italic>O</italic><sub><italic>j</italic></sub> is the jth object in <italic>C</italic><sub><italic>i</italic></sub>, and <italic>q</italic><sub><italic>j</italic></sub> is the number of nearest neighbors</td><td align="left"></td></tr><tr><td align="left"></td><td align="left">of <italic>O</italic><sub><italic>j</italic></sub> which are not in cluster <italic>C</italic><sub><italic>i</italic></sub>.</td><td align="left"></td></tr></tbody></table><table-wrap-foot><p><italic>D</italic> denote the data set; <italic>N</italic>: number of objects in <italic>D</italic>; <italic>C</italic>: center of <italic>D</italic>;</p><p><italic>k</italic>: number of clusters; <italic>C</italic><sub><italic>i</italic></sub>: the i–th cluster; <italic>n</italic><sub><italic>i</italic></sub>: number of objects in <italic>C</italic><sub><italic>i</italic></sub>;</p><p><italic>c</italic><sub><italic>i</italic></sub>: center of <italic>C</italic><sub><italic>i</italic></sub>; <italic>d</italic>(<italic>x</italic>,<italic>y</italic>): distance between <italic>x</italic> and <italic>y</italic>; NN : number of nearest neighbors</p></table-wrap-foot></table-wrap></p>
<p>Since the clustering is done on graph representations of the data, we also utilized specific graph quality measures to evaluate the quality of the resulting graphs: modularity (<xref ref-type="bibr" rid="CR47">Newman 2006</xref>) and conductance (<xref ref-type="bibr" rid="CR8">Arora et al. 2009</xref>). 
<list list-type="order"><list-item><p><bold>Modularity</bold>: This quantifies the strength of <italic>modules</italic> (analogous to clusters) created when clustering a graph. A graph with high modularity has more than expected edges internal to its modules, and fewer than expected edges between modules. We applied modularity to evaluate the “clusterability" of a graph based on a minimal threshold of 0.6.</p></list-item><list-item><p><bold>Conductance</bold>: The conductance of a cluster is the fraction of all edges in the graph that point outside the cluster (<xref ref-type="bibr" rid="CR62">Yang and Leskovec 2012</xref>). A low conductance implies a “better” cluster, because a higher proportion of a graph’s edges are internal to that cluster. For our experiments, clustering configurations were acceptable conductance-wise if they had a conductance value of 0.07 or less.</p></list-item></list></p>
</sec>
<sec id="Sec8">
<title>Feature Extraction Phase</title>
<p>The objective of this phase is to obtain a set of features that discriminate among the clusters, as these features could be potential biomarkers for delineating the ASD subgroups. We employed the BestFirst search method (<xref ref-type="bibr" rid="CR23">Eibe et al. 2016</xref>), implemented in Weka (<xref ref-type="bibr" rid="CR29">Hall et al. 2009</xref>). The BestFirst search method traverses the attribute (feature) space to find a good subset. The quality of the subset found is measured by an attribute subset evaluator. It performs a greedy hill climbing, i.e. searching forward from the empty set of attributes, toward the goal of finding the most locally predictive attributes. The CFS (Correlation-based Feature Selection) subset evaluator was used to determine the merit of each subset. The CFS subset evaluator (<xref ref-type="bibr" rid="CR26">Frank et al. 2016</xref>) assesses the predictive ability of each attribute individually and the degree of redundancy among them, preferring sets of attributes that are highly correlated with the class but with low inter-correlation.</p>
</sec>
</sec>
<sec id="Sec9">
<title>ASD phenotype data</title>
<sec id="Sec10">
<title>Description of phenotype features</title>
<p>The ASD sample analyzed in this work is drawn from the Simons Simplex Collection (SSC) (<xref ref-type="bibr" rid="CR25">Fischbach and Lord 2010</xref>) population, a comprehensive, rigorous, reliable and consistent dataset supported by the Simons Foundation for Autism Research Initiatives (SFARI). (Simplex indicates that only one child in the family is affected with ASD while both parents and at least one sibling are unaffected.) To ensure reliability of clustering results, individuals missing any Autism Diagnostic Interview-Revised (ADI-R) (<xref ref-type="bibr" rid="CR39">Lord et al. 1994</xref>) or Autism Diagnostic Observation Schedule (ADOS) (<xref ref-type="bibr" rid="CR38">Lord et al. 1989</xref>) scores were excluded. The final dataset consisted of 2680 subjects, 2316 males (86.4%) and 364 females (13.6%) between ages of 4 and 17 years old.</p>
<p>In cluster analysis, the quality of input features has a significant impact on the outcome. Hence, having a robust and diverse set of features is key to meaningful results. In contrast to previous work (<xref ref-type="bibr" rid="CR48">Nguyen et al. 2018</xref>; <xref ref-type="bibr" rid="CR43">Matta et al. 2017</xref>; <xref ref-type="bibr" rid="CR3">Al-Jabery et al. 2016</xref>; <xref ref-type="bibr" rid="CR50">Obafemi-Ajayi et al. 2015</xref>), we included some new sets of features: ADOS social affect score, word delay, ADI-R Q86 abnormality evident score, and ADI-R Q30 language total score. A total of 36 features (Table <xref ref-type="table" rid="Tab2">2</xref>) were used in this work that spanned core diagnostic (ADIR and ADOS scores), ASD-specific symptoms, cognitive and adaptive functioning (IQ score), language and communication profiles (Vineland adaptive measures and Social Responsiveness Scale (SRS) scores, regression, and word delay), behavioral problems (Aberrant Behavior Checklist (ABC), Repetitive Behavior Scale (RBS), and Child Behavior Checklist (CBCL) scores), and possible genetic indicators (Parents’ Broader Autism Phenotype Questionnaire (BAPQ) scores).
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Description of 36 phenotype features used to cluster ASD sample</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Category</th><th align="left">ASD phenotype features</th></tr></thead><tbody><tr><td align="justify">
<italic>ASD-specific symptom scores</italic>
</td><td align="justify">ADOS communication &amp; social interaction score</td></tr><tr><td align="justify"></td><td align="justify">ADOS restricted &amp; repetitive behavior score</td></tr><tr><td align="justify"></td><td align="justify">ADOS Social Affect score</td></tr><tr><td align="justify"></td><td align="justify">Social score (ADI-R A)</td></tr><tr><td align="justify"></td><td align="justify">Verbal score (ADI-R B)</td></tr><tr><td align="justify"></td><td align="justify">Repetitive and stereotyped patterns of behavior (ADI-R C)</td></tr><tr><td align="justify"></td><td align="justify">Abnormality evidence (ADI-R Q86)</td></tr><tr><td align="justify">
<italic>Cognitive &amp; Adaptive functions</italic>
</td><td align="justify">Vineland social score</td></tr><tr><td align="justify"></td><td align="justify">Vineland daily living skills score</td></tr><tr><td align="justify"></td><td align="justify">Verbal &amp; non-verbal IQ score</td></tr><tr><td align="justify">
<italic>Language &amp; Communication</italic>
</td><td align="justify">Vineland communication score</td></tr><tr><td align="justify"></td><td align="justify">Regression</td></tr><tr><td align="justify"></td><td align="justify">Word delay</td></tr><tr><td align="justify"></td><td align="justify">Overall Level of Language (ADI-R Q30)</td></tr><tr><td align="justify">
<italic>Behavioral problems</italic>
</td><td align="justify">ABC <sup><italic>a</italic></sup> aggregate scores (stereotype, lethargy, irritability, hyperactivity, inappropriate speech)</td></tr><tr><td align="justify"></td><td align="justify">RBS <sup><italic>b</italic></sup> aggregate scores (compulsive, self-injurious, stereotyped, ritualistic, restricted, and sameness behavior)</td></tr><tr><td align="justify"></td><td align="justify">CBCL <sup><italic>c</italic></sup> internalizing and externalizing problems T scores</td></tr><tr><td align="justify"></td><td align="justify">SRS <sup><italic>d</italic></sup> parent aggregate scores (awareness, cognition, communication, mannerisms, motivation)</td></tr><tr><td align="justify"></td><td align="justify">SRS <sup><italic>d</italic></sup> parent T score</td></tr><tr><td align="justify">
<italic>Genetic indicators</italic>
</td><td align="justify">BAPQ <sup><italic>e</italic></sup> mean overall scores (Father &amp; Mother)</td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>ABC: Aberrant Behavior Checklist;</p><p><sup>b</sup>RBS: Repetitive Behavior Scale</p><p><sup>c</sup>CBCL: Child Behavior Checklist;</p><p><sup>d</sup>SRS: Social Responsiveness Scale.</p><p><sup>e</sup>BAPQ: Broader Autism Phenotype Questionnaire</p></table-wrap-foot></table-wrap></p>
<p>All experimental analysis involving human subjects were carried out under the guidelines and approval of Missouri State University Institutional Review Board.</p>
</sec>
<sec id="Sec11">
<title>Statistical analysis of ASD outcome measures</title>
<p>Additional features, not used in clustering, were selected as outcome measures to assess the clinical relevance of resulting cluster configuration. These include overall (total) scores for ABC, RBS, IQ, Vineland II composite standard score as well as the ADOS calculated severity score (ADOS CSS), a history of non-febrile seizures (i.e. diagnosis of epilepsy), and Peabody Picture Vocabulary Test (PPVT-4A) standard score. Note that these outcome measures are not completely independent of the input features used for clustering. We included the total scores of each of the aggregate features (ABC, RBS, IQ, Vineland) applied in the cluster analysis, as these scores tend to provide an overall picture of the ASD severity level of the proband. For example, the Vineland composite score provides an overall picture of the adaptive functioning skills. The ADOS CSS is a quantitative variable calculated using the summation of the ADOS social communication and RRBs scores. It provides a continuous measure of overall ASD symptom severity that is less influenced by child characteristics, such as age and language skills, than raw totals (<xref ref-type="bibr" rid="CR30">Hus et al. 2014</xref>). It can be used to compare ASD symptom severity across individuals of different developmental levels. As such, they provide a "purer" metric of overall ASD severity. A higher level implies higher severity with 10 as the highest level of severity. The PPVT-4A score quantifies the language skill. A higher score implies fewer deficits, and better developed skills. The epilepsy data was only available for 99.85% of the sample.</p>
<p>To validate the significance of the differences (quantified by mean and standard deviation) in these outcome measures by clusters, we employed the univariate one-way analysis of variance (ANOVA) test along with the Tukey HSD test (pairwise comparisons) for continuous variables (all except epilepsy). The ANOVA p-value reported for each ASD measure generalizes the Student’s t test for between comparisons for multiple groups. The Tukey test informs us on which pairs of clusters are actually statistically different since the ANOVA’s p value only indicates that at least one cluster is statistically different from another. The eta squared test (<italic>η</italic><sup>2</sup>) was conducted to determine the overall effect size for each clustering configuration per feature. The effect size conveys the practical significance of the ANOVA results. The Cohen’s d test was also applied to quantify the effect sizes for each pairwise comparison.</p>
</sec>
</sec>
<sec id="Sec12">
<title>Evaluation results and analysis</title>
<sec id="Sec13">
<title>Experimental setup</title>
<p>In the evaluation of our model, we investigate the effect of the following parameters: 
<list list-type="bullet"><list-item><p>NBR measure: VAT, Integrity and Tenacity algorithms were employed with the NBR-Clust framework.</p></list-item><list-item><p>Critical attack set (<italic>S</italic>): we compared the performance of reassignment of all nodes belonging to <italic>S</italic> (i.e. complete clustering) to no node reassignment of <italic>S</italic>.</p></list-item><list-item><p>Connectivity level of the kNN graph representation: from minimum connectivity (kNN2) to two above connectivity (kNN4).</p></list-item><list-item><p>Use of correlation filter algorithm: the threshold value was set at 0.8. This resulted in removal of three features (ADOS Social Affect, Verbal IQ, and SRS T score). We compared the performance using the entire set of 36 features to clustering with only these 33 features (tagged as “corr” in the results).</p></list-item><list-item><p>Number of clusters (<italic>k</italic>): Based on prior work on subgrouping of ASD patients (Ingram et al. <xref ref-type="bibr" rid="CR31">2008</xref>; Cuccaro et al. <xref ref-type="bibr" rid="CR19">2012</xref>; Georgiades et al. <xref ref-type="bibr" rid="CR28">2013</xref>; Ousley and Cermak <xref ref-type="bibr" rid="CR52">2014</xref>; Veatch et al. <xref ref-type="bibr" rid="CR59">2014</xref>; Obafemi-Ajayi et al. <xref ref-type="bibr" rid="CR51">2015</xref>, b; Al-Jabery et al. <xref ref-type="bibr" rid="CR3">2016</xref>; Nguyen et al. <xref ref-type="bibr" rid="CR48">2018</xref>), we varied the number of clusters from <italic>k</italic>=2 to 5. The determination of the optimal number of clusters was independent of our NBR-Clust framework but rather based on what is reported in ASD literature and also from previous DSM-IV subtypes (<xref ref-type="bibr" rid="CR37">Lord et al. 2012</xref>).</p></list-item></list></p>
<p>Each feature was normalized between 0 and 1 using known standard score ranges for the phenotype feature. The source code of the NBR-Clust algorithm is publicly available at (<xref ref-type="bibr" rid="CR56">Node-Based Resilience Measure Clustering Project Website 2018</xref>) while the cluster validation platform suite is accessible at (<xref ref-type="bibr" rid="CR55">Nguyen and Obafemi-Ajayi 2017</xref>). The statistical analyses were implemented using IBM SPSS software while the feature extraction experiments were carried out in WEKA(<xref ref-type="bibr" rid="CR26">Frank et al. 2016</xref>).</p>
<p>The combinations of different levels of connectivity (kNN2, kNN3, kNN4) and using all features (36) versus correlation filtered set (33) resulted in a total of six base graphs. These six graphs were clustered using VAT-Clust, Integrity-Clust, and Tenacity-Clust, to yield results that had <italic>k</italic>=2, 3, 4 and 5 clusters with and without attack set node reassignment for a total of 144 different clustering output configurations.</p>
</sec>
<sec id="Sec14">
<title>Results</title>
<p>The critical attack set node reassignment results (traditonal clustering) are analyzed separately from without node reassignment (NR) configurations. The set of 7 optimal clustering configurations selected based on majority voting scheme of the nine ICVIs and graph quality measures per NBR measure algorithm is presented in Table <xref ref-type="table" rid="Tab3">3</xref>. The instances where the clustering output attained the best score for the specified ICVI or graph quality measure are highlighted in bold. All optimal configurations, except for Tenacity-Clust with node reassignment, were obtained from the kNN2 graphs, implying the usefulness of min-connectivity graphs, as expected. Four out of the seven groupings examined in Table <xref ref-type="table" rid="Tab3">3</xref> favored a 5-cluster configuration as optimal. In general, the filtered data set did not seem to demonstrate an impact on the clustering outcomes, except in the case of the kNN3 graphs.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Optimal Cluster configuration by graph type and resilience measures</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"></th><th align="left" colspan="4">Complete clustering</th><th align="left" colspan="3">No node reassignment</th></tr><tr><th align="left"></th><th align="left">Integrity k=3</th><th align="left">Tenacity k=5</th><th align="left">VAT k=4</th><th align="left">kNN3 Integrity <sup><italic>a</italic></sup>k=5</th><th align="left">VAT k=2</th><th align="left">Integrity k=5</th><th align="left">Tenacity k=5</th></tr></thead><tbody><tr><td align="left">Silhouette <italic>↑</italic></td><td align="justify">0.11</td><td align="justify">0.05</td><td align="justify">0.07</td><td align="justify">0.07</td><td align="justify">0.12</td><td align="justify">0.04</td><td align="justify">0.05</td></tr><tr><td align="left">Davies-Bouldin <italic>↓</italic></td><td align="justify">3.18</td><td align="justify">4.28</td><td align="justify">4.19</td><td align="justify">4.40</td><td align="justify">3.37</td><td align="justify">3.66</td><td align="justify">3.75</td></tr><tr><td align="left">Xie-Beni <italic>↓</italic></td><td align="justify">3.38</td><td align="justify">7.16</td><td align="justify">8.10</td><td align="justify">8.92</td><td align="justify">3.01</td><td align="justify">5.77</td><td align="justify">6.48</td></tr><tr><td align="left">Dunn <italic>↑</italic></td><td align="justify">0.13</td><td align="justify">0.15</td><td align="justify">0.15</td><td align="justify">0.17</td><td align="justify">0.14</td><td align="justify">0.14</td><td align="justify">0.14</td></tr><tr><td align="left">Calinski-Harabasz <italic>↑</italic></td><td align="justify">152.57</td><td align="justify">154.11</td><td align="justify">166.22</td><td align="justify">165.32</td><td align="justify">167.71</td><td align="justify">142.52</td><td align="justify">141.58</td></tr><tr><td align="left">I Index <italic>↑</italic></td><td align="justify">0.14</td><td align="justify">0.08</td><td align="justify">0.12</td><td align="justify">0.08</td><td align="justify">0.12</td><td align="justify">0.06</td><td align="justify">0.09</td></tr><tr><td align="left">SD Index <italic>↓</italic></td><td align="justify">9.96</td><td align="justify">14.62</td><td align="justify">14.40</td><td align="justify">20.10</td><td align="justify">8.52</td><td align="justify">7.71</td><td align="justify">9.10</td></tr><tr><td align="left">SDb w Index <italic>↓</italic></td><td align="justify">1.37</td><td align="justify">1.07</td><td align="justify">1.16</td><td align="justify">1.06</td><td align="justify">1.87</td><td align="justify">1.10</td><td align="justify">1.05</td></tr><tr><td align="left">CVNN Index <italic>↓</italic></td><td align="justify">1.38</td><td align="justify">0.95</td><td align="justify">1.21</td><td align="justify">0.54</td><td align="justify">2.00</td><td align="justify">2.00</td><td align="justify">2.00</td></tr><tr><td align="left">Separability <italic>↑</italic></td><td align="justify">31.63</td><td align="justify">11.14</td><td align="justify">20.21</td><td align="justify">8.34</td><td align="justify">8.53</td><td align="justify">11.39</td><td align="justify">15.25</td></tr><tr><td align="left">Modularity (&gt; 0.6)</td><td align="justify">0.42</td><td align="justify">0.72</td><td align="justify">0.65</td><td align="justify">0.68</td><td align="justify">0.27</td><td align="justify">0.67</td><td align="justify">0.68</td></tr><tr><td align="left">Conductance (&lt; 0.07)</td><td align="justify">0.02</td><td align="justify">0.04</td><td align="justify">0.03</td><td align="justify">0.06</td><td align="justify">0.06</td><td align="justify">0.05</td><td align="justify">0.04</td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>kNN3 using Integrity measure on correlation filtered data</p></table-wrap-foot></table-wrap></p>
<p>The visualizations of the set of 7 optimal clustering configurations, using the ForceAtlas layout algorithm in Gephi (<xref ref-type="bibr" rid="CR12">Bastian et al. 2009</xref>), are illustrated in Figs. <xref ref-type="fig" rid="Fig1">1</xref> and <xref ref-type="fig" rid="Fig2">2</xref>.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Visualization of optimal clustering results by resilience measure. NR indicates no reassignment of attack set nodes. <bold>a</bold> kNN2 Integrity k=3. Red nodes denotes C0, Blue: C2, and Green: C1. <bold>b</bold> kNN2 VAT k=2 NR. Red nodes denotes C0, and Blue: C1. <bold>c</bold> kNN2 VAT k=4. Red nodes de- notes C2, Blue: C3, Purple: C0, and Green: C1. <bold>d</bold> kNN2 Integrity k=5 NR. Red nodes denotes C0, Blue: C2, Gold: C1, Purple: C3, and Green: C4. <bold>e</bold> kNN2 Tenacity k=5. Red nodes denotes C2, Blue: C3, Gold: C0, Purple: C1, and Green: C4. <bold>f</bold> kNN2 Tenacity k=5 NR. Red nodes denotes C1, Blue: C2, Gold: C3, Purple: C0, and Green: C4</p></caption><graphic id="MO1" xlink:href="41109_2018_93_Fig1_HTML"></graphic></fig>
<fig id="Fig2"><label>Fig. 2</label><caption><p>Visualization of the graph of k=5 optimal clustering result for kNN3 with Integrity using the correlated filtered set. Red nodes denotes C2, Blue: C4, Gold: C0, Purple: C3, and Green: C1</p></caption><graphic id="MO2" xlink:href="41109_2018_93_Fig2_HTML"></graphic></fig></p>
<p>The demographics (mean age at ADOS, ethnicity as quantified by percentage Caucasian, and gender) of each cluster of the optimal clustering configurations are shown in Tables <xref ref-type="table" rid="Tab4">4</xref> and <xref ref-type="table" rid="Tab5">5</xref>. We observe that there are no significant differences in the demographics across clusters for age and gender distribution. However, the distribution of percentage Caucasian varied across clusters.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Demographics per cluster configuration with node reassignment</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"></th><th align="left" colspan="3">Integrity k=3</th><th align="left" colspan="4">VAT k=4</th><th align="left" colspan="4">Tenacity k=5</th><th align="left"></th></tr><tr><th align="left"></th><th align="left">C0</th><th align="left">C1</th><th align="left">C2</th><th align="left">C0</th><th align="left">C1</th><th align="left">C2</th><th align="left">C3</th><th align="left">C0</th><th align="left">C1</th><th align="left">C2</th><th align="left">C3</th><th align="left">C4</th></tr></thead><tbody><tr><td align="left">Mean age</td><td align="left">9.0</td><td align="left">8.4</td><td align="left">8.5</td><td align="left">8.9</td><td align="left">8.6</td><td align="left">8.9</td><td align="left">8.6</td><td align="left">9.0</td><td align="left">9.0</td><td align="left">8.9</td><td align="left">8.6</td><td align="left">8.6</td></tr><tr><td align="left">% Caucasian</td><td align="left">81.0</td><td align="left">64.5</td><td align="left">73.3</td><td align="left">78.3</td><td align="left">64.4</td><td align="left">83.9</td><td align="left">71.5</td><td align="left">82.6</td><td align="left">77.5</td><td align="left">83.7</td><td align="left">71.90</td><td align="left">69.3</td></tr><tr><td align="left">% Male</td><td align="left">86.4</td><td align="left">84.1</td><td align="left">87.2</td><td align="left">87.2</td><td align="left">84.9</td><td align="left">85.8</td><td align="left">87.2</td><td align="left">85.4</td><td align="left">89.7</td><td align="left">86.6</td><td align="left">87.4</td><td align="left">82.0</td></tr></tbody></table></table-wrap>
<table-wrap id="Tab5"><label>Table 5</label><caption><p>Demographics per cluster configuration without node reassignment</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"></th><th align="left" colspan="4">kNN2 Tenacity k=5</th><th align="left" colspan="2"></th><th align="left" colspan="4">kNN2 Integrity k=5</th><th align="left" colspan="2"></th><th align="left" colspan="3">kNN2 VAT k=2</th></tr><tr><th align="left"></th><th align="left">C0</th><th align="left">C1</th><th align="left">C2</th><th align="left">C3</th><th align="left">C4</th><th align="left">S</th><th align="left">C0</th><th align="left">C1</th><th align="left">C2</th><th align="left">C3</th><th align="left">C4</th><th align="left">S</th><th align="left">C0</th><th align="left">C1</th><th align="left">S</th></tr></thead><tbody><tr><td align="left">Mean age</td><td align="left">8.8</td><td align="left">9.0</td><td align="left">8.7</td><td align="left">8.9</td><td align="left">8.6</td><td align="left">9.32</td><td align="left">8.9</td><td align="left">8.8</td><td align="left">8.7</td><td align="left">9.3</td><td align="left">8.4</td><td align="left">9.6</td><td align="left">8.9</td><td align="left">8.6</td><td align="left">8.6</td></tr><tr><td align="left">% Caucasian</td><td align="left">78.7</td><td align="left">85.3</td><td align="left">71.1</td><td align="left">74.5</td><td align="left">64.5</td><td align="left">77.8</td><td align="left">83.8</td><td align="left">77.4</td><td align="left">71.6</td><td align="left">79.3</td><td align="left">67.2</td><td align="left">83.3</td><td align="left">79.9</td><td align="left">71.7</td><td align="left">74.5</td></tr><tr><td align="left">% Male</td><td align="left">88.3</td><td align="left">85.3</td><td align="left">86.3</td><td align="left">86.1</td><td align="left">84.9</td><td align="left">100.0</td><td align="left">86.0</td><td align="left">85.1</td><td align="left">87.3</td><td align="left">88.5</td><td align="left">85.4</td><td align="left">94.4</td><td align="left">86.1</td><td align="left">87.2</td><td align="left">90.2</td></tr></tbody></table></table-wrap></p>
<p>Statistical analyses of the optimal clustering configurations for each ASD outcome measures are presented in Tables <xref ref-type="table" rid="Tab6">6</xref> and <xref ref-type="table" rid="Tab7">7</xref>. Note that for the no node reassignment results (Table <xref ref-type="table" rid="Tab7">7</xref>), though the mean and standard deviation values for <italic>S</italic> is reported for each outcome measure, it is excluded from the Anova, Tukey and Eta-squared analysis. Higher values of ADOS CSS, RBS, ABC and SRS scores implies greater ASD severity levels while higher values of full scale IQ, Vineland composite, and PPVT 4A scores implies lesser ASD severity levels. (The cohen effect size pairwise comparison results are included as a Additional file <xref ref-type="media" rid="MOESM1">1</xref>). We can observe that the overall effect sizes, as quantified by the <italic>η</italic><sup>2</sup> value is consistently high for kNN2 Tenacity 5-Cluster result in Table <xref ref-type="table" rid="Tab6">6</xref>. Cluster C4 appears to be the most severe ASD subgrouping in terms of low overall IQ, relatively high occurrence epilepsy (non-febrile seizures), low functioning skills (as quantified by the Vineland composite scores), and high ADOS CSS scores. However, their ABC and RBS-R scores are not the most severe scores, and are slightly better compared to cluster C0. Cluster C0 has very high mean IQ scores (not the highest - C2), but the ABC and RBS-R scores for that subgroup are the lowest. For the no node reassignment analysis (Table <xref ref-type="table" rid="Tab7">7</xref>), the 2-cluster VAT-clust result does not seem to convey much practical significance based on the relatively low <italic>η</italic><sup>2</sup> values across all ASD outcome measures evaluated.
<table-wrap id="Tab6"><label>Table 6</label><caption><p>Statistical analysis of optimal clustering configurations (complete clustering) by graph type and node resilience measure using selected ASD outcome measures</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Cluster (size)</th><th align="left">ABC overall</th><th align="left">RBS R overall</th><th align="left">ADOS CSS</th><th align="left">Vineland composite score</th><th align="left">Overall IQ</th><th align="left">PPVTA 4A</th><th align="left">Epilepsy</th></tr></thead><tbody><tr><td align="justify" colspan="4">kNN 2 Integrity k=3</td><td align="left" colspan="4"></td></tr><tr><td align="justify">C0 (1903)</td><td align="justify">45.73(25.8)</td><td align="justify">27.31(18.1)</td><td align="justify">7.37(1.7)</td><td align="justify">75.72(10.9)</td><td align="left">88.19(23.5)</td><td align="left">91.51(24.7)</td><td align="left">1.74%</td></tr><tr><td align="justify">C1 (189)</td><td align="justify">54.08(24.6)</td><td align="justify">29.01(13.8)</td><td align="justify">7.58(1.5)</td><td align="justify">57.57(9.6)</td><td align="left">38.91(18.7)</td><td align="left">41.75(22.3)</td><td align="left">6.91%</td></tr><tr><td align="justify">C2 (588)</td><td align="justify">47.55(25.9)</td><td align="justify">26.26(16.3)</td><td align="justify">7.63(1.6)</td><td align="justify">70.58(12.3)</td><td align="left">69.99(27.6)</td><td align="left">72.41(28.8)</td><td align="left">2.73%</td></tr><tr><td align="justify">ANOVA <italic>p</italic>-value</td><td align="justify">&lt; 0.001</td><td align="justify">0.15</td><td align="justify">0.003</td><td align="justify">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="left"></td></tr><tr><td align="justify">Tukey HSD (NS <italic>‡</italic>)</td><td align="justify">C0:C2</td><td align="justify">All pairs</td><td align="justify">C1:C0,C2</td><td align="justify">None</td><td align="left">None</td><td align="left">None</td><td align="left"></td></tr><tr><td align="justify">Eta-squared (<italic>η</italic><sup>2</sup>)</td><td align="justify">0.007</td><td align="justify">0.001</td><td align="justify">0.004</td><td align="justify">0.157</td><td align="left">0.244</td><td align="left">0.209</td><td align="left"></td></tr><tr><td align="justify" colspan="4">kNN 2 VAT k=4</td><td align="left" colspan="4"></td></tr><tr><td align="justify">C0 (811)</td><td align="justify">50.86 (28.0)</td><td align="justify">31.76 (19.6)</td><td align="justify">7.48 (1.7)</td><td align="justify">72.69 (10.3)</td><td align="left">80.06 (22.8)</td><td align="left">82.98 (24.1)</td><td align="left">2.47%</td></tr><tr><td align="justify">C1 (219)</td><td align="justify">60.02 (28.5)</td><td align="justify">32.33 (17.4)</td><td align="justify">7.68 (1.5)</td><td align="justify">57.74 (9.4)</td><td align="left">39.55 (18.7)</td><td align="left">41.93 (21.3)</td><td align="left">5.99%</td></tr><tr><td align="justify">C2 (1117)</td><td align="justify">41.55 (22.2)</td><td align="justify">23.89 (15.4)</td><td align="justify">7.24 (1.7)</td><td align="justify">78.16 (10.4)</td><td align="left">94.77 (20.8)</td><td align="left">98.34 (22.1)</td><td align="left">1.25%</td></tr><tr><td align="justify">C3 (535)</td><td align="justify">45.73 (25.2)</td><td align="justify">25.08 (16.0)</td><td align="justify">7.70 (1.6)</td><td align="justify">70.50 (12.8)</td><td align="left">69.12 (28.2)</td><td align="left">71.39 (29.1)</td><td align="left">2.82%</td></tr><tr><td align="justify">ANOVA <italic>p-value</italic></td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="left"></td></tr><tr><td align="justify">Tukey HSD (NS<sup>a</sup>)</td><td align="justify">None</td><td align="justify">C0:C1;C2:C3</td><td align="justify">C0:C1,C3 C1:C3</td><td align="justify">None</td><td align="left">None</td><td align="left">None</td><td align="left"></td></tr><tr><td align="justify">Eta-squared (<italic>η</italic><sup>2</sup>)</td><td align="justify">0.047</td><td align="justify">0.046</td><td align="justify">0.013</td><td align="justify">0.212</td><td align="left">0.322</td><td align="left">0.288</td><td align="left"></td></tr><tr><td align="justify" colspan="4">kNN 2 Tenacity k=5</td><td align="left" colspan="4"></td></tr><tr><td align="justify">C0 (535)</td><td align="justify">67.12(21.5)</td><td align="justify">41.78(18.2)</td><td align="justify">7.30(1.7)</td><td align="justify">73.71(9.7)</td><td align="left">91.46(21.6)</td><td align="left">96.46 (23.8)</td><td align="left">1.31%</td></tr><tr><td align="justify">C1 (497)</td><td align="justify">36.57(19.6)</td><td align="justify">22.10(12.6)</td><td align="justify">7.40(1.6)</td><td align="justify">74.56(10.2)</td><td align="left">80.65(22.5)</td><td align="left">82.57 (23.4)</td><td align="left">2.42%</td></tr><tr><td align="justify">C2 (781)</td><td align="justify">33.78(19.3)</td><td align="justify">18.34(11.4)</td><td align="justify">7.22(1.7)</td><td align="justify">78.85(11.0)</td><td align="left">92.99(22.8)</td><td align="left">96.59(22.9)</td><td align="left">1.41%</td></tr><tr><td align="justify">C3 (484)</td><td align="justify">44.05(23.9)</td><td align="justify">25.35(15.5)</td><td align="justify">7.58(1.7)</td><td align="justify">74.29(11.0)</td><td align="left">79.31(23.7)</td><td align="left">81.04(24.4)</td><td align="left">2.07%</td></tr><tr><td align="justify">C4 (383)</td><td align="justify">61.19(27.5)</td><td align="justify">33.83(18.9)</td><td align="justify">7.97(1.5)</td><td align="justify">58.62(9.5)</td><td align="left">42.20(19.4)</td><td align="left">44.86(22.8)</td><td align="left">5.76%</td></tr><tr><td align="justify">ANOVA <italic>p-value</italic></td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="left"></td></tr><tr><td align="justify">Tukey HSD (NS <italic>‡</italic>)</td><td align="justify">C1:C2</td><td align="justify">none</td><td align="justify">C0:C1,C2,C3 C1:C2,C3</td><td align="justify">C0:C1,C3 C1:C3</td><td align="left">C0:C2;C1:C3</td><td align="left">C0:C2;C1:C3</td><td align="left"></td></tr><tr><td align="justify">Eta-squared (<italic>η</italic><sup>2</sup>)</td><td align="justify">0.274</td><td align="justify">0.253</td><td align="justify">0.022</td><td align="justify">0.272</td><td align="left">0.361</td><td align="left">0.333</td><td align="left"></td></tr><tr><td align="justify" colspan="4">kNN 3 Integrity k=5 corr</td><td align="left" colspan="4"></td></tr><tr><td align="justify">C0 (462)</td><td align="justify">66.56(24.0)</td><td align="justify">41.65(18.3)</td><td align="justify">7.54(1.7)</td><td align="justify">73.26(9.6)</td><td align="left">87.95(22.9)</td><td align="left">92.57(24.5)</td><td align="left">0.87%</td></tr><tr><td align="justify">C1 (276)</td><td align="justify">57.20(27.4)</td><td align="justify">29.89(15.5)</td><td align="justify">7.39(1.4)</td><td align="justify">57.38(8.9)</td><td align="left">37.27(17.8)</td><td align="left">39.84(21.8)</td><td align="left">5.82%</td></tr><tr><td align="justify">C2 (743)</td><td align="justify">33.48(18.7)</td><td align="justify">17.39(10.6)</td><td align="justify">7.18(1.7)</td><td align="justify">79.86(10.6)</td><td align="left">96.22(20.6)</td><td align="left">99.49(21.6)</td><td align="left">1.62%</td></tr><tr><td align="justify">C3 (744)</td><td align="justify">46.25(24.8)</td><td align="justify">28.80(17.8)</td><td align="justify">7.53(1.6)</td><td align="justify">72.53(10.4)</td><td align="left">78.72(23.3)</td><td align="left">80.97(24.9)</td><td align="left">3.10%</td></tr><tr><td align="justify">C4 (455)</td><td align="justify">42.58(23.2)</td><td align="justify">24.26(14.9)</td><td align="justify">7.66(1.8)</td><td align="justify">73.63(12.0)</td><td align="left">77.54(25.2)</td><td align="left">79.01(26.2)</td><td align="left">1.54%</td></tr><tr><td align="justify">ANOVA <italic>p-value</italic></td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="left"></td></tr><tr><td align="justify">Tukey HSD (NS <italic>‡</italic>)</td><td align="justify">C3:C4</td><td align="justify">C1:C3</td><td align="justify">C0:C1,C3,C4 C1:C2,C3,C4 C3:C4</td><td align="justify">C0:C3,C4 C3:C4</td><td align="left">C3:C4</td><td align="left">C3:C4</td><td align="left"></td></tr><tr><td align="justify">Eta-squared (<italic>η</italic><sup>2</sup>)</td><td align="justify">0.197</td><td align="justify">0.215</td><td align="justify">0.011</td><td align="justify">0.258</td><td align="left">0.354</td><td align="left">0.306</td><td align="left"></td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>NS: implies pairs for which Tukey HSD test was not significant</p><p>The mean and standard deviation values are presented for each measure</p></table-wrap-foot></table-wrap>
<table-wrap id="Tab7"><label>Table 7</label><caption><p>Statistical analysis of optimal clustering configurations using selected ASD outcome measures: for kNN2 graphs without node reassignment</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Cluster (size)</th><th align="left">ABC overall</th><th align="left">RBS R overall</th><th align="left">ADOS CSS</th><th align="left">Vineland composite score</th><th align="left">Overall IQ</th><th align="left">PPVTA 4A</th><th align="left">Epilepsy</th></tr></thead><tbody><tr><td align="justify" colspan="4">kNN 2 VAT k=2</td><td align="justify" colspan="4"></td></tr><tr><td align="justify">C0 (2072)</td><td align="justify">47.01(26.1)</td><td align="justify">27.74(17.9)</td><td align="left">7.38(1.7)</td><td align="justify">73.99(12.0)</td><td align="justify">83.50(27.1)</td><td align="left">87.51(27.9)</td><td align="left">2.27%</td></tr><tr><td align="justify">C1 (506)</td><td align="justify">45.66(25.3)</td><td align="justify">25.01(16.1)</td><td align="left">7.69(1.6)</td><td align="justify">70.47(12.9)</td><td align="justify">69.09(28.5)</td><td align="left">71.46(29.3)</td><td align="left">2.77%</td></tr><tr><td align="justify">S (102)</td><td align="justify">46.03(21.6)</td><td align="justify">26.89(15.1)</td><td align="left">7.52(1.5)</td><td align="justify">73.71(9.6)</td><td align="justify">81.75(23.2)</td><td align="left">77.94(35.1)</td><td align="left">0.98%</td></tr><tr><td align="justify">ANOVA <italic>p-value</italic></td><td align="justify">0.295</td><td align="justify">0.002</td><td align="left">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="left"></td></tr><tr><td align="justify">Eta-squared (<italic>η</italic><sup>2</sup>)</td><td align="justify">0</td><td align="justify">0.004</td><td align="left">0.005</td><td align="justify">0.013</td><td align="justify">0.042</td><td align="left">0.049</td><td align="left"></td></tr><tr><td align="justify" colspan="4">kNN 2 Integrity k=5</td><td align="justify" colspan="4"></td></tr><tr><td align="justify">C0 (1096)</td><td align="justify">41.02(22.0)</td><td align="justify">23.30(14.8)</td><td align="left">7.19(1.7)</td><td align="justify">78.36(10.3)</td><td align="justify">94.63(20.6)</td><td align="left">97.91(22.2)</td><td align="left">1.37%</td></tr><tr><td align="justify">C1 (430)</td><td align="justify">67.76(24.6)</td><td align="justify">43.94(19.2)</td><td align="left">7.61(1.7)</td><td align="justify">70.22(9.7)</td><td align="justify">78.58(23.8)</td><td align="left">83.02(25.0)</td><td align="left">1.86%</td></tr><tr><td align="justify">C2 (402)</td><td align="justify">41.49(23.8)</td><td align="justify">24.42(15.8)</td><td align="left">7.57(1.7)</td><td align="justify">73.88(11.3)</td><td align="justify">78.34(24.3)</td><td align="left">79.36(25.4)</td><td align="left">2.00%</td></tr><tr><td align="justify">C3 (384)</td><td align="justify">32.54(18.1)</td><td align="justify">18.99(10.5)</td><td align="left">7.47(1.6)</td><td align="justify">75.41(10.6)</td><td align="justify">82.90(21.9)</td><td align="left">84.73(23.3)</td><td align="left">2.09%</td></tr><tr><td align="justify">C4 (350)</td><td align="justify">59.67(27.2)</td><td align="justify">30.74(17.2)</td><td align="left">7.83(1.5)</td><td align="justify">58.58(9.9)</td><td align="justify">40.55(19.3)</td><td align="left">43.70(22.9)</td><td align="left">6.03%</td></tr><tr><td align="justify">S (18)</td><td align="justify">56.33(22.6)</td><td align="justify">32.50(15.0)</td><td align="left">7.72(1.9)</td><td align="justify">69.33(14.2)</td><td align="justify">68.78(36.4)</td><td align="left">65.56(46.7)</td><td align="left">11.1%</td></tr><tr><td align="justify">ANOVA <italic>p-value</italic></td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="left"></td></tr><tr><td align="justify">Tukey HSD (NS<sup>a</sup>)</td><td align="justify">C0:C2</td><td align="justify">C0:C2</td><td align="left">C1:C2,C3,C4; C2:C3,C4</td><td align="justify">C2:C3</td><td align="justify">C1:C2</td><td align="left">C1:C2,C3</td><td align="left"></td></tr><tr><td align="justify">Eta-squared (<italic>η</italic><sup>2</sup>)</td><td align="justify">0.211</td><td align="justify">0.210</td><td align="left">0.019</td><td align="justify">0.279</td><td align="justify">0.383</td><td align="left">0.329</td><td align="left"></td></tr><tr><td align="justify" colspan="4">kNN 2 Tenacity k=5</td><td align="justify" colspan="4"></td></tr><tr><td align="justify">C0 (741)</td><td align="justify">47.01(26.1)</td><td align="justify">29.38(18.8)</td><td align="left">7.46(1.6)</td><td align="justify">73.25(9.9)</td><td align="justify">81.26(22.4)</td><td align="left">83.63(23.3)</td><td align="left">2.30%</td></tr><tr><td align="justify">C1 (951)</td><td align="justify">41.23(22.4)</td><td align="justify">22.84(14.8)</td><td align="left">7.08(1.7)</td><td align="justify">78.68(10.5)</td><td align="justify">95.58(20.3)</td><td align="left">99.41(21.6)</td><td align="left">1.26%</td></tr><tr><td align="justify">C2 (591)</td><td align="justify">45.06(26.3)</td><td align="justify">25.66(17.3)</td><td align="left">7.61(1.7)</td><td align="justify">71.44(13.3)</td><td align="justify">70.86(28.5)</td><td align="left">72.95(29.9)</td><td align="left">2.54%</td></tr><tr><td align="justify">C3 (216)</td><td align="justify">68.07(25.8)</td><td align="justify">41.92(17.0)</td><td align="left">8.56(1.5)</td><td align="justify">68.76(8.9)</td><td align="justify">75.79(27.1)</td><td align="left">80.39(28.1)</td><td align="left">2.33%</td></tr><tr><td align="justify">C4 (172)</td><td align="justify">54.72(25.2)</td><td align="justify">28.90(14.0)</td><td align="left">7.35(1.4)</td><td align="justify">56.13(8.9)</td><td align="justify">36.17(16.6)</td><td align="left">37.64(18.6)</td><td align="left">7.60%</td></tr><tr><td align="justify">S (9)</td><td align="justify">46.22(19.4)</td><td align="justify">23.56(15.7)</td><td align="left">7.78(1.0)</td><td align="justify">72.67(11.8)</td><td align="justify">79.00(23.5)</td><td align="left">81.88(34.3)</td><td align="left">0%</td></tr><tr><td align="justify">ANOVA <italic>p-value</italic></td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="justify">&lt; 0.001</td><td align="left">&lt; 0.001</td><td align="left"></td></tr><tr><td align="justify">Tukey HSD (NS <italic>‡</italic>)</td><td align="justify">C0:C2</td><td align="justify">C4:C0,C2</td><td align="left">C0:C2,C4 C4:C1,C2</td><td align="justify">None</td><td align="justify">C2:C3</td><td align="left">C0:C3</td><td align="left"></td></tr><tr><td align="justify">Eta-squared (<italic>η</italic><sup>2</sup>)</td><td align="justify">0.078</td><td align="justify">0.086</td><td align="left">0.054</td><td align="justify">0.214</td><td align="justify">0.298</td><td align="left">0.270</td><td align="left"></td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>NS: implies pairs for which Tukey HSD test was not significant. S is not included in the ANOVA, Tukey, and Eta-squared analyses</p><p>The mean and standard deviation values are presented for each measure)</p></table-wrap-foot></table-wrap></p>
<p>Figure <xref ref-type="fig" rid="Fig3">3</xref> illustrates the visualization of the graph of the optimal clustering result for kNN2 Tenacity 5-Cluster results in terms of distribution of high overall IQ (≥ 70) vs. lower IQ (&lt; 70). Large circles denote high IQ while small circles denote low IQ. Only the green cluster (C4) shows a high concentration of low IQ nodes (small circles). We can observe the complexity of the variation in the 5-cluster result given by Tenacity kNN2 with node reassignment. This demonstrates that the resulting clustering obtained is a combination of various factors, not just IQ scores.
<fig id="Fig3"><label>Fig. 3</label><caption><p>Visualization of optimal clustering result for kNN2 Tenacity 5-cluster graph in terms of distribution of high overall IQ (≥ 70) vs. lower IQ (&lt; 70). Large circles denote high IQ while small circles denote low IQ. Only green cluster shows a high concentration of low IQ nodes. This demonstrates that the clustering obtained is a combination of various factors, not just IQ scores</p></caption><graphic id="MO3" xlink:href="41109_2018_93_Fig3_HTML"></graphic></fig></p>
<p>The outcome of the feature extraction phase is summarized in Tables <xref ref-type="table" rid="Tab8">8</xref> and <xref ref-type="table" rid="Tab9">9</xref> for each of the seven clustering configurations. Overall, 20 different features were uncovered as discriminant for at least one of the 7 optimal clusterings. The regression feature was consistently selected for all seven results. Overall level of language (ADI-R Q30) was selected six times while both BAPQ Mother overall average score and word delay were selected five times.
<table-wrap id="Tab8"><label>Table 8</label><caption><p>Set of discriminant features by clustering result for complete clustering configuration</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Integrity k=3</th><th align="left">Tenacity (corr) k=5</th><th align="left">VAT k=4</th><th align="left">kNN3 Integrity k=5</th></tr></thead><tbody><tr><td align="justify">ADI-R Q30 (Overall level of language)</td><td align="justify">ADI-R Q30 (Overall level of language)</td><td align="justify">ADI-R Q30 (Overall level of language)</td><td align="justify">ADI-R Q30 (Overall level of language)</td></tr><tr><td align="justify">ADI-R Q86 (Abnormality evidence)</td><td align="justify">RBS-R (Ritualistic Behavior)</td><td align="justify">ADI-R Q86 (Abnormality evidence)</td><td align="justify">ABC-Inappropriate speech</td></tr><tr><td align="justify">CBCL Externalizing T Score</td><td align="justify">ABC-Irritability</td><td align="justify">Verbal score (ADI-R B)</td><td align="justify">RBS-R-Stereotyped behavior</td></tr><tr><td align="justify">Regression</td><td align="justify">BAPQ Avg (Mother)</td><td align="justify">BAPQ Avg (Mother)</td><td align="justify">BAPQ Avg (Mother)</td></tr><tr><td align="justify"></td><td align="justify">Regression</td><td align="justify">Regression</td><td align="justify">Regression</td></tr><tr><td align="justify"></td><td align="justify">ADOS Social Affect</td><td align="justify">ADI-R C (Repetitive behavior)</td><td align="justify">ADI-R C (Repetitive behavior)</td></tr><tr><td align="justify"></td><td align="justify">Social (ADI-R A)</td><td align="justify">SRS Mannerisms</td><td align="justify">Social (ADI-R A)</td></tr><tr><td align="justify"></td><td align="justify">SRS T score</td><td align="justify">Word delay</td><td align="justify">SRS cognition</td></tr><tr><td align="justify"></td><td align="justify">Word delay</td><td align="justify"></td><td align="justify">Word delay</td></tr></tbody></table></table-wrap>
<table-wrap id="Tab9"><label>Table 9</label><caption><p>Set of discriminant features by clustering result for no node reassignment</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">VAT k=2</th><th align="left">Integrity k=5</th><th align="left">Tenacity k=5</th></tr></thead><tbody><tr><td align="left">CBCL externalizing T score</td><td align="left">ABC-Inappropriate speech)</td><td align="left">ABC-Inappropriate speech)</td></tr><tr><td align="left">BAPQ Avg (Mother)</td><td align="left">ADOS social affect</td><td align="left">ADOS communication &amp; social</td></tr><tr><td align="left">Regression</td><td align="left">BAPQ Avg (Mother)</td><td align="left">ADI-R Q30 (Overall Level of Language)</td></tr><tr><td align="left">Verbal IQ</td><td align="left">ADI-R Q30 (Overall level of language)</td><td align="left">Regression</td></tr><tr><td align="left"></td><td align="left">Regression</td><td align="left">Social (ADI-R A)</td></tr><tr><td align="left"></td><td align="left">SRS T score</td><td align="left">Word delay</td></tr><tr><td align="left"></td><td align="left">Verbal score (ADI-R B)</td><td align="left"></td></tr><tr><td align="left"></td><td align="left">Word delay</td><td align="left"></td></tr></tbody></table></table-wrap></p>
</sec>
</sec>
<sec id="Sec15" sec-type="discussion">
<title>Discussion</title>
<p>Regarding appropriate graph representation, the results confirmed advantageous aspects of the min-conn setting as the kNN2 graph exhibited optimal clusterings that were not sensitive to preprocessing parametric changes compared to the kNN4 graph. This implies robustness of min-connectivity graphs. As expected, there were no significant differences in age and gender distribution across various cluster configurations. This suggests that the variations in the ASD severity is unrelated to age or gender. However, interestingly, the distribution of percentage Caucasian varied across clusters.</p>
<p>We had hypothesized that the results obtained by excluding the critical attack set (i.e. no node reassignment) would result in more clearly defined clusters. This is based on the assumption that the critical attack set contains possible outlier and/or overlapping nodes. As mentioned earlier, outliers in the context of this application could denote patients that may have some errors in their phenotype data from the data collection process. However, the results obtained for the configurations without node reassignment (NR) are not conclusive. The removal of the nodes, though relatively few, impacts the resulting configuration especially for VAT-Clust, which has the largest critical attack set of 108 nodes. When we compare the visualizations (Fig. <xref ref-type="fig" rid="Fig1">1</xref>) of the NR results to the traditional clustering results, in which every node is assigned to a cluster, the differences are subtle. This is probably due to the relatively small sizes of the critical attack sets (Table <xref ref-type="table" rid="Tab7">7</xref>) obtained in this work based on the grouping algorithm applied to attain the desired number of clusters. From the statistical analysis (Table <xref ref-type="table" rid="Tab7">7</xref>), the no node reassignment appears beneficial for Tenacity-Clust and Integrity-Clust</p>
<p>The clinical outcomes analyses (Tables <xref ref-type="table" rid="Tab6">6</xref> and <xref ref-type="table" rid="Tab7">7</xref>) demonstrate the significance and usefulness of the varied cluster configurations. Cluster attributes are consistent in the kNN2 integrity k=3 clustering (Table <xref ref-type="table" rid="Tab6">6</xref>). Cluster C1 has the most severe symptoms by all measures, such as lowest Overall IQ, and highest incidence of epilepsy. Cluster C0 has the lowest overall scores for ABC, RBS-R and ADOS CSS, as well as the highest Vineland Composite Score, Overall IQ, Learning Vocabulary Score (PPVTA), and the lowest incidence of epilepsy. For all measures, Cluster C2 lies between clusters C0 and C1. It is interesting also to note the cluster sizes. For this dataset, the subjects with the most severe symptoms account for approximately 7% of the sample. The group with the least severe symptoms is 71% of the sample, and the middle group counts for 22%. However, the <italic>η</italic><sup>2</sup> values are very low which conveys a relatively low confidence in the results.</p>
<p>The clustering obtained by the VAT 4-clustering is in many ways similar to the integrity 3-clustering, as can observed visually by comparing Figs. <xref ref-type="fig" rid="Fig1">1</xref>a and c, along with statistical results from Table <xref ref-type="table" rid="Tab6">6</xref>. The most severe cluster has the smallest size while the least severe is the largest cluster. As mentioned in the previous section, the overall effect sizes are consistently high for kNN2 Tenacity 5-Cluster result in Table <xref ref-type="table" rid="Tab6">6</xref> which conveys a strong confidence in the results. The variations observed in the varying levels of ASD severity complexity is interesting across clusters, for example, between clusters C0 and C4. Cluster C4 is characterized by the largest ASD severity level in terms of low overall IQ, relatively high occurrence epilepsy (non-febrile seizures), low functioning skills (as quantified by the Vineland composite scores), and high ADOS CSS scores. However, their aberrent behavior checklist and stereotyped behavior scores are not the most severe scores. It is slightly better compared to cluster CO. Cluster C0 has very high mean IQ scores (not the highest - C2) but the aberrent behavior checklist and stereotyped Behavior scores for that subgroup is the lowest. This provides further evidence that there is an ASD subgroup with relatively IQ scores but very severe behavioral problems (<xref ref-type="bibr" rid="CR50">Obafemi-Ajayi et al. 2015</xref>).</p>
<p>Four of the seven optimal clusterings consisted of 5 clusters. Two of the clusterings were obtained using integrity (both with and without reassigment) and two of the clusterings were obtained using tenacity (again both with and without reassignment). These clusterings can be compared visually in Figs. <xref ref-type="fig" rid="Fig1">1</xref> and <xref ref-type="fig" rid="Fig2">2</xref>. We can observe that they all share some similarities in their configuration. According to Table <xref ref-type="table" rid="Tab6">6</xref>, the kNN2 Tenacity 5-clustering configuration obtained using the filtered 33 features set had consistently high eta-squared values across all the outcome measures. Figure <xref ref-type="fig" rid="Fig4">4</xref> summarizes the trends across the outcome measures for its five clusters using box plot charts. These charts (Fig. <xref ref-type="fig" rid="Fig4">4</xref>) were generated using the normalized values of the outcome measures between 0 and 100 to aid ease of comparisons across the diverse ranges for each measure. The outcome measures for which higher values implies higher ASD severity (ABC, RBS-R and ADOS-CSS) are illustrated in Fig. <xref ref-type="fig" rid="Fig4">4</xref>a while the measures for which higher values implies lower ASD severity (ABC, RBS-R and ADOS-CSS) are illustrated in Fig. <xref ref-type="fig" rid="Fig4">4</xref>b. Cluster C2 (the red cluster in Fig. <xref ref-type="fig" rid="Fig1">1</xref>e) denotes the subgroup with the lowest ASD severity (i.e. high functioning group) across all six measures. It is also the largest subgroup. Cluster C4 (the green cluster in Fig. <xref ref-type="fig" rid="Fig1">1</xref>e) denotes the subgroup with the highest ASD severity (i.e. low functioning group) across all six measures. It is also the smallest subgroup. Cluster C0, the gold cluster in Fig. <xref ref-type="fig" rid="Fig1">1</xref>e), is characterized by high IQ and PPVTA (vocabulary) scores as well as a low ADOS-CSS score but severe Vineland composite, ABC and RBS-R scores. The RBS-R and ABC scores are the lowest among all the clusters. This suggests that there is a subgroup with high IQ and vocabulary skills but very severe behavioral skills. Cluster C3, the blue cluster in Fig. <xref ref-type="fig" rid="Fig1">1</xref>e), is a subgroup that consistently lies in between the C2(least severe, red) and C4 (most severe, green) subgroups in all measures. In contrast, C1, the purple cluster in Fig. <xref ref-type="fig" rid="Fig1">1</xref>e), is consistently in between C0 (gold) and C2 (red) except for its ADOS-CSS scores, that is slightly higher for both. When we comparing C1 and C3 subgroups with each other, we can observe that C1 (purple) is less severe than C3 (blue) across all six outcome measures.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Analysis of ASD outcome measures (normalized values using known features ranges) across clusters for kNN2 Tenacity 5 clustering configuration. The color of the boxes correlate to the colors of the clusters in Fig. <xref ref-type="fig" rid="Fig1">1</xref>e. Gold denotes C0, Purple: C1, Red: C2, Blue: C3, and Green: C4. <bold>a</bold> Outcome Measures for which values are positively correlated with ASD severity. <bold>b</bold> Outcome Measures for which values are inversely correlated with ASD severity</p></caption><graphic id="MO4" xlink:href="41109_2018_93_Fig4_HTML"></graphic></fig></p>
<p>The feature extraction results seem to suggest that the following phenotypes could be useful biomarkers in delineating ASD subgroups: Regression, Word Delay, ADI-R Q30 (Overall Level of Language), ADI-R Q86 (Abnormality evidence), RBS-R aggregate score (Ritualistic Behavior), ABC aggregate scores (Irritability, Inappropriate Speech), CBCL Externalizing T Score, Verbal score (ADI-R B), RBS-R-Stereotyped Behavior, BAPQ Avg (Mother), ADI-R C (Repetitive Behavior), Social (ADI-R A), and SRS aggregate scores (Mannerisms, Cognition, overall T Score). These results support evidence that language delay, regression and social scores are useful biomarkers for delineating meaningful subgroups.</p>
</sec>
<sec id="Sec16" sec-type="conclusion">
<title>Conclusion</title>
<p>This paper investigated the application of the NBR-Clust graph-based method to cluster analysis of ASD phenotypes of 2680 simplex ASD probands using different node resilience measures. To determine the optimal clustering configuration, we applied a holistic approach using three main criteria: internal cluster validation indices, graph quality measures, and distribution of resulting clusters. We presented a rigorous clinical/behavioral analysis of the highly ranked results by graph type and resilience measure. The results obtained demonstrate the potential and usefulness of NBR-Clust. The results favored a 5-cluster ASD sub-grouping configuration and identified a set of potentially useful phenotype biomarkers. Future work will include refinement of the critical attack set to identify specifically the outlier nodes for enhanced biomarker detection. Further studies are also needed to verify the potential ASD biomarkers identified in this work with respect to their application in management of ASD.</p>
</sec>
<sec sec-type="supplementary-material">
<title>Additional file</title>
<sec id="Sec17">
<p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41109_2018_93_MOESM1_ESM.xlsx"><label>Additional file 1</label><caption><p>Cohen-d test values for Tables 6 and 7 to evaluate the effect sizes for each pairwise comparison. (XLSX 32 kb)</p></caption></media></supplementary-material>
</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We appreciate obtaining access to Simons Simplex Collection phenotype data analyzed in this study via SFARI base: www.sfari.org. We also appreciate the support of Ms. Cynthia Germeroth in uploading the data into the SAP HANA in-memory database.</p>
<sec id="d29e5966">
<title>Availability of data and materials</title>
<p>The data utilized in this work was obtained from the Simons Simplex Collection, supported by Simons Foundation for Autism Research Initiatives (SFARI): <ext-link ext-link-type="uri" xlink:href="http://www.sfari.org">www.sfari.org</ext-link>. The data is available upon request by contacting SFARI base directly.</p>
</sec>
</ack>
<notes notes-type="author-contribution">
<title>Authors’ contributions</title>
<p>JM ran all NBR experiments, interpreted results of analyses, prepared manuscript figures, contributed to the conception and design of the study and is the first author of the manuscript. JZ ran the correlation filter algorithm, cluster validation experiments, conducted the statistical analysis, and prepared the tables for the manuscript. GE supervised all the NBR experiments and guided the interpretation of the analysis, contributed to the conception and design of the study, and participated in drafting and revising the manuscript. TOA collected the behavioral and clinical data, supervised analyses of these data, contributed to the conception and design of the study, contributed to drafting and revising the manuscript, and is the corresponding author. All authors read and approved the final manuscript.</p>
</notes>
<notes notes-type="COI-statement">
<sec>
<title>Competing interests</title>
<p>The authors declare that they have no competing interests.</p>
</sec>
<sec>
<title>Publisher’s Note</title>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</sec>
</notes>
<ref-list id="Bib1">
<title>References</title>
<ref id="CR1">
<mixed-citation publication-type="other">Abbas, M, Le T, Bensmail H, Honavar V, El-Manzalawy Y (2018) Microbiomarkers discovery in inflammatory bowel diseases using network-based feature selection. Proceedings of the 9th ACM Conference on Bioinformatics, Computational Biology and Health Informatics.</mixed-citation>
</ref>
<ref id="CR2">
<mixed-citation publication-type="other">Aggarwal, CC, Reddy CK (2013) Data Clustering: Algorithms and Applications. Chapman and Hall/CRC.</mixed-citation>
</ref>
<ref id="CR3">
<mixed-citation publication-type="other">Al-Jabery, K, Obafemi-Ajayi T, Olbricht GR, Takahashi TN, Kanne S, Wunsch D (2016) Ensemble statistical and subspace clustering model for analysis of autism spectrum disorder phenotypes In: Engineering in Medicine and Biology Society (EMBC), 2016 IEEE 38th Annual International Conference of The, 3329–3333.. IEEE.</mixed-citation>
</ref>
<ref id="CR4">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Alpert</surname>
<given-names>CJ</given-names>
</name>
<name>
<surname>Kahng</surname>
<given-names>AB</given-names>
</name>
<name>
<surname>Yao</surname>
<given-names>S-Z</given-names>
</name>
</person-group>
<article-title>Spectral partitioning with multiple eigenvectors</article-title>
<source/>Discret Appl Math
          <year>1999</year>
<volume>90</volume>
<issue>1-3</issue>
<fpage>3</fpage>
<lpage>26</lpage>
<pub-id pub-id-type="doi">10.1016/S0166-218X(98)00083-3</pub-id>
</element-citation>
</ref>
<ref id="CR5">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Alves</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Mesquita</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Gómez-Gardeñes</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Agero</surname>
<given-names>U</given-names>
</name>
</person-group>
<article-title>Graph analysis of cell clusters forming vascular networks</article-title>
<source/>Royal Society open science
          <year>2018</year>
<volume>5</volume>
<issue>3</issue>
<fpage>171592</fpage>
<pub-id pub-id-type="doi">10.1098/rsos.171592</pub-id>
<pub-id pub-id-type="pmid">29657767</pub-id>
</element-citation>
</ref>
<ref id="CR6">
<mixed-citation publication-type="other">Akiki, TJ, Averill CL, Wrocklage KM, Scott JC, Averill LA, Schweinsburg B, Alexander-Bloch A, Martini B, Southwick SM, Krystal JH, et al. (2018) Default mode network abnormalities in posttraumatic stress disorder: A novel network-restricted topology approach. NeuroImage.</mixed-citation>
</ref>
<ref id="CR7">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Arbelaitz</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Gurrutxaga</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Muguerza</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Pérez</surname>
<given-names>JM</given-names>
</name>
<name>
<surname>Perona</surname>
<given-names>I</given-names>
</name>
</person-group>
<article-title>An extensive comparative study of cluster validity indices</article-title>
<source/>Pattern Recognit
          <year>2013</year>
<volume>46</volume>
<issue>1</issue>
<fpage>243</fpage>
<lpage>256</lpage>
<pub-id pub-id-type="doi">10.1016/j.patcog.2012.07.021</pub-id>
</element-citation>
</ref>
<ref id="CR8">
<mixed-citation publication-type="other">Arora, S, Rao S, Vazirani UV (2009) Expander flows, geometric embeddings and graph partitioning. J. ACM 56(2).</mixed-citation>
</ref>
<ref id="CR9">
<mixed-citation publication-type="other">Association, AP, <italic>et al</italic> (2013) Diagnostic and Statistical Manual of Mental Disorders (DSM-5®;). American Psychiatric Pub.</mixed-citation>
</ref>
<ref id="CR10">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<collab>Autism and Developmental Disabilities Monitoring Network Surveillance Year 2010 Principal Investigators</collab>
</person-group>
<article-title>Prevalence of autism spectrum disorder among children aged 8 years—autism and developmental disabilities monitoring network, 11 sites, united states, 2010</article-title>
<source/>Morb Mortal Wkly Rep: Surveill Summ
          <year>2014</year>
<volume>63</volume>
<issue>2</issue>
<fpage>1</fpage>
<lpage>21</lpage>
</element-citation>
</ref>
<ref id="CR11">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Barefoot</surname>
<given-names>CA</given-names>
</name>
<name>
<surname>Entringer</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Swart</surname>
<given-names>H</given-names>
</name>
</person-group>
<article-title>Vulnerability in graphs-a comparative survey</article-title>
<source/>J Comb Math Comb Comput
          <year>1987</year>
<volume>1</volume>
<fpage>12</fpage>
<lpage>22</lpage>
</element-citation>
</ref>
<ref id="CR12">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bastian</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Heymann</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Jacomy</surname>
<given-names>M</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Gephi: an open source software for exploring and manipulating networks</article-title>
<source/>Icwsm
          <year>2009</year>
<volume>8</volume>
<fpage>361</fpage>
<lpage>362</lpage>
</element-citation>
</ref>
<ref id="CR13">
<mixed-citation publication-type="other">Borwey, J, Ahlert D, Obafemi-Ajayi T, Ercal G (2015) A graph-theoretic clustering methodology based on vertex-attack tolerance In: FLAIRS Conference, 404–409.</mixed-citation>
</ref>
<ref id="CR14">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Brandes</surname>
<given-names>U</given-names>
</name>
</person-group>
<article-title>A faster algorithm for betweenness centrality</article-title>
<source/>J Math Sociol
          <year>2001</year>
<volume>25</volume>
<issue>2</issue>
<fpage>163</fpage>
<lpage>177</lpage>
<pub-id pub-id-type="doi">10.1080/0022250X.2001.9990249</pub-id>
</element-citation>
</ref>
<ref id="CR15">
<mixed-citation publication-type="other">Brugere, I, Gallagher B, Berger-Wolf TY (2018) Network structure inference, a survey: Motivations, methods, and applications. ACM Comput Surv 51(2):24–12439. New York 10.1145/3154524.</mixed-citation>
</ref>
<ref id="CR16">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Brun</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Sima</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Hua</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Lowey</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Carroll</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Suh</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Dougherty</surname>
<given-names>ER</given-names>
</name>
</person-group>
<article-title>Model-based evaluation of clustering validation measures</article-title>
<source/>Pattern Recog
          <year>2007</year>
<volume>40</volume>
<issue>3</issue>
<fpage>807</fpage>
<lpage>824</lpage>
<pub-id pub-id-type="doi">10.1016/j.patcog.2006.06.026</pub-id>
</element-citation>
</ref>
<ref id="CR17">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chaste</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Klei</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Sanders</surname>
<given-names>SJ</given-names>
</name>
<name>
<surname>Hus</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Murtha</surname>
<given-names>MT</given-names>
</name>
<name>
<surname>Lowe</surname>
<given-names>JK</given-names>
</name>
<name>
<surname>Willsey</surname>
<given-names>AJ</given-names>
</name>
<name>
<surname>Moreno-De-Luca</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Timothy</surname>
<given-names>WY</given-names>
</name>
<name>
<surname>Fombonne</surname>
<given-names>E</given-names>
</name>
<etal></etal>
</person-group>
<article-title>A genome-wide association study of autism using the simons simplex collection: Does reducing phenotypic heterogeneity in autism increase genetic homogeneity?</article-title>
<source/>Biol Psychiatry
          <year>2015</year>
<volume>77</volume>
<issue>9</issue>
<fpage>775</fpage>
<lpage>784</lpage>
<pub-id pub-id-type="doi">10.1016/j.biopsych.2014.09.017</pub-id>
<pub-id pub-id-type="pmid">25534755</pub-id>
</element-citation>
</ref>
<ref id="CR18">
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Cozzens</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Stueckle</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Moazzami</surname>
<given-names>D</given-names>
</name>
</person-group>
<article-title>The tenacity of a graph</article-title>
<source/>Seventh International Conference on the Theory and Applications of Graphs
          <year>1995</year>
<publisher-loc>New York</publisher-loc>
<publisher-name>Wiley</publisher-name>
<fpage>1111</fpage>
<lpage>1122</lpage>
</element-citation>
</ref>
<ref id="CR19">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Cuccaro</surname>
<given-names>ML</given-names>
</name>
<name>
<surname>Tuchman</surname>
<given-names>RF</given-names>
</name>
<name>
<surname>Hamilton</surname>
<given-names>KL</given-names>
</name>
<name>
<surname>Wright</surname>
<given-names>HH</given-names>
</name>
<name>
<surname>Abramson</surname>
<given-names>RK</given-names>
</name>
<name>
<surname>Haines</surname>
<given-names>JL</given-names>
</name>
<name>
<surname>Gilbert</surname>
<given-names>JR</given-names>
</name>
<name>
<surname>Pericak-Vance</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>Exploring the relationship between autism spectrum disorder and epilepsy using latent class cluster analysis</article-title>
<source/>J Autism Dev Disord
          <year>2012</year>
<volume>42</volume>
<issue>8</issue>
<fpage>1630</fpage>
<lpage>1641</lpage>
<pub-id pub-id-type="doi">10.1007/s10803-011-1402-y</pub-id>
<pub-id pub-id-type="pmid">22105141</pub-id>
</element-citation>
</ref>
<ref id="CR20">
<mixed-citation publication-type="other">Cukierski, WJ, Foran DJ (2008) Using betweenness centrality to identify manifold shortcuts In: Data Mining Workshops, 2008. ICDMW’08. IEEE International Conference On, 949–958.. IEEE.</mixed-citation>
</ref>
<ref id="CR21">
<mixed-citation publication-type="other">Dale, J, Matta J, Howard S, Ercal G, Qiu W, Obafemi-Ajayi T (2018) Analysis of grapevine gene expression data using node-based resilience clustering In: IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology.</mixed-citation>
</ref>
<ref id="CR22">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Eaves</surname>
<given-names>LC</given-names>
</name>
<name>
<surname>Ho</surname>
<given-names>HH</given-names>
</name>
<name>
<surname>Eaves</surname>
<given-names>DM</given-names>
</name>
</person-group>
<article-title>Subtypes of autism by cluster analysis</article-title>
<source/>J Autism Dev Disord
          <year>1994</year>
<volume>24</volume>
<issue>1</issue>
<fpage>3</fpage>
<lpage>22</lpage>
<pub-id pub-id-type="doi">10.1007/BF02172209</pub-id>
<pub-id pub-id-type="pmid">8188572</pub-id>
</element-citation>
</ref>
<ref id="CR23">
<mixed-citation publication-type="other">Eibe, F, Hall M, Witten I, Pal J (2016) The weka workbench. Online Appendix for Data Mini: Pract Mach Learn Tools Tech 4.</mixed-citation>
</ref>
<ref id="CR24">
<mixed-citation publication-type="other">Ercal, G (2014) On vertex attack tolerance of regular graphs. CoRR abs/1409.2172.</mixed-citation>
</ref>
<ref id="CR25">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fischbach</surname>
<given-names>GD</given-names>
</name>
<name>
<surname>Lord</surname>
<given-names>C</given-names>
</name>
</person-group>
<article-title>The simons simplex collection: a resource for identification of autism genetic risk factors</article-title>
<source/>Neuron
          <year>2010</year>
<volume>68</volume>
<issue>2</issue>
<fpage>192</fpage>
<lpage>195</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuron.2010.10.006</pub-id>
<pub-id pub-id-type="pmid">20955926</pub-id>
</element-citation>
</ref>
<ref id="CR26">
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Frank</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Hall</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Witten</surname>
<given-names>I</given-names>
</name>
</person-group>
<source/>The weka workbench. Data mining: Practical machine learning tools and techniques
          <year>2016</year>
<publisher-loc>Burlington</publisher-loc>
<publisher-name>Morgan Kaufmann</publisher-name>
</element-citation>
</ref>
<ref id="CR27">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Georgiades</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Szatmari</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Boyle</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>Importance of studying heterogeneity in autism</article-title>
<source/>Neuropsychiatry
          <year>2013</year>
<volume>3</volume>
<issue>2</issue>
<fpage>123</fpage>
<lpage>125</lpage>
<pub-id pub-id-type="doi">10.2217/npy.13.8</pub-id>
</element-citation>
</ref>
<ref id="CR28">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Georgiades</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Szatmari</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Boyle</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Hanna</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Duku</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Zwaigenbaum</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Bryson</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Fombonne</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Volden</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Mirenda</surname>
<given-names>P</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Investigating phenotypic heterogeneity in children with autism spectrum disorder: a factor mixture modeling approach</article-title>
<source/>J Child Psychol Psychiatry
          <year>2013</year>
<volume>54</volume>
<issue>2</issue>
<fpage>206</fpage>
<lpage>215</lpage>
<pub-id pub-id-type="doi">10.1111/j.1469-7610.2012.02588.x</pub-id>
<pub-id pub-id-type="pmid">22862778</pub-id>
</element-citation>
</ref>
<ref id="CR29">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hall</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Frank</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Holmes</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Pfahringer</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Reutemann</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Witten</surname>
<given-names>IH</given-names>
</name>
</person-group>
<article-title>The weka data mining software: an update</article-title>
<source/>ACM SIGKDD Explor Newsl
          <year>2009</year>
<volume>11</volume>
<issue>1</issue>
<fpage>10</fpage>
<lpage>18</lpage>
<pub-id pub-id-type="doi">10.1145/1656274.1656278</pub-id>
</element-citation>
</ref>
<ref id="CR30">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hus</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Gotham</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Lord</surname>
<given-names>C</given-names>
</name>
</person-group>
<article-title>Standardizing ados domain scores: Separating severity of social affect and restricted and repetitive behaviors</article-title>
<source/>J Autism Dev Disord
          <year>2014</year>
<volume>44</volume>
<issue>10</issue>
<fpage>2400</fpage>
<lpage>2412</lpage>
<pub-id pub-id-type="doi">10.1007/s10803-012-1719-1</pub-id>
<pub-id pub-id-type="pmid">23143131</pub-id>
</element-citation>
</ref>
<ref id="CR31">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ingram</surname>
<given-names>DG</given-names>
</name>
<name>
<surname>Takahashi</surname>
<given-names>TN</given-names>
</name>
<name>
<surname>Miles</surname>
<given-names>JH</given-names>
</name>
</person-group>
<article-title>Defining autism subgroups: a taxometric solution</article-title>
<source/>J Autism Dev Disord
          <year>2008</year>
<volume>38</volume>
<issue>5</issue>
<fpage>950</fpage>
<lpage>960</lpage>
<pub-id pub-id-type="doi">10.1007/s10803-007-0469-y</pub-id>
<pub-id pub-id-type="pmid">17985224</pub-id>
</element-citation>
</ref>
<ref id="CR32">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Guyon</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Elisseeff</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>An introduction to variable and feature selection</article-title>
<source/>J Mach Learn Res
          <year>2003</year>
<volume>3</volume>
<issue>Mar</issue>
<fpage>1157</fpage>
<lpage>1182</lpage>
</element-citation>
</ref>
<ref id="CR33">
<mixed-citation publication-type="other">Kovács, F, Legány C, Babos A (2005) Cluster validity measurement techniques In: 6th International Symposium of Hungarian Researchers on Computational Intelligence.</mixed-citation>
</ref>
<ref id="CR34">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lavelle</surname>
<given-names>TA</given-names>
</name>
<name>
<surname>Weinstein</surname>
<given-names>MC</given-names>
</name>
<name>
<surname>Newhouse</surname>
<given-names>JP</given-names>
</name>
<name>
<surname>Munir</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Kuhlthau</surname>
<given-names>KA</given-names>
</name>
<name>
<surname>Prosser</surname>
<given-names>LA</given-names>
</name>
</person-group>
<article-title>Economic burden of childhood autism spectrum disorders</article-title>
<source/>Pediatrics
          <year>2014</year>
<volume>133</volume>
<issue>3</issue>
<fpage>520</fpage>
<lpage>529</lpage>
<pub-id pub-id-type="doi">10.1542/peds.2013-0763</pub-id>
</element-citation>
</ref>
<ref id="CR35">
<mixed-citation publication-type="other">Liu, Y, Li Z, Xiong H, Gao X, Wu J (2010) Understanding of internal clustering validation measures In: Data Mining (ICDM), 2010 IEEE 10th International Conference On, 911–916.. IEEE.</mixed-citation>
</ref>
<ref id="CR36">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Liu</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Li</surname>
<given-names>Z</given-names>
</name>
<name>
<surname>Xiong</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Gao</surname>
<given-names>X</given-names>
</name>
<name>
<surname>Wu</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Wu</surname>
<given-names>S</given-names>
</name>
</person-group>
<article-title>Understanding and enhancement of internal clustering validation measures</article-title>
<source/>IEEE Trans Cybern
          <year>2013</year>
<volume>43</volume>
<issue>3</issue>
<fpage>982</fpage>
<lpage>994</lpage>
<pub-id pub-id-type="doi">10.1109/TSMCB.2012.2223671</pub-id>
<pub-id pub-id-type="pmid">23193245</pub-id>
</element-citation>
</ref>
<ref id="CR37">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lord</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Petkova</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Hus</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Gan</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Lu</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Martin</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Ousley</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Guy</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Bernier</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Gerdts</surname>
<given-names>J</given-names>
</name>
<etal></etal>
</person-group>
<article-title>A multisite study of the clinical diagnosis of different autism spectrum disorders</article-title>
<source/>Arch Gen Psychiatr
          <year>2012</year>
<volume>69</volume>
<issue>3</issue>
<fpage>306</fpage>
<lpage>313</lpage>
<pub-id pub-id-type="doi">10.1001/archgenpsychiatry.2011.148</pub-id>
<pub-id pub-id-type="pmid">22065253</pub-id>
</element-citation>
</ref>
<ref id="CR38">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lord</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Rutter</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Goode</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Heemsbergen</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Jordan</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Mawhood</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Schopler</surname>
<given-names>E</given-names>
</name>
</person-group>
<article-title>Austism diagnostic observation schedule: A standardized observation of communicative and social behavior</article-title>
<source/>J Autism Dev Disord
          <year>1989</year>
<volume>19</volume>
<issue>2</issue>
<fpage>185</fpage>
<lpage>212</lpage>
<pub-id pub-id-type="doi">10.1007/BF02211841</pub-id>
<pub-id pub-id-type="pmid">2745388</pub-id>
</element-citation>
</ref>
<ref id="CR39">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lord</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Rutter</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Le Couteur</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Autism diagnostic interview-revised: a revised version of a diagnostic interview for caregivers of individuals with possible pervasive developmental disorders</article-title>
<source/>J Autism Dev Disord
          <year>1994</year>
<volume>24</volume>
<issue>5</issue>
<fpage>659</fpage>
<lpage>685</lpage>
<pub-id pub-id-type="doi">10.1007/BF02172145</pub-id>
<pub-id pub-id-type="pmid">7814313</pub-id>
</element-citation>
</ref>
<ref id="CR40">
<mixed-citation publication-type="other">Marcus, DK, Preszler J, Zeigler-Hill V (2018) A network of dark personality traits: What lies at the heart of darkness?J Res Pers 73:56–62. 10.1016/j.jrp.2017.11.003.</mixed-citation>
</ref>
<ref id="CR41">
<mixed-citation publication-type="other">Matta, J (2017) A comparison of approaches to computing betweenness centrality for large graphs In: International Workshop on Complex Networks and Their Applications, 3–13.. Springer.</mixed-citation>
</ref>
<ref id="CR42">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Matta</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Ercal</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Borwey</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>The vertex attack tolerance of complex networks</article-title>
<source/>RAIRO-Oper Res
          <year>2017</year>
<volume>51</volume>
<issue>4</issue>
<fpage>1055</fpage>
<lpage>1076</lpage>
<pub-id pub-id-type="doi">10.1051/ro/2017008</pub-id>
</element-citation>
</ref>
<ref id="CR43">
<mixed-citation publication-type="other">Matta, J, Nguyen T, Ercal G, Obafemi-Ajayi T (2017) Applications of novel graph theoretic methods to clustering autism spectrum disorders phenotypes In: International Conference on Bioinformatics and Computational Biology, 113–119.</mixed-citation>
</ref>
<ref id="CR44">
<mixed-citation publication-type="other">Matta, J, Obafemi-Ajayi T, Borwey J, Wunsch D, Ercal G (2016) Robust graph-theoretic clustering approaches using node-based resilience measures In: 2016 IEEE 16th International Conference on Data Mining (ICDM), 320–329. 10.1109/ICDM.2016.0043.</mixed-citation>
</ref>
<ref id="CR45">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>McPartland</surname>
<given-names>JC</given-names>
</name>
</person-group>
<article-title>Considerations in biomarker development for neurodevelopmental disorders</article-title>
<source/>Curr Opin Neurol
          <year>2016</year>
<volume>29</volume>
<issue>2</issue>
<fpage>118</fpage>
<pub-id pub-id-type="doi">10.1097/WCO.0000000000000300</pub-id>
<pub-id pub-id-type="pmid">26844621</pub-id>
</element-citation>
</ref>
<ref id="CR46">
<mixed-citation publication-type="other">Miles, J (2011) Autism subgroups from a medical genetics perspective. Autism Spectr Disord:705–721.</mixed-citation>
</ref>
<ref id="CR47">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Newman</surname>
<given-names>ME</given-names>
</name>
</person-group>
<article-title>Modularity and community structure in networks</article-title>
<source/>Proc Natl Acad Sci
          <year>2006</year>
<volume>103</volume>
<issue>23</issue>
<fpage>8577</fpage>
<lpage>8582</lpage>
<pub-id pub-id-type="doi">10.1073/pnas.0601602103</pub-id>
<pub-id pub-id-type="pmid">16723398</pub-id>
</element-citation>
</ref>
<ref id="CR48">
<mixed-citation publication-type="other">Nguyen, T, Nowell K, Bodner KE, Obafemi-Ajayi T (2018) Ensemble validation paradigm for intelligent data analysis in autism spectrum disorders In: Computational Intelligence in Bioinformatics and Computational Biology (CIBCB), 2018 IEEE Conference On.. IEEE.</mixed-citation>
</ref>
<ref id="CR49">
<mixed-citation publication-type="other">Obafemi-Ajayi, T, Al-Jabery K, Salminen L, Laidlaw D, Cabeen R, Wunsch D, Paul R (2017) Neuroimaging biomarkers of cognitive decline in healthy older adults via unified learning In: Computational Intelligence (SSCI), 2017 IEEE Symposium Series On.. IEEE.</mixed-citation>
</ref>
<ref id="CR50">
<mixed-citation publication-type="other">Obafemi-Ajayi, T, Lam D, Takahashi TN, Kanne S, Wunsch D (2015) Sorting the phenotypic heterogeneity of autism spectrum disorders: A hierarchical clustering model In: Computational Intelligence in Bioinformatics and Computational Biology (CIBCB), 2015 IEEE Conference On, 1–7.. IEEE.</mixed-citation>
</ref>
<ref id="CR51">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Obafemi-Ajayi</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Miles</surname>
<given-names>JH</given-names>
</name>
<name>
<surname>Takahashi</surname>
<given-names>TN</given-names>
</name>
<name>
<surname>Qi</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Aldridge</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Zhang</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Xin</surname>
<given-names>S-Q</given-names>
</name>
<name>
<surname>He</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Duan</surname>
<given-names>Y</given-names>
</name>
</person-group>
<article-title>Facial structure analysis separates autism spectrum disorders into meaningful clinical subgroups</article-title>
<source/>J Autism Dev Disord
          <year>2015</year>
<volume>45</volume>
<issue>5</issue>
<fpage>1302</fpage>
<lpage>1317</lpage>
<pub-id pub-id-type="doi">10.1007/s10803-014-2290-8</pub-id>
<pub-id pub-id-type="pmid">25351828</pub-id>
</element-citation>
</ref>
<ref id="CR52">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ousley</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Cermak</surname>
<given-names>T</given-names>
</name>
</person-group>
<article-title>Autism spectrum disorder: defining dimensions and subgroups</article-title>
<source/>Curr Dev Disord Rep
          <year>2014</year>
<volume>1</volume>
<issue>1</issue>
<fpage>20</fpage>
<lpage>28</lpage>
<pub-id pub-id-type="doi">10.1007/s40474-013-0003-1</pub-id>
<pub-id pub-id-type="pmid">25072016</pub-id>
</element-citation>
</ref>
<ref id="CR53">
<mixed-citation publication-type="other">Pan, Y, Duron, Bush E, Ma Y, Sims P, Gutmann D, et al. (2018) Graph complexity analysis identifies an etv5 tumor-specific network in human and murine low-grade glioma 13(5):e0190001. Public Library of Science.</mixed-citation>
</ref>
<ref id="CR54">
<mixed-citation publication-type="other">Pierro, RD, Costantini G, Benzi IMA, Madeddu F, Preti E (2018) Grandiose and entitled, but still fragile: A network analysis of pathological narcissistic traits. Pers Ubiquit Comput. 10.1016/j.paid.2018.04.003.</mixed-citation>
</ref>
<ref id="CR55">
<mixed-citation publication-type="other">Nguyen, T, Obafemi-Ajayi T (2017) Cluster Validation Platform. GitHub.</mixed-citation>
</ref>
<ref id="CR56">
<mixed-citation publication-type="other">Node-Based Resilience Measure Clustering Project Website (2018). <ext-link ext-link-type="uri" xlink:href="http://www.cs.siue.edu/~gercal/clustering/">http://www.cs.siue.edu/~gercal/clustering/</ext-link>.</mixed-citation>
</ref>
<ref id="CR57">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Spencer</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Takahashi</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Chakraborty</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Miles</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Shyu</surname>
<given-names>C-R</given-names>
</name>
</person-group>
<article-title>Heritable genotype contrast mining reveals novel gene associations specific to autism subgroups</article-title>
<source/>J Biomed Inform
          <year>2018</year>
<volume>77</volume>
<fpage>50</fpage>
<lpage>61</lpage>
<pub-id pub-id-type="doi">10.1016/j.jbi.2017.11.016</pub-id>
<pub-id pub-id-type="pmid">29197649</pub-id>
</element-citation>
</ref>
<ref id="CR58">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stevens</surname>
<given-names>MC</given-names>
</name>
<name>
<surname>Fein</surname>
<given-names>DA</given-names>
</name>
<name>
<surname>Dunn</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Allen</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Waterhouse</surname>
<given-names>LH</given-names>
</name>
<name>
<surname>Feinstein</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Rapin</surname>
<given-names>I</given-names>
</name>
</person-group>
<article-title>Subgroups of children with autism by cluster analysis: A longitudinal examination</article-title>
<source/>J Am Acad Child Adolesc Psychiatry
          <year>2000</year>
<volume>39</volume>
<issue>3</issue>
<fpage>346</fpage>
<lpage>352</lpage>
<pub-id pub-id-type="doi">10.1097/00004583-200003000-00017</pub-id>
<pub-id pub-id-type="pmid">10714055</pub-id>
</element-citation>
</ref>
<ref id="CR59">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Veatch</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Veenstra-VanderWeele</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Potter</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Pericak-Vance</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Haines</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>Genetically meaningful phenotypic subgroups in autism spectrum disorders</article-title>
<source/>Genes Brain Behav
          <year>2014</year>
<volume>13</volume>
<issue>3</issue>
<fpage>276</fpage>
<lpage>285</lpage>
<pub-id pub-id-type="doi">10.1111/gbb.12117</pub-id>
<pub-id pub-id-type="pmid">24373520</pub-id>
</element-citation>
</ref>
<ref id="CR60">
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Vendramin</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Campello</surname>
<given-names>RJ</given-names>
</name>
<name>
<surname>Hruschka</surname>
<given-names>ER</given-names>
</name>
</person-group>
<article-title>Relative clustering validity criteria: A comparative overview</article-title>
<source/>Stat Anal Data Min
          <year>2010</year>
<volume>3</volume>
<issue>4</issue>
<fpage>209</fpage>
<lpage>235</lpage>
</element-citation>
</ref>
<ref id="CR61">
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Xu</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Wunsch II</surname>
<given-names>D</given-names>
</name>
</person-group>
<source/>Clustering
          <year>2009</year>
<publisher-loc>Piscataway</publisher-loc>
<publisher-name>Wiley</publisher-name>
</element-citation>
</ref>
<ref id="CR62">
<mixed-citation publication-type="other">Yang, J, Leskovec J (2012) Defining and evaluating network communities based on ground-truth In: Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics. MDS ’12, 3–138.. ACM, New York. <ext-link ext-link-type="uri" xlink:href="http://doi.acm.org/10.1145/2350190.2350193">http://doi.acm.org/10.1145/2350190.2350193</ext-link>.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
</pmc-articleset>