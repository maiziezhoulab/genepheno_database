<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="research-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">Sci Rep</journal-id>
<journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id>
<journal-title-group>
<journal-title>Scientific Reports</journal-title>
</journal-title-group>
<issn pub-type="epub">2045-2322</issn>
<publisher>
<publisher-name>Nature Publishing Group UK</publisher-name>
<publisher-loc>London</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">32433501</article-id>
<article-id pub-id-type="pmc">7239902</article-id>
<article-id pub-id-type="publisher-id">65384</article-id>
<article-id pub-id-type="doi">10.1038/s41598-020-65384-4</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Applying Machine Learning to Kinematic and Eye Movement Features of a Movement Imitation Task to Predict Autism Diagnosis</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Vabalas</surname>
<given-names>Andrius</given-names>
</name>
<address>
<email>andrius.vabalas@manchester.ac.uk</email>
</address>
<xref ref-type="aff" rid="Aff1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gowen</surname>
<given-names>Emma</given-names>
</name>
<xref ref-type="aff" rid="Aff2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Poliakoff</surname>
<given-names>Ellen</given-names>
</name>
<xref ref-type="aff" rid="Aff2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Casson</surname>
<given-names>Alexander J.</given-names>
</name>
<xref ref-type="aff" rid="Aff1">1</xref>
</contrib>
<aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000000121662407</institution-id><institution-id institution-id-type="GRID">grid.5379.8</institution-id><institution>The University of Manchester, Department of Electrical and Electronic Engineering, </institution></institution-wrap>Manchester, United Kingdom </aff>
<aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000000121662407</institution-id><institution-id institution-id-type="GRID">grid.5379.8</institution-id><institution>The University of Manchester, School of Biological Sciences, </institution></institution-wrap>Manchester, United Kingdom </aff>
</contrib-group>
<pub-date pub-type="epub">
<day>20</day>
<month>5</month>
<year>2020</year>
</pub-date>
<pub-date pub-type="pmc-release">
<day>20</day>
<month>5</month>
<year>2020</year>
</pub-date>
<pub-date pub-type="collection">
<year>2020</year>
</pub-date>
<volume>10</volume>
<elocation-id>8346</elocation-id>
<history>
<date date-type="received">
<day>4</day>
<month>12</month>
<year>2019</year>
</date>
<date date-type="accepted">
<day>30</day>
<month>4</month>
<year>2020</year>
</date>
</history>
<permissions>
<copyright-statement>© The Author(s) 2020</copyright-statement>
<license license-type="OpenAccess">
<license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
</license>
</permissions>
<abstract id="Abs1">
<p id="Par1">Autism is a developmental condition currently identified by experts using observation, interview, and questionnaire techniques and primarily assessing social and communication deficits. Motor function and movement imitation are also altered in autism and can be measured more objectively. In this study, motion and eye tracking data from a movement imitation task were combined with supervised machine learning methods to classify 22 autistic and 22 non-autistic adults. The focus was on a reliable machine learning application. We have used nested validation to develop models and further tested the models with an independent data sample. Feature selection was aimed at selection stability to assure result interpretability. Our models predicted diagnosis with 73% accuracy from kinematic features, 70% accuracy from eye movement features and 78% accuracy from combined features. We further explored features which were most important for predictions to better understand movement imitation differences in autism. Consistent with the behavioural results, most discriminative features were from the experimental condition in which non-autistic individuals tended to successfully imitate unusual movement kinematics while autistic individuals tended to fail. Machine learning results show promise that future work could aid in the diagnosis process by providing quantitative tests to supplement current qualitative ones.</p>
</abstract>
<kwd-group kwd-group-type="npg-subject">
<title>Subject terms</title>
<kwd>Machine learning</kwd>
<kwd>Human behaviour</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta>
<meta-name>issue-copyright-statement</meta-name>
<meta-value>© The Author(s) 2020</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="Sec1" sec-type="introduction">
<title>Introduction</title>
<p id="Par2">Autism is a group of complex developmental conditions characterised by deficits in social skills, verbal and non-verbal communication, and restrictive, repetitive behaviours. However, precise expression of symptoms can vary considerably and there are no universal biomarkers. It is one of the most prevalent developmental disorders affecting approximately 1% of the population, resulting in ~700,000 individuals living with autism in the UK<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Currently, its diagnosis relies on clinical experts using observation, interview, and questionnaire techniques, which depend on interpretative coding. The diagnostic process is complex, long and expensive, and the average waiting time between recognising initial concerns and actual clinical diagnosis is more than 3 years in the UK<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. Thus, valuable time is lost, because early identification and intervention are associated with better outcomes<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. Although, the majority of autistic individuals receive diagnosis in childhood, many remained undiagnosed until adulthood or not at all. The diagnostic process for the adult population is complicated, as current diagnostic instruments have only been validated for use with children<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>. With adults, clinicians rarely rely on standardised diagnostic methods making diagnosis less accurate, more subjective and lengthier<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>. Thus researching relevant diagnostic criteria for the adult population is critical and listed as one of top ten priorities by the UK’s leading autism research charity Autistica<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>.</p>
<p id="Par3">In addition to social and communication deficits, current diagnostic criteria recognize repetitive behaviours and movements as core symptoms of autism<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. However, a broad range of other motor functions are also implicated in autism. Even in the earliest characterization of the disorder, Kanner<sup><xref ref-type="bibr" rid="CR7">7</xref></sup> recognized unusual motor behaviours and described affected children as “clumsy”. However, only in the last two decades have motor deficits in autism received more attention and increasingly became recognised as important symptoms. In a recent large meta-analysis of studies investigating gait and balance, arm motor function and movement planning, a large and highly significant overall effect size was found showing gross motor impairments in autistic individuals in all examined domains<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. Motor function deficits are likely to be a good autism biomarker as they occur in the majority of autistic individuals<sup><xref ref-type="bibr" rid="CR9">9</xref>–<xref ref-type="bibr" rid="CR12">12</xref></sup>, are present from the first year and persist into adulthood<sup><xref ref-type="bibr" rid="CR13">13</xref>,<xref ref-type="bibr" rid="CR14">14</xref></sup> and can be measured more directly and objectively, compared to social or communication deficits.</p>
<p id="Par4">The ability to imitate or copy movements performed by others is also altered in autism. Imitation is a common every-day behaviour important for learning, social interaction and language skills. Metanalyses of imitation studies show deficits in autistic individuals<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR16">16</xref></sup>, with consistent findings of a reduced rate of spontaneous imitation<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> and poorer imitation of non-meaningful actions or imitation of manner and style of actions<sup><xref ref-type="bibr" rid="CR18">18</xref>–<xref ref-type="bibr" rid="CR21">21</xref></sup>. Building on that, several studies have used tasks requiring participants to imitate hand aiming movements while the style of the movement, such as the speed or size, was manipulated<sup><xref ref-type="bibr" rid="CR22">22</xref>–<xref ref-type="bibr" rid="CR24">24</xref></sup>. These studies used uniform movements allowing them to calculate precise kinematic measures (e.g. velocity, amplitude) by using motion tracking and to objectively compare the performance of autistic and non-autistic individuals. The results consistently showed that imitation precision of the style of the movement is lower in autistic compared to non-autistic adults and also that imitation is not solely an <italic>automatic</italic> behaviour driven by bottom-up processes, but that top-down attentional processes also play a role<sup><xref ref-type="bibr" rid="CR22">22</xref>–<xref ref-type="bibr" rid="CR27">27</xref></sup>. For example, group differences in imitation of the style of an action are removed if participants are explicitly asked to attend to the kinematics of the action<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. As reduced imitation of movement style by autistic individuals is reported consistently it is likely to be more universally present and specific to autism compared to other imitation and movement deficits. This suggests that kinematic data from such imitation tasks could offer good discriminability between autistic and non-autistic groups as well as potential for good machine learning (ML) classification performance.</p>
<p id="Par5">ML methods are well suited for the investigation of heterogeneous and multifaceted conditions such as autism because ML methods, in contrast, to more frequently used traditional univariate methods, make use of complex interactions between multiple variables and classes. However, ML has only recently become more widely used in clinical fields, including autism research. Most of the studies which used ML for autism prediction have used brain imaging data<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>, but studies from other domains also exist including ones which have used movement data.</p>
<p id="Par6">The studies which have applied ML methods on kinematic data used various tasks: tracking gameplay with sensors on a tablet screen surface<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>, tracking reach-and-throw a ball movements<sup><xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup> and tracking a simple movement imitation task<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. The studies had small sample sizes 20 to 82 (mean 40.5) and achieved high classification accuracy rates of 86.7% to 100%. However, the studies used result validation methods which do not necessarily sufficiently control for fitting random noise in the data<sup><xref ref-type="bibr" rid="CR33">33</xref>,<xref ref-type="bibr" rid="CR34">34</xref></sup> and did not test the models with new <italic>unseen</italic> data. The studies also did not assess if classification performance was statistically significantly different from random guessing.</p>
<p id="Par7">The ideal ML model would approximate only the regularities, but not the noise inherent in the training data and then generalise well when tested with new <italic>unseen</italic> data. However, if the model is not sufficiently validated/tested it is unclear how much of its performance is dependent on the noise fitting or on the regularities in the data. Recent ML study surveys suggest that avoiding fitting noise is particularly important when available sample sizes are small — surveyed studies with smaller sample sizes tended to report higher performance estimates<sup><xref ref-type="bibr" rid="CR28">28</xref>,<xref ref-type="bibr" rid="CR35">35</xref>,<xref ref-type="bibr" rid="CR36">36</xref></sup>, while theoretically the opposite should be the case<sup><xref ref-type="bibr" rid="CR37">37</xref>–<xref ref-type="bibr" rid="CR39">39</xref></sup>. In our recent study<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>, in which we asked participants to perform a very simple and short pointing task, we used nested cross-validation, which fully separates training and validation data and has been shown to provide an “<italic>almost unbiased estimate</italic> [of performance]”<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>, even with small sample sizes<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. In the study the sample size was small (<italic>N</italic> = 46) and 71% classification accuracy was modest compared to other studies which used kinematic data to predict autism diagnosis.</p>
<p id="Par8">In this study we investigated whether a simple imitation task could discriminate between autistic and non-autistic individuals and characterise autism-specific motor differences. 22 autistic and 22 non-autistic adults performed simple point to point movement sequences after observing them on the screen (Fig. <xref ref-type="fig" rid="Fig1">1a</xref>). A motion tracker was employed to collect kinematic data and we also tracked eye movements, while participants observed the movements to imitate. The style of the pointing movements was manipulated, so that movements were performed either in low or high trajectory and either slow or fast. The behavioural results from this experiment, described in detail in Gowen <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>, showed that autistic individuals imitated the style of the movement to a lesser extent than non-autistic individuals, consistent with earlier work using this task<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. Eye tracking also showed reduced visual attention to the movement when it was presented on the screen. These differences, however, diminished when participants were instructed to pay close attention to movement kinematics. Thus, in this study, we predicted that features from the experimental block when participants were instructed to simply copy what they saw would be more discriminative between groups than features from the block when they were asked to pay attention to the movement kinematics.<fig id="Fig1"><label>Figure 1</label><caption><p>(<bold>a</bold>) Four pointing locations for movement sequences. For kinematic and eye movement data analysis only movements between the two locations indicated with yellow arrows were included. Visual targets are for illustrative purposes only and were not displayed during the video clips or on the table in front of participants. (<bold>b</bold>) Description of kinematic features. (<bold>c</bold>) Kinematic feature structure. (<bold>d</bold>) Eye movement behaviour feature structure. SD - standard deviation. Panel (a) was adapted from<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>, creative commons license CC BY 4.0.</p></caption><graphic id="d30e424" xlink:href="41598_2020_65384_Fig1_HTML"></graphic></fig></p>
<p id="Par9">In contrast to previous ML in autism studies, which have used movement measures, we have also included eye movement behaviour measures, using them separately and in combination. Developing ML models with combined data from different modalities is likely to provide complementary information for predictions and improve classification performance<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>.</p>
<p id="Par10">A key consideration for the ML work was the reliability of the methods. We aimed to avoid overfitting at the model development stage for the models to reliably predict labels with <italic>unseen</italic> testing data. This is not an easy task with datasets such as ours, which have a large number of measures (features) and a small number of observations (samples). Both, validation to avoid noise fitting<sup><xref ref-type="bibr" rid="CR33">33</xref>,<xref ref-type="bibr" rid="CR35">35</xref></sup>, and selection of consistent discriminative feature sets used for predictions<sup><xref ref-type="bibr" rid="CR42">42</xref>–<xref ref-type="bibr" rid="CR44">44</xref></sup> have to be considered.</p>
<p id="Par11">To alleviate overfitting in addition to using nested validation we have also tested the models with an independent data. This approach should both provide reliable performance estimates and also show if at model development stage nested validation sufficiently controls noise fitting. The 44-participant sample was split into two parts: data from 30 participants (equally balanced between groups) was used for model development and the remaining data from 14 participants for independent testing of the developed models. As an additional safeguard, we have also assessed if classification performance given by our models was statistically significantly different from random guessing.</p>
<p id="Par12">To reduce data dimensionality, we have used several traditional feature elimination/selection methods. Those methods are designed to retain features which are most relevant for classification task and some also consider feature redundancy. However, selected feature sets are not always consistent - different feature sets tend to be retained if traditional selection methods are applied on different subsets of the data<sup><xref ref-type="bibr" rid="CR42">42</xref>,<xref ref-type="bibr" rid="CR43">43</xref></sup> — especially if the data is high dimensional and the sample size is small<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. This reduces result interpretability as consistently selected features may aid in understanding and visualisation of the problem. To overcome this issue, we have designed methods aimed at selection stability, with a new “Wrapped <italic>t</italic>-test” method showing good results. This allowed a more meaningful exploration of discriminative features to shed light on autism-specific motor patterns.</p>
<p id="Par13">In sum we have used a movement imitation task which in previous studies has consistently shown differences between autistic and non-autistic individuals. For ML classification we have combined motion and eye tracking data, and the main aim was reliable ML application. Nested validation was used at model development stage to assure good generalisability when the models were tested with hold-out data. To aid understanding which features were important for classifying individuals as autistic or non-autistic we have used feature selection methods aimed at selection stability.</p>
</sec>
<sec id="Sec2">
<title>Methods</title>
<sec id="Sec3">
<title>Experiment and data</title>
<p id="Par14">We have used separate model development and independent model testing datasets. In the development set, the sample consisted of 15 autistic and 15 non-autistic adults, matched for age, gender, handedness, and IQ. A hold-out testing set, also equivalently matched, consisted of 7 autistic and 7 non-autistic participants (Table <xref ref-type="table" rid="Tab1">1</xref>). The experimental protocol and stimuli are fully described in Gowen <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. During the experiment, all participants were asked to imitate sequences of simple hand movements. Participants first watched then imitated a video shown on a screen while their eye and hand movements were recorded using an eye tracker and a motion tracker. Movement sequences were simple and consisted of two point-to-point movements between three out of four possible locations 15 cm apart on a horizontal straight line, (Fig. <xref ref-type="fig" rid="Fig1">1a</xref>). All movements were performed with the dominant hand and only data collected between the locations indicated with arrows in (Fig. <xref ref-type="fig" rid="Fig1">1a</xref>) were used. In the videos, vertical amplitude and speed of the movements were manipulated resulting in three conditions: direct, elevated, and direct-fast. Another manipulation was related to attention. Participants first performed a block of imitation trials with a general instruction to simply copy what they saw. Then, in a second block, they were explicitly instructed to attend closely to the kinematic characteristics of the movement (the speed and height). This resulted in six different types of trials: condition(3) × block(2). The experimental procedures involving human subjects described in this paper were carried out in accordance with the Declaration of Helsinki and approved by the University of Manchester research ethics committee, ref: 2017-2541-4204. Informed consent was obtained from all participants.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Characteristics of training and test samples, <italic>p</italic> - two-sample <italic>t</italic>-test statistic (<italic>α</italic> level 0.05, two-tailed), f - female, m - male, lh - left-handed, rh - right-handed.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2"></th><th>Training sample Autistic</th><th>Non-autistic</th><th rowspan="2">Autistic vs non-autistic</th><th>Independent test sample Autistic)</th><th>Non-autistic)</th><th rowspan="2">Autistic vs non-autistic</th><th rowspan="2">Training vs independent sample</th></tr><tr><th>(n = 15)</th><th>(n = 15)</th><th>(n = 7</th><th>(n = 7</th></tr></thead><tbody><tr><td>Age</td><td>33.1</td><td>32.2</td><td><italic>p</italic> = 0.73</td><td>28.16</td><td>27.90</td><td><italic>p</italic> = 0.95</td><td><italic>p</italic> = 0.06</td></tr><tr><td>IQ</td><td>122.0</td><td>124.8</td><td><italic>p</italic> = 0.51</td><td>122.14</td><td>126.29</td><td><italic>p</italic> = 0.46</td><td><italic>p</italic> = 0.82</td></tr><tr><td>Gender</td><td>3f/12 m</td><td>3 f/12 m</td><td></td><td>4 f/3 m</td><td>4 f/3 m</td><td></td><td>20% f vs 57% f</td></tr><tr><td>Handedness</td><td>3 lh/12 rh</td><td>3 lh/12 rh</td><td></td><td>1 lh/6 rh</td><td>1 lh/6 rh</td><td></td><td>20% lh vs 14% lh</td></tr></tbody></table></table-wrap></p>
<sec id="Sec4">
<title>Kinematic features</title>
<p id="Par15">A Polhemus Fastrak motion tracker was used for kinematic data collection with a single motion sensor attached to the distal phalange of the index finger. The movement was sampled at 120 Hz in X, Y, Z coordinates, filtered with a 120 Hz Butterworth filter, and features based on velocity, acceleration, jerk and amplitude were calculated for each pointing movement, (Fig. <xref ref-type="fig" rid="Fig1">1b</xref>). Features were based on the mean and variability (standard deviation (SD)) of each of those measures. In total there were 120 kinematic features per block, 40 per condition (Fig. <xref ref-type="fig" rid="Fig1">1c</xref>).</p>
</sec>
<sec id="Sec5">
<title>Eye movement features</title>
<p id="Par16">An EyeLink 1000 Plus eye-tracker (SR Research) was used to collect eye movement behaviour data while participants were watching the videos to be imitated. Features were calculated using Data Viewer (SR Research) and MATLAB. The features were based on saccade measures and on visual attention to the finger performing movement sequences (description is given in Supplementary Method<xref ref-type="media" rid="MOESM1">s</xref>). Both means and variability measures (SDs) for each measure were calculated resulting in 48 features per block (Fig. <xref ref-type="fig" rid="Fig1">1d</xref>).</p>
</sec>
<sec id="Sec6">
<title>Combined features</title>
<p id="Par17">For combined data, both kinematic and eye movement behaviour features were combined to a single feature set.</p>
</sec>
</sec>
<sec id="Sec7">
<title>Data normalisation, cleaning</title>
<p id="Par18">For both datasets, individual trial outliers were removed at the level of participant and group outliers were replaced with group means. Outliers were identified based on the non-recursive procedure recommended by Van Selst and Jolicoeur<sup><xref ref-type="bibr" rid="CR45">45</xref></sup>. In the eye movement dataset, we have also removed trials in which missing data (blinks, pupil/corneal reflection loss) was over 1/3 of the total trial duration. Outlier removal and trials with missing data resulted in 2.3% missing values in kinematic dataset and 7.0% in eye movement dataset. Missing values were replaced with group means. Features were normalised by using standard score (z-score) transformation. Normalisation parameters (means and SDs) were calculated separately from training data to transform hold out data and validation data in each cross-validation (CV) fold during model development.</p>
</sec>
<sec id="Sec8">
<title>Classification algorithm</title>
<p id="Par19">For classification, Support Vector Machine (SVM) algorithm<sup><xref ref-type="bibr" rid="CR46">46</xref></sup> was used. It separates the classes by maximising the gap between training examples from each class. The examples in the test data are assigned a label based on which side of the gap they fall. In this study SVM with radial basis function (RBF) kernel was used. Regularisation parameters <italic>C</italic> and <italic>γ</italic> were optimised using grid search with grid parameters set to: <italic>C</italic> = 2<sup><italic>j</italic></sup>, where <italic>j</italic> = 1, 2, … 7 and <italic>γ</italic>  = 2<sup><italic>i</italic></sup>, where <italic>i</italic> = −1, −2, … −7 and by using 10-fold CV. SVM and grid search were implemented with Libsvm<sup><xref ref-type="bibr" rid="CR47">47</xref></sup> and Scikit-learn<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> libraries.</p>
</sec>
<sec id="Sec9">
<title>Validation and performance evaluation</title>
<p id="Par20">At the model development stage, nested cross-validation (CV)<sup><xref ref-type="bibr" rid="CR49">49</xref></sup> (bounded by the dashed line in Fig. <xref ref-type="fig" rid="Fig2">2</xref>) was used for result validation. Nested CV similarly to commonly used K-fold CV<sup><xref ref-type="bibr" rid="CR50">50</xref></sup> approach validates the results iteratively in CV folds, using all of the available data for training and also reusing all of it for validation. Both validation methods thus are economical and well suited when available data is small as is the case in this study. The nested CV is, however, different from K-fold CV in a significant aspect — it avoids pooling training and validation data. When a nested CV is performed a portion of data is split at the beginning of each CV fold for validation and a model is then developed on the reduced training set, including data normalisation feature selection and parameter tuning. This is repeated iteratively with splitting a different portion of the data for validation, and each time developing a new model for training from scratch until all of the data is used. By using the nested CV approach validation data is separate from model development and in that respect this approach is similar to Train/Test Split testing. Varma and Simon<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> have demonstrated that nested CV produces almost unbiased performance estimates, while the K-fold CV approach, which pools train and test data, can produce significantly over-optimistic results. In this study 10-fold Nested CV was used and the performance of the model was calculated as a mean performance of ten CV folds. Developed models were tested with independent data (yellow in Fig. <xref ref-type="fig" rid="Fig2">2</xref>) by testing each of 10 developed models separately and averaging the results. The process of model development and testing with an independent sample was repeated 50 times to obtain performance distributions, represented by confidence intervals in the graphs, and both model development and testing classification results are reported in the results section.<fig id="Fig2"><label>Figure 2</label><caption><p>Nested validation for model development and additional testing with independent data. Independent testing (yellow) was applied to each developed model and results averaged. Devel. - development, ACC - overall model accuracy, <italic>ACC</italic><sub><italic>i</italic></sub>. - accuracy in a single CV fold, n - sub-sample size, k - number of CV folds.</p></caption><graphic id="d30e781" xlink:href="41598_2020_65384_Fig2_HTML"></graphic></fig></p>
</sec>
<sec id="Sec10">
<title>Feature selection</title>
<p id="Par21">In this study, we have used several traditional feature selection methods and developed own methods aimed at feature selection stability. Datasets in which the number of features exceeds the number of observations are problematic for pattern recognition<sup><xref ref-type="bibr" rid="CR34">34</xref>,<xref ref-type="bibr" rid="CR51">51</xref>,<xref ref-type="bibr" rid="CR52">52</xref></sup>. However, such datasets are common in neuroimaging, gene expression, behaviour tracking and many other technology-based research areas. In this study both kinematic and eye movement datasets also have more features than samples. Commonly, to overcome this issue, a portion of features are eliminated and in recent years various techniques were developed to accomplish this. Feature elimination/selection achieves several objectives: reliable classifier performance, elimination of irrelevant and redundant features, and selection of stable feature sets.</p>
<p id="Par22">Using too many features can increase classification error and this effect is exacerbated when sample size is small. Hua <italic>et al</italic>.<sup><xref ref-type="bibr" rid="CR53">53</xref></sup> performed simulations to find an optimal number of features as a function of sample size for different classifiers and found that with training sample sizes comparable to the ones used in this study an optimal number of features is ≈10 and in this study, with each feature selection method, we reduced feature number to 10.</p>
<p id="Par23">Feature selection/elimination addresses not only classification robustness but also allows to eliminate features which are redundant or irrelevant for a classification task. Feature elimination methods used in this study can be subdivided into filter and wrapper methods. Filter methods simply apply a mathematical rule which addresses feature relevance, redundancy, or both for feature ranking and highly ranked features are selected for predictions. In wrapper methods, the performance of a classifier is a criterion for feature selection/elimination. This way, feature selection is <italic>wrapped</italic> around a classification model and finds a feature subset giving highest classification performance.</p>
<p id="Par24">In this study, we have used several traditional filter feature selection methods. These include Student’s <italic>t</italic>-test, which considers only feature relevance by simply ranking features based on how different feature means are between the two classes, as well as two methods which in addition to feature relevance also consider feature redundancy. ReliefF weighs features by considering their interactions<sup><xref ref-type="bibr" rid="CR54">54</xref></sup>. It uses the K-nearest neighbour method to weigh-up features which discriminate best from the neighbours of the different class. mRMR (minimum redundancy maximum relevance) selects features which discriminate categories well but are dissimilar to each other<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>. Both minimum redundancy and maximum relevance criteria are based on mutual information. We have also used a wrapper method SVM-RFE<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>, which eliminates a set number of features which are deemed least important for separating classes by an SVM algorithm, in a number of iterations.</p>
<p id="Par25">The selected most relevant features may aid in understanding and visualisation of a particular problem and may be useful for biomarker discovery. However, an issue of feature selection stability exists. Frequently, by using different feature selection methods or different subsets of data in a training sample (e.g. in different CV folds), selected features do not match, although classification performance may be comparable<sup><xref ref-type="bibr" rid="CR42">42</xref>,<xref ref-type="bibr" rid="CR43">43</xref></sup>. A major contributor to feature selection instability is small sample/high dimensional data<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. To measure feature selection stability we used Kuncheva’s index (KI)<sup><xref ref-type="bibr" rid="CR57">57</xref></sup>. It shows similarity of feature sets as follows:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$KI=\frac{2}{m(m-1)}\mathop{\sum }\limits_{i=1}^{m-1}\,\mathop{\sum }\limits_{j=m+1}^{m}\,\frac{(|{S}_{i}\cap {S}_{j}|l)-{k}^{2}}{k(l-k))},$$\end{document}</tex-math><mml:math display="block" id="M2"><mml:mi>K</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mi>m</mml:mi><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mspace width=".25em"></mml:mspace><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mspace width=".25em"></mml:mspace><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∩</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic position="anchor" xlink:href="41598_2020_65384_Article_Equ1.gif"></graphic></alternatives></disp-formula>where <italic>m</italic> is a number of feature subsets for similarity calculation, <italic>l</italic> is a number of features in a full dataset, <italic>k</italic> is a number of features in each subset (must be of equal cardinality). KI takes values between −1 and 1, with −1 meaning no overlap between feature subsets and 1 meaning that all feature subsets are identical.</p>
<p id="Par26">Traditional feature selection methods consider feature relevance and/or redundancy, but selection stability is rarely explicitly considered. Therefore, below we present three approaches which aim to increase feature selection stability.</p>
<sec id="Sec11">
<title>Ensemble feature selection</title>
<p id="Par27">One way to improve the generalization of classifier predictions is to aggregate the predictions of multiple classifiers<sup><xref ref-type="bibr" rid="CR58">58</xref></sup>. We have applied a similar approach to feature selection by combining different feature selectors. SVM-RFE, <italic>t</italic>-test, mRMR and ReliefF rankings were combined by simple voting and 10 highest ranked features were selected (Fig. <xref ref-type="fig" rid="Fig3">3a</xref>).<fig id="Fig3"><label>Figure 3</label><caption><p>Overview of our three feature selection methods (<bold>a</bold>) Ensemble — rankings of four feature selectors were combined and the 10 highest ranked features were selected. (<bold>b</bold>) <italic>t</italic>-test with bagging — <italic>t</italic>-test feature selection was performed 100 times on random subsamples of size <italic>n</italic>/2 and the 10 most frequently selected features in all the subsamples were selected. (<bold>c</bold>) Wrapped <italic>t</italic>-test — 10 features were selected using <italic>t</italic>-test ranking and their classification performance was assessed with an SVM classifier. If the accuracy was &gt;50%, those features were made to be more likely to be selected in the future iterations by adjusting their <italic>t</italic>-statistics up (or adjusted down if accuracy was &lt;50% making them less likely to be selected). Adjustments were accumulated until Kuncheva’s index (KI) was equal to 1 in 100 consecutive iterations. Blank box — initial feature set; blue/white box — ranked features; red/white box — combined ranks; red box — final feature set.</p></caption><graphic id="d30e1032" xlink:href="41598_2020_65384_Fig3_HTML"></graphic></fig></p>
</sec>
<sec id="Sec12">
<title><italic>t</italic>-test with bagging</title>
<p id="Par28">Meinshausen and Bühlmann<sup><xref ref-type="bibr" rid="CR59">59</xref></sup> proposed “stability selection” as a technique to improve feature selection stability. A general idea of the technique is that, instead of applying a selection algorithm on a whole dataset to select a feature set, feature selection is performed multiple times on random subsamples of the data. In this study, we have combined this approach with <italic>t</italic>-test ranking. Features were ranked 100 times on the random subsamples of the data of size <italic>n</italic>/2 and the final feature set comprised of 10 most frequently selected features in all of the subsamples (Fig. <xref ref-type="fig" rid="Fig3">3b</xref>).</p>
</sec>
<sec id="Sec13">
<title>Wrapped <italic>t</italic>-test</title>
<p id="Par29">In this work, we introduce a new method which is also centred on feature selection stability and combines aspects of both wrapper and filter approaches. Instead of removing or adding features based on classification performance, as in traditional wrapper methods, we adjusted ranking statistics of a filter selector by a small magnitude in multiple iterations until a ranking algorithm consistently selected identical feature sets (Fig. <xref ref-type="fig" rid="Fig3">3c</xref>). In this study, we have used the absolute value of Student’s <italic>t</italic>-test (two-sample) statistic for ranking. In the first iteration, we have selected 10 features with highest <italic>t</italic>-statistics and then in subsequent iterations, we adjusted <italic>t</italic>-statistics for those features based on classification performance in the outer 10-fold nested CV loop. <italic>t</italic>-statistics were adjusted up or down if classification accuracy was above or below 50% (random guessing level for a balanced two-class data set). Adjustments from all iterations were summed until ranking consistently selected identical feature sets in 100 consecutive iterations. Adjustment magnitude of 0.0001 was chosen because it allowed the algorithm to converge in a manageable number of iterations (&lt;100,000). Although this algorithm is computationally demanding, in the end, it provides a single consistent feature set. It is advantageous compared to other methods as a single consistent set allows a clear interpretation of what measures were important for separating classes.</p>
</sec>
</sec>
<sec id="Sec14">
<title>Result significance</title>
<p id="Par30">Statistical result significance was assessed with permutation testing. The labels of the data samples were randomly permutated 100 times and empirical <italic>p</italic>-statistic calculated as in Ojala and Garriga<sup><xref ref-type="bibr" rid="CR60">60</xref></sup>. A significance level of 0.05 was used.</p>
</sec>
</sec>
<sec id="Sec15" sec-type="results">
<title>Results</title>
<sec id="Sec16">
<title>Classification performance using data from general instruction and attention instruction experimental conditions</title>
<p id="Par31">Classification performance of all feature selection algorithms, followed by the SVM-RBF classifier, in the general instruction block was higher than in the attention instruction block. The difference was moderate for kinematic data (Fig. <xref ref-type="fig" rid="Fig4">4a</xref> and Table <xref ref-type="table" rid="Tab2">2</xref>) and more marked for eye movement behaviour (Fig. <xref ref-type="fig" rid="Fig4">4b</xref> and Table <xref ref-type="table" rid="Tab3">3</xref>) and combined data (Fig. <xref ref-type="fig" rid="Fig4">4c</xref> and Table <xref ref-type="table" rid="Tab4">4</xref>). Based on these results for further analyses we have used only data from the general instruction block.<fig id="Fig4"><label>Figure 4</label><caption><p>A box and whisker plot showing accuracy distributions of four algorithms with different feature selection using (<bold>a</bold>) kinematic, (<bold>b</bold>) eye movement behaviour, and (<bold>c</bold>) combined data. Green - general instruction block, yellow - attention instruction block.</p></caption><graphic id="d30e1132" xlink:href="41598_2020_65384_Fig4_HTML"></graphic></fig><table-wrap id="Tab2"><label>Table 2</label><caption><p>Kinematic data classification results. Acc. - accuracy, n.s. - not significant.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3">Algorithm</th><th colspan="4">General instruction block</th><th colspan="4">Attention instruction block</th></tr><tr><th colspan="2">Development</th><th colspan="2">Testing</th><th colspan="2">Development</th><th colspan="2">Testing</th></tr><tr><th>Acc.</th><th>KI</th><th>Acc.</th><th><italic>p</italic></th><th>Acc.</th><th>KI</th><th>Acc.</th><th><italic>p</italic></th></tr></thead><tbody><tr><td><italic>t</italic>-test</td><td>66%</td><td>0.66</td><td><underline>68%</underline></td><td>&lt;0.01</td><td>66%</td><td>0.73</td><td><underline>58%</underline></td><td>n.s.</td></tr><tr><td>SVM-RFE</td><td>71%</td><td>0.44</td><td><underline>57%</underline></td><td>n.s.</td><td>62%</td><td>0.41</td><td><underline>56%</underline></td><td>n.s.</td></tr><tr><td>ReliefF</td><td>60%</td><td>0.53</td><td><underline>63%</underline></td><td>n.s.</td><td>63%</td><td>0.66</td><td><underline>58%</underline></td><td>n.s.</td></tr><tr><td>mRMR</td><td>56%</td><td>0.21</td><td><underline>62%</underline></td><td>0.03</td><td>66%</td><td>0.35</td><td><underline>61%</underline></td><td>n.s.</td></tr></tbody></table></table-wrap><table-wrap id="Tab3"><label>Table 3</label><caption><p>Eye movement behaviour data classification results. Acc. - accuracy, n.s. - not significant.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3">Algorithm</th><th colspan="4">General instruction block</th><th colspan="4">Attention instruction block</th></tr><tr><th colspan="2">Development</th><th colspan="2">Testing</th><th colspan="2">Development</th><th colspan="2">Testing</th></tr><tr><th>Acc.</th><th>KI</th><th>Acc.</th><th><italic>p</italic></th><th>Acc.</th><th>KI</th><th>Acc.</th><th><italic>p</italic></th></tr></thead><tbody><tr><td><italic>t</italic>-test</td><td>77%</td><td>0.77</td><td><underline>71%</underline></td><td>0.02</td><td>61%</td><td>0.63</td><td><underline>41%</underline></td><td>n.s.</td></tr><tr><td>SVM-RFE</td><td>65%</td><td>0.46</td><td><underline>56%</underline></td><td>n.s.</td><td>59%</td><td>0.47</td><td><underline>45%</underline></td><td>n.s.</td></tr><tr><td>ReliefF</td><td>76%</td><td>0.73</td><td><underline>70%</underline></td><td>0.02</td><td>57%</td><td>0.60</td><td><underline>42%</underline></td><td>n.s.</td></tr><tr><td>mRMR</td><td>77%</td><td>0.36</td><td><underline>65%</underline></td><td>n.s.</td><td>62%</td><td>0.25</td><td><underline>42%</underline></td><td>n.s.</td></tr></tbody></table></table-wrap><table-wrap id="Tab4"><label>Table 4</label><caption><p>Combined data classification results. Acc. - accuracy, n.s. - not significant.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3">Algorithm</th><th colspan="4">General instruction block</th><th colspan="4">Attention instruction block</th></tr><tr><th colspan="2">Development</th><th colspan="2">Testing</th><th colspan="2">Development</th><th colspan="2">Testing</th></tr><tr><th>Acc.</th><th>KI</th><th>Acc.</th><th><italic>p</italic></th><th>Acc.</th><th>KI</th><th>Acc.</th><th><italic>p</italic></th></tr></thead><tbody><tr><td><italic>t</italic>-test</td><td>75%</td><td>0.76</td><td><underline>73%</underline></td><td>&lt;0.01</td><td>65%</td><td>0.62</td><td><underline>54%</underline></td><td>n.s.</td></tr><tr><td>SVM-RFE</td><td>66%</td><td>0.32</td><td><underline>65%</underline></td><td>0.03</td><td>62%</td><td>0.34</td><td><underline>53%</underline></td><td>n.s.</td></tr><tr><td>ReliefF</td><td>76%</td><td>0.72</td><td><underline>69%</underline></td><td>0.01</td><td>63%</td><td>0.64</td><td><underline>59%</underline></td><td>n.s.</td></tr><tr><td>mRMR</td><td>68%</td><td>0.31</td><td><underline>69%</underline></td><td>0.01</td><td>62%</td><td>0.33</td><td><underline>60%</underline></td><td>n.s.</td></tr></tbody></table></table-wrap></p>
<p id="Par32">Overall, classification accuracies at the model development stage (columns <italic>Development</italic>) were comparable to accuracies when those models were used to predict labels in independent test data-set (columns <italic>Testing</italic>), Tables <xref ref-type="table" rid="Tab2">2</xref>, <xref ref-type="table" rid="Tab3">3</xref>, and <xref ref-type="table" rid="Tab4">4</xref>. Nested cross-validation was sufficient to control overfitting and produced results which generalised well to the independent test sample.</p>
<p id="Par33">An algorithm using the simplest <italic>t</italic>-test feature selection outperformed all other algorithms in terms of classification accuracy and feature selection stability (KI) and this was the case for all data types (Fig. <xref ref-type="fig" rid="Fig4">4</xref>). In our previous study where we used kinematic features from a simple movement task<sup><xref ref-type="bibr" rid="CR40">40</xref></sup> we have obtained similar results — <italic>t</italic>-test feature selection outperformed other algorithms. Additionally, in other studies which had high dimensional/small sample datasets <italic>t</italic>-test consistently outperformed other algorithms in terms of selection stability and classification accuracy<sup><xref ref-type="bibr" rid="CR61">61</xref>,<xref ref-type="bibr" rid="CR62">62</xref></sup>. Taking this into consideration in the next section, we report the results of two variations of <italic>t</italic>-test feature selection: using bagging, combining <italic>t</italic>-test with wrapper selection approach, as well as, an ensemble of feature selectors which includes <italic>t</italic>-test.</p>
</sec>
<sec id="Sec17">
<title>Improved feature selection</title>
<p id="Par34">The idea behind an ensemble method is that a combination of output produced by multiple algorithms is potentially better than the output of a single algorithm. Ensembles have been shown to produce less variable and more robust results, especially with high dimensional/small sample data<sup><xref ref-type="bibr" rid="CR63">63</xref></sup>. With our datasets, the ensemble method outperformed SVM-RFE, ReliefF, and mRMR, both in classification accuracy and feature selection stability. <italic>t</italic>-test alone, however, produced very similar results to the ensemble (Figs. <xref ref-type="fig" rid="Fig4">4</xref> and <xref ref-type="fig" rid="Fig5">5</xref>).<fig id="Fig5"><label>Figure 5</label><caption><p>A box and whisker plot showing accuracy distributions of three algorithms with different feature selection using kinematic, eye movement behaviour, and combined data. Dashed lines show classification performance using <italic>t</italic>-test feature selection alone.</p></caption><graphic id="d30e1787" xlink:href="41598_2020_65384_Fig5_HTML"></graphic></fig></p>
<p id="Par35">The <italic>t</italic>-test feature selection consistently produced the most stable feature sets which nearly consistently outperformed other algorithms, thus we further explored two variations of <italic>t</italic>-test algorithm, with the aim of improving feature selection stability. First, we used <italic>t</italic>-test with bagging. Instead of applying the <italic>t</italic>-test algorithm on a whole data, feature selection was performed 100 times on the random subsamples of the size <italic>n</italic>/2. The results of <italic>t</italic>-test with bagging, however, did not show improvement on <italic>t</italic>-test alone both in stability or performance (Figs. <xref ref-type="fig" rid="Fig4">4</xref> and <xref ref-type="fig" rid="Fig5">5</xref>).</p>
<p id="Par36">Finally, we have used our new “Wrapped <italic>t</italic>-test” method which combines features of both filter and wrapper methods. Figure <xref ref-type="fig" rid="Fig6">6</xref> shows that cumulative adjustments of <italic>t</italic>-statistics progressively led to more stable feature selection demonstrated by increasing KI and also progressively better classification accuracy at a model development stage. Importantly, classification accuracy also increased on the independent dataset with the kinematic data (Fig. <xref ref-type="fig" rid="Fig6">6a</xref>) and combined data (Fig. <xref ref-type="fig" rid="Fig6">6c</xref>). There was no such effect with eye data (Fig. <xref ref-type="fig" rid="Fig6">6b</xref>). With kinematic data classification accuracy was 73%, with a sensitivity of 88%, specificity of 59%, and <italic>p</italic> &lt; 0.01, with eye data 70% accuracy, 43% sensitivity, 97% specificity, <italic>p</italic> = 0.02, with combined data 78% accuracy, 57% sensitivity, 99% specificity, <italic>p</italic> &lt; 0.01. This approach produced the best classification accuracy on kinematic and combined datasets (Table <xref ref-type="table" rid="Tab5">5</xref>). However, it did not show improvement of the eye dataset. This was likely because eye features were more similar and inter-correlated (<inline-formula id="IEq1"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{{r}}=0.48$$\end{document}</tex-math><mml:math id="M4"><mml:mover accent="true"><mml:mi mathvariant="italic">r</mml:mi><mml:mo mathvariant="italic">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.48</mml:mn></mml:math><inline-graphic xlink:href="41598_2020_65384_Article_IEq1.gif"></inline-graphic></alternatives></inline-formula>) than kinematic (<inline-formula id="IEq2"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{{r}}=0.20$$\end{document}</tex-math><mml:math id="M6"><mml:mover accent="true"><mml:mi mathvariant="italic">r</mml:mi><mml:mo mathvariant="italic">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.20</mml:mn></mml:math><inline-graphic xlink:href="41598_2020_65384_Article_IEq2.gif"></inline-graphic></alternatives></inline-formula>) or combined (<inline-formula id="IEq3"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{{r}}=0.20$$\end{document}</tex-math><mml:math id="M8"><mml:mover accent="true"><mml:mi mathvariant="italic">r</mml:mi><mml:mo mathvariant="italic">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.20</mml:mn></mml:math><inline-graphic xlink:href="41598_2020_65384_Article_IEq3.gif"></inline-graphic></alternatives></inline-formula>) features, and the number of features was considerably lower.<fig id="Fig6"><label>Figure 6</label><caption><p>Illustration of Wrapped <italic>t</italic>-test algorithm performance over successive iterations with (<bold>a</bold>) kinematic, (<bold>b</bold>) eye movement behaviour, and (<bold>c</bold>) combined datasets. In each model development iteration feature selection was performed 10 times – in each nested CV fold. Iterations were performed until KI was equal to 1 in 100 subsequent iterations. Thick dash-dot lines show fitted 5<sup><italic>th</italic></sup> order polynomial trend.</p></caption><graphic id="d30e1927" xlink:href="41598_2020_65384_Fig6_HTML"></graphic></fig><table-wrap id="Tab5"><label>Table 5</label><caption><p>Classification results with ensemble, <italic>t</italic>-test with bagging, and Wrapped <italic>t</italic>-test feature selection.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="3">Algorithm</th><th colspan="4">Kinematic data</th><th colspan="4">Eye movement behaviour data</th><th colspan="4">Combined data</th></tr><tr><th colspan="2">Development</th><th colspan="2">Testing</th><th colspan="2">Development</th><th colspan="2">Testing</th><th colspan="2">Development</th><th colspan="2">Testing</th></tr><tr><th>Acc.</th><th>KI</th><th>Acc.</th><th><italic>p</italic></th><th>Acc.</th><th>KI</th><th>Acc.</th><th><italic>p</italic></th><th>Acc.</th><th>KI</th><th>Acc.</th><th><italic>p</italic></th></tr></thead><tbody><tr><td>Ensemble</td><td>67%</td><td>0.61</td><td><underline>63%</underline></td><td>0.05</td><td>76%</td><td>0.71</td><td><underline>70%</underline></td><td>&lt;0.01</td><td>71%</td><td>0.59</td><td><underline>76%</underline></td><td>&lt;0.01</td></tr><tr><td><italic>t</italic>-test with bagging</td><td>65%</td><td>0.60</td><td><underline>67%</underline></td><td>0.03</td><td>77%</td><td>0.74</td><td><underline>71%</underline></td><td>0.03</td><td>74%</td><td>0.75</td><td><underline>72%</underline></td><td>&lt;0.01</td></tr><tr><td>Wrapped <italic>t</italic>-test</td><td>85%</td><td>1.00</td><td><underline>73%</underline></td><td>&lt;0.01</td><td>83%</td><td>1.00</td><td><underline>70%</underline></td><td>0.02</td><td>84%</td><td>1.00</td><td><underline>78%</underline></td><td>&lt;0.01</td></tr></tbody></table></table-wrap></p>
</sec>
<sec id="Sec18">
<title>Discriminatic kinematic features</title>
<p id="Par37">Here we interpret why selected kinematic features were salient for classification. For similar interpretation of selected discriminative features in eye movement and combined datasets see a Supplementary Note. Wrapped <italic>t</italic>-test feature selection was stable — we repeated feature selection on randomly sub-sampled data ten times and consistent feature sets were selected each time. Among the selected features in the kinematic dataset, 7 out of 10 features were from the elevated condition (Fig. <xref ref-type="fig" rid="Fig7">7c</xref>). This corresponds with the behavioural results in previous studies, which used imitation tasks and have shown reduced vertical amplitude modulation in individuals with autism<sup><xref ref-type="bibr" rid="CR22">22</xref>–<xref ref-type="bibr" rid="CR24">24</xref></sup>. Our data also shows a significant difference in movement vertical amplitude between autistic and non-autistic individuals when they were asked to imitate elevated trials, <italic>t</italic>(42) = 3.0, <italic>p</italic> = 0.004, <italic>d</italic> = 0.93, Fig. <xref ref-type="fig" rid="Fig7">7a</xref>. There were also differences in the acceleration profile between autistic and non-autistic individuals in elevated trials (Fig. <xref ref-type="fig" rid="Fig7">7b</xref>). Autistic individuals reached peak acceleration earlier in the movement, <italic>t</italic>(42) = 2.5, <italic>p</italic> = 0.017, <italic>d</italic> = 0.75, and peak deceleration later in the movement, <italic>t</italic>(29.4) = 3.0, <italic>p</italic> = 0.006, <italic>d</italic> = 0.90. This corresponds with the selected discriminative feature set as six out of ten features were acceleration/deceleration measures in elevated condition. Overall, both discriminative features and statistical differences suggest that non-autistic individuals reduced acceleration and deceleration and increased vertical amplitude in order to copy unusual elevated movement kinematics, while autistic individuals tended to retain their usual style of movement.<fig id="Fig7"><label>Figure 7</label><caption><p>(<bold>a</bold>) Movement vertical amplitude and (<bold>b</bold>) acceleration averaged for autistic and non-autistic participants in the elevated experimental condition, general instruction block. Shaded areas show the difference between groups. (<bold>c</bold>) Features selected with Wrapped <italic>t</italic>-test selection method. Mean difference column shows whether the mean for particular feature was greater for autistic (A) or non-autistic (N) class and gives a <italic>p</italic>-value of two-sample <italic>t</italic>-test.</p></caption><graphic id="d30e2248" xlink:href="41598_2020_65384_Fig7_HTML"></graphic></fig></p>
</sec>
</sec>
<sec id="Sec19" sec-type="discussion">
<title>Discussion</title>
<p id="Par38">Differences between autistic and non-autistic individuals have been shown across a broad range of movement and movement imitation tasks<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR16">16</xref></sup>. Among the more consistent findings is reduced imitation of movement style/manner by autistic individuals<sup><xref ref-type="bibr" rid="CR18">18</xref>–<xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR23">23</xref></sup>. In this study, we have used an imitation task in which movement style was manipulated and explored whether kinematic and eye movement behaviour measures could predict autism diagnosis. Developed models achieved a classification accuracy of 73% with kinematic data and 70% with eye movement data. We have also combined data from both kinematic and eye movement behaviour modalities. This provided complementary information for predictions and models on combined data gave the highest classification performance of 78%.</p>
<p id="Par39">To date, only a handful of ML studies used kinematic data for autism prediction. All studies had small sample sizes and achieved high classification accuracy. Models developed with small sample/high dimensional data are prone to fit noise and not necessarily an underlying pattern separating classes<sup><xref ref-type="bibr" rid="CR51">51</xref>,<xref ref-type="bibr" rid="CR64">64</xref></sup>. However, completely separating training and validation data (treating validation data as <italic>unseen</italic>) is sufficient to control overfitting and produce reliable performance estimates<sup><xref ref-type="bibr" rid="CR33">33</xref>,<xref ref-type="bibr" rid="CR36">36</xref></sup>. To the best of our knowledge, those studies did not avoid pooling training and validation data while developing their ML models and did not take other steps to control for the fitting of random noise in the data. Classification results were not tested with independent data and researchers did not assess the statistical significance of the results.</p>
<p id="Par40">Our focus for ML work was the reliability of used methods. We aimed to avoid fitting the noise in the data during model development stage to help assure that the models reliably predict labels with independent/<italic>unseen</italic> data during the testing stage. This was, however, not an easy task because of the characteristics of our datasets, which had a small number of samples and a high number of features. Such datasets are problematic for pattern recognition<sup><xref ref-type="bibr" rid="CR34">34</xref>,<xref ref-type="bibr" rid="CR35">35</xref>,<xref ref-type="bibr" rid="CR51">51</xref>,<xref ref-type="bibr" rid="CR52">52</xref></sup> and both result validation and consistent feature selection required careful consideration.</p>
<p id="Par41">For result validation at the model development stage, we used nested CV because it was shown to produce reliable results<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>. Moreover, we have shown that nested CV produces reliable results regardless of sample size<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. In addition to that, we have further verified that our models were not overfitted, by testing the results with an independent dataset. Classification performance at the model development stage was comparable to independent validation performance, showing that nested validation was sufficient to control overfitting. This was the case even though training and independent testing datasets were significantly different in terms of gender composition. There were 20% of females in model development dataset and 57% in the independent testing dataset (Table <xref ref-type="table" rid="Tab1">1</xref>). There are more males than females with autism diagnosis and recent studies suggest that there may be phenotypic gender differences<sup><xref ref-type="bibr" rid="CR65">65</xref>,<xref ref-type="bibr" rid="CR66">66</xref></sup>.</p>
<p id="Par42">Reliable feature selection was also a difficult issue to overcome. Traditional filter and wrapper feature selection methods produced only modest classification results, however, ranking feature sets with <italic>t</italic>-test consistently outperformed other methods in terms of feature selection stability and classification performance. Therefore, we developed two feature selection variations based on <italic>t</italic>-test with the main goal to improve feature selection stability. We used <italic>t</italic>-test with bagging by randomly subsampling data and aggregating feature ranks from multiple iterations. This method, however, did not show improvement on using <italic>t</italic>-test feature selection alone. A new “Wrapped <italic>t</italic>-test” algorithm combined aspects of filter and wrapper approaches. We adjusted <italic>t</italic>-statistics used for feature ranking by a small magnitude in multiple iterations based on classifier performance. We ran this algorithm until <italic>t</italic>-test algorithm consistently ranked identical feature sets. With increasing feature selection stability this algorithm increasingly fitted training data, importantly, it also produced a better performance on independent data as well. In addition to good classification performance, this method provided a stable final set of 10 features which has helped to illustrate movement imitation differences in autism.</p>
<p id="Par43">In the kinematic feature set, selected using a wrapped <italic>t</italic>-test, seven out of ten features were from the trials where movements were performed in elevated amplitude, and the same condition showed significant differences between autistic and non-autistic groups using parametric statistical tests. After watching videos of elevated movements to imitate, autistic individuals performed movements using a lower vertical amplitude than non-autistic individuals. As a consequence, autistic individuals also reached peak acceleration earlier in the movement and peak deceleration later in the movement. These results suggest that autistic individuals tended to retain their usual style of the movement when the movement to imitate had unusual kinematics. This is consistent with a number of studies which shown that while autistic individuals are more able to imitate goals of the action, they are less proficient at imitating the style or kinematics<sup><xref ref-type="bibr" rid="CR18">18</xref>–<xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR24">24</xref>,<xref ref-type="bibr" rid="CR67">67</xref></sup>.</p>
<p id="Par44">In a previous study<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>, which applied ML methods to the data from a similar imitation experiment with different participants, researchers selected exclusively only variability measures as most discriminative kinematic features, although feature selection was performed in a not fully algorithmic way (several feature selection algorithms were combined with selection decisions by researchers). This was not the case in our study with both means and SDs selected (Fig. <xref ref-type="fig" rid="Fig7">7c</xref>). However, in full feature sets, we found that autistic individuals tended both to perform movements with greater variability and to pay visual attention to the observed movement more variably. In the kinematic dataset autistic individuals showed higher variability than non-autistic individuals in 73% of 120 variability features (9% statistically significantly at 0.05 <italic>α</italic> level, two-tailed), in the eye movement behaviour dataset in 90% of 48 variability features (42% statistically significantly at 0.05 <italic>α</italic> level, two-tailed). Increased variability is a common finding in autism, reported for reaching movements<sup><xref ref-type="bibr" rid="CR68">68</xref></sup>, hand aiming movements<sup><xref ref-type="bibr" rid="CR69">69</xref></sup>, sustained force<sup><xref ref-type="bibr" rid="CR70">70</xref></sup>, precision grip<sup><xref ref-type="bibr" rid="CR71">71</xref></sup>, walking<sup><xref ref-type="bibr" rid="CR72">72</xref></sup> and Saccadic eye movements<sup><xref ref-type="bibr" rid="CR73">73</xref></sup>. Increased variability suggests differences in sensorimotor control and is especially apparent with challenging tasks and those requiring precision<sup><xref ref-type="bibr" rid="CR70">70</xref></sup>.</p>
</sec>
<sec id="Sec20" sec-type="conclusion">
<title>Conclusion</title>
<p id="Par45">In this study, we used a movement imitation task, which based on previous evidence, suggested good discriminability between autistic and non-autistic groups. ML classified autistic and non-autistic individuals with 73% accuracy using kinematic measures and with 70% accuracy using eye movement behaviour measures. Moreover, combining measures from both modalities provided complementary information for predictions and gave a classification accuracy of 78%. We have overcome overfitting and stable feature selection issues by using nested validation and feature selection aimed at selection stability and show that even small-sample studies can achieve statistically significant predictions which generalise to <italic>unseen</italic> data. The results show a promise that future work could aid in diagnostic process, by reliably applying ML methods and possibly combining features from several modalities.</p>
</sec>
<sec sec-type="supplementary-material">
<title>Supplementary information</title>
<sec id="Sec21">
<p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41598_2020_65384_MOESM1_ESM.pdf"><caption><p>Supplementary Information.</p></caption></media></supplementary-material>
</p>
</sec>
</sec>
</body>
<back>
<fn-group>
<fn>
<p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</fn>
</fn-group>
<sec>
<title>Supplementary information</title>
<p>is available for this paper at 10.1038/s41598-020-65384-4.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>E.G., E.P., and A.J.C hold academic positions at the University of Manchester and are funded centrally. A.V. was supported by the UK Engineering and Physical Sciences Research Council (website: <ext-link ext-link-type="uri" xlink:href="https://epsrc.ukri.org/">https://epsrc.ukri.org/</ext-link>) and its Doctoral Training Partnership with the University of Manchester (ref.: EP/M507969/1). Funders did not play a role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript. There was no additional internal or external funding received for this study.</p>
</ack>
<notes notes-type="author-contribution">
<title>Author contributions</title>
<p>A.V., E.G., E.P., and A.J.C. conceptualised/designed the study, developed methodology, and reviewed the manuscript. A.V. conducted the experiment, collected data, performed formal analyses, visualised the results, and wrote the main manuscript text. A.J.C. acquired funding.</p>
</notes>
<notes notes-type="data-availability">
<title>Data availability</title>
<p>The datasets generated and analysed during the current study are available at The University of Manchester repository: 10.17632/fnt6jtc5np.4.</p>
</notes>
<notes id="FPar1" notes-type="COI-statement">
<title>Competing interests</title>
<p id="Par46">The authors declare no competing interests.</p>
</notes>
<ref-list id="Bib1">
<title>References</title>
<ref id="CR1">
<label>1.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Brugha</surname>
<given-names>TS</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Epidemiology of autism spectrum disorders in adults in the community in england</article-title>
<source/>Arch. Gen. Psychiatry
          <year>2011</year>
<volume>68</volume>
<fpage>459</fpage>
<pub-id pub-id-type="pmid">21536975</pub-id>
</element-citation>
</ref>
<ref id="CR2">
<label>2.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Crane</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Chester</surname>
<given-names>JW</given-names>
</name>
<name>
<surname>Goddard</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Henry</surname>
<given-names>LA</given-names>
</name>
<name>
<surname>Hill</surname>
<given-names>E</given-names>
</name>
</person-group>
<article-title>Experiences of autism diagnosis: A survey of over 1000 parents in the united kingdom</article-title>
<source/>Autism
          <year>2016</year>
<volume>20</volume>
<fpage>153</fpage>
<lpage>162</lpage>
<pub-id pub-id-type="pmid">25810370</pub-id>
</element-citation>
</ref>
<ref id="CR3">
<label>3.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bradshaw</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Steiner</surname>
<given-names>AM</given-names>
</name>
<name>
<surname>Gengoux</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Koegel</surname>
<given-names>LK</given-names>
</name>
</person-group>
<article-title>Feasibility and effectiveness of very early intervention for infants at-risk for autism spectrum disorder: A systematic review</article-title>
<source/>J. Autism Dev. Disord.
          <year>2015</year>
<volume>45</volume>
<fpage>778</fpage>
<lpage>794</lpage>
<pub-id pub-id-type="pmid">25218848</pub-id>
</element-citation>
</ref>
<ref id="CR4">
<label>4.</label>
<mixed-citation publication-type="other">Cusack, J. &amp; Sterry, R. <italic>Your questions: shaping future autism research</italic> (London: Autistica, 2016).</mixed-citation>
</ref>
<ref id="CR5">
<label>5.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rutherford</surname>
<given-names>M</given-names>
</name>
<etal></etal>
</person-group>
<article-title>A national study to investigate the clinical use of standardised instruments in autism spectrum disorder assessment of children and adults in scotland</article-title>
<source/>Res. Autism Spectr. Disord.
          <year>2016</year>
<volume>29</volume>
<fpage>93</fpage>
<lpage>100</lpage>
</element-citation>
</ref>
<ref id="CR6">
<label>6.</label>
<mixed-citation publication-type="other">American Psychiatric Association<italic>. Diagnostic and statistical manual of mental disorders: DSM-5 R</italic> (American Psychiatric Pub, Washington, DC, 2013).</mixed-citation>
</ref>
<ref id="CR7">
<label>7.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kanner</surname>
<given-names>L</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Autistic disturbances of affective contact</article-title>
<source/>Nerv. Child
          <year>1943</year>
<volume>2</volume>
<fpage>217</fpage>
<lpage>250</lpage>
</element-citation>
</ref>
<ref id="CR8">
<label>8.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fournier</surname>
<given-names>KA</given-names>
</name>
<name>
<surname>Hass</surname>
<given-names>CJ</given-names>
</name>
<name>
<surname>Naik</surname>
<given-names>SK</given-names>
</name>
<name>
<surname>Lodha</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Cauraugh</surname>
<given-names>JH</given-names>
</name>
</person-group>
<article-title>Motor coordination in autism spectrum disorders: A synthesis and meta-analysis</article-title>
<source/>J. Autism Dev. Disord.
          <year>2010</year>
<volume>40</volume>
<fpage>1227</fpage>
<lpage>1240</lpage>
<pub-id pub-id-type="pmid">20195737</pub-id>
</element-citation>
</ref>
<ref id="CR9">
<label>9.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Green</surname>
<given-names>D</given-names>
</name>
<etal></etal>
</person-group>
<article-title>The severity and nature of motor impairment in asperger’s syndrome: a comparison with specific developmental disorder of motor function</article-title>
<source/>J. child psychology psychiatry
          <year>2002</year>
<volume>43</volume>
<fpage>655</fpage>
<lpage>668</lpage>
</element-citation>
</ref>
<ref id="CR10">
<label>10.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Green</surname>
<given-names>D</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Impairment in movement skills of children with autistic spectrum disorders</article-title>
<source/>Dev. Medicine &amp; Child Neurol.
          <year>2009</year>
<volume>51</volume>
<fpage>311</fpage>
<lpage>316</lpage>
</element-citation>
</ref>
<ref id="CR11">
<label>11.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hilton</surname>
<given-names>C</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Relationship between motor skill impairment and severity in children with asperger syndrome</article-title>
<source/>Res. Autism Spectr. Disord.
          <year>2007</year>
<volume>1</volume>
<fpage>339</fpage>
<lpage>349</lpage>
</element-citation>
</ref>
<ref id="CR12">
<label>12.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Miyahara</surname>
<given-names>M</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Brief report: motor incoordination in children with asperger syndrome and learning disabilities</article-title>
<source/>J. autism developmental disorders
          <year>1997</year>
<volume>27</volume>
<fpage>595</fpage>
<lpage>603</lpage>
</element-citation>
</ref>
<ref id="CR13">
<label>13.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Abu-Dahab</surname>
<given-names>SMN</given-names>
</name>
<name>
<surname>Skidmore</surname>
<given-names>ER</given-names>
</name>
<name>
<surname>Holm</surname>
<given-names>MB</given-names>
</name>
<name>
<surname>Rogers</surname>
<given-names>JC</given-names>
</name>
<name>
<surname>Minshew</surname>
<given-names>NJ</given-names>
</name>
</person-group>
<article-title>Motor and tactile-perceptual skill differences between individuals with high-functioning autism and typically developing individuals ages 5–21</article-title>
<source/>J. Autism Dev. Disord.
          <year>2013</year>
<volume>43</volume>
<fpage>2241</fpage>
<lpage>2248</lpage>
<pub-id pub-id-type="pmid">22318760</pub-id>
</element-citation>
</ref>
<ref id="CR14">
<label>14.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Biscaldi</surname>
<given-names>M</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Deficits in motor abilities and developmental fractionation of imitation performance in high-functioning autism spectrum disorders</article-title>
<source/>Eur. Child &amp; Adolesc. Psychiatry
          <year>2014</year>
<volume>23</volume>
<fpage>599</fpage>
<lpage>610</lpage>
</element-citation>
</ref>
<ref id="CR15">
<label>15.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Edwards</surname>
<given-names>LA</given-names>
</name>
</person-group>
<article-title>A meta-analysis of imitation abilities in individuals with autism spectrum disorders</article-title>
<source/>Autism Res.
          <year>2014</year>
<volume>7</volume>
<fpage>363</fpage>
<lpage>380</lpage>
<pub-id pub-id-type="pmid">24863681</pub-id>
</element-citation>
</ref>
<ref id="CR16">
<label>16.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Williams</surname>
<given-names>JHG</given-names>
</name>
<name>
<surname>Whiten</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Singh</surname>
<given-names>T</given-names>
</name>
</person-group>
<article-title>A systematic review of action imitation in autistic spectrum disorder</article-title>
<source/>J. Autism Dev. Disord.
          <year>2004</year>
<volume>34</volume>
<fpage>285</fpage>
<lpage>299</lpage>
<pub-id pub-id-type="pmid">15264497</pub-id>
</element-citation>
</ref>
<ref id="CR17">
<label>17.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ingersoll</surname>
<given-names>B</given-names>
</name>
</person-group>
<article-title>The effect of context on imitation skills in children with autism</article-title>
<source/>Res. Autism Spectr. Disord.
          <year>2008</year>
<volume>2</volume>
<fpage>332</fpage>
<lpage>340</lpage>
</element-citation>
</ref>
<ref id="CR18">
<label>18.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rogers</surname>
<given-names>SJ</given-names>
</name>
<name>
<surname>Bennetto</surname>
<given-names>L</given-names>
</name>
<name>
<surname>McEvoy</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Pennington</surname>
<given-names>BF</given-names>
</name>
</person-group>
<article-title>Imitation and pantomime in high-functioning adolescents with autism spectrum disorders</article-title>
<source/>Child Dev.
          <year>1996</year>
<volume>67</volume>
<fpage>2060</fpage>
<pub-id pub-id-type="pmid">9022229</pub-id>
</element-citation>
</ref>
<ref id="CR19">
<label>19.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Vanvuchelen</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Roeyers</surname>
<given-names>H</given-names>
</name>
<name>
<surname>De Weerdt</surname>
<given-names>W</given-names>
</name>
</person-group>
<article-title>Nature of motor imitation problems in school-aged males with autism: how congruent are the error types?</article-title>
<source/>Dev. Medicine Child Neurol.
          <year>2007</year>
<volume>49</volume>
<fpage>6</fpage>
<lpage>12</lpage>
</element-citation>
</ref>
<ref id="CR20">
<label>20.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Vivanti</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Nadig</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Ozonoff</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Rogers</surname>
<given-names>SJ</given-names>
</name>
</person-group>
<article-title>What do children with autism attend to during imitation tasks?</article-title>
<source/>J. Exp. Child Psychol.
          <year>2008</year>
<volume>101</volume>
<fpage>186</fpage>
<lpage>205</lpage>
<pub-id pub-id-type="pmid">18582895</pub-id>
</element-citation>
</ref>
<ref id="CR21">
<label>21.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Vivanti</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Trembath</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Dissanayake</surname>
<given-names>C</given-names>
</name>
</person-group>
<article-title>Mechanisms of imitation impairment in autism spectrum disorder</article-title>
<source/>J. Abnorm. Child Psychol.
          <year>2014</year>
<volume>42</volume>
<fpage>1395</fpage>
<lpage>1405</lpage>
<pub-id pub-id-type="pmid">24736983</pub-id>
</element-citation>
</ref>
<ref id="CR22">
<label>22.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wild</surname>
<given-names>KS</given-names>
</name>
<name>
<surname>Poliakoff</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Jerrison</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Gowen</surname>
<given-names>E</given-names>
</name>
</person-group>
<article-title>Goal-directed and goal-less imitation in autism spectrum disorder</article-title>
<source/>J. Autism Dev. Disord.
          <year>2012</year>
<volume>42</volume>
<fpage>1739</fpage>
<lpage>1749</lpage>
<pub-id pub-id-type="pmid">22146933</pub-id>
</element-citation>
</ref>
<ref id="CR23">
<label>23.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Forbes</surname>
<given-names>PAG</given-names>
</name>
<name>
<surname>Pan</surname>
<given-names>X</given-names>
</name>
<name>
<surname>Hamilton</surname>
<given-names>AF</given-names>
</name>
</person-group>
<article-title>Reduced mimicry to virtual reality avatars in autism spectrum disorder</article-title>
<source/>J. Autism Dev. Disord.
          <year>2016</year>
<volume>46</volume>
<fpage>3788</fpage>
<lpage>3797</lpage>
<pub-id pub-id-type="pmid">27696183</pub-id>
</element-citation>
</ref>
<ref id="CR24">
<label>24.</label>
<mixed-citation publication-type="other">Gowen, E., Vabalas, A., Casson, A. J. &amp; Poliakoff, E. Instructions to attend to an observed action increases imitation in autistic adults. <italic>Autism</italic>, 10.1177/1362361319882810 (2019).</mixed-citation>
</ref>
<ref id="CR25">
<label>25.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hayes</surname>
<given-names>SJ</given-names>
</name>
<name>
<surname>Dutoy</surname>
<given-names>CA</given-names>
</name>
<name>
<surname>Elliott</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Gowen</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Bennett</surname>
<given-names>SJ</given-names>
</name>
</person-group>
<article-title>Atypical biological motion kinematics are represented by complementary lower-level and top-down processes during imitation learning</article-title>
<source/>Acta Psychol.
          <year>2016</year>
<volume>163</volume>
<fpage>10</fpage>
<lpage>16</lpage>
</element-citation>
</ref>
<ref id="CR26">
<label>26.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hayes</surname>
<given-names>SJ</given-names>
</name>
<name>
<surname>Roberts</surname>
<given-names>JW</given-names>
</name>
<name>
<surname>Elliott</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Bennett</surname>
<given-names>SJ</given-names>
</name>
</person-group>
<article-title>Top-down attentional processes modulate the coding of atypical biological motion kinematics in the absence of motor signals</article-title>
<source/>J. Exp. Psychol. Hum. Percept. Perform.
          <year>2014</year>
<volume>40</volume>
<fpage>1641</fpage>
<pub-id pub-id-type="pmid">24955699</pub-id>
</element-citation>
</ref>
<ref id="CR27">
<label>27.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bek</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Poliakoff</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Marshall</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Trueman</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Gowen</surname>
<given-names>E</given-names>
</name>
</person-group>
<article-title>Enhancing voluntary imitation through attention and motor imagery</article-title>
<source/>Exp. Brain Res.
          <year>2016</year>
<volume>234</volume>
<fpage>1819</fpage>
<lpage>1828</lpage>
<pub-id pub-id-type="pmid">26892882</pub-id>
</element-citation>
</ref>
<ref id="CR28">
<label>28.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Arbabshirani</surname>
<given-names>MR</given-names>
</name>
<name>
<surname>Plis</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Sui</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Calhoun</surname>
<given-names>VD</given-names>
</name>
</person-group>
<article-title>Single subject prediction of brain disorders in neuroimaging: Promises and pitfalls</article-title>
<source/>NeuroImage
          <year>2016</year>
<volume>145</volume>
<fpage>137</fpage>
<lpage>165</lpage>
<pub-id pub-id-type="pmid">27012503</pub-id>
</element-citation>
</ref>
<ref id="CR29">
<label>29.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Anzulewicz</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Sobota</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Delafield-Butt</surname>
<given-names>JT</given-names>
</name>
</person-group>
<article-title>Toward the Autism Motor Signature: Gesture patterns during smart tablet gameplay identify children with autism</article-title>
<source/>Sci. Reports
          <year>2016</year>
<volume>6</volume>
<fpage>1</fpage>
<lpage>13</lpage>
</element-citation>
</ref>
<ref id="CR30">
<label>30.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Crippa</surname>
<given-names>A</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Use of machine learning to identify children with autism and their motor abnormalities</article-title>
<source/>J. Autism Dev. Disord.
          <year>2015</year>
<volume>45</volume>
<fpage>2146</fpage>
<lpage>2156</lpage>
<pub-id pub-id-type="pmid">25652603</pub-id>
</element-citation>
</ref>
<ref id="CR31">
<label>31.</label>
<mixed-citation publication-type="other">Perego, P., Forti, S., Crippa, A., Valli, A. &amp; Reni, G. Reach and throw movement analysis with support vector machines in early diagnosis of autism. In <italic>2009 Annual International Conference of the IEEE Engineering in Medicine and Biology Society</italic>, 2555–2558 (IEEE, 2009).</mixed-citation>
</ref>
<ref id="CR32">
<label>32.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Li</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Sharma</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Meng</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Purushwalkam</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Gowen</surname>
<given-names>E</given-names>
</name>
</person-group>
<article-title>Applying machine learning to identify autistic adults using imitation: An exploratory study</article-title>
<source/>PloS One
          <year>2017</year>
<volume>12</volume>
<fpage>e0182652</fpage>
<pub-id pub-id-type="pmid">28813454</pub-id>
</element-citation>
</ref>
<ref id="CR33">
<label>33.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Varma</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Simon</surname>
<given-names>R</given-names>
</name>
</person-group>
<article-title>Bias in error estimation when using cross-validation for model selection</article-title>
<source/>BMC Bioinforma.
          <year>2006</year>
<volume>7</volume>
<fpage>1</fpage>
<lpage>8</lpage>
</element-citation>
</ref>
<ref id="CR34">
<label>34.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Combrisson</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Jerbi</surname>
<given-names>K</given-names>
</name>
</person-group>
<article-title>Exceeding chance level by chance: The caveat of theoretical chance levels in brain signal classification and statistical assessment of decoding accuracy</article-title>
<source/>J. Neurosci. Methods
          <year>2015</year>
<volume>250</volume>
<fpage>126</fpage>
<lpage>136</lpage>
<pub-id pub-id-type="pmid">25596422</pub-id>
</element-citation>
</ref>
<ref id="CR35">
<label>35.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Varoquaux</surname>
<given-names>G</given-names>
</name>
</person-group>
<article-title>Cross-validation failure: Small sample sizes lead to large error bars</article-title>
<source/>NeuroImage
          <year>2018</year>
<volume>180</volume>
<fpage>68</fpage>
<lpage>77</lpage>
<pub-id pub-id-type="pmid">28655633</pub-id>
</element-citation>
</ref>
<ref id="CR36">
<label>36.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Vabalas</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Gowen</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Poliakoff</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Casson</surname>
<given-names>AJ</given-names>
</name>
</person-group>
<article-title>Machine learning algorithm validation with a limited sample size</article-title>
<source/>PLoS One
          <year>2019</year>
<volume>14</volume>
<fpage>1</fpage>
<lpage>20</lpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0224365</pub-id>
</element-citation>
</ref>
<ref id="CR37">
<label>37.</label>
<mixed-citation publication-type="other">Figueroa, R. L., Zeng-Treitler, Q., Kandula, S. &amp; Ngo, L. H. Predicting sample size required for classification performance. <italic>BMC Med. Informatics Decis. Mak</italic>. <bold>12</bold> (2012).</mixed-citation>
</ref>
<ref id="CR38">
<label>38.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mukherjee</surname>
<given-names>S</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Estimating dataset size requirements for classifying dna microarray data</article-title>
<source/>J. Comput. Biol.
          <year>2003</year>
<volume>10</volume>
<fpage>119</fpage>
<lpage>142</lpage>
<pub-id pub-id-type="pmid">12804087</pub-id>
</element-citation>
</ref>
<ref id="CR39">
<label>39.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Beleites</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Neugebauer</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Bocklitz</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Krafft</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Popp</surname>
<given-names>J</given-names>
</name>
</person-group>
<source/>Sample size planning for classification models. Anal. Chimica Acta
          <year>2013</year>
<volume>760</volume>
<fpage>25</fpage>
<lpage>33</lpage>
</element-citation>
</ref>
<ref id="CR40">
<label>40.</label>
<mixed-citation publication-type="other">Vabalas, A., Gowen, E., Poliakoff, E. &amp; Casson, A. J. Kinematic features of a simple and short movement task to predict autism diagnosis. In <italic>2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society</italic> (EMBC), 1421–1424 (IEEE, 2019).</mixed-citation>
</ref>
<ref id="CR41">
<label>41.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhang</surname>
<given-names>D</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Multimodal classification of alzheimer’s disease and mild cognitive impairment</article-title>
<source/>Neuroimage
          <year>2011</year>
<volume>55</volume>
<fpage>856</fpage>
<lpage>867</lpage>
<pub-id pub-id-type="pmid">21236349</pub-id>
</element-citation>
</ref>
<ref id="CR42">
<label>42.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bolón-Canedo</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Sánchez-Maroño</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Alonso-Betanzos</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>A review of feature selection methods on synthetic data</article-title>
<source/>Knowl. Inf. Syst.
          <year>2013</year>
<volume>34</volume>
<fpage>483</fpage>
<lpage>519</lpage>
</element-citation>
</ref>
<ref id="CR43">
<label>43.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kalousis</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Prados</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Hilario</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>Stability of feature selection algorithms: A study on high-dimensional spaces</article-title>
<source/>Knowl. Inf. Syst.
          <year>2007</year>
<volume>12</volume>
<fpage>95</fpage>
<lpage>116</lpage>
</element-citation>
</ref>
<ref id="CR44">
<label>44.</label>
<mixed-citation publication-type="other">Loscalzo, S., Yu, L. &amp; Ding, C. Consensus group stable feature selection. In <italic>Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</italic>, 567–576 (ACM, 2009).</mixed-citation>
</ref>
<ref id="CR45">
<label>45.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Van Selst</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Jolicoeur</surname>
<given-names>P</given-names>
</name>
</person-group>
<article-title>A solution to the effect of sample size on outlier elimination</article-title>
<source/>The Q. J. Exp. Psychol. Sect. A
          <year>1994</year>
<volume>47</volume>
<fpage>631</fpage>
<lpage>650</lpage>
</element-citation>
</ref>
<ref id="CR46">
<label>46.</label>
<mixed-citation publication-type="other">Boser, B. E., Guyon, I. M. &amp; Vapnik, V. N. A training algorithm for optimal margin classifiers. <italic>Proc. fifth annual workshop on Comput. learning theory</italic> 144–152 (1992).</mixed-citation>
</ref>
<ref id="CR47">
<label>47.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chang</surname>
<given-names>C-C</given-names>
</name>
<name>
<surname>Lin</surname>
<given-names>C-J</given-names>
</name>
</person-group>
<article-title>Libsvm: A library for support vector machines. ACM Transactions on Intell</article-title>
<source/>Syst. Technol.
          <year>2013</year>
<volume>2</volume>
<fpage>1</fpage>
<lpage>39</lpage>
</element-citation>
</ref>
<ref id="CR48">
<label>48.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Pedregosa</surname>
<given-names>F</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Scikit-learn: Machine learning in python</article-title>
<source/>J. Mach. Learn. Res.
          <year>2011</year>
<volume>12</volume>
<fpage>2825</fpage>
<lpage>2830</lpage>
</element-citation>
</ref>
<ref id="CR49">
<label>49.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stone</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>Cross-validatory choice and assessment of statistical predictions</article-title>
<source/>J. Royal Stat. Soc.
          <year>1974</year>
<volume>36</volume>
<fpage>111</fpage>
<lpage>147</lpage>
</element-citation>
</ref>
<ref id="CR50">
<label>50.</label>
<mixed-citation publication-type="other">James, G., Witten, D., Hastie, T. &amp; Tibshirani, R. <italic>An introduction to statistical learning: with applications in R</italic> (Springer, New York, 2013).</mixed-citation>
</ref>
<ref id="CR51">
<label>51.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Raudys</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Jain</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Small sample size effects in statistical pattern recognition: recommendations for practitioners</article-title>
<source/>IEEE Transactions on Pattern Analysis Mach. Intell.
          <year>1991</year>
<volume>13</volume>
<fpage>252</fpage>
<lpage>264</lpage>
</element-citation>
</ref>
<ref id="CR52">
<label>52.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kanal</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Chandrasekaran</surname>
<given-names>B</given-names>
</name>
</person-group>
<article-title>On dimensionality and sample size in statistical pattern classification</article-title>
<source/>Pattern Recognit.
          <year>1971</year>
<volume>3</volume>
<fpage>225</fpage>
<lpage>234</lpage>
</element-citation>
</ref>
<ref id="CR53">
<label>53.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hua</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Xiong</surname>
<given-names>Z</given-names>
</name>
<name>
<surname>Lowey</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Suh</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Dougherty</surname>
<given-names>ER</given-names>
</name>
</person-group>
<article-title>Optimal number of features as a function of sample size for various classification rules</article-title>
<source/>Bioinformatics
          <year>2005</year>
<volume>21</volume>
<fpage>1509</fpage>
<lpage>1515</lpage>
<pub-id pub-id-type="pmid">15572470</pub-id>
</element-citation>
</ref>
<ref id="CR54">
<label>54.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Urbanowicz</surname>
<given-names>RJ</given-names>
</name>
<name>
<surname>Olson</surname>
<given-names>RS</given-names>
</name>
<name>
<surname>Schmitt</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Meeker</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Moore</surname>
<given-names>JH</given-names>
</name>
</person-group>
<article-title>Benchmarking relief-based feature selection methods for bioinformatics data mining</article-title>
<source/>J. Biomed. Informatics
          <year>2018</year>
<volume>85</volume>
<fpage>168</fpage>
<lpage>188</lpage>
</element-citation>
</ref>
<ref id="CR55">
<label>55.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Peng</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Long</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Ding</surname>
<given-names>C</given-names>
</name>
</person-group>
<article-title>Feature selection based on mutual information: criteria of max-dependency, max-relevance, and min-redundancy</article-title>
<source/>IEEE Transactions on Pattern Analysis &amp; Mach. Intell.
          <year>2005</year>
<volume>27</volume>
<fpage>1226</fpage>
<lpage>1238</lpage>
</element-citation>
</ref>
<ref id="CR56">
<label>56.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Guyon</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Weston</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Barnhill</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Vapnik</surname>
<given-names>V</given-names>
</name>
</person-group>
<article-title>Gene selection for cancer classification using support vector machines</article-title>
<source/>Mach. Learn.
          <year>2002</year>
<volume>46</volume>
<fpage>389</fpage>
<lpage>422</lpage>
</element-citation>
</ref>
<ref id="CR57">
<label>57.</label>
<mixed-citation publication-type="other">Kuncheva, L. I. <italic>A stability index for feature selection. Int. Multi-conference: artificial intelligence applications</italic> 390–395 (2007).</mixed-citation>
</ref>
<ref id="CR58">
<label>58.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bauer</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Kohavi</surname>
<given-names>R</given-names>
</name>
</person-group>
<article-title>An empirical comparison of voting classification algorithms: Bagging, boosting, and variants</article-title>
<source/>Mach. Learn.
          <year>1999</year>
<volume>36</volume>
<fpage>105</fpage>
<lpage>139</lpage>
</element-citation>
</ref>
<ref id="CR59">
<label>59.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Meinshausen</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Bühlmann</surname>
<given-names>P</given-names>
</name>
</person-group>
<article-title>Stability selection</article-title>
<source/>J. R. Stat. Soc. Ser. B. Stat. Methodol.
          <year>2010</year>
<volume>72</volume>
<fpage>417</fpage>
<lpage>473</lpage>
</element-citation>
</ref>
<ref id="CR60">
<label>60.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ojala</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Garriga</surname>
<given-names>GC</given-names>
</name>
</person-group>
<article-title>Permutation tests for studying classifier performance</article-title>
<source/>J. Mach. Learn. Res.
          <year>2010</year>
<volume>11</volume>
<fpage>1833</fpage>
<lpage>1863</lpage>
</element-citation>
</ref>
<ref id="CR61">
<label>61.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Haury</surname>
<given-names>AC</given-names>
</name>
<name>
<surname>Gestraud</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Vert</surname>
<given-names>JP</given-names>
</name>
</person-group>
<article-title>The influence of feature selection methods on accuracy, stability and interpretability of molecular signatures</article-title>
<source/>PLoS One
          <year>2011</year>
<volume>6</volume>
<fpage>1</fpage>
<lpage>12</lpage>
</element-citation>
</ref>
<ref id="CR62">
<label>62.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dernoncourt</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Hanczar</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Zucker</surname>
<given-names>JD</given-names>
</name>
</person-group>
<article-title>Analysis of feature selection stability on high dimension and small sample data</article-title>
<source/>Comput. Stat. Data Analysis
          <year>2014</year>
<volume>71</volume>
<fpage>681</fpage>
<lpage>693</lpage>
</element-citation>
</ref>
<ref id="CR63">
<label>63.</label>
<mixed-citation publication-type="other">Bolón-Canedo, V., Sánchez-Maroño, N. &amp; Alonso-Betanzos, A. Data classification using an ensemble of filters. <italic>Neurocomputing</italic><bold>135</bold> (2014).</mixed-citation>
</ref>
<ref id="CR64">
<label>64.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jain</surname>
<given-names>AK</given-names>
</name>
<name>
<surname>Chandrasekaran</surname>
<given-names>B</given-names>
</name>
</person-group>
<article-title>39 dimensionality and sample size considerations in pattern recognition practice</article-title>
<source/>Handb. Stat.
          <year>1982</year>
<volume>2</volume>
<fpage>835</fpage>
<lpage>855</lpage>
</element-citation>
</ref>
<ref id="CR65">
<label>65.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Krishnan</surname>
<given-names>MC</given-names>
</name>
</person-group>
<article-title>Sex differences in autism spectrum disorder. The Complex</article-title>
<source/>Autism Spectr. Disord.
          <year>2018</year>
<volume>26</volume>
<fpage>69</fpage>
<lpage>86</lpage>
</element-citation>
</ref>
<ref id="CR66">
<label>66.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lai</surname>
<given-names>MC</given-names>
</name>
<etal></etal>
</person-group>
<article-title>A behavioral comparison of male and female adults with high functioning autism spectrum conditions</article-title>
<source/>PLoS ONE
          <year>2011</year>
<volume>6</volume>
<fpage>e20835</fpage>
<pub-id pub-id-type="pmid">21695147</pub-id>
</element-citation>
</ref>
<ref id="CR67">
<label>67.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hayes</surname>
<given-names>SJ</given-names>
</name>
<name>
<surname>Andrew</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Elliott</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Gowen</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Bennett</surname>
<given-names>SJ</given-names>
</name>
</person-group>
<article-title>Low fidelity imitation of atypical biological kinematics in autism spectrum disorders is modulated by self-generated selective attention</article-title>
<source/>J. Autism Dev. Disord.
          <year>2016</year>
<volume>46</volume>
<fpage>502</fpage>
<lpage>513</lpage>
<pub-id pub-id-type="pmid">26349922</pub-id>
</element-citation>
</ref>
<ref id="CR68">
<label>68.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mari</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Castiello</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Marks</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Marraffa</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Prior</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>The reach-to-grasp movement in children with autism spectrum disorder</article-title>
<source/>Philos. Transactions Royal Soc. Lond. Ser. B-Biological Sci.
          <year>2003</year>
<volume>358</volume>
<fpage>393</fpage>
<lpage>403</lpage>
</element-citation>
</ref>
<ref id="CR69">
<label>69.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Glazebrook</surname>
<given-names>CM</given-names>
</name>
<name>
<surname>Gonzalez</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Hansen</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Elliott</surname>
<given-names>D</given-names>
</name>
</person-group>
<article-title>The role of vision for online control of manual aiming movements in persons with autism spectrum disorders</article-title>
<source/>Autism
          <year>2009</year>
<volume>13</volume>
<fpage>411</fpage>
<lpage>433</lpage>
<pub-id pub-id-type="pmid">19535469</pub-id>
</element-citation>
</ref>
<ref id="CR70">
<label>70.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mosconi</surname>
<given-names>MW</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Feedforward and feedback motor control abnormalities implicate cerebellar dysfunctions in autism spectrum disorder</article-title>
<source/>J. Neurosci.
          <year>2015</year>
<volume>35</volume>
<fpage>2015</fpage>
<lpage>2025</lpage>
<pub-id pub-id-type="pmid">25653359</pub-id>
</element-citation>
</ref>
<ref id="CR71">
<label>71.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>David</surname>
<given-names>FJ</given-names>
</name>
<name>
<surname>Baranek</surname>
<given-names>GT</given-names>
</name>
<name>
<surname>Wiesen</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Miao</surname>
<given-names>AF</given-names>
</name>
<name>
<surname>Thorpe</surname>
<given-names>DE</given-names>
</name>
</person-group>
<article-title>Coordination of precision grip in 2-6 years-old children with autism spectrum disorders compared to children developing typically and children with developmental disabilities</article-title>
<source/>Front. Integr. Neurosci.
          <year>2012</year>
<volume>6</volume>
<fpage>122</fpage>
<pub-id pub-id-type="pmid">23293589</pub-id>
</element-citation>
</ref>
<ref id="CR72">
<label>72.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Vernazza-Martin</surname>
<given-names>S</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Goal directed locomotion and balance control in autistic children</article-title>
<source/>J. Autism Dev. Disord.
          <year>2005</year>
<volume>35</volume>
<fpage>91</fpage>
<lpage>102</lpage>
<pub-id pub-id-type="pmid">15796125</pub-id>
</element-citation>
</ref>
<ref id="CR73">
<label>73.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Schmitt</surname>
<given-names>LM</given-names>
</name>
<name>
<surname>Cook</surname>
<given-names>EH</given-names>
</name>
<name>
<surname>Sweeney</surname>
<given-names>JA</given-names>
</name>
<name>
<surname>Mosconi</surname>
<given-names>MW</given-names>
</name>
</person-group>
<article-title>Saccadic eye movement abnormalities in autism spectrum disorder indicate dysfunctions in cerebellum and brainstem</article-title>
<source/>Mol. Autism
          <year>2014</year>
<volume>5</volume>
<fpage>1</fpage>
<lpage>13</lpage>
<pub-id pub-id-type="pmid">24410847</pub-id>
</element-citation>
</ref>
</ref-list>
</back>
</article>
</pmc-articleset>