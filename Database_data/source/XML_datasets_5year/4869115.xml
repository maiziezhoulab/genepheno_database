<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="research-article" xmlns:mml="http://www.w3.org/1998/Math/MathML">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">Sci Rep</journal-id>
<journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id>
<journal-title-group>
<journal-title>Scientific Reports</journal-title>
</journal-title-group>
<issn pub-type="epub">2045-2322</issn>
<publisher>
<publisher-name>Nature Publishing Group</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">27185194</article-id>
<article-id pub-id-type="pmc">4869115</article-id>
<article-id pub-id-type="pii">srep26094</article-id>
<article-id pub-id-type="doi">10.1038/srep26094</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Miotto</surname>
<given-names>Riccardo</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Li</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kidd</surname>
<given-names>Brian A.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dudley</surname>
<given-names>Joel T.</given-names>
</name>
<xref ref-type="corresp" rid="c1">a</xref>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Genetics and Genomic Sciences, Icahn School of Medicine at Mount Sinai</institution>, New York, NY, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Harris Center for Precision Wellness, Icahn School of Medicine at Mount Sinai</institution>, New York, NY, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution>Icahn Institute for Genomics and Multiscale Biology, Icahn School of Medicine at Mount Sinai</institution>, New York, NY, <country>USA</country></aff>
</contrib-group>
<author-notes>
<corresp id="c1">
<label>a</label>
<email>joel.dudley@mssm.edu</email>
</corresp>
</author-notes>
<pub-date pub-type="epub">
<day>17</day>
<month>05</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<year>2016</year>
</pub-date>
<volume>6</volume>
<elocation-id>26094</elocation-id>
<history>
<date date-type="received">
<day>28</day>
<month>01</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>27</day>
<month>04</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-statement>Copyright © 2016, Macmillan Publishers Limited</copyright-statement>
<copyright-year>2016</copyright-year>
<copyright-holder>Macmillan Publishers Limited</copyright-holder>
<license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/" xmlns:xlink="http://www.w3.org/1999/xlink">
<!--author-paid-->
<license-p>This work is licensed under a Creative Commons Attribution 4.0 International License. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in the credit line; if the material is not included under the Creative Commons license, users will need to obtain permission from the license holder to reproduce the material. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p>
</license>
</permissions>
<abstract>
<p>Secondary use of electronic health records (EHRs) promises to advance clinical research and better inform clinical decision making. Challenges in summarizing and representing patient data prevent widespread practice of predictive modeling using EHRs. Here we present a novel unsupervised deep feature learning method to derive a general-purpose patient representation from EHR data that facilitates clinical predictive modeling. In particular, a three-layer stack of denoising autoencoders was used to capture hierarchical regularities and dependencies in the aggregated EHRs of about 700,000 patients from the Mount Sinai data warehouse. The result is a representation we name “deep patient”. We evaluated this representation as broadly predictive of health states by assessing the probability of patients to develop various diseases. We performed evaluation using 76,214 test patients comprising 78 diseases from diverse clinical domains and temporal windows. Our results significantly outperformed those achieved using representations based on raw EHR data and alternative feature learning strategies. Prediction performance for severe diabetes, schizophrenia, and various cancers were among the top performing. These findings indicate that deep learning applied to EHRs can derive patient representations that offer improved clinical predictions, and could provide a machine learning framework for augmenting clinical decision systems.</p>
</abstract>
</article-meta>
</front>
<body>
<p>A primary goal of precision medicine is to develop quantitative models for patients that can be used to predict health status, as well as to help prevent disease or disability. In this context, electronic health records (EHRs) offer great promise for accelerating clinical research and predictive analysis<xref ref-type="bibr" rid="b1">1</xref>. Recent studies have shown that secondary use of EHRs has enabled data-driven prediction of drug effects and interactions<xref ref-type="bibr" rid="b2">2</xref>, identification of type 2 diabetes subgroups<xref ref-type="bibr" rid="b3">3</xref>, discovery of comorbidity clusters in autism spectrum disorders<xref ref-type="bibr" rid="b4">4</xref>, and improvements in recruiting patients for clinical trials<xref ref-type="bibr" rid="b5">5</xref>. However, predictive models and tools based on modern machine learning techniques have not been widely and reliably used in clinical decision support systems or workflows<xref ref-type="bibr" rid="b6">6</xref><xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b8">8</xref><xref ref-type="bibr" rid="b9">9</xref>.</p>
<p>EHR data is challenging to represent and model due to its high dimensionality, noise, heterogeneity, sparseness, incompleteness, random errors, and systematic biases<xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b10">10</xref><xref ref-type="bibr" rid="b11">11</xref>. Moreover, the same clinical phenotype can be expressed using different codes and terminologies. For example, a patient diagnosed with “type 2 diabetes mellitus” can be identified by laboratory values of hemoglobin A1C greater than 7.0, presence of 250.00 ICD-9 code, “type 2 diabetes mellitus” mentioned in the free-text clinical notes, and so on. These challenges have made it difficult for machine learning methods to identify patterns that produce predictive clinical models for real-world applications<xref ref-type="bibr" rid="b12">12</xref>.</p>
<p>The success of predictive algorithms largely depends on feature selection and data representation<xref ref-type="bibr" rid="b12">12</xref><xref ref-type="bibr" rid="b13">13</xref>. A common approach with EHRs is to have a domain expert designate the patterns to look for (i.e., the learning task and the targets) and to specify clinical variables in an ad-hoc manner<xref ref-type="bibr" rid="b7">7</xref>. Although appropriate in some situations, supervised definition of the feature space scales poorly, does not generalize well, and misses opportunities to discover novel patterns and features. To address these shortcomings, data-driven approaches for feature selection in EHRs have been proposed<xref ref-type="bibr" rid="b14">14</xref><xref ref-type="bibr" rid="b15">15</xref><xref ref-type="bibr" rid="b16">16</xref>. A limitation of these methods is that patients are often represented as a 2-dimensional vector composed by all the data descriptors available in the clinical data warehouse. This representation is sparse, noisy, and repetitive, which makes it not suitable for modeling the hierarchical information embedded or latent in EHRs.</p>
<p>Unsupervised feature learning attempts to overcome limitations of supervised feature space definition by automatically identifying patterns and dependencies in the data to learn a compact and general representation that make it easier to automatically extract useful information when building classifiers or other predictors. Despite the success of feature learning with text, multimedia, and marketing<xref ref-type="bibr" rid="b12">12</xref>, as well as the rising popularity of deep learning<xref ref-type="bibr" rid="b17">17</xref> (i.e., learning based on hierarchies of neural networks), these techniques have not been used broadly with EHR data. Here we show that unsupervised deep feature learning applied to pre-process patient-level aggregated EHR data results in representations that are better understood by the machine and significantly improve predictive clinical models for a diverse array of clinical conditions.</p>
<p>This paper presents a novel framework we call “deep patient” to represent patients by a set of general features, which are inferred automatically from a large-scale EHR database through a deep learning approach. Specifically, a deep neural network composed of a stack of denoising autoencoders was used to process EHRs in an unsupervised manner that captured stable structures and regular patterns in the data, which, grouped together, compose the deep patient representation. Deep patient is domain free (i.e., not related to any specific task since learned over a large multi-domain dataset), does not require any additional human effort, and can be easily applied to different predictive applications, both supervised and unsupervised. To prove the effectiveness of the proposed representation we apply deep patient to predict patient future diseases and show that the deep patient consistently outperforms original EHR representations as well as common (shallow) feature learning models in a large-scale real world data experiment.</p>
<sec disp-level="1">
<title>Material and Methods</title>
<p>This section presents the deep patient method and describes the pipeline implemented to evaluate the benefits of this representation in the task of predicting future diseases.</p>
<sec disp-level="2">
<title>Deep Patient Representation</title>
<p><xref ref-type="fig" rid="f1">Figure 1</xref> shows the high-level conceptual framework to derive the deep patient representation. EHRs are first extracted from the clinical data warehouse, pre-processed to identify and normalize clinically relevant phenotypes, and grouped in patient vectors (i.e., raw representation, <xref ref-type="fig" rid="f1">Fig. 1A</xref>). Each patient can be described by just a single vector or by a sequence of vectors computed in, e.g., predefined temporal windows. The collection of vectors obtained from all the patients is used as input of the feature learning algorithm to discover a set of high level general descriptors (<xref ref-type="fig" rid="f1">Fig. 1B</xref>). Every patient in the data warehouse is then represented using these features and such deep representation can be applied to different clinical tasks (<xref ref-type="fig" rid="f1">Fig. 1C</xref>).</p>
<p>We derived the patient representation using a multi-layer neural network in a deep learning architecture (i.e., deep patient). Each layer of the network is trained to produce a higher-level representation of the observed patterns, based on the data it receives as input from the layer below, by optimizing a local unsupervised criterion (<xref ref-type="fig" rid="f2">Fig. 2</xref>). Every level produces a representation of the input pattern that is more abstract than the previous level because it is obtained by composing more non-linear operations. This process is loosely analogous to neuroscience models of cognition that hierarchically combine lower-level features to a unified and compact representation. The last network of the chain outputs the final patient representation.</p>
</sec>
<sec disp-level="2">
<title>Denoising Autoencoders</title>
<p>We implemented our framework using a stack of denoising autoencoders (SDA), which are independently trained layer by layer; all the autoencoders in the architecture share the same structure and functionalities<xref ref-type="bibr" rid="b18">18</xref>. Briefly, an autoencoder takes an input <inline-formula id="d33e226"><inline-graphic id="d33e227" xlink:href="srep26094-m1.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula> and first transforms it (with an <italic>encoder</italic>) to a hidden representation <inline-formula id="d33e232"><inline-graphic id="d33e233" xlink:href="srep26094-m2.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula>through a deterministic mapping:</p>
<p>
<disp-formula id="eq3">
<inline-graphic id="d33e237" xlink:href="srep26094-m3.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic>
</disp-formula>
</p>
<p>parameterized by <inline-formula id="d33e240"><inline-graphic id="d33e241" xlink:href="srep26094-m4.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula>, where <inline-formula id="d33e243"><inline-graphic id="d33e244" xlink:href="srep26094-m5.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula> is a non-linear transformation (e.g., sigmoid, tangent) named “activation function”, <italic><bold>W</bold></italic> is a weight coefficient matrix, and <italic><bold>b</bold></italic> is a bias vector. The latent representation <italic><bold>y</bold></italic> is then mapped back (with a <italic>decoder</italic>) to a reconstructed vector <inline-formula id="d33e262"><inline-graphic id="d33e263" xlink:href="srep26094-m6.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula>, such as:</p>
<p>
<disp-formula id="eq7">
<inline-graphic id="d33e267" xlink:href="srep26094-m7.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic>
</disp-formula>
</p>
<p>with <inline-formula id="d33e270"><inline-graphic id="d33e271" xlink:href="srep26094-m8.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula> and <inline-formula id="d33e273"><inline-graphic id="d33e274" xlink:href="srep26094-m9.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula> (i.e., tied weights). The hope is that the code <italic><bold>y</bold></italic> is a distributed representation that captures the coordinates along the main factors of variation in the data. When training the model, the algorithm searches the parameters that minimize the difference between <italic><bold>x</bold></italic> and <italic><bold>z</bold></italic> (i.e., the reconstruction error <inline-formula id="d33e289"><inline-graphic id="d33e290" xlink:href="srep26094-m10.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula>).</p>
<p>Autoencoders are often trained to reconstruct the input from a noisy version of the initial data (i.e., denoising) in order to prevent overfitting. This is done by first corrupting the initial input <italic><bold>x</bold></italic> to get a partially destroyed version <inline-formula id="d33e298"><inline-graphic id="d33e299" xlink:href="srep26094-m11.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula> through a stochastic mapping <inline-formula id="d33e301"><inline-graphic id="d33e302" xlink:href="srep26094-m12.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula>. The corrupted input <inline-formula id="d33e304"><inline-graphic id="d33e305" xlink:href="srep26094-m13.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula> is then mapped, as with the basic autoencoder, to a hidden code <inline-formula id="d33e307"><inline-graphic id="d33e308" xlink:href="srep26094-m14.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula> and then to the decoded representation <italic><bold>z</bold></italic> (see the <xref ref-type="supplementary-material" rid="S1">Supplementary Appendix A</xref> online for a graphical representation). We implemented input corruption using the masking noise algorithm<xref ref-type="bibr" rid="b18">18</xref>, in which a fraction <italic><bold>y</bold></italic> of the elements of <italic><bold>x</bold></italic> chosen at random is turned to zero. This can be viewed as simulating the presence of missed components in the EHRs (e.g., medications or diagnoses not recorded in the patient records), thus assuming that the input clinical data is a degraded or “noisy” version of the actual clinical situation. All information about those masked components is then removed from that input pattern, and denoising autoencoders can be seen as trained to fill-in these artificially introduced blanks.</p>
<p>The parameters of the model <italic>θ</italic> and <italic>θ</italic>′ are optimized over the training dataset to minimize the average reconstruction error,</p>
<p>
<disp-formula id="eq15">
<inline-graphic id="d33e338" xlink:href="srep26094-m15.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic>
</disp-formula>
</p>
<p>where <inline-formula id="d33e341"><inline-graphic id="d33e342" xlink:href="srep26094-m16.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula> is a loss function and <italic>N</italic> is the number of patients in the training set. We used the reconstruction cross-entropy function as loss function, i.e.,</p>
<p>
<disp-formula id="eq17">
<inline-graphic id="d33e349" xlink:href="srep26094-m17.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic>
</disp-formula>
</p>
<p>Optimization is carried out by mini-batch stochastic gradient descent, which iterates through small subsets of the training patients and modifies the parameters in the opposite direction of the gradient of the loss function to minimize the reconstruction error. The learned encoding function <inline-formula id="d33e353"><inline-graphic id="d33e354" xlink:href="srep26094-m18.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula> is then applied to the clean input <italic><bold>x</bold></italic> and the resulting code <italic><bold>y</bold></italic> is the distributed representation (i.e., the input of the following autoencoder in the SDA architecture or the final deep patient representation).</p>
</sec>
<sec disp-level="2">
<title>Evaluation Design</title>
<p>Feature learning algorithms are usually evaluated in supervised applications to take advantage of the available manually annotated labels. Here we used the Mount Sinai data warehouse to learn the deep features and we evaluated them in predicting patient future diseases. The Mount Sinai Health System generates a high volume of structured, semi-structured and unstructured data as part of its healthcare and clinical operations, which include inpatient, outpatient and emergency room visits. Patients in the system can have as long as 12 years of follow up unless they moved or changed insurance. Electronic records were completely implemented by our health system starting in 2003. The data related to patients who visited the hospital prior to 2003 was migrated to the electronic format as well but we may lack certain details of hospital visits (i.e., some diagnoses or medications may not have been recorded or transferred). The entire EHR dataset contains approximately 4.2 million de-identified patients as of March 2015, and it was made available for use under IRB approval following HIPAA guidelines. We retained all patients with at least one diagnosed disease expressed as numerical ICD-9 between 1980 and 2014, inclusive. This led to a dataset of about 1.2 million patients, with every patient having an average of 88.9 records. Then, we considered all records up to December 31, 2013 (i.e., “split-point”) as training data (i.e., 34 years of training information) and all the diagnoses in 2014 as testing data.</p>
</sec>
<sec disp-level="2">
<title>EHR Processing</title>
<p>For each patient in the dataset, we retained some general demographic details (i.e., age, gender and race), and common clinical descriptors available in a structured format such as diagnoses (ICD-9 codes), medications, procedures, and lab tests, as well as free-text clinical notes recorded before the split-point. All the clinical records were pre-processed using the Open Biomedical Annotator to obtain harmonized codes for procedures and lab tests, normalized medications based on brand name and dosages, and to extract clinical concepts from the free-text notes<xref ref-type="bibr" rid="b19">19</xref>. In particular, the Open Biomedical Annotator and its RESTful API leverages the National Center for Biomedical Ontology (NCBO) BioPortal<xref ref-type="bibr" rid="b20">20</xref>, which provides a large set of ontologies, including SNOMED-CT, UMLS and RxNorm, to extract biomedical concepts from text and to provide their normalized and standard versions<xref ref-type="bibr" rid="b21">21</xref>.</p>
<p>The handling of the normalized records differed by data type. For diagnoses, medications, procedures and lab tests, we simply counted the presence of each normalized code in the patient EHRs, aiming to facilitate the modeling of related clinical events. Free-text clinical notes required more sophisticated processing. We applied the tool described in LePendu <italic>et al</italic>.<xref ref-type="bibr" rid="b22">22</xref>, which allowed identifying the negated tags and those related to family history. A tag that appeared as negated in the note was considered not relevant and discarded<xref ref-type="bibr" rid="b5">5</xref>. Negated tags were identified using NegEx, a regular expression algorithm that implements several phrases indicating negation, filters out sentences containing phrases that falsely appear to be negation phrases, and limits the scope of the negation phrases<xref ref-type="bibr" rid="b23">23</xref>. A tag that was related to family history was just flagged as such and differentiated from the directly patient-related tags. We then analyzed similarities in the representation of temporally consecutive notes to remove duplicated information (e.g., notes recorded twice by mistake)<xref ref-type="bibr" rid="b24">24</xref>.</p>
<p>The parsed notes were further processed to reduce the sparseness of the representation (about 2 million normalized tags were extracted) and to obtain a semantic abstraction of the embedded clinical information. To this aim we modeled the parsed notes using topic modeling<xref ref-type="bibr" rid="b25">25</xref>, an unsupervised inference process that captures patterns of word co-occurrences within documents to define topics and represent a document as a multinomial over these topics. Topic modeling has been applied to generalize clinical notes and improve automatic processing of patients data in several studies (e.g., see<xref ref-type="bibr" rid="b5">5</xref><xref ref-type="bibr" rid="b26">26</xref><xref ref-type="bibr" rid="b27">27</xref><xref ref-type="bibr" rid="b28">28</xref>). We used latent Dirichlet allocation as our implementation of topic modeling<xref ref-type="bibr" rid="b29">29</xref> and we estimated the number of topics through perplexity analysis over one million random notes. We found that 300 topics obtained the best mathematical generalization; therefore, each note was eventually summarized as a multinomial of 300 topic probabilities. For each patient, we eventually retained one single topic-based representation averaged over all the notes available before the split-point.</p>
</sec>
<sec disp-level="2">
<title>Dataset</title>
<p>All patients with at least one recorded ICD-9 code were split in three independent datasets for evaluation purposes (i.e., every patient appeared in only one dataset). First, we held back 81,214 patients having at least one new ICD-9 diagnosis assigned in 2014 and at least ten records before that. These patients composed validation (i.e., 5,000 patients) and test (i.e., 76,214 patients) sets for the supervised evaluation (i.e., future disease prediction). In particular, all the diagnoses in 2014 were used to evaluate the predictions computed using the patient data recorded before the split-point (i.e., prediction from the patient clinical status). The requirement of having at least ten records per patient was set to ensure that each test case had some minimum of clinical history that could lead to reasonable predictions. We then randomly sampled a subset of 200,000 different patients with at least five records before the split-point to use as training set for the disease prediction experiment.</p>
<p>We used ICD-9 codes to state the diagnosis of a disease to a patient. However, since different codes can refer to the same disease, we mapped the codes to a disease categorization structure used at Mount Sinai, which groups ICD-9s into a vocabulary of 231 general disease definitions<xref ref-type="bibr" rid="b30">30</xref>. This list was filtered to retain only diseases that had at least 10 training patients and manually polished by a practicing physician to remove all the diseases that could not be predicted from the considered EHR labels alone because related to social behaviors (e.g., HIV) and external life events (e.g., injuries, poisoning), or that were too general (e.g., “other form of cancers”). The final vocabulary included 78 diseases, which are reported in the <xref ref-type="supplementary-material" rid="S1">Supplementary Appendix B</xref> online.</p>
<p>Finally, we created the training set for the feature learning algorithms using the remaining patients having at least five records by December 2013. The choice of having at least five records per patient was done to remove some uninformative cases and to decrease the training set size and, consequently, the time of computation. This lead to a dataset composed of 704,587 patients and 60,238 clinical descriptors. Descriptors appearing in more than 80% of patients or present in fewer than five patients were removed from the dataset to avoid biases and noise in the learning process leading to a final vocabulary of 41,072 descriptors. Overall, the raw patient dataset used for feature learning was composed by 200 million non-zero entries (i.e., about 1% of all the entries in the patient-descriptor matrix).</p>
</sec>
<sec disp-level="2">
<title>Patient Representation Learning</title>
<p>SDAs were applied to the dataset of 704,857 patients to derive the deep patient representation. All the feature values in the dataset were first normalized to lie between zero and one to reduce the variance of the data while preserving zero entries. We used the same parameters in all the autoencoders of the deep architecture (regardless the layer) since this configuration usually leads to similar performances as having different parameters for each layer and is easier to evaluate<xref ref-type="bibr" rid="b18">18</xref><xref ref-type="bibr" rid="b31">31</xref>. In particular, we found that using 500 hidden units per layer and a noise corruption factor <inline-formula id="d33e422"><inline-graphic id="d33e423" xlink:href="srep26094-m19.jpg" xmlns:xlink="http://www.w3.org/1999/xlink"></inline-graphic></inline-formula> lead to a good generalization error and consistent predictions when tuning the model using the validation data set. We used a deep architecture composed by three layers of autoencoders and sigmoid activation functions (i.e., “DeepPatient”). Preliminary results on disease prediction using a different number of layers are reported in the <xref ref-type="supplementary-material" rid="S1">Supplementary Appendix C</xref> online. The deep feature model was then applied to train and test sets for supervised evaluation; hence each patient in these datasets was represented by a dense vector of 500 features.</p>
<p>We compared the deep patient representation with other well-known feature learning algorithms having demonstrated utility in various domains including medicine<xref ref-type="bibr" rid="b12">12</xref>. All of these algorithms were applied to the scaled dataset as well and performed only one transformation to the original data (i.e., shallow feature learning). In particular, we considered principal component analysis (i.e., “PCA” with 100 principal components), k-means clustering (i.e., “K-Means” with 500 clusters), Gaussian mixture model (i.e., “GMM” with 200 mixtures and full covariance matrix), and independent component analysis (i.e., “ICA” with 100 principal components). In particular, PCA uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of linearly uncorrelated variables called principal components, which are less than or equal to the number of original variables. The first principal component accounts for the greatest possible variability in the data, and each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to the preceding components. K-means groups unlabeled data into <italic>k</italic> clusters, in such a way that each data point belongs to the cluster with the closest mean. In feature learning, the centroids of the cluster are used to produce features, i.e., each feature value is the distance of the data point from each cluster centroid. GMM is a probabilistic model that assumes all the data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters. ICA represents data using a weighted sum of independent non-Gaussian components, which are learned from the data using signal separation algorithms. As done for DeepPatient, the number of latent variables of each model was identified through preliminary experiments by optimizing learning errors or expectations as well as prediction results obtained in the validation set. We also included in the comparison the patient representation based on the original descriptors after removal of the frequent and rare variables (i.e., “RawFeat” with 41,072 entries).</p>
</sec>
<sec disp-level="2">
<title>Future Disease Prediction</title>
<p>To predict the probability that patients might develop a certain disease given their current clinical status, we implemented random forest classifiers trained over each disease using a dataset of 200,000 patients (<italic>one-vs.-all</italic> learning). We used random forests because they often demonstrate better performances than other standard classifiers, are easy to tune, and are robust to overfitting<xref ref-type="bibr" rid="b32">32</xref><xref ref-type="bibr" rid="b33">33</xref>. By preliminary experiments on the validation dataset we tuned every disease classifier to have 100 trees. For each patient in the test set (and for all the different representations), we computed the probability to develop every disease in the vocabulary (i.e., each patient was represented by a vector of disease probabilities).</p>
</sec>
</sec>
<sec disp-level="1">
<title>Results</title>
<p>We evaluated the disease predictions in two applicative clinical tasks: disease classification (i.e., <italic>evaluation by disease</italic>) and patient disease tagging (i.e., <italic>evaluation by patient</italic>). For each patient we considered only the prediction of novel diseases, discarding the re-diagnosis of a disease. If not reported otherwise, all the metrics used in the experiments were upper-bounded by one.</p>
<sec disp-level="2">
<title>Evaluation by Disease</title>
<p>To measure how well the deep patient representation performed at predicting whether a patient developed new diseases, we evaluated the ability of the classifier to determine if test patients were likely to be diagnosed with a certain disease within a one-year interval. For each disease, we took the scores obtained by all patients in the test set (i.e., 76,214 patients) and measured the area under the receiver operating characteristic curve (i.e., AUC-ROC), accuracy, and F-score<xref ref-type="bibr" rid="b34">34</xref>. The ROC curve is a plot of true positive rate versus false positive rate found over the set of predictions. AUC is computed by integrating the ROC curve and it is lower bounded by 0.5. Accuracy is the proportion of true results (both true positives and true negative) among the total number of cases examined. F-score is the harmonic mean of classification precision and recall, where precision is the number of correct positive results divided by the number of all positive results, and recall is the number of correct positive results divided by the number of positive results that should have been returned. Accuracy and F-score require a threshold to discriminate between positive and negative predictions; we set that threshold to 0.6, with this value optimizing the tradeoff between precision and recall for all representations in the validation set by reducing the number of false positive predictions.</p>
<p>The results for all the different data representations are reported in <xref ref-type="table" rid="t1">Table 1</xref>. The performance metrics of DeepPatient are superior to those obtained by RawFeat (i.e., no feature learning applied to EHR data). In particular, DeepPatient achieved an average AUC-ROC of 0.773, while RawFeat just got 0.659 (i.e., 15% improvement). Accuracy and F-score improved by 15% and 54% respectively, showing that the quality of the positive predictions (i.e., the patients that actually develop that disease) is improved by pre-processing EHRs with a deep architecture. Moreover, DeepPatient consistently and significantly outperforms all other feature learning methods. <xref ref-type="table" rid="t2">Table 2</xref> compares the AUC-ROC obtained by RawFeat, PCA and DeepPatient for a subset of 10 diseases (see the <xref ref-type="supplementary-material" rid="S1">Supplementary Appendix D</xref> online for the results on the entire vocabulary of diseases). While DeepPatient always outperforms RawFeat, PCA does not lead to any improvement for several diseases (e.g., “Schizophrenia”, “Multiple Myeloma”). Overall, DeepPatient reported the highest AUC-ROC score on every disease but “Cancer of brain and nervous system”, where PCA performed slightly better (AUC-ROC of 0.757 vs. 0.742). Remarkably large improvements in the AUC-ROC score (i.e., more than 60%) were obtained for several diseases, such as “Cancer of testis”, “Attention-deficit and disruptive behavior disorders”, “Sickle cell anemia”, and “Cancer of prostate”. In contrast, some diseases (e.g., “Hypertension”, “Diabetes mellitus without complications”, “Disorders of lipid metabolism”) were difficult to classify and resulted in AUC-ROC scores lower than 0.600 for all representations.</p>
</sec>
<sec disp-level="2">
<title>Evaluation by Patient</title>
<p>In this experiment we examined how well DeepPatient performed at the patient-specific level. To this aim we retained again only the disease predictions with score greater than 0.6 (i.e., tags) and measured the quality of these annotations over different temporal windows for all the patients having true diagnoses in that period. In particular, we considered diagnoses assigned within 30 (i.e., 16,374 patients), 60 (i.e., 21,924 patients), 90 (i.e., 25,220 patients), and 180 (i.e., 33,607 patients) days. Overall, we found that DeepPatient consistently out-performed other methods across all time intervals examined (<xref ref-type="table" rid="t3">Table 3</xref> and <xref ref-type="fig" rid="f3">Fig. 3</xref>).</p>
<p>In particular, we first measured precision-at-<italic>k</italic> (Prec@k, with <italic>k</italic> equal to 1, 3, and 5), which averages the ratio of correct diseases assigned to each patients in each time window within the greatest <italic>k</italic> disease scores (<xref ref-type="table" rid="t3">Table 3</xref>). In each comparison, we included the model of theoretical upper bound (i.e., “UppBnd”), which reports the best results possible (i.e., all the correct diseases are assigned to each patients). As can be seen, DeepPatient obtained about 55% corrected predictions when suggesting three or more diseases per patient, regardless the time interval. Moreover, when we contrasted DeepPatient with the upper bound, we found a 5–15% improvement over every other method across all times. Last, we report R-precision, which is the precision-at-<italic>R</italic> of the assigned diseases, where <italic>R</italic> is the number of patient diagnoses in the ground truth for the considered time interval<xref ref-type="bibr" rid="b34">34</xref> (<xref ref-type="fig" rid="f3">Fig. 3</xref>). Also in this case DeepPatient obtained significant improvements ranging from 5% to 12% over the other models (with ICA obtaining the second best results).</p>
</sec>
</sec>
<sec disp-level="1">
<title>Discussion</title>
<p>We present a novel application of deep learning to derive predictive patient descriptors from EHRs that we call “deep patient”. This method captures hierarchical regularities and dependencies in the data to create a compact, general-purpose set of patient features that can be effectively used in predictive clinical applications. Results obtained on future disease prediction, in fact, were consistently better than those obtained by other feature learning models as well as than just using the raw EHR data (i.e., the common approach when applying machine learning to EHRs). This shows that pre-processing patient data using a deep sequence of non-linear transformations helps the machine to better understand the information embedded in the EHRs and to effectively make inference out of it. This opens new possibilities for clinical predictive modeling because pre-processing EHR data with deep learning can help improving also ad-hoc frameworks previously proposed in literature towards more effective predictions. In addition, the deep patient leads to more compact and lower dimensional representations than the original EHRs, allowing clinical analytics engines to scale better with the continuous growth of hospital data warehouses.</p>
<sec disp-level="2">
<title>Context and Significance</title>
<p>Deep learning was recently applied to medicine and genomics to reconstruct brain circuits<xref ref-type="bibr" rid="b35">35</xref> and to predict the activity of potential drug molecules<xref ref-type="bibr" rid="b36">36</xref>, the effects of mutations in non-coding DNA on gene expressions<xref ref-type="bibr" rid="b37">37</xref><xref ref-type="bibr" rid="b38">38</xref>, and the sequence specificities of DNA and RNA-binding proteins<xref ref-type="bibr" rid="b39">39</xref>. To the best of our knowledge, deep feature learning is not yet applied to derive a general-purpose representation of patients from aggregated EHR data. Deep belief networks were recently applied to a small clinical dataset of Chinese patients to recommend acupuncture treatments, with features that were supervised optimized for the specific task<xref ref-type="bibr" rid="b40">40</xref>. Differently, we applied deep learning to derive patient representations from a large-scale dataset that are not optimized for any specific task and can fit different clinical applications.</p>
<p>We used stacked denoising autoencoders (SDAs) to process EHR data and learn the deep patient representation. SDAs are sequences of three-layer neural networks with a central layer to reconstruct high-dimensional input vectors<xref ref-type="bibr" rid="b12">12</xref><xref ref-type="bibr" rid="b17">17</xref><xref ref-type="bibr" rid="b18">18</xref><xref ref-type="bibr" rid="b41">41</xref>. To the best of our knowledge, SDAs have never been applied in the clinical domain. A two-layer stacked autoencoder without the denoising component was applied to EHRs to model longitudinal sequences of serum uric acid measurements in order to suggest multiple population subtypes and to distinguish the uric-acid signatures of gout vs. acute leukemia despite not being optimized for the task<xref ref-type="bibr" rid="b42">42</xref>. Here we apply SDAs and feature learning to derive a general representation of the patients, without focusing on a particular clinical descriptor or domain.</p>
<p>The deep patient representation was evaluated by predicting patient’s future diseases—modeling a practical task in clinical decision making. Previous studies investigated disease prediction in several specific domains, including cardiovascular disease<xref ref-type="bibr" rid="b43">43</xref>, heart failure<xref ref-type="bibr" rid="b9">9</xref>, bone diseases<xref ref-type="bibr" rid="b44">44</xref>, chronic kidney disease<xref ref-type="bibr" rid="b45">45</xref>, as well as for diagnosis code assignment<xref ref-type="bibr" rid="b46">46</xref><xref ref-type="bibr" rid="b47">47</xref>. However, the previous efforts generally develop approaches that are highly tuned to a specific disease or phenotype. In contrast, we focused the evaluation of our method on different diseases to show that the deep patient framework learns descriptors that are not domain specific.</p>
</sec>
<sec disp-level="2">
<title>Potential Applications</title>
<p>The deep patient representation improved predictions for different categories of diseases. This demonstrates that the learned features describe patients in a way that is general and effective to be processed by automated methods in different domains. We believe that a deep patient representation inferred from EHRs could benefit other tasks as well, such as personalized prescriptions, treatment recommendations, and clinical trial recruitment. In contrast to representations that are supervised optimized for a specific task<xref ref-type="bibr" rid="b48">48</xref>, a completely unsupervised vector-oriented representation can be applied to other unsupervised tasks as well, such as patient clustering and similarity. This work represents a first step towards the next generation of predictive clinical systems that can (i) scale to include many millions to billions of patient records and (ii) use a single, distributed patient representation to effectively support clinicians in their daily activities—rather than multiple systems working with different patient representations. In this scenario, the deep learning framework would be deployed to the EHR system and models would be constantly updated to follow the changes in the patient population. However, given that the feature learned by neural networks are not easily interpretable, the framework would be paired with a feature selection tools to help the clinicians understanding what drove the different predictions.</p>
<p>Higher-level descriptors derived from a large-scale patient data warehouse can also enhance the sharing of information between hospitals. In fact, deep features can abstract patient data to a higher level that cannot be fully reconstructed, which facilitates the safe exchange of data between institutions to derive additional representations based on different population distributions (provided with the same underlying EHR representation). As an example, a patient having a clinical status not common for the area where he resides could benefit from being represented using features learned from other hospital data warehouses, where his conditions might be more common. In addition, collaboration between hospitals towards a joint feature learning effort would lead to even better deep representations that would likely improve the design and the performances of a large number of healthcare analytics platforms.</p>
<p>The disease prediction application that was evaluated in this study can be used in a number of clinical tasks towards personalized medicine, such as data-driven assessment of individual patient risk. In fact, clinicians could benefit from a healthcare platform that learns optimal care pathways from the historical patient data, which is a natural extension of the deep patient approach. For example, physicians could monitor their patients, check if any disease is likely to occur in the near future given the clinical status, and preempt the trajectory through data driven selection of interventions. Similarly, the platform could automatically detect patients of the hospital with high probability to develop certain diseases and alert the appropriate care providers.</p>
</sec>
<sec disp-level="2">
<title>Limitations and Future Works</title>
<p>We note some limitations of the current study that highlight opportunities for future method enhancement. As already mentioned, some diseases did not show high predictive power. This was partially related to the fact that we only included the frequency of a laboratory test and we relied on test co-occurrences to determine patient patterns, but we did not considered the test result. Yet, lab test results are not easy to process at this large scale, since they can be available as text flags, values with different unit of measure, ranges, and so on. However, we found that some of the diseases with low performance metrics (e.g., “Diabetes mellitus without complications”, “Hypertension”) are usually screened by laboratory tests collected during routine checkups, making the frequency of those tests not valid discriminant factors. Future work will explore how to include the lab test values to improve the performance of the deep patient representation (i.e., better raw representations are likely to lead to better deep models). Similarly, describing a patient with a temporal sequence of vectors covering predefined consecutive time intervals instead of summarizing all data in one vector is expected to improve the final result as well. The addition of other categories of EHR data, such as insurance details, family history and social behaviors, might also lead to better representations that should obtain reliable prediction models in a larger number of clinical domains. Moreover, the SDA model is likely to take benefit of additional data pre-processing. A common extension is to pre-process the data using PCA to remove irrelevant factors before deep modeling<xref ref-type="bibr" rid="b31">31</xref>. This approach improved both accuracy and efficiency with other media and should benefit the clinical domain as well.</p>
<p>In future work we plan to investigate the application of the deep representations to other clinical tasks involving automatic prediction, such as personalized prescriptions, therapy recommendation, and clinical trial recruitment. We also plan to investigate thoroughly the application of the deep patient to a specific clinical domain and task to qualitatively evaluate its outcomes (e.g., what are the rules the algorithm discovers and that improve the predictions, how they can be visualized, if they are novel). Further, we aim to evaluate the methodology on the EHR data warehouse of other institutions to consolidate the results as well as to improve the learned features that will benefit from being estimated over a larger number of patients.</p>
</sec>
</sec>
<sec disp-level="1">
<title>Additional Information</title>
<p><bold>How to cite this article</bold>: Miotto, R. <italic>et al</italic>. Deep Patient: An Unsupervised Representation to Predict the Future of Patients from the Electronic Health Records. <italic>Sci. Rep.</italic>
<bold>6</bold>, 26094; doi: 10.1038/srep26094 (2016).</p>
</sec>
<sec id="S1" sec-type="supplementary-material">
<title>Supplementary Material</title>
<supplementary-material content-type="local-data" id="d33e42">
<caption>
<title>Supplementary Information</title>
</caption>
<media xlink:href="srep26094-s1.pdf" xmlns:xlink="http://www.w3.org/1999/xlink"></media>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>This work is supported by funding from the NIH National Center for Advancing Translational Sciences (NCATS) Clinical and Translational Science Awards (UL1TR001433), National Cancer Institute (NCI) (U54CA189201), and National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) (R01DK098242) to J.T.D.</p>
</ack>
<ref-list>
<ref id="b1">
<mixed-citation publication-type="journal"><name><surname>Hersh</surname><given-names>W. R.</given-names></name>
<article-title>Adding value to the electronic health record through secondary use of data for quality assurance, research, and surveillance</article-title>. <source/>Am. J. Manag. Care
<volume>13</volume>, <fpage>277</fpage>–<lpage>278</lpage> (<year>2007</year>).<pub-id pub-id-type="pmid">17567224</pub-id></mixed-citation>
</ref>
<ref id="b2">
<mixed-citation publication-type="journal"><name><surname>Tatonetti</surname><given-names>N. P.</given-names></name>, <name><surname>Ye</surname><given-names>P. P.</given-names></name>, <name><surname>Daneshjou</surname><given-names>R.</given-names></name> &amp; <name><surname>Altman</surname><given-names>R. B.</given-names></name>
<article-title>Data-driven prediction of drug effects and interactions</article-title>. <source/>Sci. Transl. Med.
<volume>4</volume>, <fpage>125ra131</fpage> (<year>2012</year>).</mixed-citation>
</ref>
<ref id="b3">
<mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>L.</given-names></name>
<etal></etal>. <article-title>Identification of type 2 diabetes subgroups through topological analysis of patient similarity</article-title>. <source/>Sci. Transl. Med.
<volume>7</volume>, <fpage>311ra174</fpage> (<year>2015</year>).</mixed-citation>
</ref>
<ref id="b4">
<mixed-citation publication-type="journal"><name><surname>Doshi-Velez</surname><given-names>F.</given-names></name>, <name><surname>Ge</surname><given-names>Y.</given-names></name> &amp; <name><surname>Kohane</surname><given-names>I.</given-names></name>
<article-title>Comorbidity clusters in autism spectrum disorders: an electronic health record time-series analysis</article-title>. <source/>Pediatrics
<volume>133</volume>, <fpage>e54</fpage>–<lpage>63</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">24323995</pub-id></mixed-citation>
</ref>
<ref id="b5">
<mixed-citation publication-type="journal"><name><surname>Miotto</surname><given-names>R.</given-names></name> &amp; <name><surname>Weng</surname><given-names>C.</given-names></name>
<article-title>Case-based reasoning using electronic health records efficiently identifies eligible patients for clinical trials</article-title>. <source/>J. Am. Med. Inform. Assoc. <volume>22</volume>, <fpage>E141</fpage>–<lpage>E150</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25769682</pub-id></mixed-citation>
</ref>
<ref id="b6">
<mixed-citation publication-type="journal"><name><surname>Bellazzi</surname><given-names>R.</given-names></name> &amp; <name><surname>Zupan</surname><given-names>B.</given-names></name>
<article-title>Predictive data mining in clinical medicine: current issues and guidelines</article-title>. <source/>Int. J. Med. Inform.
<volume>77</volume>, <fpage>81</fpage>–<lpage>97</lpage> (<year>2008</year>).<pub-id pub-id-type="pmid">17188928</pub-id></mixed-citation>
</ref>
<ref id="b7">
<mixed-citation publication-type="journal"><name><surname>Jensen</surname><given-names>P. B.</given-names></name>, <name><surname>Jensen</surname><given-names>L. J.</given-names></name> &amp; <name><surname>Brunak</surname><given-names>S.</given-names></name>
<article-title>Mining electronic health records: towards better research applications and clinical care</article-title>. <source/>Nat. Rev. Genet.
<volume>13</volume>, <fpage>395</fpage>–<lpage>405</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22549152</pub-id></mixed-citation>
</ref>
<ref id="b8">
<mixed-citation publication-type="journal"><name><surname>Dahlem</surname><given-names>D.</given-names></name>, <name><surname>Maniloff</surname><given-names>D.</given-names></name> &amp; <name><surname>Ratti</surname><given-names>C.</given-names></name>
<article-title>Predictability bounds of electronic health records</article-title>. <source/>Sci. Rep. <volume>5</volume>, <fpage>11865</fpage> (<year>2015</year>).<pub-id pub-id-type="pmid">26148751</pub-id></mixed-citation>
</ref>
<ref id="b9">
<mixed-citation publication-type="journal"><name><surname>Wu</surname><given-names>J. L.</given-names></name>, <name><surname>Roy</surname><given-names>J.</given-names></name> &amp; <name><surname>Stewart</surname><given-names>W. F.</given-names></name>
<article-title>Prediction modeling using EHR data: challenges, strategies, and a comparison of machine learning approaches</article-title>. <source/>Med. Care
<volume>48</volume>, <fpage>S106</fpage>–<lpage>S113</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20473190</pub-id></mixed-citation>
</ref>
<ref id="b10">
<mixed-citation publication-type="journal"><name><surname>Weiskopf</surname><given-names>N. G.</given-names></name>, <name><surname>Hripcsak</surname><given-names>G.</given-names></name>, <name><surname>Swaminathan</surname><given-names>S.</given-names></name> &amp; <name><surname>Weng</surname><given-names>C.</given-names></name>
<article-title>Defining and measuring completeness of electronic health records for secondary use</article-title>. <source/>J. Biomed. Inform.
<volume>46</volume>, <fpage>830</fpage>–<lpage>836</lpage> (<year>2013</year>).<pub-id pub-id-type="pmid">23820016</pub-id></mixed-citation>
</ref>
<ref id="b11">
<mixed-citation publication-type="journal"><name><surname>Weiskopf</surname><given-names>N. G.</given-names></name> &amp; <name><surname>Weng</surname><given-names>C.</given-names></name>
<article-title>Methods and dimensions of electronic health record data quality assessment: enabling reuse for clinical research</article-title>. <source/>J. Am. Med. Inform. Assoc. <volume>20</volume>, <fpage>144</fpage>–<lpage>151</lpage> (<year>2013</year>).<pub-id pub-id-type="pmid">22733976</pub-id></mixed-citation>
</ref>
<ref id="b12">
<mixed-citation publication-type="journal"><name><surname>Bengio</surname><given-names>Y.</given-names></name>, <name><surname>Courville</surname><given-names>A.</given-names></name> &amp; <name><surname>Vincent</surname><given-names>P.</given-names></name>
<article-title>Representation learning: a review and new perspectives</article-title>. <source/>IEEE T. Pattern Anal. Mach. Intell. <volume>35</volume>, <fpage>1798</fpage>–<lpage>1828</lpage> (<year>2013</year>).</mixed-citation>
</ref>
<ref id="b13">
<mixed-citation publication-type="journal"><name><surname>Jordan</surname><given-names>M. I.</given-names></name> &amp; <name><surname>Mitchell</surname><given-names>T. M.</given-names></name>
<article-title>Machine learning: trends, perspectives, and prospects</article-title>. <source/>Science
<volume>349</volume>, <fpage>255</fpage>–<lpage>260</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">26185243</pub-id></mixed-citation>
</ref>
<ref id="b14">
<mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>S. H.</given-names></name>
<etal></etal>. <article-title>Toward personalizing treatment for depression: predicting diagnosis and severity</article-title>. <source/>J. Am. Med. Inform. Assoc. <volume>21</volume>, <fpage>1069</fpage>–<lpage>1075</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">24988898</pub-id></mixed-citation>
</ref>
<ref id="b15">
<mixed-citation publication-type="journal"><name><surname>Lyalina</surname><given-names>S.</given-names></name>
<etal></etal>. <article-title>Identifying phenotypic signatures of neuropsychiatric disorders from electronic medical records</article-title>. <source/>J. Am. Med. Inform. Assoc. <volume>20</volume>, <fpage>e297</fpage>–<lpage>305</lpage> (<year>2013</year>).<pub-id pub-id-type="pmid">23956017</pub-id></mixed-citation>
</ref>
<ref id="b16">
<mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>X.</given-names></name>, <name><surname>Sontag</surname><given-names>D.</given-names></name> &amp; <name><surname>Wang</surname><given-names>F.</given-names></name>
<article-title>Unsupervised learning of disease progression models</article-title>. <source/>ACM SIGKDD, <fpage>85</fpage>–<lpage>94</lpage> (<year>2014</year>).</mixed-citation>
</ref>
<ref id="b17">
<mixed-citation publication-type="journal"><name><surname>LeCun</surname><given-names>Y.</given-names></name>, <name><surname>Bengio</surname><given-names>Y.</given-names></name> &amp; <name><surname>Hinton</surname><given-names>G.</given-names></name>
<article-title>Deep learning</article-title>. <source/>Nature
<volume>521</volume>, <fpage>436</fpage>–<lpage>444</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
</ref>
<ref id="b18">
<mixed-citation publication-type="journal"><name><surname>Vincent</surname><given-names>P.</given-names></name>, <name><surname>Larochelle</surname><given-names>H.</given-names></name>, <name><surname>Lajoie</surname><given-names>I.</given-names></name>, <name><surname>Bengio</surname><given-names>Y.</given-names></name> &amp; <name><surname>Manzagol</surname><given-names>P. A.</given-names></name>
<article-title>Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion</article-title>. <source/>J. Mach. Learn. Res.
<volume>11</volume>, <fpage>3371</fpage>–<lpage>3408</lpage> (<year>2010</year>).</mixed-citation>
</ref>
<ref id="b19">
<mixed-citation publication-type="journal"><name><surname>Shah</surname><given-names>N. H.</given-names></name>
<etal></etal>. <article-title>Comparison of concept recognizers for building the Open Biomedical Annotator</article-title>. <source/>BMC Bioinformatics
<volume>10</volume>, <fpage>S14</fpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19761568</pub-id></mixed-citation>
</ref>
<ref id="b20">
<mixed-citation publication-type="journal"><name><surname>Musen</surname><given-names>M. A.</given-names></name>
<etal></etal>. <article-title>The National Center for Biomedical Ontology</article-title>. <source/>J. Am. Med. Inform. Assoc. <volume>19</volume>, <fpage>190</fpage>–<lpage>195</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22081220</pub-id></mixed-citation>
</ref>
<ref id="b21">
<mixed-citation publication-type="journal"><name><surname>Jonquet</surname><given-names>C.</given-names></name>, <name><surname>Shah</surname><given-names>N. H.</given-names></name> &amp; <name><surname>Musen</surname><given-names>M. A.</given-names></name>
<article-title>The Open Biomedical Annotator</article-title>. <source/>Summit on Translat. Bioinforma. 2009, <fpage>56</fpage>–<lpage>60</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">21347171</pub-id></mixed-citation>
</ref>
<ref id="b22">
<mixed-citation publication-type="journal"><name><surname>Lependu</surname><given-names>P.</given-names></name>, <name><surname>Iyer</surname><given-names>S. V.</given-names></name>, <name><surname>Fairon</surname><given-names>C.</given-names></name> &amp; <name><surname>Shah</surname><given-names>N. H.</given-names></name>
<article-title>Annotation analysis for testing drug safety signals using unstructured clinical notes</article-title>. <source/>J. Biomed. Semantics
<volume>3</volume>, <fpage>S5</fpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22541596</pub-id></mixed-citation>
</ref>
<ref id="b23">
<mixed-citation publication-type="journal"><name><surname>Chapman</surname><given-names>W. W.</given-names></name>, <name><surname>Bridewell</surname><given-names>W.</given-names></name>, <name><surname>Hanbury</surname><given-names>P.</given-names></name>, <name><surname>Cooper</surname><given-names>G. F.</given-names></name> &amp; <name><surname>Buchanan</surname><given-names>B. G.</given-names></name>
<article-title>A simple algorithm for identifying negated findings and diseases in discharge summaries</article-title>. <source/>J. Biomed. Inform.
<volume>34</volume>, <fpage>301</fpage>–<lpage>310</lpage> (<year>2001</year>).<pub-id pub-id-type="pmid">12123149</pub-id></mixed-citation>
</ref>
<ref id="b24">
<mixed-citation publication-type="journal"><name><surname>Cohen</surname><given-names>R.</given-names></name>, <name><surname>Elhadad</surname><given-names>M.</given-names></name> &amp; <name><surname>Elhadad</surname><given-names>N.</given-names></name>
<article-title>Redundancy in electronic health record corpora: analysis, impact on text mining performance and mitigation strategies</article-title>. <source/>BMC Bioinformatics
<volume>14</volume>, <fpage>10</fpage> (<year>2013</year>).<pub-id pub-id-type="pmid">23323800</pub-id></mixed-citation>
</ref>
<ref id="b25">
<mixed-citation publication-type="journal"><name><surname>Blei</surname><given-names>D. M.</given-names></name>
<article-title>Probabilistic topic models</article-title>. <source/>Commun. ACM
<volume>55</volume>, <fpage>77</fpage>–<lpage>84</lpage> (<year>2012</year>).</mixed-citation>
</ref>
<ref id="b26">
<mixed-citation publication-type="journal"><name><surname>Arnold</surname><given-names>C. W.</given-names></name>, <name><surname>El-Saden</surname><given-names>S. M.</given-names></name>, <name><surname>Bui</surname><given-names>A. A.</given-names></name> &amp; <name><surname>Taira</surname><given-names>R.</given-names></name>
<article-title>Clinical case-based retrieval using latent topic analysis</article-title>. <source/>AMIA Annu. Symp. Proc., <fpage>26</fpage>–<lpage>30</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">21346934</pub-id></mixed-citation>
</ref>
<ref id="b27">
<mixed-citation publication-type="journal"><name><surname>Perotte</surname><given-names>A.</given-names></name>, <name><surname>Bartlett</surname><given-names>N.</given-names></name>, <name><surname>Elhadad</surname><given-names>N.</given-names></name> &amp; <name><surname>Wood</surname><given-names>F.</given-names></name>
<article-title>Hierarchically supervised latent dirichlet allocation</article-title>. <source/>NIPS, <fpage>2609</fpage>–<lpage>2617</lpage> (<year>2011</year>).</mixed-citation>
</ref>
<ref id="b28">
<mixed-citation publication-type="journal"><name><surname>Bisgin</surname><given-names>H.</given-names></name>, <name><surname>Liu</surname><given-names>Z.</given-names></name>, <name><surname>Fang</surname><given-names>H.</given-names></name>, <name><surname>Xu</surname><given-names>X.</given-names></name> &amp; <name><surname>Tong</surname><given-names>W.</given-names></name>
<article-title>Mining FDA drug labels using an unsupervised learning technique - topic modeling</article-title>. <source/>BMC Bioinformatics
<volume>12</volume>, <fpage>S11</fpage> (<year>2011</year>).<pub-id pub-id-type="pmid">22166012</pub-id></mixed-citation>
</ref>
<ref id="b29">
<mixed-citation publication-type="journal"><name><surname>Blei</surname><given-names>D. M.</given-names></name>, <name><surname>Ng</surname><given-names>A. Y.</given-names></name> &amp; <name><surname>Jordan</surname><given-names>M. I.</given-names></name>
<article-title>Latent Dirichlet allocation</article-title>. <source/>J. Mach. Learn. Res.
<volume>3</volume>, <fpage>993</fpage>–<lpage>1022</lpage> (<year>2003</year>).</mixed-citation>
</ref>
<ref id="b30">
<mixed-citation publication-type="journal"><name><surname>Cowen</surname><given-names>M. E.</given-names></name>
<etal></etal>. <article-title>Casemix adjustment of managed care claims data using the clinical classification for health policy research method</article-title>. <source/>Med. Care
<volume>36</volume>, <fpage>1108</fpage>–<lpage>1113</lpage> (<year>1998</year>).<pub-id pub-id-type="pmid">9674627</pub-id></mixed-citation>
</ref>
<ref id="b31">
<mixed-citation publication-type="journal"><name><surname>Larochelle</surname><given-names>H.</given-names></name>, <name><surname>Bengio</surname><given-names>Y.</given-names></name>, <name><surname>Louradour</surname><given-names>J.</given-names></name> &amp; <name><surname>Lamblin</surname><given-names>P.</given-names></name>
<article-title>Exploring strategies for training deep neural networks</article-title>. <source/>J. Mach. Learn. Res.
<volume>10</volume>, <fpage>1</fpage>–<lpage>40</lpage> (<year>2009</year>).</mixed-citation>
</ref>
<ref id="b32">
<mixed-citation publication-type="journal"><name><surname>Breiman</surname><given-names>L.</given-names></name>
<article-title>Random forests</article-title>. <source/>Mach. Learn.
<volume>45</volume>, <fpage>5</fpage>–<lpage>32</lpage> (<year>2001</year>).</mixed-citation>
</ref>
<ref id="b33">
<mixed-citation publication-type="journal"><name><surname>Fernandez-Delgado</surname><given-names>M.</given-names></name>, <name><surname>Cernadas</surname><given-names>E.</given-names></name>, <name><surname>Barro</surname><given-names>S.</given-names></name> &amp; <name><surname>Amorim</surname><given-names>D.</given-names></name>
<article-title>Do we need hundreds of classifiers to solve real world classification problems?</article-title>
<source/>J. Mach. Learn. Res.
<volume>15</volume>, <fpage>3133</fpage>–<lpage>3181</lpage> (<year>2014</year>).</mixed-citation>
</ref>
<ref id="b34">
<mixed-citation publication-type="journal"><name><surname>Manning</surname><given-names>C. D.</given-names></name>, <name><surname>Raghavan</surname><given-names>P.</given-names></name> &amp; <name><surname>Schütze</surname><given-names>H.</given-names></name>
<source/>Introduction to Information Retrieval. (Cambridge University Press, <year>2008</year>).</mixed-citation>
</ref>
<ref id="b35">
<mixed-citation publication-type="journal"><name><surname>Helmstaedter</surname><given-names>M.</given-names></name>
<etal></etal>. <article-title>Connectomic reconstruction of the inner plexiform layer in the mouse retina</article-title>. <source/>Nature
<volume>500</volume>, <fpage>168</fpage>–<lpage>174</lpage> (<year>2013</year>).<pub-id pub-id-type="pmid">23925239</pub-id></mixed-citation>
</ref>
<ref id="b36">
<mixed-citation publication-type="journal"><name><surname>Ma</surname><given-names>J. S.</given-names></name>, <name><surname>Sheridan</surname><given-names>R. P.</given-names></name>, <name><surname>Liaw</surname><given-names>A.</given-names></name>, <name><surname>Dahl</surname><given-names>G. E.</given-names></name> &amp; <name><surname>Svetnik</surname><given-names>V.</given-names></name>
<article-title>Deep neural nets as a method for quantitative structure-activity relationships</article-title>. <source/>J. Chem. Inf. Model
<volume>55</volume>, <fpage>263</fpage>–<lpage>274</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25635324</pub-id></mixed-citation>
</ref>
<ref id="b37">
<mixed-citation publication-type="journal"><name><surname>Leung</surname><given-names>M. K. K.</given-names></name>, <name><surname>Xiong</surname><given-names>H. Y.</given-names></name>, <name><surname>Lee</surname><given-names>L. J.</given-names></name> &amp; <name><surname>Frey</surname><given-names>B. J.</given-names></name>
<article-title>Deep learning of the tissue-regulated splicing code</article-title>. <source/>Bioinformatics
<volume>30</volume>, <fpage>121</fpage>–<lpage>129</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">24273246</pub-id></mixed-citation>
</ref>
<ref id="b38">
<mixed-citation publication-type="journal"><name><surname>Xiong</surname><given-names>H. Y.</given-names></name>
<etal></etal>. <article-title>The human splicing code reveals new insights into the genetic determinants of disease</article-title>. <source/>Science
<volume>347</volume>, <fpage>144</fpage>–<lpage>151</lpage> (<year>2015</year>).</mixed-citation>
</ref>
<ref id="b39">
<mixed-citation publication-type="journal"><name><surname>Alipanahi</surname><given-names>B.</given-names></name>, <name><surname>Delong</surname><given-names>A.</given-names></name>, <name><surname>Weirauch</surname><given-names>M. T.</given-names></name> &amp; <name><surname>Frey</surname><given-names>B. J.</given-names></name>
<article-title>Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</article-title>. <source/>Nature Biotech. <volume>33</volume>, <fpage>831</fpage>–<lpage>838</lpage> (<year>2015</year>).</mixed-citation>
</ref>
<ref id="b40">
<mixed-citation publication-type="journal"><name><surname>Liang</surname><given-names>Z.</given-names></name>, <name><surname>Zhang</surname><given-names>G.</given-names></name>, <name><surname>Huang</surname><given-names>J. X.</given-names></name> &amp; <name><surname>Hu</surname><given-names>Q. V.</given-names></name>
<article-title>Deep learning for healthcare decision making with EMRs</article-title>. <source/>IEEE BIBM, <fpage>556</fpage>–<lpage>559</lpage> (<year>2014</year>).</mixed-citation>
</ref>
<ref id="b41">
<mixed-citation publication-type="journal"><name><surname>Hinton</surname><given-names>G. E.</given-names></name> &amp; <name><surname>Salakhutdinov</surname><given-names>R. R.</given-names></name>
<article-title>Reducing the dimensionality of data with neural networks</article-title>. <source/>Science
<volume>313</volume>, <fpage>504</fpage>–<lpage>507</lpage> (<year>2006</year>).<pub-id pub-id-type="pmid">16873662</pub-id></mixed-citation>
</ref>
<ref id="b42">
<mixed-citation publication-type="journal"><name><surname>Lasko</surname><given-names>T. A.</given-names></name>, <name><surname>Denny</surname><given-names>J. C.</given-names></name> &amp; <name><surname>Levy</surname><given-names>M. A.</given-names></name>
<article-title>Computational phenotype discovery using unsupervised feature learning over noisy, sparse, and irregular clinical data</article-title>. <source/>PLoS One
<volume>8</volume>, <fpage>e66341</fpage> (<year>2013</year>).<pub-id pub-id-type="pmid">23826094</pub-id></mixed-citation>
</ref>
<ref id="b43">
<mixed-citation publication-type="journal"><name><surname>Kennedy</surname><given-names>E. H.</given-names></name>, <name><surname>Wiitala</surname><given-names>W. L.</given-names></name>, <name><surname>Hayward</surname><given-names>R. A.</given-names></name> &amp; <name><surname>Sussman</surname><given-names>J. B.</given-names></name>
<article-title>Improved cardiovascular risk prediction using non-parametric regression and electronic health record data</article-title>. <source/>Med. Care
<volume>51</volume>, <fpage>251</fpage>–<lpage>258</lpage> (<year>2013</year>).<pub-id pub-id-type="pmid">23269109</pub-id></mixed-citation>
</ref>
<ref id="b44">
<mixed-citation publication-type="journal"><name><surname>Hui</surname><given-names>L.</given-names></name>, <name><surname>Xiaoyi</surname><given-names>L.</given-names></name>, <name><surname>Ramanathan</surname><given-names>M.</given-names></name> &amp; <name><surname>Aidong</surname><given-names>Z.</given-names></name>
<article-title>Prediction and informative risk factor selection of bone diseases</article-title>. <source/>IEEE/ACM T. Comput. Biol. Bioinform. <volume>12</volume>, <fpage>79</fpage>–<lpage>91</lpage> (<year>2015</year>).</mixed-citation>
</ref>
<ref id="b45">
<mixed-citation publication-type="journal"><name><surname>Perotte</surname><given-names>A.</given-names></name>, <name><surname>Ranganath</surname><given-names>R.</given-names></name>, <name><surname>Hirsch</surname><given-names>J. S.</given-names></name>, <name><surname>Blei</surname><given-names>D.</given-names></name> &amp; <name><surname>Elhadad</surname><given-names>N.</given-names></name>
<article-title>Risk prediction for chronic kidney disease progression using heterogeneous electronic health record data and time series analysis</article-title>. <source/>J. Am. Med. Inform. Assoc.
<volume>22</volume>, <fpage>872</fpage>–<lpage>880</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25896647</pub-id></mixed-citation>
</ref>
<ref id="b46">
<mixed-citation publication-type="journal"><name><surname>Perotte</surname><given-names>A.</given-names></name>
<etal></etal>. <article-title>Diagnosis code assignment: Models and evaluation metrics</article-title>. <source/>J. Am. Med. Inform. Assoc. <volume>21</volume>, <fpage>231</fpage>–<lpage>237</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">24296907</pub-id></mixed-citation>
</ref>
<ref id="b47">
<mixed-citation publication-type="journal"><name><surname>Gottlieb</surname><given-names>A.</given-names></name>, <name><surname>Stein</surname><given-names>G. Y.</given-names></name>, <name><surname>Ruppin</surname><given-names>E.</given-names></name>, <name><surname>Altman</surname><given-names>R. B.</given-names></name> &amp; <name><surname>Sharan</surname><given-names>R.</given-names></name>
<article-title>A method for inferring medical diagnoses from patient similarities</article-title>. <source/>BMC Med.
<volume>11</volume>, <fpage>194</fpage>–<lpage>203</lpage> (<year>2013</year>).<pub-id pub-id-type="pmid">24004670</pub-id></mixed-citation>
</ref>
<ref id="b48">
<mixed-citation publication-type="journal"><name><surname>Yao</surname><given-names>L. X.</given-names></name>, <name><surname>Zhang</surname><given-names>Y. Y.</given-names></name>, <name><surname>Li</surname><given-names>Y.</given-names></name>, <name><surname>Sanseau</surname><given-names>P.</given-names></name> &amp; <name><surname>Agarwal</surname><given-names>P.</given-names></name>
<article-title>Electronic health records: Implications for drug discovery</article-title>. <source/>Drug Discov. Today
<volume>16</volume>, <fpage>594</fpage>–<lpage>599</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">21624499</pub-id></mixed-citation>
</ref>
</ref-list>
<fn-group>
<fn>
<p><bold>Author Contributions</bold> R.M. initiated the idea, conducted the research, and wrote the article; L.L. helped collecting the data; B.A.K. refined the article; J.T.D. supervised and supported the research. All the authors edited and reviewed the manuscript.</p>
</fn>
</fn-group>
</back>
<floats-group>
<fig id="f1">
<label>Figure 1</label>
<caption>
<title>Conceptual framework used to derive the deep patient representation through unsupervised deep learning of a large EHR data warehouse.</title>
<p>(<bold>A</bold>) Pre-processing stage to obtain raw patient representations from the EHRs. (<bold>B</bold>) The raw representations are modeled by the unsupervised deep architecture leading to a set of general and robust features. (<bold>C</bold>) The deep features are applied to the entire hospital database to derive patient representations that can be applied to a number of clinical tasks.</p>
</caption>
<graphic xlink:href="srep26094-f1" xmlns:xlink="http://www.w3.org/1999/xlink"></graphic>
</fig>
<fig id="f2">
<label>Figure 2</label>
<caption>
<title>Diagram of the unsupervised deep feature learning pipeline to transform a raw dataset into the deep patient representation through multiple layers of neural networks.</title>
<p>Each layer of the neural network is trained to produce a higher-level representation from the result of the previous layer.</p>
</caption>
<graphic xlink:href="srep26094-f2" xmlns:xlink="http://www.w3.org/1999/xlink"></graphic>
</fig>
<fig id="f3">
<label>Figure 3</label>
<caption>
<title>R-precision obtained in the disease tagging experiment by the different patient representations over several prediction time intervals (expressed as number of days).</title>
<p>We reports results for patients represented with original descriptors (RawFeat) and pre-processed by principal component analysis (PCA), independent component analysis (ICA), Gaussian mixture model (GMM), k-means clustering (K-Means), and three-layer stacked denoising autoencoders (DeepPatient).</p>
</caption>
<graphic xlink:href="srep26094-f3" xmlns:xlink="http://www.w3.org/1999/xlink"></graphic>
</fig>
<table-wrap id="t1" position="float">
<label>Table 1</label>
<caption>
<title>Disease classification results in terms of area under the ROC curve (AUC-ROC), accuracy and F-score.</title>
</caption>
<table border="1" frame="hsides" rules="groups">
<colgroup>
<col align="left"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
</colgroup>
<thead valign="bottom">
<tr>
<th align="center" charoff="50" colspan="4" valign="top">Time Interval = 1 year (76,214 patients)</th>
</tr>
<tr>
<th align="left" charoff="50" rowspan="2" valign="top">Patient Representation</th>
<th align="center" charoff="50" rowspan="2" valign="top">AUC-ROC</th>
<th align="center" charoff="50" colspan="2" valign="top">Classification Threshold = 0.6<hr/></th>
</tr>
<tr>
<th align="center" charoff="50" valign="top">Accuracy</th>
<th align="center" charoff="50" valign="top">F-Score</th>
</tr>
</thead>
<tbody valign="top">
<tr>
<td align="left" charoff="50" valign="top">RawFeat</td>
<td align="center" charoff="50" valign="top">0.659</td>
<td align="center" charoff="50" valign="top">0.805</td>
<td align="center" charoff="50" valign="top">0.084</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">PCA</td>
<td align="center" charoff="50" valign="top">0.696</td>
<td align="center" charoff="50" valign="top">0.879</td>
<td align="center" charoff="50" valign="top">0.104</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">GMM</td>
<td align="center" charoff="50" valign="top">0.632</td>
<td align="center" charoff="50" valign="top">0.891</td>
<td align="center" charoff="50" valign="top">0.072</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">K-Means</td>
<td align="center" charoff="50" valign="top">0.672</td>
<td align="center" charoff="50" valign="top">0.887</td>
<td align="center" charoff="50" valign="top">0.093</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">ICA</td>
<td align="center" charoff="50" valign="top">0.695</td>
<td align="center" charoff="50" valign="top">0.882</td>
<td align="center" charoff="50" valign="top">0.101</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">DeepPatient</td>
<td align="center" charoff="50" valign="top">
<bold>0.773</bold>
<sup>
<bold>*</bold>
</sup>
</td>
<td align="center" charoff="50" valign="top">
<bold>0.929</bold>
<sup>
<bold>*</bold>
</sup>
</td>
<td align="center" charoff="50" valign="top">
<bold>0.181</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="t1-fn1">
<p>(*) The difference with the corresponding second best measurement is statistically significant (p &lt; 0.05, t-test).</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="t2" position="float">
<label>Table 2</label>
<caption>
<title>Area under the ROC curve obtained in the disease classification experiment using patient data represented with original descriptors (“RawFeat”) and pre-processed by principal component analysis (“PCA”) and three-layer stacked denoising autoencoders (“DeepPatient”).</title>
</caption>
<table border="1" frame="hsides" rules="groups">
<colgroup>
<col align="left"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
</colgroup>
<thead valign="bottom">
<tr>
<th align="center" charoff="50" colspan="4" valign="top">Time Interval = 1 year (76,214 patients)</th>
</tr>
<tr>
<th align="left" charoff="50" rowspan="2" valign="top">Disease</th>
<th align="center" charoff="50" colspan="3" valign="top">Area under the ROC curve<hr/></th>
</tr>
<tr>
<th align="center" charoff="50" valign="top">RawFeat</th>
<th align="center" charoff="50" valign="top">PCA</th>
<th align="center" charoff="50" valign="top">DeepPatient</th>
</tr>
</thead>
<tbody valign="top">
<tr>
<td align="left" charoff="50" valign="top">Diabetes mellitus with complications</td>
<td align="center" charoff="50" valign="top">0.794</td>
<td align="center" charoff="50" valign="top">0.861</td>
<td align="center" charoff="50" valign="top">
<bold>0.907</bold>
</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">Cancer of rectum and anus</td>
<td align="center" charoff="50" valign="top">0.863</td>
<td align="center" charoff="50" valign="top">0.821</td>
<td align="center" charoff="50" valign="top">
<bold>0.887</bold>
</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">Cancer of liver and intrahepatic bile duct</td>
<td align="center" charoff="50" valign="top">0.830</td>
<td align="center" charoff="50" valign="top">0.867</td>
<td align="center" charoff="50" valign="top">
<bold>0.886</bold>
</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">Regional enteritis and ulcerative colitis</td>
<td align="center" charoff="50" valign="top">0.814</td>
<td align="center" charoff="50" valign="top">0.843</td>
<td align="center" charoff="50" valign="top">
<bold>0.870</bold>
</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">Congestive heart failure (non-hypertensive)</td>
<td align="center" charoff="50" valign="top">0.808</td>
<td align="center" charoff="50" valign="top">0.808</td>
<td align="center" charoff="50" valign="top">
<bold>0.865</bold>
</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">Attention-deficit and disruptive behavior disorders</td>
<td align="center" charoff="50" valign="top">0.730</td>
<td align="center" charoff="50" valign="top">0.797</td>
<td align="center" charoff="50" valign="top">
<bold>0.863</bold>
</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">Cancer of prostate</td>
<td align="center" charoff="50" valign="top">0.692</td>
<td align="center" charoff="50" valign="top">0.820</td>
<td align="center" charoff="50" valign="top">
<bold>0.859</bold>
</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">Schizophrenia</td>
<td align="center" charoff="50" valign="top">0.791</td>
<td align="center" charoff="50" valign="top">0.788</td>
<td align="center" charoff="50" valign="top">
<bold>0.853</bold>
</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">Multiple myeloma</td>
<td align="center" charoff="50" valign="top">0.783</td>
<td align="center" charoff="50" valign="top">0.739</td>
<td align="center" charoff="50" valign="top">
<bold>0.849</bold>
</td>
</tr>
<tr>
<td align="left" charoff="50" valign="top">Acute myocardial infarction</td>
<td align="center" charoff="50" valign="top">0.771</td>
<td align="center" charoff="50" valign="top">0.775</td>
<td align="center" charoff="50" valign="top">
<bold>0.847</bold>
</td>
</tr>
</tbody>
</table>
</table-wrap>
<table-wrap id="t3" position="float">
<label>Table 3</label>
<caption>
<title>Patient disease tagging results for diagnoses assigned during different time intervals in terms of precision-at-<italic>k</italic>, with <italic>k</italic>
<bold> = </bold>1, 3, 5; UppBnd shows the best results achievable (i.e., all the correct diagnoses assigned to all the patients).</title>
</caption>
<table border="1" frame="hsides" rules="groups">
<colgroup>
<col align="left"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
<col align="center"/>
</colgroup>
<thead valign="bottom">
<tr>
<th align="left" charoff="50" rowspan="2" valign="top">Time Interval</th>
<th align="center" charoff="50" rowspan="2" valign="top">Metrics</th>
<th align="center" charoff="50" rowspan="2" valign="top">UppBnd</th>
<th align="center" charoff="50" colspan="4" valign="top">Patient Representation<hr/></th>
</tr>
<tr>
<th align="center" charoff="50" valign="top">RawFeat</th>
<th align="center" charoff="50" valign="top">PCA</th>
<th align="center" charoff="50" valign="top">ICA</th>
<th align="center" charoff="50" valign="top">DeepPatient</th>
</tr>
</thead>
<tbody valign="top">
<tr>
<td align="left" charoff="50" rowspan="3" valign="top"><bold>30 days</bold>
<italic>(16,374 patients)</italic></td>
<td align="center" charoff="50" valign="top">Prec@1</td>
<td align="center" charoff="50" valign="top">1.000</td>
<td align="center" charoff="50" valign="top">0.319</td>
<td align="center" charoff="50" valign="top">0.343</td>
<td align="center" charoff="50" valign="top">0.345</td>
<td align="center" charoff="50" valign="top">
<bold>0.392</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
<tr>
<td align="center" charoff="50" valign="top">Prec@3</td>
<td align="center" charoff="50" valign="top">0.492</td>
<td align="center" charoff="50" valign="top">0.217</td>
<td align="center" charoff="50" valign="top">0.251</td>
<td align="center" charoff="50" valign="top">0.255</td>
<td align="center" charoff="50" valign="top">
<bold>0.277</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
<tr>
<td align="center" charoff="50" valign="top">Prec@5</td>
<td align="center" charoff="50" valign="top">0.319</td>
<td align="center" charoff="50" valign="top">0.191</td>
<td align="center" charoff="50" valign="top">0.214</td>
<td align="center" charoff="50" valign="top">0.215</td>
<td align="center" charoff="50" valign="top">
<bold>0.226</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
<tr>
<td align="left" charoff="50" rowspan="3" valign="top"><bold>60 days</bold>
<italic>(21,924 patients)</italic></td>
<td align="center" charoff="50" valign="top">Prec@1</td>
<td align="center" charoff="50" valign="top">1.000</td>
<td align="center" charoff="50" valign="top">0.329</td>
<td align="center" charoff="50" valign="top">0.349</td>
<td align="center" charoff="50" valign="top">0.353</td>
<td align="center" charoff="50" valign="top">
<bold>0.402</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
<tr>
<td align="center" charoff="50" valign="top">Prec@3</td>
<td align="center" charoff="50" valign="top">0.511</td>
<td align="center" charoff="50" valign="top">0.221</td>
<td align="center" charoff="50" valign="top">0.254</td>
<td align="center" charoff="50" valign="top">0.259</td>
<td align="center" charoff="50" valign="top">
<bold>0.282</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
<tr>
<td align="center" charoff="50" valign="top">Prec@5</td>
<td align="center" charoff="50" valign="top">0.335</td>
<td align="center" charoff="50" valign="top">0.199</td>
<td align="center" charoff="50" valign="top">0.216</td>
<td align="center" charoff="50" valign="top">0.219</td>
<td align="center" charoff="50" valign="top">
<bold>0.230</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
<tr>
<td align="left" charoff="50" rowspan="3" valign="top"><bold>90 days</bold>
<italic>(25,220 patients)</italic></td>
<td align="center" charoff="50" valign="top">Prec@1</td>
<td align="center" charoff="50" valign="top">1.000</td>
<td align="center" charoff="50" valign="top">0.332</td>
<td align="center" charoff="50" valign="top">0.353</td>
<td align="center" charoff="50" valign="top">0.360</td>
<td align="center" charoff="50" valign="top">
<bold>0.404</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
<tr>
<td align="center" charoff="50" valign="top">Prec@3</td>
<td align="center" charoff="50" valign="top">0.521</td>
<td align="center" charoff="50" valign="top">0.243</td>
<td align="center" charoff="50" valign="top">0.257</td>
<td align="center" charoff="50" valign="top">0.262</td>
<td align="center" charoff="50" valign="top">
<bold>0.285</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
<tr>
<td align="center" charoff="50" valign="top">Prec@5</td>
<td align="center" charoff="50" valign="top">0.345</td>
<td align="center" charoff="50" valign="top">0.201</td>
<td align="center" charoff="50" valign="top">0.219</td>
<td align="center" charoff="50" valign="top">0.220</td>
<td align="center" charoff="50" valign="top">
<bold>0.232</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
<tr>
<td align="left" charoff="50" rowspan="3" valign="top"><bold>180 days</bold>
<italic>(33,607 patients)</italic></td>
<td align="center" charoff="50" valign="top">Prec@1</td>
<td align="center" charoff="50" valign="top">1.000</td>
<td align="center" charoff="50" valign="top">0.331</td>
<td align="center" charoff="50" valign="top">0.361</td>
<td align="center" charoff="50" valign="top">0.363</td>
<td align="center" charoff="50" valign="top">
<bold>0.418</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
<tr>
<td align="center" charoff="50" valign="top">Prec@3</td>
<td align="center" charoff="50" valign="top">0.549</td>
<td align="center" charoff="50" valign="top">0.246</td>
<td align="center" charoff="50" valign="top">0.261</td>
<td align="center" charoff="50" valign="top">0.265</td>
<td align="center" charoff="50" valign="top">
<bold>0.290</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
<tr>
<td align="center" charoff="50" valign="top">Prec@5</td>
<td align="center" charoff="50" valign="top">0.370</td>
<td align="center" charoff="50" valign="top">0.207</td>
<td align="center" charoff="50" valign="top">0.221</td>
<td align="center" charoff="50" valign="top">0.224</td>
<td align="center" charoff="50" valign="top">
<bold>0.236</bold>
<sup>
<bold>*</bold>
</sup>
</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="t3-fn1">
<p>(*) The difference with the corresponding second best measurement is statistically significant (p &lt; 0.05, t-test).</p>
</fn>
</table-wrap-foot>
</table-wrap>
</floats-group>
</article>
</pmc-articleset>