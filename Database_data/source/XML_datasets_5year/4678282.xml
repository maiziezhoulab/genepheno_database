<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="research-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
<journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLoS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">26658140</article-id>
<article-id pub-id-type="pmc">4678282</article-id>
<article-id pub-id-type="publisher-id">PONE-D-15-18490</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0144418</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>An Effective Method to Identify Heritable Components from Multivariate Phenotypes</article-title>
<alt-title alt-title-type="running-head">Identify Heritable Components</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Sun</surname>
<given-names>Jiangwen</given-names>
</name>
<xref ref-type="aff" rid="aff001">
<sup>1</sup>
</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kranzler</surname>
<given-names>Henry R.</given-names>
</name>
<xref ref-type="aff" rid="aff002">
<sup>2</sup>
</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bi</surname>
<given-names>Jinbo</given-names>
</name>
<xref ref-type="aff" rid="aff001">
<sup>1</sup>
</xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Department of Computer Science and Engineering, University of Connecticut, Storrs, Connecticut, United States of America</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Treatment Research Center, University of Pennsylvania Perelman School of Medicine and Philadelphia VAMC, Philadelphia, Pennsylvania, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor">
<name>
<surname>Rutherford</surname>
<given-names>Suzannah</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"></xref>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Fred Hutchinson Cancer Research Center, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="COI-statement" id="coi001">
<p><bold>Competing Interests: </bold>J. Sun and J. Bi declare that they have no competing interests. Although unrelated to this study, H. R. Kranzler has served as a consultant or advisory board member for the following companies: Alkermes, Lilly, Lundbeck, Otsuka, Pfizer, and Roche. He is a member of the Alcohol Clinical Trials Group of the American Society of Clinical Psychopharmacology, which is supported by Abbvie, Alkermes, Ethypharm, Lilly, Lundbeck, and Pfizer. This does not alter the authors’ adherence to PLOS ONE policies on sharing data and materials.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: JB JS HRK. Performed the experiments: JS JB. Analyzed the data: JS JB HRK. Contributed reagents/materials/analysis tools: JS JB. Wrote the paper: JB JS HRK.</p>
</fn>
<corresp id="cor001">* E-mail: <email>jinbo@engr.uconn.edu</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>14</day>
<month>12</month>
<year>2015</year>
</pub-date>
<volume>10</volume>
<issue>12</issue>
<elocation-id>e0144418</elocation-id>
<history>
<date date-type="received">
<day>28</day>
<month>4</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>18</day>
<month>11</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-statement>© 2015 Sun et al</copyright-statement>
<copyright-year>2015</copyright-year>
<copyright-holder>Sun et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/">
<license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="pone.0144418.pdf" xlink:type="simple"></self-uri>
<abstract>
<p>Multivariate phenotypes may be characterized collectively by a variety of low level traits, such as in the diagnosis of a disease that relies on multiple disease indicators. Such multivariate phenotypes are often used in genetic association studies. If highly heritable components of a multivariate phenotype can be identified, it can maximize the likelihood of finding genetic associations. Existing methods for phenotype refinement perform unsupervised cluster analysis on low-level traits and hence do not assess heritability. Existing heritable component analytics either cannot utilize general pedigrees or have to estimate the entire covariance matrix of low-level traits from limited samples, which leads to inaccurate estimates and is often computationally prohibitive. It is also difficult for these methods to exclude fixed effects from other covariates such as age, sex and race, in order to identify truly heritable components. We propose to search for a combination of low-level traits and directly maximize the heritability of this combined trait. A quadratic optimization problem is thus derived where the objective function is formulated by decomposing the traditional maximum likelihood method for estimating the heritability of a quantitative trait. The proposed approach can generate linearly-combined traits of high heritability that has been corrected for the fixed effects of covariates. The effectiveness of the proposed approach is demonstrated in simulations and by a case study of cocaine dependence. Our approach was computationally efficient and derived traits of higher heritability than those by other methods. Additional association analysis with the derived cocaine-use trait identified genetic markers that were replicated in an independent sample, further confirming the utility and advantage of the proposed approach.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by NIH grant R01DA037349 and NSF grant DBI-1356655.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"></fig-count>
<table-count count="5"></table-count>
<page-count count="22"></page-count>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>This paper discusses a new algorithm and the results from applying this algorithm to a cocaine dependence dataset. The algorithm, its software package, analysis result tables and figures are fully available via GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/JavonSun/hca/tree/master/hca-ml-matlab">https://github.com/JavonSun/hca/tree/master/hca-ml-matlab</ext-link>). The human subject data used in this analysis were collected in other NIH-funded studies, and aggregated by HRK and other investigators. These data are subject to NIH data sharing policy in the original studies.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<title>Data Availability</title>
<p>This paper discusses a new algorithm and the results from applying this algorithm to a cocaine dependence dataset. The algorithm, its software package, analysis result tables and figures are fully available via GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/JavonSun/hca/tree/master/hca-ml-matlab">https://github.com/JavonSun/hca/tree/master/hca-ml-matlab</ext-link>). The human subject data used in this analysis were collected in other NIH-funded studies, and aggregated by HRK and other investigators. These data are subject to NIH data sharing policy in the original studies.</p>
</notes>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Identifying genetic variation that underlies complex phenotypes has important implications for genetics and biology [<xref ref-type="bibr" rid="pone.0144418.ref001">1</xref>, <xref ref-type="bibr" rid="pone.0144418.ref002">2</xref>]. The power of most gene discovery studies is positively associated with the heritability of the trait [<xref ref-type="bibr" rid="pone.0144418.ref003">3</xref>]. Higher heritability of a trait implies that the trait varies due to stronger genetic influence. Thus, there is greater chance to detect its genetic causative variants. The narrow sense heritability <italic>h</italic>
<sup>2</sup> is defined by the percentage of phenotypic variance that is due to additive genetic effects. The broad sense heritability <italic>H</italic>
<sup>2</sup> is defined by the proportion of phenotypic variance due to all genetic variation.</p>
<p>Many complex phenotypes comprise a variety of low level traits (or phenotypic features) that are often highly variable. Association analysis of such a complex phenotype is impeded by this phenotypic heterogeneity [<xref ref-type="bibr" rid="pone.0144418.ref004">4</xref>]. For example, the diagnosis of drug dependence is determined by various patterns of drug use, their effects, and related behaviors [<xref ref-type="bibr" rid="pone.0144418.ref005">5</xref>]. A binary multivariate trait defined by the diagnosis of cocaine dependence, which partitions the population into cases (subjects with the disorder) and controls (subjects without the disorder), cannot differentiate the heterogeneous manifestations of the disease. Because of this, the success of identifying genetic variants is limited when using this binary trait in association analysis [<xref ref-type="bibr" rid="pone.0144418.ref006">6</xref>, <xref ref-type="bibr" rid="pone.0144418.ref007">7</xref>]. Identifying highly heritable components of the disease could permit the detection of genetic variants that are not detectable using the standard diagnosis-based traits [<xref ref-type="bibr" rid="pone.0144418.ref008">8</xref>–<xref ref-type="bibr" rid="pone.0144418.ref012">12</xref>]. Efforts have been made to enhance the binary trait by capturing more phenotypic variation, such as defining a multivariate trait as symptom count [<xref ref-type="bibr" rid="pone.0144418.ref007">7</xref>]. However, this kind of multivariate trait can have low heritability and may thus be sub-optimal for association analysis.</p>
<p>Heritable component analysis methods identify principal components of the data, i.e., linear combinations of low level traits, that are heritable [<xref ref-type="bibr" rid="pone.0144418.ref013">13</xref>–<xref ref-type="bibr" rid="pone.0144418.ref016">16</xref>]. All current methods decompose the identification of heritable components into solving two separate subproblems in sequence. They first estimate two covariance matrices of the low-level traits: <bold>Σ</bold>
<sub><italic>a</italic></sub>, the variance due to additive genetic effects taking into account the relationships of individuals (family structure); and <bold>Σ</bold>, the covariance matrix due to effects other than additive genetic effects. If there are <italic>d</italic> low level traits in <bold>x</bold>, this means that two <italic>d</italic>-by-<italic>d</italic> matrices need to be estimated from the sample. Once the two covariance matrices are computed, a generalized eigenproblem is solved to identify the combination coefficients <bold>w</bold> so that the ratio of <bold>w</bold>
<sup>⊤</sup>
<bold>Σ</bold>
<sub><italic>a</italic></sub>
<bold>w</bold>/<bold>w</bold>
<sup>⊤</sup>
<bold>Σ</bold>
<bold>w</bold> is maximized, leading to high heritability for the combined trait <bold>w</bold>
<sup>⊤</sup>
<bold>x</bold>.</p>
<p>A few methods have been developed in the literature to estimate the two covariance matrices. In [<xref ref-type="bibr" rid="pone.0144418.ref014">14</xref>, <xref ref-type="bibr" rid="pone.0144418.ref015">15</xref>], the two matrices are estimated based on the genetic effect of a single quantitative-trait locus to all the low level traits. This method has limited utility when the variance-covariance of the low level traits is due to multiple genetic loci (which is often the case for complex phenotypes). In [<xref ref-type="bibr" rid="pone.0144418.ref013">13</xref>, <xref ref-type="bibr" rid="pone.0144418.ref016">16</xref>, <xref ref-type="bibr" rid="pone.0144418.ref017">17</xref>], the two covariance matrices are estimated from family pedigrees of the sample. The approach used in [<xref ref-type="bibr" rid="pone.0144418.ref013">13</xref>] takes only siblings in a family, so it is inadequate to handle general (complex) pedigrees. The two approaches in [<xref ref-type="bibr" rid="pone.0144418.ref016">16</xref>] and [<xref ref-type="bibr" rid="pone.0144418.ref017">17</xref>] can handle general pedigrees. The first one derives an analytic formula for the covariance matrices based on Analysis of Variance (ANOVA). Although reducing the computational cost, the analytic formula is unable to take into account the fixed effects from covariates such as sex, age or race, which is also a problem for the method in [<xref ref-type="bibr" rid="pone.0144418.ref013">13</xref>]. Currently, the most comprehensive approach is a maximum likelihood method [<xref ref-type="bibr" rid="pone.0144418.ref017">17</xref>] that can estimate the fixed effects and covariance matrices together, but this method is computationally prohibitive as discussed in [<xref ref-type="bibr" rid="pone.0144418.ref016">16</xref>]. Even when <italic>d</italic> = 20 low level traits are used, this method can run for days, and as observed in our experiments, the method may not converge. It requires very large sample to obtain reliable estimates of two covariance matrices and <italic>d</italic> combination coefficients, totally 2<italic>d</italic>
<sup>2</sup> + <italic>d</italic> parameters, from a sample.</p>
<p>We show that, to obtain highly heritable components of a multivariate trait, the estimation of two covariance matrices is unnecessary. We propose an optimization approach that directly identifies a linear combination of low level traits whose estimated heritability is maximized. This optimization problem is formulated by decomposing the maximum likelihood method for estimating trait heritability. An <italic>sequential quadratic programming</italic> algorithm is developed to optimize the problem. We then extend the basic formulation to correct fixed effects of covariates in the component analysis. Because we do not estimate any covariance matrix, our approach is computationally much more efficient than those in [<xref ref-type="bibr" rid="pone.0144418.ref013">13</xref>, <xref ref-type="bibr" rid="pone.0144418.ref017">17</xref>]. The proposed approach is validated in both simulations and a case study on cocaine dependence. The effectiveness of the approach is demonstrated not only by the higher cross-validated heritability of the derived traits than the existing methods but also by a follow-up association study that compares the utility of the derived traits with the commonly used phenotype. Specifically, a highly heritable multivariate trait was derived for cocaine dependence. More statistically significant associations were found for this trait than for a symptom-count phenotype.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<p>We first introduce the standard methods for heritability estimation, and then derive our formulation that maximizes the heritability of a linearly-combined trait. An efficient algorithm is developed to optimize the formulation. At last, we extend the approach to take into consideration the fixed effects of covariates.</p>
<sec id="sec003">
<title>Background: Heritability Estimation</title>
<p>To estimate the heritability of a quantitative trait <italic>y</italic>, the well established maximum likelihood method is based on linear mixture models [<xref ref-type="bibr" rid="pone.0144418.ref003">3</xref>, <xref ref-type="bibr" rid="pone.0144418.ref018">18</xref>]. The method assumes that the phenotype <bold>y</bold>
<sup><italic>i</italic></sup> of a family <italic>i</italic> follows a multivariate normal distribution with covariance <bold>Ω</bold>
<sub><italic>i</italic></sub> and separate means for male and female family members, <italic>μ</italic>
<sub><italic>m</italic></sub> and <italic>μ</italic>
<sub><italic>f</italic></sub>, respectively. Separate means are used for males and females based on the general observation that males and females present differences in quantitative traits, such as height and weight. The (<italic>j</italic>, <italic>k</italic>)-th entry of <bold>Ω</bold>
<sub><italic>i</italic></sub> is the phenotypic covariance of two family members <italic>j</italic> and <italic>k</italic>, given by
<disp-formula id="pone.0144418.e001"><alternatives><graphic id="pone.0144418.e001g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e001.jpg"></graphic><mml:math id="M1"><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mo mathvariant="bold">Δ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mo mathvariant="bold">Γ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives><label>(1)</label></disp-formula>
where <inline-formula id="pone.0144418.e002"><alternatives><graphic id="pone.0144418.e002g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e002.jpg"></graphic><mml:math id="M2"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0144418.e003"><alternatives><graphic id="pone.0144418.e003g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e003.jpg"></graphic><mml:math id="M3"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> are the variance components due to additive and dominant genetic effects, respectively, and <inline-formula id="pone.0144418.e004"><alternatives><graphic id="pone.0144418.e004g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e004.jpg"></graphic><mml:math id="M4"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> denotes the variance component due to environmental factors. <xref ref-type="disp-formula" rid="pone.0144418.e001">Eq (1)</xref> can be extended to include other effects, such as an epistatic genetic effect <inline-formula id="pone.0144418.e005"><alternatives><graphic id="pone.0144418.e005g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e005.jpg"></graphic><mml:math id="M5"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>I</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>. The quantity <inline-formula id="pone.0144418.e006"><alternatives><graphic id="pone.0144418.e006g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e006.jpg"></graphic><mml:math id="M6"><mml:msubsup><mml:mo>Φ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is the kinship coefficient between members <italic>j</italic> and <italic>k</italic>. It is the probability that two alleles randomly drawn from <italic>j</italic> and <italic>k</italic> at a genetic locus are identical by descent (IBD), i.e., that these two alleles are identical copies of the same ancestral allele. An allele is one of the alternative forms at a genetic locus. As the human genome is diploid, each individual has two copies of an allele that may differ at a genetic locus. The quantity <inline-formula id="pone.0144418.e007"><alternatives><graphic id="pone.0144418.e007g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e007.jpg"></graphic><mml:math id="M7"><mml:msubsup><mml:mo>Δ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is the probability that members <italic>j</italic> and <italic>k</italic> share both alleles at a genetic locus. Both matrices <bold>Φ</bold>
<sub><italic>i</italic></sub> and <bold>Δ</bold>
<sub><italic>i</italic></sub> can be calculated from the family pedigrees [<xref ref-type="bibr" rid="pone.0144418.ref003">3</xref>]. Example entries of <bold>Φ</bold> and <bold>Δ</bold> between selected family members are illustrated in <xref ref-type="table" rid="pone.0144418.t001">Table 1</xref> where random mating is assumed. The parameter <inline-formula id="pone.0144418.e008"><alternatives><graphic id="pone.0144418.e008g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e008.jpg"></graphic><mml:math id="M8"><mml:msubsup><mml:mo>Γ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is an environmental indicator that encodes whether <italic>j</italic> and <italic>k</italic> live together (<inline-formula id="pone.0144418.e009"><alternatives><graphic id="pone.0144418.e009g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e009.jpg"></graphic><mml:math id="M9"><mml:mrow><mml:msubsup><mml:mo>Γ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>) or apart (<inline-formula id="pone.0144418.e010"><alternatives><graphic id="pone.0144418.e010g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e010.jpg"></graphic><mml:math id="M10"><mml:mrow><mml:msubsup><mml:mo>Γ</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>).</p>
<table-wrap id="pone.0144418.t001" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0144418.t001</object-id>
<label>Table 1</label>
<caption>
<title>Elements of the matrices Φ and Δ for selected relationships in a family when random mating is assumed.</title>
</caption>
<alternatives>
<graphic id="pone.0144418.t001g" xlink:href="pone.0144418.t001"></graphic>
<table border="0" frame="box" rules="all">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="1">Relationship</th>
<th align="center" colspan="1" rowspan="1">Φ</th>
<th align="center" colspan="1" rowspan="1">Δ</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Same person</td>
<td align="center" colspan="1" rowspan="1">1/2</td>
<td align="center" colspan="1" rowspan="1">1</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Parent-Child</td>
<td align="center" colspan="1" rowspan="1">1/4</td>
<td align="center" colspan="1" rowspan="1">0</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Full-siblings</td>
<td align="center" colspan="1" rowspan="1">1/4</td>
<td align="center" colspan="1" rowspan="1">1/4</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Half-siblings</td>
<td align="center" colspan="1" rowspan="1">1/8</td>
<td align="center" colspan="1" rowspan="1">0</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Monozygotic twins</td>
<td align="center" colspan="1" rowspan="1">1/2</td>
<td align="center" colspan="1" rowspan="1">1</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Grandparent-grandchild</td>
<td align="center" colspan="1" rowspan="1">1/8</td>
<td align="center" colspan="1" rowspan="1">0</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Uncle/aunt-nephew/niece</td>
<td align="center" colspan="1" rowspan="1">1/8</td>
<td align="center" colspan="1" rowspan="1">0</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">First cousins</td>
<td align="center" colspan="1" rowspan="1">1/16</td>
<td align="center" colspan="1" rowspan="1">0</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Double first cousins</td>
<td align="center" colspan="1" rowspan="1">1/8</td>
<td align="center" colspan="1" rowspan="1">1/16</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Spouses</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>The narrow sense heritability is given by <inline-formula id="pone.0144418.e011"><alternatives><graphic id="pone.0144418.e011g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e011.jpg"></graphic><mml:math id="M11"><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> where <inline-formula id="pone.0144418.e012"><alternatives><graphic id="pone.0144418.e012g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e012.jpg"></graphic><mml:math id="M12"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> is the total variance in <italic>y</italic>, i.e., <inline-formula id="pone.0144418.e013"><alternatives><graphic id="pone.0144418.e013g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e013.jpg"></graphic><mml:math id="M13"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, while the broad sense heritability is given by <inline-formula id="pone.0144418.e014"><alternatives><graphic id="pone.0144418.e014g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e014.jpg"></graphic><mml:math id="M14"><mml:mrow><mml:msup><mml:mi>H</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. In this paper, we target at quantitative traits with higher narrow sense heritability, which we henceforth simply refer to as heritability. However, our formulation can be easily modified to derive a quantitative trait of high <italic>H</italic>
<sup>2</sup>.</p>
<p>The five parameters, <italic>μ</italic>
<sub><italic>m</italic></sub>, <italic>μ</italic>
<sub><italic>f</italic></sub>, <inline-formula id="pone.0144418.e015"><alternatives><graphic id="pone.0144418.e015g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e015.jpg"></graphic><mml:math id="M15"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0144418.e016"><alternatives><graphic id="pone.0144418.e016g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e016.jpg"></graphic><mml:math id="M16"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0144418.e017"><alternatives><graphic id="pone.0144418.e017g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e017.jpg"></graphic><mml:math id="M17"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>, are estimated by maximizing the log likelihood of the trait values over all sample families [<xref ref-type="bibr" rid="pone.0144418.ref018">18</xref>]. The log likelihood is computed by
<disp-formula id="pone.0144418.e018"><alternatives><graphic id="pone.0144418.e018g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e018.jpg"></graphic><mml:math id="M18"><mml:mrow><mml:mi>L</mml:mi><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo form="prefix">ln</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold">y</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:msubsup><mml:mo mathvariant="bold">Ω</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold">y</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives><label>(2)</label></disp-formula>
where <italic>μ</italic>
<sup><italic>i</italic></sup> denotes a vector of the means <italic>μ</italic>
<sub><italic>m</italic></sub> and <italic>μ</italic>
<sub><italic>f</italic></sub> for male or female members, respectively, in the family <italic>i</italic>. The gradient and Hessian of <xref ref-type="disp-formula" rid="pone.0144418.e018">Eq (2)</xref> with respect to <italic>μ</italic>
<sub><italic>m</italic></sub>, <italic>μ</italic>
<sub><italic>f</italic></sub>, <inline-formula id="pone.0144418.e019"><alternatives><graphic id="pone.0144418.e019g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e019.jpg"></graphic><mml:math id="M19"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0144418.e020"><alternatives><graphic id="pone.0144418.e020g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e020.jpg"></graphic><mml:math id="M20"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0144418.e021"><alternatives><graphic id="pone.0144418.e021g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e021.jpg"></graphic><mml:math id="M21"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> can be calculated, and a Newton-Raphson algorithm or a scoring method [<xref ref-type="bibr" rid="pone.0144418.ref018">18</xref>] can be applied to maximize the log likelihood <xref ref-type="disp-formula" rid="pone.0144418.e018">Eq (2)</xref>.</p>
<p>The heritability of a quantitative trait <italic>y</italic> is often estimated with correction for the effects of covariates <bold>z</bold>, such as age, sex, or race. These covariate effects are modeled as fixed effects on <italic>y</italic>. Thus, a linear regression model <italic>y</italic> = <bold>z</bold>
<sup>⊤</sup>
<bold>v</bold> + <italic>ϵ</italic> can be built where <bold>v</bold> indicates the combination weights for the covariates. The heritability of the residual <italic>ϵ</italic> is then estimated using the described maximum likelihood method and treated as the heritability of <italic>y</italic> after adjusting for covariate effects.</p>
</sec>
<sec id="sec004">
<title>Proposed Quadratic Optimization</title>
<p>In heritability estimation, a trait is given, and we search for the values of <inline-formula id="pone.0144418.e022"><alternatives><graphic id="pone.0144418.e022g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e022.jpg"></graphic><mml:math id="M22"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0144418.e023"><alternatives><graphic id="pone.0144418.e023g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e023.jpg"></graphic><mml:math id="M23"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0144418.e024"><alternatives><graphic id="pone.0144418.e024g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e024.jpg"></graphic><mml:math id="M24"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> that maximize the likelihood of observing the trait values and compute the heritability as <inline-formula id="pone.0144418.e025"><alternatives><graphic id="pone.0144418.e025g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e025.jpg"></graphic><mml:math id="M25"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. In our study, we solve the inverse problem that a trait must be derived so that its heritability is maximized when estimated by the above maximum likelihood method.</p>
<p>For a given set of <italic>d</italic> phenotypic features <bold>x</bold>, we find a linearly combined trait <italic>y</italic> : <italic>y</italic> = <bold>x</bold>
<sup>⊤</sup>
<bold>w</bold>. If a trait <italic>y</italic> has the highest possible heritability, the covariance of <italic>y</italic> among any family members in family <italic>i</italic>, <inline-formula id="pone.0144418.e026"><alternatives><graphic id="pone.0144418.e026g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e026.jpg"></graphic><mml:math id="M26"><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, should be due to the additive effect <inline-formula id="pone.0144418.e027"><alternatives><graphic id="pone.0144418.e027g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e027.jpg"></graphic><mml:math id="M27"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> only, and <inline-formula id="pone.0144418.e028"><alternatives><graphic id="pone.0144418.e028g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e028.jpg"></graphic><mml:math id="M28"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. In other words, for such a trait, the covariance matrix of the phenotype <bold>y</bold>
<sup><italic>i</italic></sup> of a family <italic>i</italic> relies only on the additive effect parameter <inline-formula id="pone.0144418.e029"><alternatives><graphic id="pone.0144418.e029g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e029.jpg"></graphic><mml:math id="M29"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and the kinship matrix <bold>Φ</bold>
<sup><italic>i</italic></sup>, i.e., <inline-formula id="pone.0144418.e030"><alternatives><graphic id="pone.0144418.e030g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e030.jpg"></graphic><mml:math id="M30"><mml:mrow><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msup><mml:mo>Φ</mml:mo><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. Thus <inline-formula id="pone.0144418.e031"><alternatives><graphic id="pone.0144418.e031g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e031.jpg"></graphic><mml:math id="M31"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> is equal to the total variance <inline-formula id="pone.0144418.e032"><alternatives><graphic id="pone.0144418.e032g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e032.jpg"></graphic><mml:math id="M32"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> of <italic>y</italic>. We need to search for the values of <bold>w</bold> that maximize the likelihood of observing <inline-formula id="pone.0144418.e033"><alternatives><graphic id="pone.0144418.e033g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e033.jpg"></graphic><mml:math id="M33"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, or in other words, that maximize the likelihood of <inline-formula id="pone.0144418.e034"><alternatives><graphic id="pone.0144418.e034g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e034.jpg"></graphic><mml:math id="M34"><mml:mrow><mml:msub><mml:mo mathvariant="bold">Ω</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msup><mml:mo>Φ</mml:mo><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>Let <bold>X</bold>
<sub><italic>i</italic></sub> be the data matrix on the <italic>d</italic> features (as columns) for the subjects (as rows) in family <italic>i</italic>. Then the trait values of the family members form a vector <inline-formula id="pone.0144418.e035"><alternatives><graphic id="pone.0144418.e035g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e035.jpg"></graphic><mml:math id="M35"><mml:mrow><mml:msup><mml:mi mathvariant="bold">y</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. Because <italic>y</italic> is homogeneously dependent on the unknown <bold>w</bold>, <bold>w</bold> can be scaled so that the sample variance of <italic>y</italic> is 1, which implies that <inline-formula id="pone.0144418.e036"><alternatives><graphic id="pone.0144418.e036g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e036.jpg"></graphic><mml:math id="M36"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> (and hence <inline-formula id="pone.0144418.e037"><alternatives><graphic id="pone.0144418.e037g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e037.jpg"></graphic><mml:math id="M37"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>). Substituting the values of <bold>Ω</bold>
<sub><italic>i</italic></sub>, <bold>y</bold>
<sup><italic>i</italic></sup> and <inline-formula id="pone.0144418.e038"><alternatives><graphic id="pone.0144418.e038g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e038.jpg"></graphic><mml:math id="M38"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> into the log likelihood in <xref ref-type="disp-formula" rid="pone.0144418.e018">Eq (2)</xref> yields the following maximization problem:
<disp-formula id="pone.0144418.e039"><alternatives><graphic id="pone.0144418.e039g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e039.jpg"></graphic><mml:math id="M39"><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mi mathvariant="bold">w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo form="prefix">ln</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mo mathvariant="bold">Φ</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">w</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">w</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
which is equivalent to the following minimization problem after eliminating constants (for example, <inline-formula id="pone.0144418.e040"><alternatives><graphic id="pone.0144418.e040g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e040.jpg"></graphic><mml:math id="M40"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo form="prefix">ln</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:msub><mml:mo>Φ</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> does not vary in terms of <bold>w</bold>, <italic>μ</italic>
<sub><italic>m</italic></sub> or <italic>μ</italic>
<sub><italic>f</italic></sub>, and thus is a constant,)
<disp-formula id="pone.0144418.e041"><alternatives><graphic id="pone.0144418.e041g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e041.jpg"></graphic><mml:math id="M41"><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">min</mml:mo><mml:mrow><mml:mi mathvariant="bold">w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">w</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">w</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>(3)</label></disp-formula>
</p>
<p>We then consolidate the parameters <bold>w</bold>, <italic>μ</italic>
<sub><italic>m</italic></sub> and <italic>μ</italic>
<sub><italic>f</italic></sub> into a single column vector <bold>β</bold> = [<bold>w</bold>
<sup>⊤</sup>, <italic>μ</italic>
<sub><italic>m</italic></sub>, <italic>μ</italic>
<sub><italic>f</italic></sub>]<sup>⊤</sup>. Note that <italic>μ</italic>
<sup><italic>i</italic></sup> is a vector of length of the number of family members with corresponding entries equal to either <italic>μ</italic>
<sub><italic>m</italic></sub> or <italic>μ</italic>
<sub><italic>f</italic></sub> depending on the gender of the family member. We can simplify <xref ref-type="disp-formula" rid="pone.0144418.e059">Eq (4)</xref> to have <inline-formula id="pone.0144418.e042"><alternatives><graphic id="pone.0144418.e042g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e042.jpg"></graphic><mml:math id="M42"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">w</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi>β</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> and <bold>H</bold>
<sub><italic>i</italic></sub> is defined by
<disp-formula id="pone.0144418.e043"><alternatives><graphic id="pone.0144418.e043g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e043.jpg"></graphic><mml:math id="M43"><mml:mrow><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msubsup><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></disp-formula>
where <inline-formula id="pone.0144418.e044"><alternatives><graphic id="pone.0144418.e044g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e044.jpg"></graphic><mml:math id="M44"><mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0144418.e045"><alternatives><graphic id="pone.0144418.e045g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e045.jpg"></graphic><mml:math id="M45"><mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> are column vectors with length equal to the number of members in family <italic>i</italic>. For males in the family, −1 is assigned at their corresponding entries in <inline-formula id="pone.0144418.e046"><alternatives><graphic id="pone.0144418.e046g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e046.jpg"></graphic><mml:math id="M46"><mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and 0 at other positions of the vector. The vector of <inline-formula id="pone.0144418.e047"><alternatives><graphic id="pone.0144418.e047g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e047.jpg"></graphic><mml:math id="M47"><mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is similarly defined for female family members. For instance, a family <italic>i</italic> has three members included in a study, and they are ordered as a male member, a female member and then another male member. The vector <inline-formula id="pone.0144418.e048"><alternatives><graphic id="pone.0144418.e048g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e048.jpg"></graphic><mml:math id="M48"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> and the vector <inline-formula id="pone.0144418.e049"><alternatives><graphic id="pone.0144418.e049g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e049.jpg"></graphic><mml:math id="M49"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, which ensures that <inline-formula id="pone.0144418.e050"><alternatives><graphic id="pone.0144418.e050g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e050.jpg"></graphic><mml:math id="M50"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:msub><mml:mi>μ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msubsup><mml:msub><mml:mi>μ</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. Then, the objective function of <xref ref-type="disp-formula" rid="pone.0144418.e059">Eq (4)</xref> becomes
<disp-formula id="pone.0144418.e051"><alternatives><graphic id="pone.0144418.e051g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e051.jpg"></graphic><mml:math id="M51"><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">w</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">w</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
By stacking the <bold>H</bold>
<sub><italic>i</italic></sub> matrices of different families in columns, we get another matrix <bold>H</bold>. Similarly, we can form a matrix <bold>X</bold>, so the trait values of all subjects <bold>y</bold> = <bold>X</bold>
<sup>⊤</sup>
<bold>w</bold>. The sample variance of the trait <italic>y</italic> is, by definition, (1/<italic>n</italic>)(<bold>y</bold> − <bold><italic>μ</italic></bold>)<sup>⊤</sup>(<bold>y</bold> − <bold><italic>μ</italic></bold>). It is equal to (1/<italic>n</italic>)(<bold>X</bold>
<sup>⊤</sup>
<bold>w</bold> − <bold><italic>μ</italic></bold>)<sup>⊤</sup>(<bold>X</bold>
<sup>⊤</sup>
<bold>w</bold> − <bold><italic>μ</italic></bold>) = (1/<italic>n</italic>)<bold><italic>β</italic></bold>
<sup>⊤</sup>
<bold>H</bold>
<bold>H</bold>
<sup>⊤</sup>
<bold><italic>β</italic></bold>. Then, the condition of <inline-formula id="pone.0144418.e052"><alternatives><graphic id="pone.0144418.e052g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e052.jpg"></graphic><mml:math id="M52"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> corresponds to a constraint on <bold><italic>β</italic></bold>: (1/<italic>n</italic>)<bold><italic>β</italic></bold>
<sup>⊤</sup>
<bold>H</bold>
<bold>H</bold>
<sup>⊤</sup>
<bold><italic>β</italic></bold> = 1, which can be rewritten as <bold>β</bold>
<sup>⊤</sup>
<bold>H</bold>
<bold>H</bold>
<sup>⊤</sup>
<bold><italic>β</italic></bold> − <italic>n</italic> = 0.</p>
<p>As a matter of fact, <italic>μ</italic>
<sub><italic>m</italic></sub> and <italic>μ</italic>
<sub><italic>f</italic></sub> are not free parameters, as they are determined once <bold>w</bold> is determined. They are equal to the sample means of the trait, i.e., Mean(<bold>x</bold>
<sup>⊤</sup>
<bold>w</bold>), for male and female, respectively. Let <bold>x</bold>
<sub><italic>m</italic></sub> and <bold>x</bold>
<sub><italic>f</italic></sub> be the two means of the data vector <bold>x</bold> respectively over male and female samples. Then, <inline-formula id="pone.0144418.e053"><alternatives><graphic id="pone.0144418.e053g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e053.jpg"></graphic><mml:math id="M53"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>m</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">w</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0144418.e054"><alternatives><graphic id="pone.0144418.e054g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e054.jpg"></graphic><mml:math id="M54"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>f</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">w</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. These equations give two additional constraints. Let <inline-formula id="pone.0144418.e055"><alternatives><graphic id="pone.0144418.e055g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e055.jpg"></graphic><mml:math id="M55"><mml:mrow><mml:msub><mml:mi mathvariant="bold">a</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>m</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0144418.e056"><alternatives><graphic id="pone.0144418.e056g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e056.jpg"></graphic><mml:math id="M56"><mml:mrow><mml:msub><mml:mi mathvariant="bold">a</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>f</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, then the two constraints on <bold><italic>β</italic></bold> state that <inline-formula id="pone.0144418.e057"><alternatives><graphic id="pone.0144418.e057g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e057.jpg"></graphic><mml:math id="M57"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">a</mml:mi><mml:mi>m</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0144418.e058"><alternatives><graphic id="pone.0144418.e058g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e058.jpg"></graphic><mml:math id="M58"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">a</mml:mi><mml:mi>f</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>Imposing all of these constraints on <xref ref-type="disp-formula" rid="pone.0144418.e059">Eq (4)</xref> yields an optimization problem where a quadratic objective needs to be minimized subject to a quadratic constraint and two linear equality constraints as follows:
<disp-formula id="pone.0144418.e059"><alternatives><graphic id="pone.0144418.e059g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e059.jpg"></graphic><mml:math id="M59"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">min</mml:mo><mml:mi mathvariant="bold-italic">β</mml:mi></mml:munder><mml:mphantom><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mphantom></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>subject</mml:mtext><mml:mspace width="4.pt"></mml:mspace><mml:mtext>to</mml:mtext><mml:mphantom><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mphantom></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mi mathvariant="bold">H</mml:mi><mml:msup><mml:mi mathvariant="bold">H</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>-</mml:mo><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">a</mml:mi><mml:mi>m</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:mspace width="3.33333pt"></mml:mspace><mml:msubsup><mml:mi mathvariant="bold">a</mml:mi><mml:mi>f</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(4)</label></disp-formula>
</p>
<p>According to statistical learning theory [<xref ref-type="bibr" rid="pone.0144418.ref019">19</xref>], optimizing only the empirical heritability on the training sample as in <xref ref-type="disp-formula" rid="pone.0144418.e059">Eq (4)</xref> will lead to the so-called overfitting problem, which means that the resultant model <italic>y</italic> = <bold>x</bold>
<sup>⊤</sup>
<bold>w</bold> has low validation heritability despite a high training heritability. To enhance the generalizability of the derived model to new samples, a regularization condition on <bold>w</bold>, <italic>R</italic>(<bold>w</bold>), is required to control the complexity of the model. The objective function in <xref ref-type="disp-formula" rid="pone.0144418.e059">Eq (4)</xref> thus becomes
<disp-formula id="pone.0144418.e060"><alternatives><graphic id="pone.0144418.e060g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e060.jpg"></graphic><mml:math id="M60"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(5)</label></disp-formula>
where <italic>λ</italic> is a pre-specified tuning parameter for balancing the two terms in the objective function, and <italic>R</italic>(<bold>w</bold>) can be realized in different forms and be application-specific. For example, <italic>R</italic>(<bold>w</bold>) can be implemented with the ℓ<sub>1</sub> vector norm: <inline-formula id="pone.0144418.e061"><alternatives><graphic id="pone.0144418.e061g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e061.jpg"></graphic><mml:math id="M61"><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>d</mml:mi></mml:msubsup><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, which is known to create shrinkage effects on <bold>w</bold> as shown in the Least Absolute Shrinkage and Selection Operator (LASSO) method [<xref ref-type="bibr" rid="pone.0144418.ref020">20</xref>]. When features in <bold>x</bold> are clustered in multiple groups and sparsity in the level of each feature group is desirable, <italic>R</italic>(<bold>w</bold>) can be implemented by the ℓ<sub>2,1</sub> vector norm as used in the group LASSO [<xref ref-type="bibr" rid="pone.0144418.ref021">21</xref>] and defined by <inline-formula id="pone.0144418.e062"><alternatives><graphic id="pone.0144418.e062g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e062.jpg"></graphic><mml:math id="M62"><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:msubsup><mml:msqrt><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">G</mml:mi><mml:mi>ℓ</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msubsup><mml:mi mathvariant="bold">w</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> where <inline-formula id="pone.0144418.e063"><alternatives><graphic id="pone.0144418.e063g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e063.jpg"></graphic><mml:math id="M63"><mml:msub><mml:mi mathvariant="script">G</mml:mi><mml:mi>ℓ</mml:mi></mml:msub></mml:math></alternatives></inline-formula> contains the indices of the features in the group ℓ.</p>
<p>Specifically, we develop an algorithm in the next section to solve the following optimization problem with the ℓ<sub>1</sub> norm regularization condition
<disp-formula id="pone.0144418.e064"><alternatives><graphic id="pone.0144418.e064g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e064.jpg"></graphic><mml:math id="M64"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">min</mml:mo><mml:mi mathvariant="bold-italic">β</mml:mi></mml:munder><mml:mphantom><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mphantom></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>subject</mml:mtext><mml:mspace width="4.pt"></mml:mspace><mml:mtext>to</mml:mtext><mml:mphantom><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mphantom></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mi mathvariant="bold">H</mml:mi><mml:msup><mml:mi mathvariant="bold">H</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>-</mml:mo><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">a</mml:mi><mml:mi>m</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:mspace width="3.33333pt"></mml:mspace><mml:msubsup><mml:mi mathvariant="bold">a</mml:mi><mml:mi>f</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(6)</label></disp-formula>
Note that Problem <xref ref-type="disp-formula" rid="pone.0144418.e059">Eq (4)</xref> is a special case of Problem <xref ref-type="disp-formula" rid="pone.0144418.e064">Eq (6)</xref> when <italic>λ</italic> = 0. Hence, a solver for Problem <xref ref-type="disp-formula" rid="pone.0144418.e064">Eq (6)</xref> can also solve Problem <xref ref-type="disp-formula" rid="pone.0144418.e059">Eq (4)</xref>.</p>
</sec>
<sec id="sec005">
<title>Solving the Proposed Optimization Problem</title>
<p>The objective function in <xref ref-type="disp-formula" rid="pone.0144418.e064">Eq (6)</xref> is not differentiable because of the ℓ<sub>1</sub> norm regularization condition. However, by a widely used change-of-variables strategy, we can convert it into an equivalent differentiable form so gradient based solvers can be used. We introduce two sets of variables <bold>u</bold> ≥ 0 and <bold>v</bold> ≥ 0 both of length equal to that of <bold>w</bold>. We set <bold>w</bold> = <bold>u</bold> − <bold>v</bold>, which gives <inline-formula id="pone.0144418.e065"><alternatives><graphic id="pone.0144418.e065g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e065.jpg"></graphic><mml:math id="M65"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">w</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">u</mml:mi><mml:mo>-</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. Correspondingly, we replace the parameter vector <bold><italic>β</italic></bold> by <bold>γ</bold> = [<bold>u</bold>
<sup>⊤</sup>,<bold>v</bold>
<sup>⊤</sup>, <italic>μ</italic>
<sub><italic>m</italic></sub>, <italic>μ</italic>
<sub><italic>f</italic></sub>]<sup>⊤</sup>, and replace <bold>H</bold>
<sub><italic>i</italic></sub> by
<disp-formula id="pone.0144418.e066"><alternatives><graphic id="pone.0144418.e066g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e066.jpg"></graphic><mml:math id="M66"><mml:mrow><mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
so we have <bold>H</bold>
<sub><italic>i</italic></sub>
<italic><bold>β</bold></italic> = <bold>K</bold>
<sub><italic>i</italic></sub>
<italic><bold>γ</bold></italic>.</p>
<p>Stacking all <bold>K</bold>
<sub><italic>i</italic></sub>’s in columns leads to the full matrix <bold>K</bold>. The quadratic constraint in <xref ref-type="disp-formula" rid="pone.0144418.e064">Eq (6)</xref> then becomes <bold>γ</bold>
<sup>⊤</sup>
<bold>K</bold>
<bold>K</bold>
<sup>⊤</sup>
<bold>γ</bold> − <italic>n</italic> = 0. By setting <inline-formula id="pone.0144418.e067"><alternatives><graphic id="pone.0144418.e067g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e067.jpg"></graphic><mml:math id="M67"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">b</mml:mi><mml:mi>m</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0144418.e068"><alternatives><graphic id="pone.0144418.e068g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e068.jpg"></graphic><mml:math id="M68"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">b</mml:mi><mml:mi>f</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, the linear constraints in <xref ref-type="disp-formula" rid="pone.0144418.e064">Eq (6)</xref> become <inline-formula id="pone.0144418.e069"><alternatives><graphic id="pone.0144418.e069g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e069.jpg"></graphic><mml:math id="M69"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">b</mml:mi><mml:mi>m</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0144418.e070"><alternatives><graphic id="pone.0144418.e070g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e070.jpg"></graphic><mml:math id="M70"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">b</mml:mi><mml:mi>f</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. We have bound constraints on the new variables, i.e., <bold>u</bold> ≥ 0 and <bold>v</bold> ≥ 0. We hence design a matrix <bold>J</bold> = [<bold>I</bold>
<sub>2<italic>d</italic> × 2<italic>d</italic></sub>, [0]<sub>2<italic>d</italic></sub>, [0]<sub>2<italic>d</italic></sub>] where <bold>I</bold>
<sub>2<italic>d</italic> × 2<italic>d</italic></sub> is the identity matrix of dimension 2<italic>d</italic> × 2<italic>d</italic>, and [0]<sub>2<italic>d</italic></sub> is a column vector of all zero entries with length of 2<italic>d</italic>. Then, the bound constraints can be written as <bold>J</bold>
<bold>γ</bold> ≥ 0. Overall, with the new variables <bold>u</bold> and <bold>v</bold>, <xref ref-type="disp-formula" rid="pone.0144418.e064">Eq (6)</xref> can be re-written as follows
<disp-formula id="pone.0144418.e071"><alternatives><graphic id="pone.0144418.e071g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e071.jpg"></graphic><mml:math id="M71"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">min</mml:mo><mml:mo mathvariant="bold-italic">γ</mml:mo></mml:munder><mml:mphantom><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mphantom></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>f</mml:mi><mml:mspace width="1pt"></mml:mspace><mml:mo>:</mml:mo><mml:mspace width="1pt"></mml:mspace><mml:msup><mml:mo mathvariant="bold-italic">γ</mml:mo><mml:mi>⊤</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold">K</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo mathvariant="bold-italic">γ</mml:mo><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>d</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>γ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>subject</mml:mtext><mml:mspace width="4.pt"></mml:mspace><mml:mtext>to</mml:mtext><mml:mphantom><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mphantom></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mspace width="1pt"></mml:mspace><mml:mo>:</mml:mo><mml:mspace width="1pt"></mml:mspace><mml:msup><mml:mo mathvariant="bold-italic">γ</mml:mo><mml:mi>⊤</mml:mi></mml:msup><mml:mi mathvariant="bold">K</mml:mi><mml:msup><mml:mi mathvariant="bold">K</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mo mathvariant="bold-italic">γ</mml:mo><mml:mo>-</mml:mo><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mspace width="1pt"></mml:mspace><mml:mo>:</mml:mo><mml:mspace width="1pt"></mml:mspace><mml:msubsup><mml:mi mathvariant="bold">b</mml:mi><mml:mi>m</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo mathvariant="bold-italic">γ</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mspace width="1pt"></mml:mspace><mml:mo>:</mml:mo><mml:mspace width="1pt"></mml:mspace><mml:msubsup><mml:mi mathvariant="bold">b</mml:mi><mml:mi>f</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo mathvariant="bold-italic">γ</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:mspace width="1pt"></mml:mspace><mml:mo>:</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mspace width="1pt"></mml:mspace><mml:mo>:</mml:mo><mml:mspace width="1pt"></mml:mspace><mml:mi mathvariant="bold">J</mml:mi><mml:mo mathvariant="bold-italic">γ</mml:mo><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(7)</label></disp-formula>
where <italic>e</italic> = 2<italic>d</italic> + 3 is the total number of constraints in the problem.</p>
<p>It can be proved mathematically that the optimal solution of <xref ref-type="disp-formula" rid="pone.0144418.e071">Eq (7)</xref> is identical to the optimal solution of <xref ref-type="disp-formula" rid="pone.0144418.e064">Eq (6)</xref> in the sense that the optimal <bold>w</bold> = <bold>u</bold> − <bold>v</bold>. Note that the regularization condition in <xref ref-type="disp-formula" rid="pone.0144418.e071">Eq (7)</xref>, <inline-formula id="pone.0144418.e072"><alternatives><graphic id="pone.0144418.e072g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e072.jpg"></graphic><mml:math id="M72"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>γ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, is just equal to <inline-formula id="pone.0144418.e073"><alternatives><graphic id="pone.0144418.e073g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e073.jpg"></graphic><mml:math id="M73"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>d</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. At optimality of <xref ref-type="disp-formula" rid="pone.0144418.e071">Eq (7)</xref>, either <italic>u</italic>
<sub><italic>j</italic></sub> = 0 or <italic>v</italic>
<sub><italic>j</italic></sub> = 0 for the <italic>j</italic>th feature because otherwise they would not be optimal. If both <italic>u</italic>
<sub><italic>j</italic></sub> &gt; 0 and <italic>v</italic>
<sub><italic>j</italic></sub> &gt; 0 and assume <italic>u</italic>
<sub><italic>j</italic></sub> ≥ <italic>v</italic>
<sub><italic>j</italic></sub>, then we have another solution, (<inline-formula id="pone.0144418.e074"><alternatives><graphic id="pone.0144418.e074g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e074.jpg"></graphic><mml:math id="M74"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0144418.e075"><alternatives><graphic id="pone.0144418.e075g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e075.jpg"></graphic><mml:math id="M75"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>), that achieves lower objective value than (<italic>u</italic>
<sub><italic>j</italic></sub>, <italic>v</italic>
<sub><italic>j</italic></sub>) because the first term of <italic>f</italic> remains the same whereas the second term of <italic>f</italic> is reduced by 2<italic>v</italic>
<sub><italic>j</italic></sub>. Thus, at optimality, the regularizer of <xref ref-type="disp-formula" rid="pone.0144418.e071">Eq (7)</xref>
<inline-formula id="pone.0144418.e076"><alternatives><graphic id="pone.0144418.e076g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e076.jpg"></graphic><mml:math id="M76"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>γ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>d</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>d</mml:mi></mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mo>=</mml:mo></mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>d</mml:mi></mml:msubsup><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>Although <xref ref-type="disp-formula" rid="pone.0144418.e071">Eq (7)</xref> is not a convex problem due to the quadratic equality constraint <italic>g</italic>
<sub>1</sub>, we can solve it efficiently by the framework of sequential quadratic programming (SQP) [<xref ref-type="bibr" rid="pone.0144418.ref022">22</xref>]. A SQP algorithm solves the optimization problem iteratively. At each iteration, it approximates the original problem by a convex quadratic program, for which a solution can be easily computed. A quadratic program is defined as a minimization of a quadratic objective function subject to linear constraints. To form the approximate subproblem, the Lagrangian function of <xref ref-type="disp-formula" rid="pone.0144418.e071">Eq (7)</xref> is used:
<disp-formula id="pone.0144418.e077"><alternatives><graphic id="pone.0144418.e077g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e077.jpg"></graphic><mml:math id="M77"><mml:mrow><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">γ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(8)</label></disp-formula>
where <bold>α</bold> contains all Lagrange multipliers and <italic>k</italic> indexes the constraints. We use the second-order Taylor expansion to approximate the Lagrangian which forms the quadratic objective function of the subproblem, and use the first-order expansions to approximate the original constraints which form linear constraints for the subproblem.</p>
<p>The gradients of the objective function <italic>f</italic> and the constraints <italic>g</italic>
<sub><italic>i</italic>:<italic>i</italic> = 1:<italic>e</italic></sub> with respect to <bold>γ</bold> can be calculated as follows:
<disp-formula id="pone.0144418.e078"><alternatives><graphic id="pone.0144418.e078g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e078.jpg"></graphic><mml:math id="M78"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>(</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold">K</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>)</mml:mo><mml:mi mathvariant="bold-italic">γ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mi mathvariant="bold">c</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>∇</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">K</mml:mi><mml:msup><mml:mi mathvariant="bold">K</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="bold-italic">γ</mml:mi><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:mspace width="3.33333pt"></mml:mspace><mml:mo>∇</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">b</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>∇</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">b</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:mspace width="3.33333pt"></mml:mspace><mml:mo>∇</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:mo>:</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <inline-formula id="pone.0144418.e079"><alternatives><graphic id="pone.0144418.e079g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e079.jpg"></graphic><mml:math id="M79"><mml:mrow><mml:mi mathvariant="bold">c</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>d</mml:mi></mml:mrow><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> and [1]<sub>2<italic>d</italic></sub> is a column vector of all ones with length of 2<italic>d</italic>. The Hessian of <inline-formula id="pone.0144418.e080"><alternatives><graphic id="pone.0144418.e080g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e080.jpg"></graphic><mml:math id="M80"><mml:mi mathvariant="script">L</mml:mi></mml:math></alternatives></inline-formula> with respect to <italic><bold>γ</bold></italic> is calculated as:
<disp-formula id="pone.0144418.e081"><alternatives><graphic id="pone.0144418.e081g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e081.jpg"></graphic><mml:math id="M81"><mml:mrow><mml:msubsup><mml:mo>∇</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">γ</mml:mi><mml:mi mathvariant="bold-italic">γ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mi mathvariant="script">L</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mi>i</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="bold">K</mml:mi><mml:mi>i</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>α</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:msup><mml:mi mathvariant="bold">K</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>(9)</label></disp-formula>
</p>
<p>The subproblem at each iteration is formulated based on the current iterates <bold>γ</bold>
<sub><italic>t</italic></sub> and Lagrange multipliers <bold>α</bold>
<sub><italic>t</italic></sub>. At the iteration <italic>t</italic> + 1, the search directions for both <bold>γ</bold> and <bold>α</bold> can be computed by solving the following quadratic program
<disp-formula id="pone.0144418.e082"><alternatives><graphic id="pone.0144418.e082g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e082.jpg"></graphic><mml:math id="M82"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo form="prefix" movablelimits="true">min</mml:mo><mml:mi mathvariant="bold">p</mml:mi></mml:munder><mml:mphantom><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mphantom></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">γ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo>∇</mml:mo><mml:mi>f</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">γ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:mi mathvariant="bold">p</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mi mathvariant="bold">p</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msubsup><mml:mo>∇</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">γ</mml:mi><mml:mi mathvariant="bold-italic">γ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">γ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>subject</mml:mtext><mml:mspace width="4.pt"></mml:mspace><mml:mtext>to</mml:mtext><mml:mphantom><mml:mi>a</mml:mi><mml:mi>a</mml:mi></mml:mphantom></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>∇</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">γ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:mi mathvariant="bold">p</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">γ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mn>3</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>∇</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">γ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:mi mathvariant="bold">p</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">γ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>≽</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>4</mml:mn><mml:mo>:</mml:mo><mml:mi>e</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(10)</label></disp-formula>
where <bold>p</bold> is the search direction of <bold>γ</bold>, along which the objective function <italic>f</italic> can be decreased. Let <inline-formula id="pone.0144418.e083"><alternatives><graphic id="pone.0144418.e083g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e083.jpg"></graphic><mml:math id="M83"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">p</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula> be the solution to this subproblem and <inline-formula id="pone.0144418.e084"><alternatives><graphic id="pone.0144418.e084g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e084.jpg"></graphic><mml:math id="M84"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">q</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula> be the corresponding optimal Lagrange multipliers of <inline-formula id="pone.0144418.e085"><alternatives><graphic id="pone.0144418.e085g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e085.jpg"></graphic><mml:math id="M85"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">p</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, the search direction of <bold>α</bold> is calculated as <inline-formula id="pone.0144418.e086"><alternatives><graphic id="pone.0144418.e086g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e086.jpg"></graphic><mml:math id="M86"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">q</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Then, a line search method, such as those described in [<xref ref-type="bibr" rid="pone.0144418.ref022">22</xref>], can be used to determine a step size of moving along the directions. Then, <bold>γ</bold> and <bold>α</bold> are updated as follows:
<disp-formula id="pone.0144418.e087"><alternatives><graphic id="pone.0144418.e087g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e087.jpg"></graphic><mml:math id="M87"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">p</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:mspace width="3.33333pt"></mml:mspace><mml:mspace width="3.33333pt"></mml:mspace><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">q</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>(11)</label></disp-formula>
Algorithm 1 summarizes the SQP algorithm that we developed to solve <xref ref-type="disp-formula" rid="pone.0144418.e071">Eq (7)</xref>, and hence <xref ref-type="disp-formula" rid="pone.0144418.e064">Eq (6)</xref>.</p>
<p specific-use="line">
<bold>Algorithm 1</bold> A sequential quadratic programming approach to solving <xref ref-type="disp-formula" rid="pone.0144418.e071">Eq (7)</xref>
</p>
<p specific-use="line"> 
<bold>Input: K</bold>
<sub><italic>i</italic></sub>, <bold>Φ</bold>
<sub><italic>i</italic></sub>, <inline-formula id="pone.0144418.e088"><alternatives><graphic id="pone.0144418.e088g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e088.jpg"></graphic><mml:math id="M88"><mml:msubsup><mml:mi mathvariant="bold">a</mml:mi><mml:mi>m</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0144418.e089"><alternatives><graphic id="pone.0144418.e089g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e089.jpg"></graphic><mml:math id="M89"><mml:msubsup><mml:mi mathvariant="bold">a</mml:mi><mml:mi>f</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>, <italic>λ</italic>
</p>
<p specific-use="line"> 
<bold>Output: γ</bold>
</p>
<p specific-use="line"> 1. Initialize <bold>γ</bold> with <bold>u</bold> = <bold>1</bold>, <bold>v</bold> = <bold>0</bold>, and <italic>μ</italic>
<sub><italic>m</italic></sub>, <italic>μ</italic>
<sub><italic>f</italic></sub> equal to the sample male and female means of the obtained trait when <bold>w</bold> = <bold>1</bold>.</p>
<p specific-use="line"> 2. Initialize <bold>α</bold> with <bold>α</bold> = <bold>1</bold>.</p>
<p specific-use="line"> 3. Evaluate <italic>f</italic>, <inline-formula id="pone.0144418.e090"><alternatives><graphic id="pone.0144418.e090g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e090.jpg"></graphic><mml:math id="M90"><mml:mrow><mml:mo>∇</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pone.0144418.e091"><alternatives><graphic id="pone.0144418.e091g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e091.jpg"></graphic><mml:math id="M91"><mml:mrow><mml:mo>∇</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0144418.e092"><alternatives><graphic id="pone.0144418.e092g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e092.jpg"></graphic><mml:math id="M92"><mml:mrow><mml:msubsup><mml:mo>∇</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mi>γ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mi mathvariant="script">L</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> with the current <bold>γ</bold> and <bold>α</bold>.</p>
<p specific-use="line"> 4. Solve <xref ref-type="disp-formula" rid="pone.0144418.e082">Eq (10)</xref> to obtain <inline-formula id="pone.0144418.e093"><alternatives><graphic id="pone.0144418.e093g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e093.jpg"></graphic><mml:math id="M93"><mml:mover accent="true"><mml:mi mathvariant="bold">p</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0144418.e094"><alternatives><graphic id="pone.0144418.e094g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e094.jpg"></graphic><mml:math id="M94"><mml:mover accent="true"><mml:mi mathvariant="bold">q</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>.</p>
<p specific-use="line"> 5. Perform line search to find the learning step size <italic>s</italic>.</p>
<p specific-use="line"> 6. Update <bold>γ</bold> and <bold>α</bold> as in <xref ref-type="disp-formula" rid="pone.0144418.e087">Eq (11)</xref>.</p>
<p specific-use="line"> Repeat 3–6 until <bold>γ</bold> reaches a fixed point.</p>
</sec>
<sec id="sec006">
<title>Correction for Covariates</title>
<p>As discussed in the background section, the heritability of a quantitative trait <italic>y</italic> with effects from covariates <bold>z</bold> is equal to the heritability of the residual <italic>ϵ</italic> of the linear model <italic>y</italic> = <bold>z</bold>
<sup>⊤</sup>
<bold>v</bold> + <italic>ϵ</italic>. Therefore, our objective here is to find <inline-formula id="pone.0144418.e095"><alternatives><graphic id="pone.0144418.e095g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e095.jpg"></graphic><mml:math id="M95"><mml:mover accent="true"><mml:mi mathvariant="bold">w</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0144418.e096"><alternatives><graphic id="pone.0144418.e096g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e096.jpg"></graphic><mml:math id="M96"><mml:mover accent="true"><mml:mi mathvariant="bold">v</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> that optimize the heritability estimate of <italic>ϵ</italic>: <italic>ϵ</italic> = <bold>x</bold>
<sup>⊤</sup>
<bold>w</bold> − <bold>z</bold>
<sup>⊤</sup>
<bold>v</bold>, as <italic>y</italic> = <bold>x</bold>
<sup>⊤</sup>
<bold>w</bold>. Let <bold>Z</bold>
<sub><italic>p</italic> × <italic>n</italic></sub> be the data matrix on <bold>z</bold> of length <italic>p</italic> for the <italic>n</italic> subjects, the residual is calculated for all the subjects as <italic><bold>ϵ</bold></italic> = <bold>X</bold>
<sup>⊤</sup>
<bold>w</bold> − <bold>Z</bold>
<sup>⊤</sup>
<bold>v</bold>.</p>
<p>Given the data <bold>Z</bold> and <bold>y</bold>, a linear regression model <italic>y</italic> = <bold>z</bold>
<sup>⊤</sup>
<bold>v</bold> + <italic>ϵ</italic> is typically obtained through a least squares method which has an analytical solution, <inline-formula id="pone.0144418.e097"><alternatives><graphic id="pone.0144418.e097g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e097.jpg"></graphic><mml:math id="M97"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">v</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">Z</mml:mi><mml:msup><mml:mi mathvariant="bold">Z</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold">Z</mml:mi><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. As <bold>y</bold> = <bold>X</bold>
<sup>⊤</sup>
<bold>w</bold>, we have <inline-formula id="pone.0144418.e098"><alternatives><graphic id="pone.0144418.e098g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e098.jpg"></graphic><mml:math id="M98"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">v</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">Z</mml:mi><mml:msup><mml:mi mathvariant="bold">Z</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold">Z</mml:mi><mml:msup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> and
<disp-formula id="pone.0144418.e099"><alternatives><graphic id="pone.0144418.e099g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e099.jpg"></graphic><mml:math id="M99"><mml:mrow><mml:mi mathvariant="bold-italic">ϵ</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mi mathvariant="bold">Z</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">Z</mml:mi><mml:msup><mml:mi mathvariant="bold">Z</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold">Z</mml:mi><mml:msup><mml:mi mathvariant="bold">X</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mo>)</mml:mo><mml:mi mathvariant="bold">w</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
Let <bold>M</bold> = (<bold>X</bold>
<sup>⊤</sup> − <bold>Z</bold>
<sup>⊤</sup>(<bold>Z</bold>
<bold>Z</bold>
<sup>⊤</sup>)<sup>−1</sup>
<bold>Z</bold>
<bold>X</bold>
<sup>⊤</sup>)<sup>⊤</sup>, which can be pre-calculated from data, the calculation of <italic><bold>ϵ</bold></italic> can be rewritten as <italic><bold>ϵ</bold></italic> = <bold>M</bold>
<sup>⊤</sup>
<bold>w</bold>. Then, the objective of optimizing the heritability of <italic>ϵ</italic> can be translated to finding the optimal <bold>w</bold> that gives an <italic><bold>ϵ</bold></italic> of highest estimate of heritability. Comparing to the problem of finding <bold>w</bold> that gives a trait <italic>y</italic> = <bold>x</bold>
<sup>⊤</sup>
<bold>w</bold> with highest possible heritability, the only difference we have here is that the design matrix has been changed from <bold>X</bold> to <bold>M</bold> for the parameters <bold>w</bold>. Therefore, we can use the same SQP algorithm (Algorithm 1) to find the <bold>w</bold> that optimizes the heritability of <italic>ϵ</italic>. An interesting observation in our derivation is that correcting a quantitative trait to account for covariant effects is equivalent to correcting the data matrix that used to derive the trait.</p>
</sec>
<sec id="sec007">
<title>Algorithm Evaluation</title>
<p>The proposed approach was first validated in simulations where we compared it with the current two-step approaches, i.e., estimating the two covariance matrices from pedigrees first and then solving an eigenproblem. We compared with all the three different methods that can be used to estimate the variance-covariance matrices, which were referred to, respectively, as Ott [<xref ref-type="bibr" rid="pone.0144418.ref013">13</xref>], Anova [<xref ref-type="bibr" rid="pone.0144418.ref016">16</xref>] and ML [<xref ref-type="bibr" rid="pone.0144418.ref017">17</xref>]. The following <italic>Results</italic> section provides the details of the simulation and empirical evidence showing the superior performance of our algorithm.</p>
<p>After validated in simulations, the proposed approach was then used in a case study to analyze a real-world dataset that was aggregated from genetic studies of cocaine dependence (CD) [<xref ref-type="bibr" rid="pone.0144418.ref007">7</xref>, <xref ref-type="bibr" rid="pone.0144418.ref023">23</xref>]. Our algorithm was able to derive a quantitative trait with higher heritability than that of commonly used CD phenotypes. To show how our approach could help genetic association analysis, we compared the utility of the derived trait against the symptom-count phenotype as traits in association analysis and replicated the findings on a separate sample. The narrow sense heritability of all of the tested traits in this study was estimated by the widely-used <italic>polygenic</italic> function in the Sequential Oligogenic Linkage Analysis Routines (SOLAR) program [<xref ref-type="bibr" rid="pone.0144418.ref024">24</xref>].</p>
<sec id="sec008">
<title>Ethics statement</title>
<p>The <italic>Semi-Structured Assessment for Drug Dependence and Alcoholism</italic> (SSADDA) dataset [<xref ref-type="bibr" rid="pone.0144418.ref007">7</xref>] was used in both our simulations and the case study to evaluate the proposed algorithm. The SSADDA subjects were recruited from multiple sites, including the University of Connecticut Health Center, Yale University School of Medicine, the University of Pennsylvania School of Medicine, McLean Hospital and the Medical University of South Carolina. All subjects gave written, informed consent to participate, using procedures approved by the institutional review board (IRB) at each participating site. Readers can consult with [<xref ref-type="bibr" rid="pone.0144418.ref007">7</xref>] for the details of subject recruitment in those studies. The SSADDA data were de-identified and the analyses in this present study were approved by the University of Connecticut IRB Protocol H15-045 and the University of Pennsylvania IRB Protocals 804787 and 812856.</p>
</sec>
</sec>
</sec>
<sec id="sec009" sec-type="results">
<title>Results</title>
<p>This section provides the details of the simulation process and the case study of CD together with the empirical evidence showing the superior performance of our approach.</p>
<sec id="sec010">
<title>Simulations</title>
<p>In order to make our synthetic data more realistic but with known patterns, we created the synthetic data based on family structures in the SSADDA dataset. In this dataset, there were totally 6810 subjects, of which 1915 were from small nuclear families and the remaining subjects were unrelated individuals. Based on the family structures in this data, we synthesized two quantitative traits following the same assumptions used in the maximum likelihood method for heritability estimation [<xref ref-type="bibr" rid="pone.0144418.ref018">18</xref>].</p>
<sec id="sec011">
<title>Experimental data and procedure</title>
<p>The values of the first trait <italic>y</italic>
<sub>1</sub> were randomly drawn for each family from a multivariate Gaussian distribution: <italic>N</italic>(<bold><italic>μ</italic></bold>, <bold>Ω</bold>), where <bold><italic>μ</italic></bold> and <bold>Ω</bold> were determined as follows. The dimension of <bold><italic>μ</italic></bold> was determined by the number of subjects in the family, such that each dimension corresponded to an individual in the family. The value of <bold><italic>μ</italic></bold> used in the simulations may vary between families according to the gender of the members. Precisely, if a family member is male, <italic>μ</italic> was set to <italic>μ</italic>
<sub><italic>m</italic></sub>; otherwise it was set to <italic>μ</italic>
<sub><italic>f</italic></sub>. The covariance matrix <bold>Ω</bold> was given by the following equation:
<disp-formula id="pone.0144418.e100"><alternatives><graphic id="pone.0144418.e100g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e100.jpg"></graphic><mml:math id="M100"><mml:mrow><mml:mo mathvariant="bold">Ω</mml:mo><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo mathvariant="bold">Φ</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo mathvariant="bold">Δ</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mi mathvariant="bold">I</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives><label>(12)</label></disp-formula>
where <bold>Φ</bold> and <bold>Δ</bold> were composed according to <xref ref-type="table" rid="pone.0144418.t001">Table 1</xref>. Without loss of generality, in this study we used identity matrix <bold>I</bold> as the matrix <bold>Γ</bold> in <xref ref-type="disp-formula" rid="pone.0144418.e001">Eq (1)</xref>. The quantitative trait <italic>y</italic>
<sub>1</sub> was simulated with the following choices of the parameters:
<disp-formula id="pone.0144418.e101"><alternatives><graphic id="pone.0144418.e101g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e101.jpg"></graphic><mml:math id="M101"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:msub><mml:mi>μ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:msub><mml:mi>μ</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>9</mml:mn><mml:mo>,</mml:mo><mml:mspace width="3.33333pt"></mml:mspace><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>3</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives><label>(13)</label></disp-formula>
Hence, 80% of the phenotypic variance was due to additive genetic effects, and the ideal heritability is 0.8 according to <xref ref-type="disp-formula" rid="pone.0144418.e101">Eq (13)</xref>. By the random nature of the simulation, the actual heritability of the simulated trait may vary a little.</p>
<p>In order to evaluate if our approach can correct for fixed effects of covariates, we created another quantitative trait <italic>y</italic>
<sub>2</sub> by adding effects from age and race to <italic>y</italic>
<sub>1</sub>. Let <italic>c</italic>
<sub>1</sub> and <italic>c</italic>
<sub>2</sub> measure the effects of age and race respectively on <italic>y</italic>
<sub>2</sub>, we calculated <italic>y</italic>
<sub>2</sub> as follows: <italic>y</italic>
<sub>2</sub> = <italic>y</italic>
<sub>1</sub> + <italic>c</italic>
<sub>1</sub> × <italic>age</italic> + <italic>c</italic>
<sub>2</sub> × <italic>race</italic>. The values of the two <italic>c</italic>’s were arbitrarily set to <italic>c</italic>
<sub>1</sub> = 1.1 and <italic>c</italic>
<sub>2</sub> = 0.7, (which can certainly be set to any other non-zero values). Using SOLAR, we estimated the heritability of <italic>y</italic>
<sub>1</sub> with sex as covariate (<italic>h</italic>
<sup>2</sup> = 0.796) and the heritability of <italic>y</italic>
<sub>2</sub> with sex, age, race as covariates (<italic>h</italic>
<sup>2</sup> = 0.797).</p>
<p>We next simulated data of phenotypic features for the two quantitative traits. For each trait, we synthesized a dataset consisting of <italic>d</italic> = 10 relevant phenotypic features. We first specified the weights <bold>w</bold> of the features; then we generated data for these features as follows. For each subject, we randomly picked <italic>d</italic> − 1 features and drew their values randomly from the standard multivariate Gaussian distribution. Assume that the <italic>k</italic>-th feature is the remaining feature. Its value for subject <italic>i</italic> was computed by <inline-formula id="pone.0144418.e102"><alternatives><graphic id="pone.0144418.e102g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e102.jpg"></graphic><mml:math id="M102"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msubsup><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msubsup><mml:mi>x</mml:mi><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> (where <italic>w</italic>
<sub><italic>k</italic></sub> ≠ 0 because these 10 features were created with non-zero weights in the linear model). This procedure guaranteed that the trait <inline-formula id="pone.0144418.e103"><alternatives><graphic id="pone.0144418.e103g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e103.jpg"></graphic><mml:math id="M103"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>d</mml:mi></mml:msubsup><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, and because the feature computed from the values of other features varied randomly among subjects, every feature had a portion of randomly-drawn data.</p>
<p>In practice, a multivariate trait may not depend on all of the considered phenotypic features. In order to test if our approach can identify the relevant features, we created four other datasets for each of the traits, respectively, consisting of <italic>d</italic> = 20, 30, 40 and 50 features where only the first 10 of them were created following the above procedure, thus relevant to the simulated traits. The other features were all randomly drawn from standard Gaussian distribution and assigned a weight of 0. By simulating the data in this way, there was at least one linear combination of the features in each dataset that led to the simulated traits of high heritability. If our approach is to work, it should find this linear combination which is considered as the groundtruth model. There is a likelihood that another linear combination could give even higher heritability due to the random nature of the data, but this likelihood is small. In our experiments, none of the algorithms could locate any other combinations with higher heritability than the implanted one.</p>
<p>In practice, a multivariate trait may also depend on some features that are not observed. In our simulations, it implied that some of the ten relevant features might be absent. Therein, we further explored how our approach performed in the situation where the data was incomplete by randomly removing relevant features. We experimented with removing one to five relevant features incrementally. Note that in this sensitivity test, there was no longer a groundtruth model for the algorithm to test against because the implanted linear model had been broken with missing features. In this case, if our approach is to work, it should find a combination that leads to a heritability estimate no lower than that of the original features and that derived by other known methods.</p>
<p>The three previous methods evaluated in our comparison all used a regularization condition in their eigenproblem, so they also had a tuning parameter <italic>λ</italic>. In the experiments with each dataset, the parameters <italic>λ</italic> of all methods were tuned in the same three-fold cross validation process. More specifically, for each dataset, we randomly split the sample into three groups, and each group had the same amount of unrelated individuals and families with multiple members whenever it was possible. Samples in each group were used in one of the three folds, respectively, as the validation data to test the heritability of the trait derived by a method from the rest of the samples. We repeated this three-fold cross validation with 10 random splits for each choice of <italic>λ</italic> on each dataset. The choices of <italic>λ</italic> were pre-specified to the range of [0, 50] with a step size of 1. For each method, the choice of <italic>λ</italic> that gave the best cross validated heritability was used in the subsequent analysis.</p>
<p>In the experiments with the trait <italic>y</italic>
<sub>1</sub>, all methods did not use covariate data as the trait was not simulated with fixed effects. In the experiments with the trait <italic>y</italic>
<sub>2</sub>, because Ott [<xref ref-type="bibr" rid="pone.0144418.ref013">13</xref>] and Anova [<xref ref-type="bibr" rid="pone.0144418.ref016">16</xref>] could not take into account any covariate, we compared our approach with only the maximum likelihood method (ML) [<xref ref-type="bibr" rid="pone.0144418.ref017">17</xref>] with sex, age and race as covariates for fair comparison. The ML software package, downloaded from <ext-link ext-link-type="uri" xlink:href="http://www.genetics.ucla.edu/software/mendel">http://www.genetics.ucla.edu/software/mendel</ext-link>, had the default maximum number of iterations equal to 200, and we also experimented with 500 and 1000. We observed that the ML method could not reach convergence in the experiments with even 20 phenotypic features within a reasonable time limit (two days). Due to this computational hurdle, the ML method could not be applied to datasets with over 20 features.</p>
</sec>
<sec id="sec012">
<title>Observations from simulations</title>
<p>We first examined the algorithmic behavior of the proposed approach. <xref ref-type="fig" rid="pone.0144418.g001">Fig 1</xref> shows box plots of three-fold cross validated heritability (average values over the 10 trials and standard deviations) of the linear models derived by our approach for the simulated trait <italic>y</italic>
<sub>1</sub> from the five datasets. We observed that the proposed method was able to recover the linearly-combined traits with a relatively wide range of <italic>λ</italic> choices. From <xref ref-type="fig" rid="pone.0144418.g001">Fig 1</xref>, when <italic>λ</italic> = 1, 1, 13, 18, and 18 respectively for the five datasets, the best validation heritability was obtained. This observation shows that when the underlying model gets sparse, larger <italic>λ</italic> is favorable to prevent overfitting by removing irrelevant features. We had similar observations in the experiments with <italic>y</italic>
<sub>2</sub> as shown in <xref ref-type="fig" rid="pone.0144418.g002">Fig 2</xref>. <xref ref-type="fig" rid="pone.0144418.g002">Fig 2</xref> reports the same box plots for the simulated trait <italic>y</italic>
<sub>2</sub>. The validation heritability of the derived traits were high (with a small decrease when more irrelevant features were experimented), which demonstrated that the proposed approach could effectively correct for covariates in finding heritable components.</p>
<fig id="pone.0144418.g001" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0144418.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Three-fold cross validated heritability of the linear models derived for the trait <italic>y</italic>
<sub>1</sub> (simulated without covariate effects) when <italic>λ</italic> varies from 0 to 50 with a step size 1, on synthetic datasets consisting of 10, 20, 30, 40 and 50 features.</title>
</caption>
<graphic xlink:href="pone.0144418.g001"></graphic>
</fig>
<fig id="pone.0144418.g002" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0144418.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Three-fold cross validated heritability of the linear models derived for the trait <italic>y</italic>
<sub>2</sub> (simulated with covariate effects) when <italic>λ</italic> varies from 0 to 50 with a step size 1, on synthetic datasets consisting of 10, 20, 30, 40 and 50 features.</title>
</caption>
<graphic xlink:href="pone.0144418.g002"></graphic>
</fig>
<p>We next examined the comparison of our approach against the state of the art. To be more thorough, we compared all four methods using four different metrics including validated heritablity, sum of squared residuals to the simulated trait <italic>y</italic>
<sub>1</sub> or <italic>y</italic>
<sub>2</sub> (SE(trait)), squared difference between the learned weights <inline-formula id="pone.0144418.e104"><alternatives><graphic id="pone.0144418.e104g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e104.jpg"></graphic><mml:math id="M104"><mml:mover accent="true"><mml:mi mathvariant="bold">w</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and the true weights <bold>w</bold>, i.e., <inline-formula id="pone.0144418.e105"><alternatives><graphic id="pone.0144418.e105g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0144418.e105.jpg"></graphic><mml:math id="M105"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">w</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mo>|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> (SE(<bold>w</bold>)), as well as the computation cost. <xref ref-type="table" rid="pone.0144418.t002">Table 2</xref> shows the cross validated heritability of the traits derived by each of the methods in the two sets of experiments with <italic>y</italic>
<sub>1</sub> and <italic>y</italic>
<sub>2</sub>. The performance was reported with the best <italic>λ</italic> choice of each method. It is clear that the traits derived by our approach always achieved the highest heritability.</p>
<table-wrap id="pone.0144418.t002" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0144418.t002</object-id>
<label>Table 2</label>
<caption>
<title>Cross validated heritability of the traits derived by different methods in the experiments without covariates (results are presented in rows from 2 to 5) and with covariates (results are presented in rows 6 and 7).</title>
</caption>
<alternatives>
<graphic id="pone.0144418.t002g" xlink:href="pone.0144418.t002"></graphic>
<table border="0" frame="box" rules="all">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="1">Method</th>
<th align="center" colspan="1" rowspan="1">10 features</th>
<th align="center" colspan="1" rowspan="1">20 features</th>
<th align="center" colspan="1" rowspan="1">30 features</th>
<th align="center" colspan="1" rowspan="1">40 features</th>
<th align="center" colspan="1" rowspan="1">50 features</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Proposed</td>
<td align="center" colspan="1" rowspan="1">
<bold>0.777</bold>(0.009)</td>
<td align="center" colspan="1" rowspan="1">
<bold>0.724</bold>(0.027)</td>
<td align="center" colspan="1" rowspan="1">
<bold>0.707</bold>(0.018)</td>
<td align="center" colspan="1" rowspan="1">
<bold>0.717</bold>(0.021)</td>
<td align="center" colspan="1" rowspan="1">
<bold>0.670</bold>(0.024)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Anova</td>
<td align="center" colspan="1" rowspan="1">0.638(0.063)</td>
<td align="center" colspan="1" rowspan="1">0.581(0.043)</td>
<td align="center" colspan="1" rowspan="1">0.430(0.042)</td>
<td align="center" colspan="1" rowspan="1">0.551(0.050)</td>
<td align="center" colspan="1" rowspan="1">0.447(0.060)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Ott</td>
<td align="center" colspan="1" rowspan="1">0.378(0.049)</td>
<td align="center" colspan="1" rowspan="1">0.465(0.080)</td>
<td align="center" colspan="1" rowspan="1">0.292(0.048)</td>
<td align="center" colspan="1" rowspan="1">0.398(0.036)</td>
<td align="center" colspan="1" rowspan="1">0.352(0.065)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">ML</td>
<td align="center" colspan="1" rowspan="1">0.755(0.020)</td>
<td align="center" colspan="1" rowspan="1">0.046(0.032)</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="center" colspan="1" rowspan="1">–</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Proposed</td>
<td align="center" colspan="1" rowspan="1">0.775(0.010)</td>
<td align="center" colspan="1" rowspan="1">0.735(0.023)</td>
<td align="center" colspan="1" rowspan="1">0.738(0.030)</td>
<td align="center" colspan="1" rowspan="1">0.708(0.031)</td>
<td align="center" colspan="1" rowspan="1">0.644(0.051)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">ML</td>
<td align="center" colspan="1" rowspan="1">0.708(0.097)</td>
<td align="center" colspan="1" rowspan="1">0.044(0.037)</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="center" colspan="1" rowspan="1">–</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001">
<p>The “–” sign indicates that those experiments were infeasible due to prohibitive computation cost.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>
<xref ref-type="table" rid="pone.0144418.t003">Table 3</xref> compares the values of SE(trait), SE(<bold>w</bold>), and the computation time in seconds. In particular, the computation cost was measured by running each of the methods on the full datasets when the best <italic>λ</italic> value was used. Across all the datasets, our approach obtained the smallest errors as measured by SE(trait) and SE(<bold>w</bold>). Because Anova used analytic formula to compute covariance matrices, and Ott used a single locus in the covariance estimation, both methods required slightly less computation cost than our approach. However, they were limited only to the situations that had no confounding factors (covariates or other loci) in the heritability calculation. Between the two comprehensive methods, our approach was significantly more efficient than the ML method in computation, making the heritable component analysis with a large number of phenotypic features feasible.</p>
<table-wrap id="pone.0144418.t003" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0144418.t003</object-id>
<label>Table 3</label>
<caption>
<title>Comparison of the methods on the sum of squared residuals (SE(trait)), squared difference of the true weights and the learned weights (SE(w)), and the computation time (in seconds) in the experiments without covariates (results are presented in rows from 3 to 7) and with covariates (results are presented in rows from 8 to 12).</title>
</caption>
<alternatives>
<graphic id="pone.0144418.t003g" xlink:href="pone.0144418.t003"></graphic>
<table border="0" frame="box" rules="all">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="2">Dataset</th>
<th align="center" colspan="4" rowspan="1">SE(trait)</th>
<th align="center" colspan="4" rowspan="1">SE(<bold>w</bold>)</th>
<th align="center" colspan="4" rowspan="1">Computation Time (sec.)</th>
</tr>
<tr>
<th align="center" colspan="1" rowspan="1">Proposed</th>
<th align="center" colspan="1" rowspan="1">Anova</th>
<th align="center" colspan="1" rowspan="1">Ott</th>
<th align="center" colspan="1" rowspan="1">ML</th>
<th align="center" colspan="1" rowspan="1">Proposed</th>
<th align="center" colspan="1" rowspan="1">Anova</th>
<th align="center" colspan="1" rowspan="1">Ott</th>
<th align="center" colspan="1" rowspan="1">ML</th>
<th align="center" colspan="1" rowspan="1">Proposed</th>
<th align="center" colspan="1" rowspan="1">Anova</th>
<th align="center" colspan="1" rowspan="1">Ott</th>
<th align="center" colspan="1" rowspan="1">ML</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">10 features</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>10.89</bold>
</td>
<td align="center" colspan="1" rowspan="1">59.03</td>
<td align="center" colspan="1" rowspan="1">67.44</td>
<td align="center" colspan="1" rowspan="1">57.97</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>0.09</bold>
</td>
<td align="center" colspan="1" rowspan="1">1.35</td>
<td align="center" colspan="1" rowspan="1">1.38</td>
<td align="center" colspan="1" rowspan="1">1.34</td>
<td align="char" char="." colspan="1" rowspan="1">0.61</td>
<td align="center" colspan="1" rowspan="1">0.17</td>
<td align="center" colspan="1" rowspan="1">0.11</td>
<td align="center" colspan="1" rowspan="1">8.24e+02</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">20 features</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>16.62</bold>
</td>
<td align="center" colspan="1" rowspan="1">60.83</td>
<td align="center" colspan="1" rowspan="1">63.08</td>
<td align="center" colspan="1" rowspan="1">128.01</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>0.17</bold>
</td>
<td align="center" colspan="1" rowspan="1">1.37</td>
<td align="center" colspan="1" rowspan="1">1.39</td>
<td align="center" colspan="1" rowspan="1">2.54</td>
<td align="char" char="." colspan="1" rowspan="1">0.85</td>
<td align="center" colspan="1" rowspan="1">0.19</td>
<td align="center" colspan="1" rowspan="1">0.15</td>
<td align="center" colspan="1" rowspan="1">1.16e+04</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">30 features</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>19.69</bold>
</td>
<td align="center" colspan="1" rowspan="1">63.03</td>
<td align="center" colspan="1" rowspan="1">72.46</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>0.21</bold>
</td>
<td align="center" colspan="1" rowspan="1">1.38</td>
<td align="center" colspan="1" rowspan="1">1.48</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="char" char="." colspan="1" rowspan="1">0.90</td>
<td align="center" colspan="1" rowspan="1">0.19</td>
<td align="center" colspan="1" rowspan="1">0.14</td>
<td align="center" colspan="1" rowspan="1">–</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">40 features</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>23.31</bold>
</td>
<td align="center" colspan="1" rowspan="1">62.71</td>
<td align="center" colspan="1" rowspan="1">68.39</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>0.27</bold>
</td>
<td align="center" colspan="1" rowspan="1">1.39</td>
<td align="center" colspan="1" rowspan="1">1.44</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="char" char="." colspan="1" rowspan="1">0.98</td>
<td align="center" colspan="1" rowspan="1">0.29</td>
<td align="center" colspan="1" rowspan="1">0.23</td>
<td align="center" colspan="1" rowspan="1">–</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">50 features</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>25.23</bold>
</td>
<td align="center" colspan="1" rowspan="1">64.22</td>
<td align="center" colspan="1" rowspan="1">67.23</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>0.29</bold>
</td>
<td align="center" colspan="1" rowspan="1">1.40</td>
<td align="center" colspan="1" rowspan="1">1.43</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="char" char="." colspan="1" rowspan="1">2.13</td>
<td align="center" colspan="1" rowspan="1">0.30</td>
<td align="center" colspan="1" rowspan="1">0.26</td>
<td align="center" colspan="1" rowspan="1">–</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">10 features</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>13.61</bold>
</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">85.98</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>0.11</bold>
</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">1.35</td>
<td align="char" char="." colspan="1" rowspan="1">0.86</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">8.85e+02</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">20 features</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>16.14</bold>
</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">173.40</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>0.18</bold>
</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">2.58</td>
<td align="char" char="." colspan="1" rowspan="1">1.07</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">1.20e+04</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">30 features</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>26.60</bold>
</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>0.31</bold>
</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="char" char="." colspan="1" rowspan="1">1.30</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">–</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">40 features</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>26.81</bold>
</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>0.29</bold>
</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="char" char="." colspan="1" rowspan="1">1.61</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">–</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">50 features</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>25.87</bold>
</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>0.31</bold>
</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">–</td>
<td align="char" char="." colspan="1" rowspan="1">2.52</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">*</td>
<td align="center" colspan="1" rowspan="1">–</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001">
<p>The “–” sign indicates that those experiments were infeasible due to prohibitive computation cost. The “*” sign indicates that the corresponding methods were not tested due to the limitation of the methods that could not handle covariates. The computation time reported for the ML method was measured when the maximum number of iterations was set to 200.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Our approach identified multivariate traits of much higher heritability than the commonly used traits. We compared the heritability of the traits derived by our approach against that of commonly-used features. We used the traits derived by our approach from the cross validation process when the best <italic>λ</italic> values were used. As shown in <xref ref-type="fig" rid="pone.0144418.g003">Fig 3</xref> (without covariates) and <xref ref-type="fig" rid="pone.0144418.g004">Fig 4</xref> (with covariates), the validation heritability of the derived traits were significantly higher than that of individual features and the average of them.</p>
<fig id="pone.0144418.g003" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0144418.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Heritability comparison between the trait derived by the proposed approach, individual features and the simple average of features (without covariate effects).</title>
</caption>
<graphic xlink:href="pone.0144418.g003"></graphic>
</fig>
<fig id="pone.0144418.g004" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0144418.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Heritability comparison between the trait derived by the proposed approach, individual features and the simple average of features (with covariate effects).</title>
</caption>
<graphic xlink:href="pone.0144418.g004"></graphic>
</fig>
<p>Without loss of generality, we used the 20 feature dataset that we synthesized for <italic>y</italic>
<sub>1</sub> to evaluate if our approach could still find heritable components when the groundtruth models were broken. The results are reported in <xref ref-type="fig" rid="pone.0144418.g005">Fig 5</xref> where we compared the heritability of our derived traits against the maximum heritability that other methods could reach and that of the original features. Clearly, the traits derived by our approach achieved much higher heritability.</p>
<fig id="pone.0144418.g005" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0144418.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Heritability comparison between the traits derived by the proposed approach, by other methods, and original features when relevant features were randomly selected and excluded from the training data.</title>
</caption>
<graphic xlink:href="pone.0144418.g005"></graphic>
</fig>
</sec>
</sec>
<sec id="sec013">
<title>A Case Study: Cocaine Use and Related Behaviors</title>
<p>We applied the proposed approach to a genetic study of cocaine use and related behaviors. Two independent sets of samples were used in our analysis: the SSADDA dataset [<xref ref-type="bibr" rid="pone.0144418.ref007">7</xref>], which was used for discovery; and the <italic>Study of Addiction: Genetics and Environment</italic> (SAGE) dataset [<xref ref-type="bibr" rid="pone.0144418.ref025">25</xref>], which was used for replication of the SSADDA findings. The SAGE data were aggregated from multiple NIH-funded projects [<xref ref-type="bibr" rid="pone.0144418.ref026">26</xref>] by NIH’s dbGap system. We downloaded the data from the dbGap public domain [<xref ref-type="bibr" rid="pone.0144418.ref025">25</xref>] through dbGap accession number phs000092.v1.p.</p>
<p>The SSADDA sample included 4895 unrelated individuals which were used in our analysis to help estimate the total phenotypic variance even though they had no effect on the covariance estimates. The SAGE dataset consisted of 58 individuals from nuclear families and 1603 unrelated individuals. The two datasets contained samples from two populations: African American (AA) and European American (EA).</p>
<p>All subjects were reported to have used cocaine in their lifetime, and were assessed on the following 13 features of cocaine use and related behaviors:
<list list-type="bullet"><list-item><p>
<italic>F1</italic>—tolerance to cocaine;</p></list-item><list-item><p>
<italic>F2</italic>—withdrawal from cocaine;</p></list-item><list-item><p>
<italic>F3</italic>—using cocaine in larger amounts or over longer period than intended;</p></list-item><list-item><p>
<italic>F4</italic>—persistent desire or unsuccessful efforts to cut down or control cocaine use;</p></list-item><list-item><p>
<italic>F5</italic>—great amount of time spent in activities necessary to obtain, use or recover from the effects of cocaine;</p></list-item><list-item><p>
<italic>F6</italic>—gave up or reduced important social, occupational, or recreational activities because of cocaine use;</p></list-item><list-item><p>
<italic>F7</italic>—cocaine use despite knowledge of persistent or recurrent physical or psychological problems likely to have been caused or exacerbated by cocaine;</p></list-item><list-item><p>
<italic>F8</italic>—number of cocaine symptom endorsed;</p></list-item><list-item><p>
<italic>F9</italic>—age when first used cocaine;</p></list-item><list-item><p>
<italic>F10</italic>—age when last used cocaine;</p></list-item><list-item><p>
<italic>F11</italic>—age when first being diagnosed with DSM4 cocaine dependence;</p></list-item><list-item><p>
<italic>F12</italic>—age when last being diagnosed with DSM4 cocaine dependence;</p></list-item><list-item><p>
<italic>F13</italic>—transition time in years between the first time cocaine use and the first cocaine dependence diagnosis.</p></list-item></list>
Features <italic>F1–F7</italic> were binary variables that took a value of “yes = 1” or “no = 0”, and <italic>F8–F13</italic> were continuous variables, which we normalized to the range of [0, 1] in the analysis.</p>
<p>The majority of the 6810 subjects interviewed with the SSADDA, were genotyped on an Illumina microarray for 988,306 autosomal single-nucleotide polymorphisms (SNPs). Genotypes for additional 37,427,733 SNPs were imputed using IMPUTE2 [<xref ref-type="bibr" rid="pone.0144418.ref027">27</xref>] from genotyped SNPs and 1000 Genomes reference panel released in June 2011 (<ext-link ext-link-type="uri" xlink:href="http://www.1000genomes.org">http://www.1000genomes.org</ext-link>). Both subjects and SNPs were undergone stringent quality control (readers can consult with [<xref ref-type="bibr" rid="pone.0144418.ref007">7</xref>] for details). After data cleaning, there were a total of 4,845 subjects (2674 AAs, 2171 EAs) and 30,078,279 SNPs (695,308 genotyped) remained for analysis. Top three ancestral principal components were computed using 145,472 SNPs that were common to discovery samples and the Hapmap panel. All of the 1661 SAGE subjects (640 AAs, 1021 EAs) in the replication dataset were genotyped for 1,072,657 SNPs.</p>
<p>We derived a multivariate trait based on the 13 features of cocaine use and related behaviors. This trait was derived from the SSADDA data by Algorithm 1 with a correction for the fixed effects of age and race. Three-fold cross validation was performed to find the optimal <italic>λ</italic>, which was subsequently used to find a linearly combined trait from the 13 features based on the entire SSADDA data. The heritability of the derived trait was estimated and compared to that of individual quantitative features in the data, including the cocaine symptom count (<italic>F8</italic>). The feature <italic>F8</italic> was recognized as a better trait than the binary trait induced by the diagnosis of cocaine dependence in a recent genomewide association study (GWAS) [<xref ref-type="bibr" rid="pone.0144418.ref007">7</xref>]. We compared the utility of the derived trait and the symptom count as traits in an association analysis. Association tests were performed on the SSADDA sample for both traits and separately for EAs and AAs to identify significant genetic markers at <italic>p</italic> &lt; 5 × 10<sup>−6</sup>. We then computed the derived trait for the subjects in the replication SAGE sample. The markers identified from the SSADDA data were tested using the replication subjects. All tests included age, sex and the first three ancestral principal components as covariates. The association test results on discovery and replication data were combined by performing meta analysis using Metal [<xref ref-type="bibr" rid="pone.0144418.ref028">28</xref>]. Genomewide associations were identified from the meta analysis. Note that the heritability of the derived trait was not estimated on the SAGE data because 97% of the SAGE subjects were unrelated individuals.</p>
<p>
<xref ref-type="fig" rid="pone.0144418.g006">Fig 6</xref> shows the box plots of the cross validated heritability of the traits derived by Algorithm 1 when <italic>λ</italic> varied from 1 to 50 with a step size 1. When <italic>λ</italic> = 2, we observed the highest heritability on average in the cross validation. We hence used <italic>λ</italic> = 2 in Algorithm 1, and derived a linear combination of the features from the entire SSADDA data. The heritability of the derived trait and all individual quantitative features was estimated using SOLAR and reported in <xref ref-type="table" rid="pone.0144418.t004">Table 4</xref>. The quantitative trait derived by our approach has substantially higher heritability than that of all other traits.</p>
<fig id="pone.0144418.g006" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0144418.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Validation heritability of the multivariate traits derived by our approach for cocaine use and related behaviors using different values of <italic>λ</italic>.</title>
</caption>
<graphic xlink:href="pone.0144418.g006"></graphic>
</fig>
<table-wrap id="pone.0144418.t004" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0144418.t004</object-id>
<label>Table 4</label>
<caption>
<title>Heritability estimates for the multivariate trait derived by the proposed method and all individual quantitative features in the data.</title>
</caption>
<alternatives>
<graphic id="pone.0144418.t004g" xlink:href="pone.0144418.t004"></graphic>
<table border="0" frame="box" rules="all">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="1">Traits</th>
<th align="center" colspan="1" rowspan="1">heritability</th>
<th align="center" colspan="1" rowspan="1">
<italic>p</italic>-value</th>
<th align="center" colspan="1" rowspan="1">standard deviation</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Trait derived by proposed method</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>0.70</bold>
</td>
<td align="center" colspan="1" rowspan="1">4.36 × 10<sup>−22</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.06</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Cocaine symptom count</td>
<td align="char" char="." colspan="1" rowspan="1">0.41</td>
<td align="center" colspan="1" rowspan="1">1.52 × 10<sup>−08</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.07</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Age when first used cocaine</td>
<td align="char" char="." colspan="1" rowspan="1">0.39</td>
<td align="center" colspan="1" rowspan="1">2.41 × 10<sup>−09</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.07</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Age when last used cocaine</td>
<td align="char" char="." colspan="1" rowspan="1">0.35</td>
<td align="center" colspan="1" rowspan="1">6.70 × 10<sup>−06</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.10</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Age when first CD diagnosis</td>
<td align="char" char="." colspan="1" rowspan="1">0.43</td>
<td align="center" colspan="1" rowspan="1">1.15 × 10<sup>−10</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.07</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Age when last CD diagnosis</td>
<td align="char" char="." colspan="1" rowspan="1">0.38</td>
<td align="center" colspan="1" rowspan="1">5.99 × 10<sup>−09</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.07</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Transition time between first cocaine use and CD diagnosis</td>
<td align="char" char="." colspan="1" rowspan="1">0.42</td>
<td align="center" colspan="1" rowspan="1">8.09 × 10<sup>−10</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.07</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Using a regularization condition based on the sparsity-favoring ℓ<sub>1</sub> vector norm created shrinkage effects on our model. In other words, our approach selected parsimonious features to use in the linear combination. <xref ref-type="fig" rid="pone.0144418.g007">Fig 7</xref> shows the combination weights of the features obtained in our model. Five of the 13 features had weight of 0, thus were not used by the model. The feature—<italic>age when first used cocaine</italic> received the largest positive weight and therefore had the strongest impact on the derived trait. The other four important features were <italic>F11</italic>—<italic>age onset of DSM4 CD diagnosis</italic>, <italic>F4</italic>—<italic>persistent desire or unsuccessful efforts to cut down or control cocaine use</italic>, <italic>F5</italic>—<italic>great amount of time spent in activities necessary to obtain, use or recover from the effects of cocaine</italic>, and <italic>F3</italic>—<italic>using cocaine in larger amounts or over longer period than intended</italic>. Features <italic>F6</italic>, <italic>F1</italic> and <italic>F2</italic> had some but limited effect on the derived trait.</p>
<fig id="pone.0144418.g007" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0144418.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Weights of the eight clinical features in the linear model of the composite trait derived by our approach to the evaluation of cocaine use and related behaviors.</title>
</caption>
<graphic xlink:href="pone.0144418.g007"></graphic>
</fig>
<p>We identified three SNPs for the AA population and four SNPs for the EA population that passed our <italic>p</italic>-value threshold (5 × 10<sup>−6</sup>) in the genomewide association tests with the discovery sample. These SNPs are listed in <xref ref-type="table" rid="pone.0144418.t005">Table 5</xref>. In recent GWAS of substance use disorders, meta analysis was commonly used to identify genomewide significant associations, e.g., [<xref ref-type="bibr" rid="pone.0144418.ref007">7</xref>, <xref ref-type="bibr" rid="pone.0144418.ref023">23</xref>, <xref ref-type="bibr" rid="pone.0144418.ref029">29</xref>]. Following the same strategy in [<xref ref-type="bibr" rid="pone.0144418.ref007">7</xref>], we identified significant markers from the meta analysis results. Another recent study that used the same 1000 Genomes reference panel identified that 10<sup>−8</sup> is an appropriate p-value threshold for use in a GWAS that employs imputed SNPs [<xref ref-type="bibr" rid="pone.0144418.ref030">30</xref>]. Based on this threshold, the markers rs833936 and rs7224135 in <xref ref-type="table" rid="pone.0144418.t005">Table 5</xref> were significantly associated with the derived trait at the genomewide level, respectively for AAs and EAs, but not with the commonly-used cocaine symptom count. The other five markers in <xref ref-type="table" rid="pone.0144418.t005">Table 5</xref> were nominally significantly (1 × 10<sup>−8</sup>&lt; meta <italic>p</italic>-value &lt; 5 × 10<sup>−6</sup>) associated with the derived trait only. In other words, using the standard phenotype in association tests would not discover these SNPs that are associated with a specific subtype (a quantitative subphenotype) of cocaine dependence. The marker rs833936 is located at the <italic>TXNIP</italic> gene which may act as an oxidative stress mediator when its expression is suppressed by synaptic activity in brain [<xref ref-type="bibr" rid="pone.0144418.ref031">31</xref>]. Two markers rs11079045 and rs7224135 are located at the <italic>PTRF</italic> gene which has been identified to be associated with cocaine abuse in an early transcriptional change study [<xref ref-type="bibr" rid="pone.0144418.ref032">32</xref>]. The <italic>EFEMP1</italic> gene has not been reported in the genetic analysis of cocaine dependence. Since all the identified SNP markers have not been thoroughly studied in genetics of cocaine dependence, our findings may promote subsequent investigations for these genes as well as subtypes of cocaine dependence. The proposed heritable component analysis for multivariate phenotypes may provide a new strategy to improve genomewide association studies of complex disorders.</p>
<table-wrap id="pone.0144418.t005" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0144418.t005</object-id>
<label>Table 5</label>
<caption>
<title>Top findings obtained by the genome-wide association analysis with the derived subphenotype.</title>
</caption>
<alternatives>
<graphic id="pone.0144418.t005g" xlink:href="pone.0144418.t005"></graphic>
<table border="0" frame="box" rules="all">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="2"></th>
<th align="left" colspan="1" rowspan="2">SNP</th>
<th align="center" colspan="1" rowspan="2">Chr</th>
<th align="center" colspan="1" rowspan="2">Gene</th>
<th align="center" colspan="3" rowspan="1">Discovery</th>
<th align="center" colspan="3" rowspan="1">Replication</th>
<th align="center" colspan="3" rowspan="1">Meta</th>
</tr>
<tr>
<th align="center" colspan="1" rowspan="1">MAF</th>
<th align="center" colspan="1" rowspan="1">
<italic>p</italic>
<sub><italic>derived</italic></sub>
</th>
<th align="center" colspan="1" rowspan="1">
<italic>p</italic>
<sub><italic>symp</italic></sub>
</th>
<th align="center" colspan="1" rowspan="1">MAF</th>
<th align="center" colspan="1" rowspan="1">
<italic>p</italic>
<sub><italic>derived</italic></sub>
</th>
<th align="center" colspan="1" rowspan="1">
<italic>p</italic>
<sub><italic>symp</italic></sub>
</th>
<th align="center" colspan="1" rowspan="1">
<italic>p</italic>
<sub><italic>derived</italic></sub>
</th>
<th align="center" colspan="1" rowspan="1">
<italic>p</italic>
<sub><italic>symp</italic></sub>
</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="3">AA</td>
<td align="left" colspan="1" rowspan="1">rs769065</td>
<td align="center" colspan="1" rowspan="1">6</td>
<td align="center" colspan="1" rowspan="1">
<italic>DNAH8</italic>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.26</td>
<td align="center" colspan="1" rowspan="1">6.14 × 10<sup>−6</sup>
</td>
<td align="center" colspan="1" rowspan="1">9.62 × 10<sup>−2</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.03</td>
<td align="center" colspan="1" rowspan="1">8.74 × 10<sup>−3</sup>
</td>
<td align="center" colspan="1" rowspan="1">3.58 × 10<sup>−2</sup>
</td>
<td align="center" colspan="1" rowspan="1">1.85 × 10<sup>−7</sup>
</td>
<td align="center" colspan="1" rowspan="1">1.57 × 10<sup>−2</sup>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>rs833936</bold>
</td>
<td align="center" colspan="1" rowspan="1">1</td>
<td align="center" colspan="1" rowspan="1">
<italic>TXNIP</italic>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.36</td>
<td align="center" colspan="1" rowspan="1">7.90 × 10<sup>−8</sup>
</td>
<td align="center" colspan="1" rowspan="1">2.51 × 10<sup>−2</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.12</td>
<td align="center" colspan="1" rowspan="1">2.22 × 10<sup>−2</sup>
</td>
<td align="center" colspan="1" rowspan="1">1.76 × 10<sup>−2</sup>
</td>
<td align="center" colspan="1" rowspan="1">
<bold>5.59</bold>
<bold>×</bold>
<bold>10</bold>
<sup><bold>−</bold><bold>9</bold></sup>
</td>
<td align="center" colspan="1" rowspan="1">2.43 × 10<sup>−3</sup>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">rs75621732</td>
<td align="center" colspan="1" rowspan="1">11</td>
<td align="center" colspan="1" rowspan="1">
<italic>MLSTD2</italic>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.06</td>
<td align="center" colspan="1" rowspan="1">1.89 × 10<sup>−6</sup>
</td>
<td align="center" colspan="1" rowspan="1">1.85 × 10<sup>−1</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.35</td>
<td align="center" colspan="1" rowspan="1">4.95 × 10<sup>−2</sup>
</td>
<td align="center" colspan="1" rowspan="1">5.60 × 10<sup>−1</sup>
</td>
<td align="center" colspan="1" rowspan="1">2.70 × 10<sup>−7</sup>
</td>
<td align="center" colspan="1" rowspan="1">1.48 × 10<sup>−1</sup>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="4">EA</td>
<td align="left" colspan="1" rowspan="1">rs11079045</td>
<td align="center" colspan="1" rowspan="1">17</td>
<td align="center" colspan="1" rowspan="1">
<italic>PTRF</italic>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.40</td>
<td align="center" colspan="1" rowspan="1">2.48 × 10<sup>−6</sup>
</td>
<td align="center" colspan="1" rowspan="1">2.24 × 10<sup>−1</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.42</td>
<td align="center" colspan="1" rowspan="1">1.48 × 10<sup>−3</sup>
</td>
<td align="center" colspan="1" rowspan="1">2.24 × 10<sup>−1</sup>
</td>
<td align="center" colspan="1" rowspan="1">1.33 × 10<sup>−8</sup>
</td>
<td align="center" colspan="1" rowspan="1">1.82 × 10<sup>−1</sup>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>rs7224135</bold>
</td>
<td align="center" colspan="1" rowspan="1">17</td>
<td align="center" colspan="1" rowspan="1">
<italic>PTRF</italic>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.40</td>
<td align="center" colspan="1" rowspan="1">7.61 × 10<sup>−7</sup>
</td>
<td align="center" colspan="1" rowspan="1">1.50 × 10<sup>−1</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.41</td>
<td align="center" colspan="1" rowspan="1">2.29 × 10<sup>−3</sup>
</td>
<td align="center" colspan="1" rowspan="1">1.50 × 10<sup>−1</sup>
</td>
<td align="center" colspan="1" rowspan="1">
<bold>6.51</bold>
<bold>×</bold>
<bold>10</bold>
<sup><bold>−</bold><bold>9</bold></sup>
</td>
<td align="center" colspan="1" rowspan="1">1.08 × 10<sup>−1</sup>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">rs10490394</td>
<td align="center" colspan="1" rowspan="1">2</td>
<td align="center" colspan="1" rowspan="1">
<italic>EFEMP1</italic>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.20</td>
<td align="center" colspan="1" rowspan="1">8.78 × 10<sup>−7</sup>
</td>
<td align="center" colspan="1" rowspan="1">1.53 × 10<sup>−1</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.19</td>
<td align="center" colspan="1" rowspan="1">9.15 × 10<sup>−3</sup>
</td>
<td align="center" colspan="1" rowspan="1">1.53 × 10<sup>−1</sup>
</td>
<td align="center" colspan="1" rowspan="1">3.22 × 10<sup>−8</sup>
</td>
<td align="center" colspan="1" rowspan="1">2.33 × 10<sup>−1</sup>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">rs7330895</td>
<td align="center" colspan="1" rowspan="1">13</td>
<td align="center" colspan="1" rowspan="1">
<italic>DACH1</italic>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.39</td>
<td align="center" colspan="1" rowspan="1">7.50 × 10<sup>−6</sup>
</td>
<td align="center" colspan="1" rowspan="1">6.00 × 10<sup>−2</sup>
</td>
<td align="char" char="." colspan="1" rowspan="1">0.34</td>
<td align="center" colspan="1" rowspan="1">2.81 × 10<sup>−2</sup>
</td>
<td align="center" colspan="1" rowspan="1">6.00 × 10<sup>−2</sup>
</td>
<td align="center" colspan="1" rowspan="1">8.00 × 10<sup>−7</sup>
</td>
<td align="center" colspan="1" rowspan="1">2.80 × 10<sup>−3</sup>
</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t005fn001">
<p>Notes: Chr—chromosome; MAF—minor allele frequency; <italic>p</italic>
<sub><italic>derived</italic></sub>—the <italic>p</italic>-value obtained with the trait derived by the proposed method; <italic>p</italic>
<sub><italic>symp</italic></sub>—the <italic>p</italic>-value obtained with the cocaine symptom count. SNPs with <italic>p</italic>-values that reach genome-wide significant level (&lt; 10<sup>−8</sup>) are in bold font.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="sec014">
<title>Discussion and Conclusion</title>
<p>In this paper, we have proposed a quadratic optimization formulation that is capable of identifying highly heritable components of complex phenotypes. The multivariate trait is derived as a linear function <italic>y</italic> = <bold>x</bold>
<sup>⊤</sup>
<bold>w</bold> of lower level traits <bold>x</bold> by explicitly maximizing its heritability. Specifically, we search for the optimal <bold>w</bold> that maximizes the likelihood of observing a high value of heritability. This is equivalent to finding the best <bold>w</bold>, so that the projected trait <bold>x</bold>
<sup>⊤</sup>
<bold>w</bold> will be best aligned with the kinship matrix <bold>Φ</bold> of the pedigree. An efficient algorithm based on sequential quadratic programming has been developed to optimize the proposed formulation. The algorithm is extended to allow the correction for covariate effects when deriving a heritable component.</p>
<p>Our simulation study provides evidence of the effectiveness of the proposed approach as a means to find highly heritable components of multivariate phenotypes. Then a case study on the phenotypes of cocaine use and dependence was conducted. A quantitative trait was identified based on thirteen cocaine use symptoms and behaviors. The trait had a heritability estimate of 0.7 (with <italic>p</italic> = 4.36 × 10<sup>−22</sup>, std = 0.06), which was much higher than a standard cocaine-use phenotype, e.g., the symptom-count trait, with heritability of 0.41. The subsequent phenotype-genotype association study demonstrated important utility of the derived trait for use in association analysis. Our results show that seven SNPs were significantly or nominally significantly associated with the derived subphenotype, but were not associated with the symptom count phenotype. Two out of the seven associated SNPs reached genome-wide significant level after correction for multi-testing following the procedure in [<xref ref-type="bibr" rid="pone.0144418.ref007">7</xref>, <xref ref-type="bibr" rid="pone.0144418.ref030">30</xref>].</p>
<p>Our formulation has a hyper-parameter <italic>λ</italic>. Using a hyper-parameter is common in machine learning algorithms such as support vector machines [<xref ref-type="bibr" rid="pone.0144418.ref033">33</xref>]. As a hyper-parameter, <italic>λ</italic> is not determined by solving the formulation itself and instead needs to be pre-specified. Both our simulation study and our case study showed that our formulation is fairly robust to the value of <italic>λ</italic> when it is chosen from a reasonably wide range. In real-world applications, hyper-parameters are often determined by a cross-validation process, which was used in our experiments.</p>
<p>Discovering heritable components of a multivariate phenotype can also improve genomic prediction [<xref ref-type="bibr" rid="pone.0144418.ref034">34</xref>]. If a trait is highly heritable, a model that is based on genomic markers to predict the trait value can achieve high accuracy [<xref ref-type="bibr" rid="pone.0144418.ref035">35</xref>]. In agricultural science, heritability of the breeding trait is considered to be one of the most important factors for the performance of a breeding program. Breeding programs targeted at conceptual but economically important phenotypes, such as feed efficiency or heat tolerance of animals, are confronted with a wide variety of available measures for the phenotype [<xref ref-type="bibr" rid="pone.0144418.ref036">36</xref>, <xref ref-type="bibr" rid="pone.0144418.ref037">37</xref>]. Residual body weight gain, residual feed intake, or relative growth rate are feed efficiency measures for dairy cattle with heritability ranging from 0.28 to 0.45 [<xref ref-type="bibr" rid="pone.0144418.ref036">36</xref>, <xref ref-type="bibr" rid="pone.0144418.ref038">38</xref>]. Each of these measures forms a multivariate trait that is defined by a linear function of low level traits, such as body weight, diet and feed energy intake, and days in milk. Our new algorithm can help the identification of more heritable measures for conceptual phenotypes of animal or plant.</p>
<p>There are limitations of our proposed technique. The non-convex quadratic optimization formulation requires a complex solver, such as sequential quadratic programming. For a sample that contains millions of subjects, it may become computationally prohibitive. More efficient solvers or approximations may be needed to scale up the proposed approach. In some applications, complex grouping structures may exist in the data between different lower level traits. A formulation that takes into account the special data structure may be more useful in producing biologically and clinically meaningful traits. As discussed in the paper, alternative regularization conditions exist, including some that may deal well with complex data structures, such as the one based on ℓ<sub>2,1</sub> vector norm. Algorithms that can solve the formulations with alternative regularization terms need to be developed. Additional empirical studies across different disciplines are needed to evaluate the capability and effectiveness of the proposed approach.</p>
</sec>
</body>
<back>
<ack>
<p>We thank Joel Gelernter, M.D., from Yale University who was instrumental in recruiting, characterizing, and genotyping the subjects in the SSADDA dataset used here. Kathleen Brady, M.D., Ph.D., of the Medical University of South Carolina, Roger Weiss, M.D., of McLean Hospital and Harvard Medical School, and David Oslin, M.D., of the University of Pennsylvania Perelman School of Medicine oversaw study recruitment at their respective sites. Funding support for that work was provided by NIH.</p>
<p>Funding support for the Study of Addiction: Genetics and Environment (SAGE) was provided through the NIH Genes, Environment and Health Initiative [GEI] (U01 HG004422). SAGE is one of the genome-wide association studies funded as part of the Gene Environment Association Studies (GENEVA) under GEI. The dataset used for the analyses described in this manuscript were obtained from dbGaP at <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000092.v1.p1">http://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000092.v1.p1</ext-link> through dbGaP accession number phs000092.v1.p.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0144418.ref001">
<label>1</label>
<mixed-citation publication-type="journal">
<name><surname>Karp</surname><given-names>RM</given-names></name>. <article-title>Mathematical challenges from genomics and molecular biology</article-title>. <source/>Notices of American Mathematics Society. <year>2002</year>;<volume>49</volume>(<issue>5</issue>):<fpage>544</fpage>–<lpage>553</lpage>.</mixed-citation>
</ref>
<ref id="pone.0144418.ref002">
<label>2</label>
<mixed-citation publication-type="journal">
<name><surname>McCarthy</surname><given-names>MI</given-names></name>, <name><surname>Abecasis</surname><given-names>GR</given-names></name>, <name><surname>Cardon</surname><given-names>LR</given-names></name>, <name><surname>Goldstein</surname><given-names>DB</given-names></name>, <name><surname>Little</surname><given-names>J</given-names></name>, <name><surname>Ioannidis</surname><given-names>JPA</given-names></name>, <etal>et al</etal>
<article-title>Genome-wide association studies for complex traits: consensus, uncertainty and challenges</article-title>. <source/>Nature Reviews Genetics. <year>2008</year>;<volume>9</volume>(<issue>5</issue>):<fpage>356</fpage>–<lpage>369</lpage>. <pub-id pub-id-type="doi">10.1038/nrg2344</pub-id>
</mixed-citation>
</ref>
<ref id="pone.0144418.ref003">
<label>3</label>
<mixed-citation publication-type="book">
<name><surname>Balding</surname><given-names>DJ</given-names></name>, <name><surname>Bishop</surname><given-names>MJ</given-names></name>, <name><surname>Cannings</surname><given-names>C</given-names></name>. <source/>Handbook of Statistical Genetics. <edition>3rd ed</edition>
<publisher-loc>Chichester, England; Hoboken, NJ</publisher-loc>: <publisher-name>John Wiley &amp; Sons</publisher-name>; <year>2008</year>.</mixed-citation>
</ref>
<ref id="pone.0144418.ref004">
<label>4</label>
<mixed-citation publication-type="journal">
<name><surname>Girirajan</surname><given-names>S</given-names></name>, <name><surname>Meschino</surname><given-names>WS</given-names></name>, <name><surname>Nezarati</surname><given-names>MM</given-names></name>, <name><surname>Asamoah</surname><given-names>A</given-names></name>, <name><surname>Jackson</surname><given-names>KE</given-names></name>, <name><surname>Gowans</surname><given-names>GC</given-names></name>, <etal>et al</etal>
<article-title>Phenotypic heterogeneity of genomic disorders and rare copy-number variants</article-title>. <source/>The New England Journal of Medicine. <year>2012</year>;<volume>367</volume>(<issue>14</issue>):<fpage>1321</fpage>–<lpage>1331</lpage>. <pub-id pub-id-type="doi">10.1056/NEJMoa1200395</pub-id>
<pub-id pub-id-type="pmid">22970919</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref005">
<label>5</label>
<mixed-citation publication-type="journal">
<name><surname>Pierucci-Lagha</surname><given-names>A</given-names></name>, <name><surname>Gelernter</surname><given-names>J</given-names></name>, <name><surname>Chan</surname><given-names>G</given-names></name>, <name><surname>Arias</surname><given-names>A</given-names></name>, <name><surname>Cubells</surname><given-names>JF</given-names></name>, <name><surname>Farrer</surname><given-names>L</given-names></name>, <etal>et al</etal>
<article-title>Reliability of DSM-IV diagnostic criteria using the semi-structured assessment for drug dependence and alcoholism (SSADDA)</article-title>. <source/>Drug and Alcohol Dependence. <year>2007</year>;<volume>91</volume>(<issue>1</issue>):<fpage>85</fpage>–<lpage>90</lpage>. <pub-id pub-id-type="doi">10.1016/j.drugalcdep.2007.04.014</pub-id>
<pub-id pub-id-type="pmid">17590536</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref006">
<label>6</label>
<mixed-citation publication-type="journal">
<name><surname>Wang</surname><given-names>JC</given-names></name>, <name><surname>Kapoor</surname><given-names>M</given-names></name>, <name><surname>Goate</surname><given-names>AM</given-names></name>. <article-title>The genetics of substance dependence</article-title>. <source/>Annu Rev Genomics Hum Genet. <year>2012</year>;<volume>13</volume>:<fpage>241</fpage>–<lpage>61</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-genom-090711-163844</pub-id>
<pub-id pub-id-type="pmid">22703173</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref007">
<label>7</label>
<mixed-citation publication-type="journal">
<name><surname>Gelernter</surname><given-names>J</given-names></name>, <name><surname>Sherva</surname><given-names>R</given-names></name>, <name><surname>Koesterer</surname><given-names>R</given-names></name>, <name><surname>Almasy</surname><given-names>L</given-names></name>, <name><surname>Zhao</surname><given-names>H</given-names></name>, <name><surname>Kranzler</surname><given-names>H</given-names></name>, <etal>et al</etal>
<article-title>Genome-wide association study of cocaine dependence and related traits: FAM53B identified as a risk gene</article-title>. <source/>Molecular Psychiatry. <year>2014</year>;<volume>19</volume>(<issue>6</issue>):<fpage>717</fpage>–<lpage>723</lpage>. <pub-id pub-id-type="doi">10.1038/mp.2013.99</pub-id>
<pub-id pub-id-type="pmid">23958962</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref008">
<label>8</label>
<mixed-citation publication-type="journal">
<name><surname>Hu</surname><given-names>VW</given-names></name>, <name><surname>Addington</surname><given-names>A</given-names></name>, <name><surname>Hyman</surname><given-names>A</given-names></name>. <article-title>Novel autism subtype-dependent genetic variants are revealed by quantitative trait and subphenotype association analyses of published GWAS data</article-title>. <source/>PloS ONE. <year>2011</year>;<volume>6</volume>(<issue>4</issue>):<fpage>e19067</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0019067</pub-id>
<pub-id pub-id-type="pmid">21556359</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref009">
<label>9</label>
<mixed-citation publication-type="journal">
<name><surname>Bi</surname><given-names>J</given-names></name>, <name><surname>Gelernter</surname><given-names>J</given-names></name>, <name><surname>Sun</surname><given-names>J</given-names></name>, <name><surname>Kranzler</surname><given-names>HR</given-names></name>. <article-title>Comparing the utility of homogeneous subtypes of cocaine use and related behaviors with DSM-IV cocaine dependence as traits for genetic association analysis</article-title>. <source/>American Journal of Medical Genetics (Part B): Neuropsychiatric Genetics. <year>2013</year>;<volume>165B</volume>(<issue>2</issue>):<fpage>148</fpage>–<lpage>156</lpage>.</mixed-citation>
</ref>
<ref id="pone.0144418.ref010">
<label>10</label>
<mixed-citation publication-type="journal">
<name><surname>Kranzler</surname><given-names>HR</given-names></name>, <name><surname>Wilcox</surname><given-names>M</given-names></name>, <name><surname>Weiss</surname><given-names>RD</given-names></name>, <name><surname>Brady</surname><given-names>K</given-names></name>, <name><surname>Hesselbrock</surname><given-names>V</given-names></name>, <name><surname>Rounsaville</surname><given-names>B</given-names></name>, <etal>et al</etal>
<article-title>The validity of cocaine dependence subtypes</article-title>. <source/>Addict Behav. <year>2008</year>;<volume>33</volume>(<issue>1</issue>):<fpage>41</fpage>–<lpage>53</lpage>. <pub-id pub-id-type="doi">10.1016/j.addbeh.2007.05.011</pub-id>
<pub-id pub-id-type="pmid">17582692</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref011">
<label>11</label>
<mixed-citation publication-type="journal">
<name><surname>Chan</surname><given-names>G</given-names></name>, <name><surname>Gelernter</surname><given-names>J</given-names></name>, <name><surname>Oslin</surname><given-names>D</given-names></name>, <name><surname>Farrer</surname><given-names>L</given-names></name>, <name><surname>Kranzler</surname><given-names>HR</given-names></name>. <article-title>Empirically derived subtypes of opioid use and related behaviors</article-title>. <source/>Addiction. <year>2011</year>;<volume>106</volume>(<issue>6</issue>):<fpage>1146</fpage>–<lpage>1154</lpage>. <pub-id pub-id-type="doi">10.1111/j.1360-0443.2011.03390.x</pub-id>
<pub-id pub-id-type="pmid">21306596</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref012">
<label>12</label>
<mixed-citation publication-type="journal">
<name><surname>Sun</surname><given-names>J</given-names></name>, <name><surname>Bi</surname><given-names>J</given-names></name>, <name><surname>Chan</surname><given-names>G</given-names></name>, <name><surname>Anton</surname><given-names>RF</given-names></name>, <name><surname>Oslin</surname><given-names>D</given-names></name>, <name><surname>Farrer</surname><given-names>L</given-names></name>, <etal>et al</etal>
<article-title>Improved methods to identify stable, highly heritable subtypes of opioid use and related behaviors</article-title>. <source/>Addictive Behaviors. <year>2012</year>;<volume>37</volume>(<issue>10</issue>):<fpage>1138</fpage>–<lpage>1144</lpage>. <pub-id pub-id-type="doi">10.1016/j.addbeh.2012.05.010</pub-id>
<pub-id pub-id-type="pmid">22694982</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref013">
<label>13</label>
<mixed-citation publication-type="journal">
<name><surname>Ott</surname><given-names>J</given-names></name>, <name><surname>Rabinowitz</surname><given-names>D</given-names></name>. <article-title>A principal-components approach based on heritability for combining phenotype information [Journal Article]</article-title>. <source/>Hum Hered. <year>1999</year>;<volume>49</volume>(<issue>2</issue>):<fpage>106</fpage>–<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1159/000022854</pub-id>
<pub-id pub-id-type="pmid">10077732</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref014">
<label>14</label>
<mixed-citation publication-type="journal">
<name><surname>Wang</surname><given-names>Y</given-names></name>, <name><surname>Fang</surname><given-names>Y</given-names></name>, <name><surname>Jin</surname><given-names>M</given-names></name>. <article-title>A ridge penalized principal-components approach based on heritability for high-dimensional data [Journal Article]</article-title>. <source/>Hum Hered. <year>2007</year>;<volume>64</volume>(<issue>3</issue>):<fpage>182</fpage>–<lpage>91</lpage>. <pub-id pub-id-type="doi">10.1159/000102991</pub-id>
<pub-id pub-id-type="pmid">17536212</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref015">
<label>15</label>
<mixed-citation publication-type="journal">
<name><surname>Klei</surname><given-names>L</given-names></name>, <name><surname>Luca</surname><given-names>D</given-names></name>, <name><surname>Devlin</surname><given-names>B</given-names></name>, <name><surname>Roeder</surname><given-names>K</given-names></name>. <article-title>Pleiotropy and principal components of heritability combine to increase power for association analysis [Journal Article]</article-title>. <source/>Genet Epidemiol. <year>2008</year>;<volume>32</volume>(<issue>1</issue>):<fpage>9</fpage>–<lpage>19</lpage>. <pub-id pub-id-type="doi">10.1002/gepi.20257</pub-id>
<pub-id pub-id-type="pmid">17922480</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref016">
<label>16</label>
<mixed-citation publication-type="journal">
<name><surname>Oualkacha</surname><given-names>K</given-names></name>, <name><surname>Labbe</surname><given-names>A</given-names></name>, <name><surname>Ciampi</surname><given-names>A</given-names></name>, <name><surname>Roy</surname><given-names>MA</given-names></name>, <name><surname>Maziade</surname><given-names>M</given-names></name>. <article-title>Principal Components of Heritability for High Dimension Quantitative Traits and General Pedigrees</article-title>. <source/>Statistical Applications in Genetics and Molecular Biology. <year>2012</year>;<volume>11</volume>(<issue>2</issue>). <pub-id pub-id-type="doi">10.2202/1544-6115.1711</pub-id>
</mixed-citation>
</ref>
<ref id="pone.0144418.ref017">
<label>17</label>
<mixed-citation publication-type="journal">
<name><surname>Lange</surname><given-names>K</given-names></name>, <name><surname>Papp</surname><given-names>J</given-names></name>, <name><surname>Sinsheimer</surname><given-names>J</given-names></name>, <name><surname>Sripracha</surname><given-names>R</given-names></name>, <name><surname>Zhou</surname><given-names>H</given-names></name>, <name><surname>Sobel</surname><given-names>E</given-names></name>. <article-title>Mendel: The Swiss army knife of genetic analysis programs</article-title>. <source/>Bioinformatics. <year>2013</year>;<volume>29</volume>:<fpage>1568</fpage>–<lpage>1570</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btt187</pub-id>
<pub-id pub-id-type="pmid">23610370</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref018">
<label>18</label>
<mixed-citation publication-type="journal">
<name><surname>Lange</surname><given-names>K</given-names></name>, <name><surname>Westlake</surname><given-names>J</given-names></name>, <name><surname>Spence</surname><given-names>MA</given-names></name>. <article-title>Extensions to pedigree analysis. III. Variance components by the scoring method</article-title>. <source/>Annals of Human Genetics. <year>1976</year>;<volume>39</volume>(<issue>4</issue>):<fpage>485</fpage>–<lpage>491</lpage>. <pub-id pub-id-type="doi">10.1111/j.1469-1809.1976.tb00156.x</pub-id>
<pub-id pub-id-type="pmid">952492</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref019">
<label>19</label>
<mixed-citation publication-type="journal">
<name><surname>Vapnik</surname><given-names>VN</given-names></name>. <article-title>An overview of statistical learning theory</article-title>. <source/>IEEE Transactions on Neural Networks. <year>1999</year>;<volume>10</volume>(<issue>5</issue>):<fpage>988</fpage>–<lpage>999</lpage>. <pub-id pub-id-type="doi">10.1109/72.788640</pub-id>
<pub-id pub-id-type="pmid">18252602</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref020">
<label>20</label>
<mixed-citation publication-type="journal">
<name><surname>Tibshirani</surname><given-names>R</given-names></name>. <article-title>Regression Shrinkage and Selection via the LASSO</article-title>. <source/>Journal of the Royal Statistical Society Series B (Methodological). <year>1996</year>;<volume>58</volume>(<issue>1</issue>):<fpage>267</fpage>–<lpage>288</lpage>.</mixed-citation>
</ref>
<ref id="pone.0144418.ref021">
<label>21</label>
<mixed-citation publication-type="journal">
<name><surname>Meier</surname><given-names>L</given-names></name>, <name><surname>Van De Geer</surname><given-names>S</given-names></name>, <name><surname>Bühlmann</surname><given-names>P</given-names></name>. <article-title>The group lasso for logistic regression</article-title>. <source/>Journal of the Royal Statistical Society: Series B (Statistical Methodology). <year>2008</year>;<volume>70</volume>(<issue>1</issue>):<fpage>53</fpage>–<lpage>71</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9868.2007.00627.x</pub-id>
</mixed-citation>
</ref>
<ref id="pone.0144418.ref022">
<label>22</label>
<mixed-citation publication-type="book">
<name><surname>Nocedal</surname><given-names>J</given-names></name>, <name><surname>Wright</surname><given-names>SJ</given-names></name>. <source/>Numerical Optimization. <edition>2nd ed</edition>
<publisher-loc>New York</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2006</year>.</mixed-citation>
</ref>
<ref id="pone.0144418.ref023">
<label>23</label>
<mixed-citation publication-type="journal">
<name><surname>Gelernter</surname><given-names>J</given-names></name>, <name><surname>Kranzler</surname><given-names>H</given-names></name>, <name><surname>Sherva</surname><given-names>R</given-names></name>, <name><surname>Koesterer</surname><given-names>R</given-names></name>, <name><surname>Almasy</surname><given-names>L</given-names></name>, <name><surname>Zhao</surname><given-names>H</given-names></name>, <etal>et al</etal>
<article-title>Genome-wide association study of opioid dependence: multiple associations mapped to calcium and potassium pathways</article-title>. <source/>Biological Psychiatry. <year>2014</year>;<volume>76</volume>(<issue>1</issue>):<fpage>66</fpage>–<lpage>74</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsych.2013.08.034</pub-id>
<pub-id pub-id-type="pmid">24143882</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref024">
<label>24</label>
<mixed-citation publication-type="journal">
<name><surname>Almasy</surname><given-names>L</given-names></name>, <name><surname>Blangero</surname><given-names>J</given-names></name>. <article-title>Multipoint quantitative-trait linkage analysis in general pedigrees</article-title>. <source/>American Journal of Human Genetics. <year>1998</year>;<volume>62</volume>(<issue>5</issue>):<fpage>1198</fpage>–<lpage>1211</lpage>. <pub-id pub-id-type="doi">10.1086/301844</pub-id>
<pub-id pub-id-type="pmid">9545414</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref025">
<label>25</label>
<mixed-citation publication-type="other">National Institutes of Health. Study of Addiction: Genetics and Environment (SAGE). NIH Project Website,<ext-link ext-link-type="uri" xlink:href="http://wwwncbinlmnihgov/projects/gap/cgi-bin/studycgi?study_id=phs000092v1p1">http://wwwncbinlmnihgov/projects/gap/cgi-bin/studycgi?study_id = phs000092v1p1</ext-link>. <year>2009</year>;</mixed-citation>
</ref>
<ref id="pone.0144418.ref026">
<label>26</label>
<mixed-citation publication-type="journal">
<name><surname>Bierut</surname><given-names>LJ</given-names></name>, <name><surname>Strickland</surname><given-names>JR</given-names></name>, <name><surname>Thompson</surname><given-names>JR</given-names></name>, <name><surname>Afful</surname><given-names>SE</given-names></name>, <name><surname>Cottler</surname><given-names>LB</given-names></name>. <article-title>Drug use and dependence in cocaine dependent subjects, community-based individuals, and their siblings</article-title>. <source/>Drug and Alcohol Dependence. <year>2008</year>;<volume>95</volume>(<issue>1–2</issue>):<fpage>14</fpage>–<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1016/j.drugalcdep.2007.11.023</pub-id>
<pub-id pub-id-type="pmid">18243582</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref027">
<label>27</label>
<mixed-citation publication-type="journal">
<name><surname>Howie</surname><given-names>BN</given-names></name>, <name><surname>Donnelly</surname><given-names>P</given-names></name>, <name><surname>Marchini</surname><given-names>J</given-names></name>. <article-title>A flexible and accurate genotype imputation method for the next generation of genome-wide association studies [Journal Article]</article-title>. <source/>PLoS Genet. <year>2009</year>;<volume>5</volume>(<issue>6</issue>):<fpage>e1000529</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pgen.1000529</pub-id>
<pub-id pub-id-type="pmid">19543373</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref028">
<label>28</label>
<mixed-citation publication-type="journal">
<name><surname>Willer</surname><given-names>CJ</given-names></name>, <name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Abecasis</surname><given-names>GR</given-names></name>. <article-title>METAL: fast and efficient meta-analysis of genomewide association scans [Journal Article]</article-title>. <source/>Bioinformatics. <year>2010</year>;<volume>26</volume>(<issue>17</issue>):<fpage>2190</fpage>–<lpage>2191</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btq340</pub-id>
<pub-id pub-id-type="pmid">20616382</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref029">
<label>29</label>
<mixed-citation publication-type="journal">
<name><surname>Gelernter</surname><given-names>J</given-names></name>, <name><surname>Kranzler</surname><given-names>H</given-names></name>, <name><surname>Sherva</surname><given-names>R</given-names></name>, <name><surname>Almasy</surname><given-names>L</given-names></name>, <name><surname>Koesterer</surname><given-names>R</given-names></name>, <name><surname>Smith</surname><given-names>A</given-names></name>, <etal>et al</etal>
<article-title>Genome-wide association study of alcohol dependence: significant findings in African-and European-Americans including novel risk loci</article-title>. <source/>Molecular Psychiatry. <year>2014</year>;<volume>19</volume>(<issue>1</issue>):<fpage>41</fpage>–<lpage>49</lpage>. <pub-id pub-id-type="doi">10.1038/mp.2013.145</pub-id>
<pub-id pub-id-type="pmid">24166409</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref030">
<label>30</label>
<mixed-citation publication-type="journal">
<name><surname>Li</surname><given-names>MX</given-names></name>, <name><surname>Yeung</surname><given-names>JMY</given-names></name>, <name><surname>Cherny</surname><given-names>SS</given-names></name>, <name><surname>Sham</surname><given-names>PC</given-names></name>. <article-title>Evaluating the effective numbers of independent tests and significant p-value thresholds in commercial genotyping arrays and public imputation reference datasets</article-title>. <source/>Human Genetics. <year>2012</year>;<volume>131</volume>(<issue>5</issue>):<fpage>747</fpage>–<lpage>756</lpage>. <pub-id pub-id-type="doi">10.1007/s00439-011-1118-2</pub-id>
<pub-id pub-id-type="pmid">22143225</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref031">
<label>31</label>
<mixed-citation publication-type="journal">
<name><surname>Bell</surname><given-names>KFS</given-names></name>, <name><surname>Soriano</surname><given-names>FX</given-names></name>, <name><surname>Papadia</surname><given-names>S</given-names></name>, <name><surname>Hardingham</surname><given-names>GE</given-names></name>. <article-title>Role of histone acetylation in the activity-dependent regulation of sulfiredoxin and sestrin 2</article-title>. <source/>Epigenetics. <year>2009</year>;<volume>4</volume>(<issue>3</issue>):<fpage>152</fpage>–<lpage>158</lpage>. <pub-id pub-id-type="doi">10.4161/epi.4.3.8753</pub-id>
<pub-id pub-id-type="pmid">19430206</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref032">
<label>32</label>
<mixed-citation publication-type="journal">
<name><surname>Lehrmann</surname><given-names>E</given-names></name>, <name><surname>Colantuoni</surname><given-names>C</given-names></name>, <name><surname>Deep-Soboslay</surname><given-names>A</given-names></name>, <name><surname>Becker</surname><given-names>KG</given-names></name>, <name><surname>Lowe</surname><given-names>R</given-names></name>, <name><surname>Huestis</surname><given-names>MA</given-names></name>, <etal>et al</etal>
<article-title>Transcriptional changes common to human cocaine cannabis and phencyclidine abuse</article-title>. <source/>PLoS ONE. <year>2006</year>;<volume>1</volume>(<issue>1</issue>):<fpage>e114</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0000114</pub-id>
<pub-id pub-id-type="pmid">17205118</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref033">
<label>33</label>
<mixed-citation publication-type="book">
<name><surname>Vapnik</surname><given-names>V</given-names></name>. <source/>Statistical Learning Theory. <publisher-loc>New York</publisher-loc>: <publisher-name>John Willey &amp; Sons, Inc</publisher-name>; <year>1998</year>.</mixed-citation>
</ref>
<ref id="pone.0144418.ref034">
<label>34</label>
<mixed-citation publication-type="journal">
<name><surname>de los Campos</surname><given-names>G</given-names></name>, <name><surname>Gianola</surname><given-names>D</given-names></name>, <name><surname>Allison</surname><given-names>DB</given-names></name>. <article-title>Predicting genetic predisposition in humans: the promise of whole-genome markers</article-title>. <source/>Nature Reviews Genetics. <year>2010</year>;<volume>11</volume>(<issue>12</issue>):<fpage>880</fpage>–<lpage>886</lpage>. <pub-id pub-id-type="doi">10.1038/nrg2898</pub-id>
</mixed-citation>
</ref>
<ref id="pone.0144418.ref035">
<label>35</label>
<mixed-citation publication-type="journal">
<name><surname>de Los Campos</surname><given-names>G</given-names></name>, <name><surname>Hickey</surname><given-names>JM</given-names></name>, <name><surname>Pong-Wong</surname><given-names>R</given-names></name>, <name><surname>Daetwyler</surname><given-names>HD</given-names></name>, <name><surname>Calus</surname><given-names>MPL</given-names></name>. <article-title>Whole-genome regression and prediction methods applied to plant and animal breeding</article-title>. <source/>Genetics. <year>2013</year>;<volume>193</volume>(<issue>2</issue>):<fpage>327</fpage>–<lpage>327</lpage>. <pub-id pub-id-type="doi">10.1534/genetics.112.143313</pub-id>
<pub-id pub-id-type="pmid">22745228</pub-id></mixed-citation>
</ref>
<ref id="pone.0144418.ref036">
<label>36</label>
<mixed-citation publication-type="book">
<name><surname>Connor</surname><given-names>EE</given-names></name>, <name><surname>Hutchison</surname><given-names>JL</given-names></name>, <name><surname>Norman</surname><given-names>HD</given-names></name>. <chapter-title>Estimating feed efficiency of lactating dairy cattle using residual feed intake</chapter-title> (Chapter 11) <source/>In Feed Efficiency in the Beef Industry, <name><surname>Hill</surname><given-names>RA</given-names></name> (ed), <publisher-name>Wiley-Blackwell</publisher-name>, <publisher-loc>NJ</publisher-loc>
<year>2012</year>;.</mixed-citation>
</ref>
<ref id="pone.0144418.ref037">
<label>37</label>
<mixed-citation publication-type="journal">
<name><surname>Boligon</surname><given-names>A</given-names></name>, <name><surname>Mercadante</surname><given-names>M</given-names></name>, <name><surname>Baldi</surname><given-names>F</given-names></name>, <name><surname>Lôbo</surname><given-names>R</given-names></name>, <name><surname>Albuquerque</surname><given-names>L</given-names></name>. <article-title>Multi-trait and random regression mature weight heritability and breeding value estimates in Nelore cattle</article-title>. <source/>South African Journal of Animal Science. <year>2009</year>;<volume>39</volume>(<issue>5</issue>):<fpage>145</fpage>–<lpage>148</lpage>.</mixed-citation>
</ref>
<ref id="pone.0144418.ref038">
<label>38</label>
<mixed-citation publication-type="journal">
<name><surname>Berry</surname><given-names>DP</given-names></name>, <name><surname>Crowley</surname><given-names>JJ</given-names></name>. <article-title>Residual intake and body weight gain: a new measure of efficiency in growing cattle</article-title>. <source/>Journal of animal science. <year>2012</year>;<volume>90</volume>(<issue>1</issue>):<fpage>109</fpage>–<lpage>115</lpage>. <pub-id pub-id-type="doi">10.2527/jas.2011-4245</pub-id>
<pub-id pub-id-type="pmid">21890504</pub-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
</pmc-articleset>