<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="research-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">J Neurodev Disord</journal-id>
<journal-id journal-id-type="iso-abbrev">J Neurodev Disord</journal-id>
<journal-title-group>
<journal-title>Journal of Neurodevelopmental Disorders</journal-title>
</journal-title-group>
<issn pub-type="ppub">1866-1947</issn>
<issn pub-type="epub">1866-1955</issn>
<publisher>
<publisher-name>BioMed Central</publisher-name>
<publisher-loc>London</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">28270868</article-id>
<article-id pub-id-type="pmc">5335849</article-id>
<article-id pub-id-type="publisher-id">9190</article-id>
<article-id pub-id-type="doi">10.1186/s11689-017-9190-0</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Preserved search asymmetry in the detection of fearful faces among neutral faces in individuals with Williams syndrome revealed by measurement of both manual responses and eye tracking</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Hirai</surname>
<given-names>Masahiro</given-names>
</name>
<address>
<phone>+81-285-58-7590</phone>
<email>hirai@jichi.ac.jp</email>
</address>
<xref ref-type="aff" rid="Aff1">1</xref>
<xref ref-type="aff" rid="Aff3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Muramatsu</surname>
<given-names>Yukako</given-names>
</name>
<address>
<email>murayuka@med.nagoya-u.ac.jp</email>
</address>
<xref ref-type="aff" rid="Aff1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Mizuno</surname>
<given-names>Seiji</given-names>
</name>
<address>
<email>seiji_mizuno@aichi-colony.jp</email>
</address>
<xref ref-type="aff" rid="Aff2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kurahashi</surname>
<given-names>Naoko</given-names>
</name>
<address>
<email>naokohayashi11@hotmail.com</email>
</address>
<xref ref-type="aff" rid="Aff2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kurahashi</surname>
<given-names>Hirokazu</given-names>
</name>
<address>
<email>hiro-k@med.nagoya-u.ac.jp</email>
</address>
<xref ref-type="aff" rid="Aff2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Nakamura</surname>
<given-names>Miho</given-names>
</name>
<address>
<email>mihon@inst-hsc.jp</email>
</address>
<xref ref-type="aff" rid="Aff1">1</xref>
</contrib>
<aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.410836.8</institution-id><institution>Institute for Developmental Research, </institution><institution>Aichi Human Service Center, </institution></institution-wrap>713-8 Kagiya-cho, Kasugai, Aichi 480-0392 Japan </aff>
<aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.410836.8</institution-id><institution>Department of Pediatrics, Central Hospital, </institution><institution>Aichi Human Service Center, </institution></institution-wrap>713-8 Kagiya-cho, Kasugai, Aichi 480-0392 Japan </aff>
<aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000000123090000</institution-id><institution-id institution-id-type="GRID">grid.410804.9</institution-id><institution>Present Address: Center for Development of Advanced Medical Technology, </institution><institution>Jichi Medical University, </institution></institution-wrap>3311-1 Yakushiji, Shimotsuke, Tochigi 392-0498 Japan </aff>
</contrib-group>
<pub-date pub-type="epub">
<day>3</day>
<month>3</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="pmc-release">
<day>3</day>
<month>3</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="collection">
<year>2017</year>
</pub-date>
<volume>9</volume>
<elocation-id>8</elocation-id>
<history>
<date date-type="received">
<day>9</day>
<month>3</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>10</day>
<month>2</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-statement>© The Author(s). 2017</copyright-statement>
<license license-type="OpenAccess">
<license-p>
<bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
</license>
</permissions>
<abstract id="Abs1">
<sec>
<title>Background</title>
<p>Individuals with Williams syndrome (WS) exhibit an atypical social phenotype termed hypersociability. One theory accounting for hypersociability presumes an atypical function of the amygdala, which processes fear-related information. However, evidence is lacking regarding the detection mechanisms of fearful faces for individuals with WS. Here, we introduce a visual search paradigm to elucidate the mechanisms for detecting fearful faces by evaluating the search asymmetry; the reaction time when both the target and distractors were swapped was asymmetrical.</p>
</sec>
<sec>
<title>Methods</title>
<p>Eye movements reflect subtle atypical attentional properties, whereas, manual responses are unable to capture atypical attentional profiles toward faces in individuals with WS. Therefore, we measured both eye movements and manual responses of individuals with WS and typically developed children and adults in visual searching for a fearful face among neutral faces or a neutral face among fearful faces. Two task measures, namely reaction time and performance accuracy, were analyzed for each stimulus as well as gaze behavior and the initial fixation onset latency.</p>
</sec>
<sec>
<title>Results</title>
<p>Overall, reaction times in the WS group and the mentally age-matched control group were significantly longer than those in the chronologically age-matched group. We observed a search asymmetry effect in all groups: when a neutral target facial expression was presented among fearful faces, the reaction times were significantly prolonged in comparison with when a fearful target facial expression was displayed among neutral distractor faces. Furthermore, the first fixation onset latency of eye movement toward a target facial expression showed a similar tendency for manual responses.</p>
</sec>
<sec>
<title>Conclusions</title>
<p>Although overall responses in detecting fearful faces for individuals with WS are slower than those for control groups, search asymmetry was observed. Therefore, cognitive mechanisms underlying the detection of fearful faces seem to be typical in individuals with WS. This finding is discussed with reference to the amygdala account explaining hypersociability in individuals with WS.</p>
</sec>
</abstract>
<kwd-group xml:lang="en">
<title>Keywords</title>
<kwd>Williams syndrome</kwd>
<kwd>Visual search</kwd>
<kwd>Fearful face detection</kwd>
<kwd>Search asymmetry</kwd>
<kwd>Attention</kwd>
<kwd>Eye tracking</kwd>
</kwd-group>
<funding-group>
<award-group>
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id>
<institution>Japan Society for the Promotion of Science</institution>
</institution-wrap>
</funding-source>
<award-id>23830127</award-id>
<award-id>23119733, 21119529</award-id>
<principal-award-recipient>
<name>
<surname>Hirai</surname>
<given-names>Masahiro</given-names>
</name>
<name>
<surname>Nakamura</surname>
<given-names>Miho</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group>
<funding-source>
<institution>Daiko Foundation</institution>
</funding-source>
</award-group>
<award-group>
<funding-source>
<institution>‘Constructive Developmental Science’ from the Ministry of Education, Culture, Sports, Science and Technology</institution>
</funding-source>
<award-id>15H01585</award-id>
<principal-award-recipient>
<name>
<surname>Hirai</surname>
<given-names>Masahiro</given-names>
</name>
</principal-award-recipient>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta>
<meta-name>issue-copyright-statement</meta-name>
<meta-value>© The Author(s) 2017</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="Sec1" sec-type="introduction">
<title>Background</title>
<p>Williams syndrome (WS) is a rare genetic disorder caused by the deletion of approximately 28 genes in chromosome 7 [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. The prevalence of WS ranges from 1 in 7500 to 1 in 20,000 [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. Besides the physical characteristics associated with WS, such as dysmorphic facial features and heart defects, a unique cognitive and behavioral profile has been described. Behaviorally, WS is characterized by hypersociability [<xref ref-type="bibr" rid="CR3">3</xref>], which is characterized by interest in both familiar and unfamiliar people [<xref ref-type="bibr" rid="CR3">3</xref>–<xref ref-type="bibr" rid="CR8">8</xref>].</p>
<p>A previous theoretical framework has proposed two accounts for hypersociability, namely the frontal lobe account and the amygdala account [<xref ref-type="bibr" rid="CR8">8</xref>–<xref ref-type="bibr" rid="CR10">10</xref>]. The frontal lobe of the brain is associated with cognitive processes, such as attention setting and shifting, working memory, and planning, that underlie goal-directed behavior [<xref ref-type="bibr" rid="CR11">11</xref>]. The frontal lobe account of hypersociability postulates that atypical social interest in other people may be caused by the impaired inhibition of the desire to approach both familiar and unfamiliar people due to an atypical brain structure and function in the frontal lobe [<xref ref-type="bibr" rid="CR8">8</xref>]. Recent neuroimaging studies have revealed that individuals with WS show atypical increases in gray matter volumes in the frontal lobes [<xref ref-type="bibr" rid="CR12">12</xref>]. Another finding showed difficulties in executive functions similar to those seen in individuals with attention deficit and hyperactivity disorders (ADHD) [<xref ref-type="bibr" rid="CR13">13</xref>]. Further evidence such as a study employing a rating system for approachability implies that the atypical social approachability of individuals with WS is not due to difficulties in the recognition of emotion but due to the problem of inhibition [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>]. Other neuroimaging evidence has suggested that the dorsolateral frontal cortex and dorsal anterior cingulate cortices in the WS group were significantly reduced in neural activity compared with typical controls during a Go/No-go inhibition task [<xref ref-type="bibr" rid="CR14">14</xref>].</p>
<p>The alternative amygdala account postulates that atypical social approachability may be due to the atypical structure and neural activity of the amygdala. The amygdala is a part of the limbic system controlling socioemotional behavior, considered to process fear-related information [<xref ref-type="bibr" rid="CR15">15</xref>]. A previous behavioral study has reported that individuals with WS displayed atypical positive social judgment of unfamiliar faces showing both positive and negative emotions [<xref ref-type="bibr" rid="CR16">16</xref>]. Recent neuroimaging studies have shown that a positive relationship between the right amygdala volume and approachability ratings, particularly ratings of “negative” faces [<xref ref-type="bibr" rid="CR17">17</xref>], was found in individuals with WS. Moreover, individuals with WS showed atypical amygdala response to fearful expressions [<xref ref-type="bibr" rid="CR18">18</xref>]. Furthermore, when individuals with WS observed both fearful faces and fearful scenes, neural activity in the amygdala and middle prefrontal cortex showed a contrast with the activity of the age- and gender-matched controls [<xref ref-type="bibr" rid="CR19">19</xref>]. For the age- and gender-matched control group, the neural activity of the amygdala in response to fearful faces was significantly enhanced compared to that in response to fearful scenes. In contrast to the neural activity occurring in controls, the neural response of the amygdala in WS individuals in response to fearful scenes was enhanced compared with that in response to fearful faces.</p>
<p>However, it remains unclear whether the amygdala account can fully explain hypersocial behavior in individuals with WS. For example, according to a neuropsychological study, the patient S.M., who did not have WS, showed complete bilateral amygdala destruction since late childhood as a consequence of Urbach–Wiethe disease. She exhibited preserved behavioral performance in terms of the <italic>detection</italic> of fearful faces [<xref ref-type="bibr" rid="CR20">20</xref>]. Additionally, findings from prefrontal theory imply that the performance of the <italic>recognition</italic> of fearful faces was preserved in individuals with WS (e.g., [<xref ref-type="bibr" rid="CR7">7</xref>]). This evidence motivated us to test whether the performances of the <italic>detection</italic> of fearful faces were preserved in individuals with WS.</p>
<p>One way of characterizing the strategy for detecting a fearful face is to adopt a visual search paradigm and evaluate visual search asymmetry as an index. Visual search asymmetry is defined as the case in which the reaction time of searching for target stimulus <italic>A</italic> among distractor stimuli <italic>B</italic> is more prolonged than that of searching for target stimulus <italic>B</italic> among distractor stimuli <italic>A</italic> [<xref ref-type="bibr" rid="CR21">21</xref>–<xref ref-type="bibr" rid="CR23">23</xref>]. Targets defined by the presence of a basic preattentive feature (e.g., stimulus <italic>A</italic>) are more easily found in a search than among distractors lacking such a feature (e.g., stimuli <italic>B</italic>) compared with the case in which the search and distractors were swapped [<xref ref-type="bibr" rid="CR22">22</xref>]. Search asymmetries can be observed in the presence and absence of low-level features, such as color, orientation, and motion information [<xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR23">23</xref>], as well as in higher levels of visual features, such as the direction of the gaze [<xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR25">25</xref>], identification of letters, [<xref ref-type="bibr" rid="CR26">26</xref>], figures [<xref ref-type="bibr" rid="CR23">23</xref>], and biological motion [<xref ref-type="bibr" rid="CR27">27</xref>]. Regarding emotional faces, previous studies have demonstrated that fearful faces were more quickly detected than happy or neutral faces by both children and adults [<xref ref-type="bibr" rid="CR28">28</xref>] as well as infants [<xref ref-type="bibr" rid="CR29">29</xref>]. Further, search asymmetry has also been reported between emotional and neutral faces [e.g., [<xref ref-type="bibr" rid="CR30">30</xref>]).</p>
<p>Atypical cognitive and neural mechanisms underlying the perception of faces in individuals with WS have been reported [<xref ref-type="bibr" rid="CR31">31</xref>–<xref ref-type="bibr" rid="CR33">33</xref>]. Face perception is well known to require configural processing, integrating several parts into a coherent figure. Studies have reported atypical visuospatial processing in people with WS [<xref ref-type="bibr" rid="CR34">34</xref>–<xref ref-type="bibr" rid="CR36">36</xref>]. To investigate the configural processing of faces, an inversion paradigm has been used, where an upside-down face is presented to participants. Inverting a face is thought to disrupt the configural processing of the face [<xref ref-type="bibr" rid="CR37">37</xref>, <xref ref-type="bibr" rid="CR38">38</xref>] but not the processing of low-level image-based properties. The face inversion effect is defined as a greater decrease in recognition performance for faces than for other mono-oriented objects presented upside down [<xref ref-type="bibr" rid="CR39">39</xref>–<xref ref-type="bibr" rid="CR41">41</xref>]. Although several studies on face perception and recognition have shown that individuals with WS exhibit normal performance accuracy on face discrimination tasks, including the recognition of unfamiliar upright faces [<xref ref-type="bibr" rid="CR32">32</xref>, <xref ref-type="bibr" rid="CR42">42</xref>, <xref ref-type="bibr" rid="CR43">43</xref>], the evidence of them exhibiting an inversion effect is not strong [<xref ref-type="bibr" rid="CR31">31</xref>–<xref ref-type="bibr" rid="CR33">33</xref>]. Furthermore, studies using behavioral response [<xref ref-type="bibr" rid="CR44">44</xref>], electroencephalography (EEG) [<xref ref-type="bibr" rid="CR45">45</xref>], and magnetoencephalography (MEG) [<xref ref-type="bibr" rid="CR46">46</xref>] have shown that some aspects of facial processing may be delayed or atypical in individuals with WS. These cumulative findings suggest that facial processing in individuals with WS is atypical. However, whether and how the processing of emotional faces, particularly of fearful faces, is modulated by this remains unclear.</p>
<p>In previous studies [<xref ref-type="bibr" rid="CR47">47</xref>, <xref ref-type="bibr" rid="CR48">48</xref>], we demonstrated that attentional capture by the presence of an upright face that is not a target stimulus differs depending on what response is measured [<xref ref-type="bibr" rid="CR48">48</xref>]. In this study, we found that manual response was unable to capture the atypical attentional profiles toward faces in individuals with WS, whereas eye movements reflected subtle atypical attentional properties. Therefore, we tested the following hypotheses by measuring both manual response and gaze behavior to overcome differences, depending on the effector.</p>
<p>We introduced a visual search paradigm to test two hypotheses regarding the detection of fearful faces in individuals with WS. First, we hypothesized that if a fearful face is a salient visual stimulus to participants compared to a neutral face, then visual search asymmetry would be observed as we found in a preliminary study using the same stimulus set among typically developed adults. This will be characterized by the reaction time for searching for an upright fearful face among neutral faces being shorter than when searching for an upright neutral face among fearful faces for control groups. If this tendency also holds true for individuals with WS, then searching for an upright fearful face among upright neutral faces would be more efficient than searching for an upright neutral face among upright fearful faces. Second, if the processing of fearful faces is dependent on configural processing, then search asymmetry would be observed only in upright faces, but it would be diminished in inverted faces. As the atypicality of inverted face processing in individuals with WS has shown inconsistent findings as mentioned above, we introduced experimental manipulation of the orientation of faces to explore the ability of configural processing of fearful faces.</p>
</sec>
<sec id="Sec2" sec-type="materials|methods">
<title>Methods</title>
<sec id="Sec3">
<title>Participants</title>
<p>Thirteen individuals with WS participated in the experiment (ten males and three females, age range 8; 10–25; 0, mean age 15.7), as shown in Table <xref ref-type="table" rid="Tab1">1</xref>. All participants had previously been phenotypically diagnosed by clinicians, and the diagnosis was subsequently confirmed using fluorescence in situ hybridization analysis. Mental age was measured using the test of Raven’s Colored Progressive Matrices (RCPM) [<xref ref-type="bibr" rid="CR49">49</xref>, <xref ref-type="bibr" rid="CR50">50</xref>].<table-wrap id="Tab1"><label>Table 1</label><caption><p>Participant information</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Group</th><th>
<italic>N</italic>
</th><th>Chronological age</th><th></th></tr><tr><th>(F/M)</th><th>Mean (Year)<break></break>Range (years; months)</th><th>RCPM score</th></tr></thead><tbody><tr><td>WS</td><td>13<break></break>(3/10)</td><td>15.7 ± 5.2<break></break>(8; 10–25; 0)</td><td>18.8 ± 4.7<break></break>(13–31)</td></tr><tr><td>MA</td><td>13<break></break>(8/5)</td><td>6.0 ± 0.7<break></break>(5; 0–7; 4)</td><td>20.3 ± 4.4<break></break>(13–27)</td></tr><tr><td>CA</td><td>13<break></break>(3/10)</td><td>16.0 ± 5.9<break></break>(8; 11–27; 11)</td><td>N/A</td></tr></tbody></table><table-wrap-foot><p>Mean ± SD</p></table-wrap-foot></table-wrap>
</p>
<p>A total of 26 typically developed children, adolescents, and adults from nearby elementary schools, junior high schools, high schools, and universities were recruited as control participants (Table <xref ref-type="table" rid="Tab1">1</xref>). For the mentally age-matched (MA) group, 13 children (five males and eight females, age range 5; 0–7; 4, mean age 6.0) were recruited and matched to the WS group based on nonverbal ability as measured by the RCPM. For the chronologically age-matched (CA) group, 13 individuals were recruited and individually matched by age to participants in the WS group (ten males and three females, age range 8; 11–27; 11, mean age 16.0). In terms of the RCPM scores, there were no group differences between the WS and matched MA groups in the first analysis (WS mean 18.8, MA mean 20.3, <italic>p</italic> = 0.23). With regard to the chronological age, there were no significant differences between the WS and CA groups in the second analysis (WS mean 15.7 years, CA mean 16.0 years, <italic>p</italic> = 0.88). All the children, their parents, and the adult participants provided informed consent to take part in the study, which was approved by the ethics committee at the Institute for Developmental Research at the Aichi Human Service Center (Reference Number: 04-08).</p>
</sec>
<sec id="Sec4">
<title>Stimuli and apparatus</title>
<p>The experiment was conducted using a computer (HP Pavilion Desktop, h8-1060jp) with Tobii Studio and E-prime 2.0 software (Psychology Software Tools, Inc., PA, USA), as well as the E-prime extension for Tobii (Tobii, Inc., Stockholm, Sweden). Stimuli were presented on a 24-in. LCD color monitor (Iiyama, PLE2407HDS), placed approximately 60 cm from the observer.</p>
<p>Both neutral and fearful faces were taken from the ATR database (Kyoyo, Japan). Five or nine faces were displayed in a circular configuration (see Fig. <xref ref-type="fig" rid="Fig1">1</xref>). The faces were various grayscale images sized to fit within a 6.3° × 4.2° square. The averaged luminance for all objects was equated using the SHINE toolbox [<xref ref-type="bibr" rid="CR51">51</xref>]. The center of each object was located at approximately 11° from the center of the display.<fig id="Fig1"><label>Fig. 1</label><caption><p>All experimental conditions. Examples of all experimental conditions were displayed (including both five- and nine-item conditions)</p></caption><graphic id="MO1" xlink:href="11689_2017_9190_Fig1_HTML"></graphic></fig>
</p>
</sec>
<sec id="Sec5">
<title>Design and procedures</title>
<p>In the experiment, we distinguished four factors: target facial expression (fearful vs. neutral), orientation (upright vs. inverted), array size (five vs. nine), and presence of the target (present vs. absent). One of the four possible combinations of the target condition (target facial expression and orientation) served as a block, with a total of four blocks presented over the course of the experiment. Within each block, the vertical orientation of distractors was always the same as that of the targets, with only the number of faces differing (five items or nine items); each array size appeared for an equal number of times. Each block consisted of 36 test trials, preceded by four practice trials. Each block comprised 36 trials of four experimental conditions (nine trials per experimental condition). Accordingly, each participant went through a total of 144 trials for the four experimental conditions. Within each block, the target was present in 50% of trials and was absent in the other 50% (i.e., it was present or absent for 18 trials each). The presentation order of each trial as well as the order of the blocks was randomized across participants. Between sessions, participants were given a 1–2-min break if required. The entire duration of the instruction, practice, calibration, and actual experiment was about 15–20 min. In our preliminary study, we found a search asymmetry effect in nine trials with adults. Task demands were minimized for individuals in both the WS and MA groups. Thus, we have chosen the number of the trials.</p>
<p>Behavioral responses were reported via a custom-made response box with two large buttons. Eye movements were recorded using the Tobii X60 eye-tracking system (Tobii, Inc., Stockholm, Sweden). The eye-tracking system was completely noninvasive, and artificial constraints on head or body movements were not necessary. The system tracked both eyes with an accuracy of 0.5° and a sampling rate of 60 Hz. The eye tracker was calibrated for each participant, using a five-point calibration for each eye.</p>
</sec>
<sec id="Sec6">
<title>Task and procedure</title>
<p>To record reliable eye movement data in each trial for younger children and people with WS, participants were required to attend to a fixation cross at the center of the screen for 1 s to initiate each trial (Fig. <xref ref-type="fig" rid="Fig2">2</xref>). If the system detected a 1-s period of fixation at the center of the screen, a stimulus was displayed. By using an eye-tracking system, we could record reliable behavioral and eye movement data for each trial from individuals with WS and typical controls, as visual stimuli were displayed only when participants fixated on the center of the screen for 1 s. Participants were asked to judge as quickly and accurately as possible whether the target facial expression was present in each array and to register their response by pressing one of the two buttons (left-hand side and right-hand side) on the response box. Seven participants were asked to press the left button using their left hand if they found a target facial expression and to press the right button with their right hand if they did not find a target facial expression. The other participants were asked to use their right hand on sighting a target facial expression, being given the opposite instructions. No feedback was given to participants.<fig id="Fig2"><label>Fig. 2</label><caption><p>Experimental procedure. The fixation cross was displayed at the center of the screen. If a participant fixates on the fixation cross for 1 s, stimulus array is displayed. After response button is pressed, stimuli disappear</p></caption><graphic id="MO2" xlink:href="11689_2017_9190_Fig2_HTML"></graphic></fig>
</p>
</sec>
<sec id="Sec7">
<title>Data analysis</title>
<p>We analyzed both behavioral responses and eye movements. We included only the correct response data, and if the reaction time was above or below the 3 SD from the mean, the trial was excluded from further analysis. For behavioral responses, both reaction time and percent correct were analyzed using a mixed design-repeated measure of analysis of variance (ANOVA). A five-way ANOVA was applied to reaction time and percent correct. The groups (Williams syndrome; WS, mentally age-matched; MA, and chronologically age-matched; CA) were used as between-subject factors and the target facial expression (fearful vs. neutral), orientation (upright vs. inverted), array size (five vs. nine), and presence of the target (present vs. absent) were used as within-subject factors.</p>
<p>For gaze behaviors, we defined areas of interest (AOI) to assess how long it took to reach the initial fixation on the target facial expression and a distractor face. In particular, we were interested in how latencies toward the target facial expression and distractor face were modulated by the type of target facial expression (i.e., fearful or neutral) and orientation depending on the group in the target present condition. One area of interest was assigned for each item in each array; each area was a circle encompassing the whole image. The latency toward the target was defined as the time to get to the AOI of the target face. The latency toward the distractor face was defined as the fastest first fixation on any of the four or eight distractor faces, regardless of their position. As in the behavioral analysis, a five-way ANOVA was applied to the latency of the initial fixation on the target facial expression or distractor face. Groups were used as between-subject factors (WS, MA, and CA). The size array (five vs. nine), orientation (upright vs. inverted), target facial expression (fearful vs. neutral), and target or distractor faces (target face vs. distractor faces) were used as within-subject factors. Tukey’s HSD was applied for multiple comparisons. In the analysis, if the assumption of sphericity was violated in Mauchly’s sphericity test, the Greenhouse–Geisser epsilon coefficient was used to correct the degrees of freedom. Both the <italic>F</italic> and <italic>p</italic> values were then recalculated, and we considered statistical significance to be <italic>p</italic> &lt; 0.05.</p>
</sec>
</sec>
<sec id="Sec8" sec-type="results">
<title>Results</title>
<p>Due to the small number of trials for each condition and relatively large individual variation in the reaction times (RTs), mean RTs were used for the analyses [<xref ref-type="bibr" rid="CR25">25</xref>, <xref ref-type="bibr" rid="CR52">52</xref>]. Note that all participants had at least six valid trials for RT analyses for each condition, as in the previous study [<xref ref-type="bibr" rid="CR25">25</xref>].</p>
<sec id="Sec9">
<title>Reaction times</title>
<p>For reaction time, as shown in Fig. <xref ref-type="fig" rid="Fig3">3</xref> (a summary of the statistical analysis is shown in Table <xref ref-type="table" rid="Tab2">2</xref>), we found significant main effects, two-way, three-way, and a four-way interaction. Follow-up analyses have shown that we did not find significant group differences in both array sizes although we found group differences in the face orientation and target facial expression condition. However, overall, we did not find group differences in terms of visual search asymmetry; there were prolonged RTs for searching for a neutral face among fearful faces, but these were not obtained for searching for a fearful face among neutral faces.<fig id="Fig3"><label>Fig. 3</label><caption><p>Mean reaction times. <bold>a</bold>
<italic>Upright</italic>, target present condition. <bold>b</bold>
<italic>Inverted</italic>, target present condition. <bold>c</bold>
<italic>Upright</italic>, target absent condition. <bold>d</bold>
<italic>Inverted</italic>, target absent condition. Each <italic>color</italic> indicates a combination of target facial expressions and array size, as shown in the figure. <italic>Error bars</italic> indicate standard error of mean (SEM)</p></caption><graphic id="MO3" xlink:href="11689_2017_9190_Fig3_HTML"></graphic></fig>
<table-wrap id="Tab2"><label>Table 2</label><caption><p>The results of statistical analysis for the reaction time</p></caption><table frame="hsides" rules="groups"><thead><tr><th></th><th>Degrees of freedom</th><th>
<italic>F</italic> value</th><th>
<italic>p</italic> value</th><th>
<italic>η</italic>
<sub><italic>p</italic></sub>
<sup>2</sup>
</th></tr></thead><tbody><tr><td>Group</td><td>2, 36</td><td align="char" char=".">16.8</td><td align="char" char=".">0.001**</td><td align="char" char=".">0.48</td></tr><tr><td>Orientation</td><td>1, 36</td><td align="char" char=".">16.7</td><td align="char" char=".">0.001**</td><td align="char" char=".">0.32</td></tr><tr><td>Orientation × group</td><td>2, 36</td><td align="char" char=".">2.63</td><td align="char" char=".">0.09</td><td align="char" char=".">0.13</td></tr><tr><td>Target facial expression</td><td>1, 36</td><td align="char" char=".">13.2</td><td align="char" char=".">0.001**</td><td align="char" char=".">0.27</td></tr><tr><td>Target facial expression × group</td><td>2, 36</td><td align="char" char=".">0.097</td><td align="char" char=".">0.91</td><td align="char" char=".">0.005</td></tr><tr><td>Array size</td><td>1, 36</td><td align="char" char=".">288.5</td><td align="char" char=".">0.001**</td><td align="char" char=".">0.89</td></tr><tr><td>Array size × group</td><td>2, 36</td><td align="char" char=".">7.69</td><td align="char" char=".">0.002**</td><td align="char" char=".">0.30</td></tr><tr><td>Presence of the target</td><td>1, 36</td><td align="char" char=".">340.5</td><td align="char" char=".">0.001**</td><td align="char" char=".">0.90</td></tr><tr><td>Presence of the target × group</td><td>2, 36</td><td align="char" char=".">6.10</td><td align="char" char=".">0.005**</td><td align="char" char=".">0.25</td></tr><tr><td>Orientation × target facial expression</td><td>1, 36</td><td align="char" char=".">5.93</td><td align="char" char=".">0.02*</td><td align="char" char=".">0.14</td></tr><tr><td>Orientation × target facial expression × group</td><td>2, 36</td><td align="char" char=".">1.14</td><td align="char" char=".">0.33</td><td align="char" char=".">0.060</td></tr><tr><td>Orientation × array size</td><td>1, 36</td><td align="char" char=".">1.75</td><td align="char" char=".">0.20</td><td align="char" char=".">0.046</td></tr><tr><td>Orientation × array size × group</td><td>2, 36</td><td align="char" char=".">0.21</td><td align="char" char=".">0.81</td><td align="char" char=".">0.011</td></tr><tr><td>Target facial expression × array size</td><td>1, 36</td><td align="char" char=".">6.34</td><td align="char" char=".">0.016*</td><td align="char" char=".">0.15</td></tr><tr><td>Target facial expression × array size × group</td><td>2, 36</td><td align="char" char=".">0.85</td><td align="char" char=".">0.44</td><td align="char" char=".">0.05</td></tr><tr><td>Orientation × target facial expression × array size</td><td>1, 36</td><td align="char" char=".">4.78</td><td align="char" char=".">0.036*</td><td align="char" char=".">0.12</td></tr><tr><td>
<italic>Orientation</italic> × <italic>target facial expression</italic> × <italic>array size</italic> × <italic>group</italic>
</td><td>
<italic>2</italic>, <italic>36</italic>
</td><td align="char" char=".">
<italic>5.35</italic>
</td><td align="char" char=".">
<italic>0.009</italic>**</td><td align="char" char=".">
<italic>0.23</italic>
</td></tr><tr><td>Orientation × presence of the target</td><td>1, 36</td><td align="char" char=".">6.10</td><td align="char" char=".">0.02*</td><td align="char" char=".">0.15</td></tr><tr><td>Orientation × presence of the target × group</td><td>2, 36</td><td align="char" char=".">0.63</td><td align="char" char=".">0.54</td><td align="char" char=".">0.03</td></tr><tr><td>Target facial expression × presence of the target</td><td>1, 36</td><td align="char" char=".">0.77</td><td align="char" char=".">0.39</td><td align="char" char=".">0.02</td></tr><tr><td>Target facial expression × presence of the target × group</td><td>2, 36</td><td align="char" char=".">1.45</td><td align="char" char=".">0.25</td><td align="char" char=".">0.05</td></tr><tr><td>Orientation × target facial expression × presence of the target</td><td>1, 36</td><td align="char" char=".">0.004</td><td align="char" char=".">0.95</td><td align="char" char=".">0.00</td></tr><tr><td>Orientation × target facial expression × presence of the target × group</td><td>2, 36</td><td align="char" char=".">2.26</td><td align="char" char=".">0.12</td><td align="char" char=".">0.11</td></tr><tr><td>Array size × presence of the target</td><td>1, 36</td><td align="char" char=".">100.0</td><td align="char" char=".">0.001**</td><td align="char" char=".">0.74</td></tr><tr><td>Array size × presence of the target × group</td><td>2, 36</td><td align="char" char=".">2.04</td><td align="char" char=".">0.15</td><td align="char" char=".">0.10</td></tr><tr><td>Orientation × array size × presence of the target</td><td>1, 36</td><td align="char" char=".">0.11</td><td align="char" char=".">0.75</td><td align="char" char=".">0.003</td></tr><tr><td>Orientation × array size × presence of the target × group</td><td>2, 36</td><td align="char" char=".">0.32</td><td align="char" char=".">0.73</td><td align="char" char=".">0.02</td></tr><tr><td>Target facial expression × array size × presence of the target</td><td>1, 36</td><td align="char" char=".">0.68</td><td align="char" char=".">0.42</td><td align="char" char=".">0.02</td></tr><tr><td>Target facial expression × array size × presence of the target × group</td><td>2, 36</td><td align="char" char=".">0.80</td><td align="char" char=".">0.46</td><td align="char" char=".">0.04</td></tr><tr><td>Orientation × target facial expression × array size × presence of the target</td><td>1, 36</td><td align="char" char=".">0.39</td><td align="char" char=".">0.54</td><td align="char" char=".">0.01</td></tr><tr><td>Orientation × target facial expression × array size × presence of the target × group</td><td>2, 36</td><td align="char" char=".">0.63</td><td align="char" char=".">0.54</td><td align="char" char=".">0.03</td></tr></tbody></table><table-wrap-foot><p>*<italic>p</italic> &lt; 0.05; **<italic>p</italic> &lt; 0.01</p><p>Italics indicate the significant effect involving the search asymmetry effect across all groups</p></table-wrap-foot></table-wrap>
</p>
<p>We firstly report main effects of the analysis. We found significant main effects for group [<italic>p</italic> &lt; 0.01; faster RTs for the CA group than those for the MA and WS groups (<italic>ps</italic> &lt; 0.01) but not significant between the MA and CA groups (WS 2899.7 ms, MA 2967.7 ms, and CA 1996.5 ms)] and target facial expression [<italic>p</italic> &lt; 0.01; faster RTs for fearful face target than those for neutral face target (fearful face target 2491.4 ms, neutral face target 2751.1 ms)]. Further, array size [faster RTs for five-item than those for nine-item (five-item 2246.1 ms, nine-item 2996.5 ms, <italic>p</italic> &lt; 0.01)] and presence of target [<italic>p</italic> &lt; 0.01, faster RTs for target present than those for target absent (target present 2227.0 ms, target absent 3015.6 ms)] were also significant. Moreover, the main effect of orientation was significant [<italic>p</italic> &lt; 0.01; faster RTs for upright than those for inverted (upright 2483.8 ms, inverted 2758.8 ms)].</p>
<p>With regard to interactions, several interactions were significant as shown in Table <xref ref-type="table" rid="Tab2">2</xref>. As we are interested in whether the search asymmetry effect was observed in the WS group and the differential search asymmetry across groups, we firstly focused on significant interactions that were involved in the target facial expression and group. As the four-way interaction of group × orientation × target facial expression × array size was significant, we further explore the nature of the simple main effect.</p>
</sec>
<sec id="Sec10">
<title>Search asymmetry effect across groups</title>
<p>For the simple main effects of group, we found differential search asymmetry effects across groups. For the WS group, the main effects of orientation (<italic>p</italic> &lt; 0.01), target facial expression (<italic>p</italic> &lt; 0.05), and array size (<italic>p</italic> &lt; 0.01) were significant. Furthermore, a two-way interaction of orientation × target facial expression was significant (<italic>p</italic> &lt; 0.05). This suggests that RTs for fearful faces were significantly faster than those for neutral faces only in the upright face condition (<italic>p</italic> &lt; 0.01) but not in the inverted face condition (<italic>p</italic> = 0.47). Furthermore, the RTs for the upright face were significantly faster than those for the inverted face condition in both fearful (<italic>p</italic> &lt; 0.01) and neutral faces (<italic>p</italic> &lt; 0.01). Furthermore, RTs for the nine-item condition were significantly longer than those for the five-item condition (3231.1 vs. 2568.3 ms).</p>
<p>For the MA group, the main effect of array size was significant (<italic>p</italic> &lt; 0.01), suggesting that the RTs for the five-item condition were significantly lower than those for the nine-item condition. The interaction of orientation × target facial expression × array size was significant (<italic>p</italic> &lt; 0.01). This suggests that the RTs for the fearful face condition were significantly faster than those for the neutral face condition in the upright and the nine-item condition (<italic>p</italic> &lt; 0.01). Further, the RTs for the upright face condition were faster than those for the inverted face condition in fearful face detection and the nine-item condition (<italic>p</italic> &lt; 0.01). Furthermore, RTs for the five-item condition were significantly faster than those for the nine-item condition (<italic>Fs</italic> &gt; 47.0, <italic>ps</italic> &lt; 0.01).</p>
<p>For the CA group, the main effects of orientation (<italic>p</italic> &lt; 0.01), target facial expression (<italic>p</italic> &lt; 0.01), and array size (<italic>p</italic> &lt; 0.01) were significant. Furthermore, the interaction of target facial expression × array size was significant (<italic>p</italic> &lt; 0.01). This suggests that the RTs for fearful face were significantly faster than those for neutral face in both five-item (<italic>p</italic> &lt; 0.05) and nine-item (<italic>p</italic> &lt; 0.01) conditions. Further, RTs for the nine-item condition were significantly longer than those for the five-item condition in both fearful (<italic>p</italic> &lt; 0.01) and neutral faces (<italic>p</italic> &lt; 0.01).</p>
</sec>
<sec id="Sec11">
<title>Search asymmetry effect depends on face orientation</title>
<p>For the simple main effects of orientation of faces, the search asymmetry effect was observed for both upright and inverted faces, but the effect was different across groups. Concerning the upright face condition, the main effects of group (<italic>p</italic> &lt; 0.01), target facial expression (<italic>p</italic> &lt; 0.01), and array size (<italic>p</italic> &lt; 0.01) were significant. Furthermore, the two-way interactions of group × array size (<italic>p</italic> &lt; 0.01) and target facial expression × array size (<italic>p</italic> &lt; 0.01) were significant. Regarding the interaction of target facial expression × array size, the RTs for the neutral face target were significantly longer than those for the fearful face target in both array sizes (<italic>Fs</italic> &gt; 6.1, <italic>ps</italic> &lt; 0.02). Further, RTs for the nine-item condition were significantly longer than those for the five-item condition in both the target facial expressions (<italic>Fs</italic> &gt; 152.8, <italic>ps</italic> &lt; 0.01). Furthermore, RTs for the nine-item condition were significantly longer than those for the five-item condition for all groups (<italic>Fs</italic> &gt; 71.0, <italic>ps</italic> &lt; 0.01). Regarding the group differences, the RTs for both the MA and WS groups were significantly longer than those for the CA group (<italic>ps</italic> &lt; 0.05) in both the five- and the nine-item conditions. However, no significant differences were found between the MA and WS groups (<italic>ps</italic> &gt; 0.08).</p>
<p>As for the inverted face condition, the main effects of group (<italic>p</italic> &lt; 0.01) and array size (<italic>p</italic> &lt; 0.01) were significant. Furthermore, the two-way interaction of group × array size (<italic>p</italic> &lt; 0.01) and the three-way interactions of group × target facial expression × array size (<italic>p</italic> &lt; 0.05) were significant. The subsequent simple main effects of the three-way interaction revealed that the RTs for the neutral face were significantly longer than those for the fearful face for the nine-item condition in the CA group. Furthermore, the RTs for the nine-item condition were significantly longer than those for the five-item condition in all groups (<italic>Fs</italic> &gt; 41.2, <italic>ps</italic> &lt; 0.01). Other simple main effects did not reach statistical significance (<italic>Fs</italic> &lt; 2.3, <italic>ps</italic> &gt; 0.13). Regarding group differences, the RTs for both the MA and WS groups were significantly longer than those for the CA group (<italic>ps</italic> &lt; 0.01) in both five- and nine-item conditions. However, no significant differences between the MA and WS groups were observed (<italic>ps</italic> &gt; 0.10).</p>
</sec>
<sec id="Sec12">
<title>Search asymmetry effect depends on the size of items</title>
<p>For the simple main effects of size, the search asymmetry effect was observed only for the nine-item condition but not for the five-item condition. For the five-item condition, the main effects of the group (<italic>p</italic> &lt; 0.01), orientation (<italic>p</italic> &lt; 0.01), and target facial expression (<italic>p</italic> &lt; 0.01) were significant.</p>
<p>For the nine-item condition, the main effects of group (<italic>p</italic> &lt; 0.01), orientation (<italic>p</italic> &lt; 0.01), and target facial expression (<italic>p</italic> &lt; 0.01) were significant. Furthermore, the two-way interaction of orientation × target facial expression was significant (<italic>p</italic> &lt; 0.01). This suggests that the RTs for fearful face were significantly faster than those for neutral face only in the upright condition (<italic>p</italic> &lt; 0.01). Further, the RTs for the upright face were significantly faster than those for the inverted face in the fearful face condition (<italic>p</italic> &lt; 0.01).</p>
</sec>
<sec id="Sec13">
<title>Group differences across facial expressions</title>
<p>For the simple main effects of target facial expressions, the group differences were observed for both upright and inverted faces. For the fearful target facial expression condition, the main effects of group (<italic>p</italic> &lt; 0.01), orientation (<italic>p</italic> &lt; 0.01), and array size (<italic>p</italic> &lt; 0.01) were significant. Furthermore, the two-way interactions of group × orientation (<italic>p</italic> &lt; 0.01), group × array size (<italic>p</italic> &lt; 0.01), and orientation × array size (<italic>p</italic> &lt; 0.05) were significant. This suggests that the RTs for upright faces were significantly shorter than those for inverted faces in all groups (<italic>Fs</italic> &gt; 5.4, <italic>ps</italic> &lt; 0.05). Furthermore, the RTs for the nine-item condition were significantly longer than those for the five-item condition in all groups (<italic>Fs</italic> &gt; 56.8, <italic>ps</italic> &lt; 0.01). Regarding group differences, the RTs for both the MA and WS groups were significantly longer than those for the CA group (<italic>ps</italic> &lt; 0.01) in both the five- and nine-item as well as both upright and inverted conditions. However, no significant differences were observed between the MA and WS groups (<italic>ps</italic> &gt; 0.17).</p>
<p>For the neutral target facial expression condition, the main effects of group (<italic>p</italic> &lt; 0.01) and array size (<italic>p</italic> &lt; 0.01) were significant. Furthermore, the two-way interactions of group × array size were significant (<italic>p</italic> &lt; 0.05). It suggests that the RTs for the nine-item condition were significantly longer than those for the five-item condition (<italic>Fs</italic> &gt; 47.2, <italic>ps</italic> &lt; 0.01). Regarding the group differences, the RTs for both MA and WS groups were significantly longer than those for the CA group (<italic>ps</italic> &lt; 0.01). However, no significant differences were observed between the MA and WS groups (<italic>ps</italic> &gt; 0.37).</p>
</sec>
<sec id="Sec14">
<title>Accuracy</title>
<p>For performance accuracy (Fig. <xref ref-type="fig" rid="Fig4">4</xref>; a summary of the statistical analysis is shown in Table <xref ref-type="table" rid="Tab3">3</xref>), we found significant main effects in the array size (<italic>p</italic> &lt; 0.01), orientation (<italic>p</italic> &lt; 0.05), and the presence of the target (<italic>p</italic> &lt; 0.01). In addition, we found significant interactions of orientation × presence of the target (<italic>p</italic> &lt; 0.05) and orientation × array size (<italic>p</italic> &lt; 0.05). However, other effects did not reach statistical significance (<italic>Fs</italic> &lt; 1.2, <italic>ps</italic> &gt; 0.27).<fig id="Fig4"><label>Fig. 4</label><caption><p>Mean percent correct. <bold>a</bold>
<italic>Upright</italic>, target present condition. <bold>b</bold>
<italic>Inverted</italic>, target present condition. <bold>c</bold>
<italic>Upright</italic>, target absent condition. <bold>d</bold>
<italic>Inverted</italic>, target absent condition. Each <italic>color</italic> indicates a combination of target facial expression and array size as shown in the figure. <italic>Error bars</italic> indicate SEM</p></caption><graphic id="MO4" xlink:href="11689_2017_9190_Fig4_HTML"></graphic></fig>
<table-wrap id="Tab3"><label>Table 3</label><caption><p>The results of statistical analysis for the accuracy</p></caption><table frame="hsides" rules="groups"><thead><tr><th></th><th>Degrees of freedom</th><th>
<italic>F</italic> value</th><th>
<italic>p</italic> value</th><th>
<italic>η</italic>
<sub><italic>p</italic></sub>
<sup>2</sup>
</th></tr></thead><tbody><tr><td>Group</td><td>2, 36</td><td align="char" char=".">1.59</td><td align="char" char=".">0.22</td><td align="char" char=".">0.08</td></tr><tr><td>Orientation</td><td>1, 36</td><td align="char" char=".">6.13</td><td align="char" char=".">0.018*</td><td align="char" char=".">0.15</td></tr><tr><td>Orientation × group</td><td>2, 36</td><td align="char" char=".">0.51</td><td align="char" char=".">0.95</td><td align="char" char=".">0.003</td></tr><tr><td>Target facial expression</td><td>1, 36</td><td align="char" char=".">0.007</td><td align="char" char=".">0.93</td><td align="char" char=".">0.000</td></tr><tr><td>Target facial expression × group</td><td>2, 36</td><td align="char" char=".">0.67</td><td align="char" char=".">0.52</td><td align="char" char=".">0.04</td></tr><tr><td>Array size</td><td>1, 36</td><td align="char" char=".">8.15</td><td align="char" char=".">0.007**</td><td align="char" char=".">0.19</td></tr><tr><td>Array size × group</td><td>2, 36</td><td align="char" char=".">2.69</td><td align="char" char=".">0.08</td><td align="char" char=".">0.13</td></tr><tr><td>Presence of the target</td><td>1, 36</td><td align="char" char=".">43.3</td><td align="char" char=".">0.001**</td><td align="char" char=".">0.55</td></tr><tr><td>Presence of the target × group</td><td>2, 36</td><td align="char" char=".">1.14</td><td align="char" char=".">0.33</td><td align="char" char=".">0.60</td></tr><tr><td>Orientation × target facial expression</td><td>1, 36</td><td align="char" char=".">0.005</td><td align="char" char=".">0.94</td><td align="char" char=".">0.00</td></tr><tr><td>Orientation × target facial expression × group</td><td>2, 36</td><td align="char" char=".">0.74</td><td align="char" char=".">0.48</td><td align="char" char=".">0.04</td></tr><tr><td>Orientation × array size</td><td>1, 36</td><td align="char" char=".">4.26</td><td align="char" char=".">0.046*</td><td align="char" char=".">0.12</td></tr><tr><td>Orientation × array size × group</td><td>2, 36</td><td align="char" char=".">0.029</td><td align="char" char=".">0.97</td><td align="char" char=".">0.002</td></tr><tr><td>Target facial expression × array size</td><td>1, 36</td><td align="char" char=".">0.76</td><td align="char" char=".">0.39</td><td align="char" char=".">0.02</td></tr><tr><td>Target facial expression × array size × group</td><td>2, 36</td><td align="char" char=".">1.16</td><td align="char" char=".">0.32</td><td align="char" char=".">0.06</td></tr><tr><td>Orientation × target facial expression × array size</td><td>1, 36</td><td align="char" char=".">0.31</td><td align="char" char=".">0.58</td><td align="char" char=".">0.02</td></tr><tr><td>Orientation × target facial expression × array size × group</td><td>2, 36</td><td align="char" char=".">1.21</td><td align="char" char=".">0.31</td><td align="char" char=".">0.06</td></tr><tr><td>Orientation × presence of the target</td><td>1, 36</td><td align="char" char=".">4.45</td><td align="char" char=".">0.042*</td><td align="char" char=".">0.11</td></tr><tr><td>Orientation × presence of the target × group</td><td>2, 36</td><td align="char" char=".">0.28</td><td align="char" char=".">0.76</td><td align="char" char=".">0.03</td></tr><tr><td>Target facial expression × presence of the target</td><td>1, 36</td><td align="char" char=".">0.11</td><td align="char" char=".">0.74</td><td align="char" char=".">0.003</td></tr><tr><td>Target facial expression × presence of the target × group</td><td>2, 36</td><td align="char" char=".">1.23</td><td align="char" char=".">0.31</td><td align="char" char=".">0.06</td></tr><tr><td>Orientation × target facial expression × presence of the target</td><td>1, 36</td><td align="char" char=".">0.95</td><td align="char" char=".">0.34</td><td align="char" char=".">0.03</td></tr><tr><td>Orientation × target facial expression × presence of the target × group</td><td>2, 36</td><td align="char" char=".">0.79</td><td align="char" char=".">0.46</td><td align="char" char=".">0.04</td></tr><tr><td>Array size × presence of the target</td><td>1, 36</td><td align="char" char=".">1.24</td><td align="char" char=".">0.27</td><td align="char" char=".">0.33</td></tr><tr><td>Array size × presence of the target × group</td><td>2, 36</td><td align="char" char=".">1.04</td><td align="char" char=".">0.36</td><td align="char" char=".">0.06</td></tr><tr><td>Orientation × array size × presence of the target</td><td>1, 36</td><td align="char" char=".">1.52</td><td align="char" char=".">0.23</td><td align="char" char=".">0.04</td></tr><tr><td>Orientation × array size × presence of the target × group</td><td>2, 36</td><td align="char" char=".">1.16</td><td align="char" char=".">0.33</td><td align="char" char=".">0.06</td></tr><tr><td>Target facial expression × array size × presence of the target</td><td>1, 36</td><td align="char" char=".">0.05</td><td align="char" char=".">0.83</td><td align="char" char=".">0.001</td></tr><tr><td>Target facial expression × array size × presence of the target × group</td><td>2, 36</td><td align="char" char=".">0.15</td><td align="char" char=".">0.86</td><td align="char" char=".">0.01</td></tr><tr><td>Orientation × target facial expression × array size × presence of the target</td><td>1, 36</td><td align="char" char=".">0.42</td><td align="char" char=".">0.52</td><td align="char" char=".">0.01</td></tr><tr><td>Orientation × target facial expression × array size × presence of the target × group</td><td>2, 36</td><td align="char" char=".">1.41</td><td align="char" char=".">0.26</td><td align="char" char=".">0.07</td></tr></tbody></table><table-wrap-foot><p>*<italic>p</italic> &lt; 0.05; **<italic>p</italic> &lt; 0.01</p></table-wrap-foot></table-wrap>
</p>
<p>To explore the nature of the interaction of orientation × presence of the target, tests of the simple main effect were performed. The simple main effect of orientation was significant within the target present condition (<italic>p</italic> &lt; 0.01) but not within the target absent condition (<italic>p</italic> = 0.92). This suggests that the accuracies for the upright condition were significantly higher than those for the inverted condition when the target was present (95.4 vs. 93.1%).</p>
<p>Further, to explore the nature of the interaction of orientation × array size, the simple main effect of orientation was significant in the nine-item condition (<italic>p</italic> &lt; 0.01) but not in the five-item condition (<italic>p</italic> = 0.46). This suggests that the accuracies for the upright condition were significantly better than those in the inverted condition in the nine-item array (96.9 vs. 95.0%). Further, the simple main effect of the size of the array was significant in the inverted condition (<italic>p</italic> &lt; 0.01) but not in the upright condition (<italic>p</italic> = 0.58). This suggests that the accuracies for the five-item condition were significantly better for the nine-item condition when the faces were upside down (96.8 vs. 95.0%).</p>
</sec>
<sec id="Sec15">
<title>Gaze behavior (initial saccade latency toward the target or distractor)</title>
<p>As we fully recorded fixation duration data from 10 individuals with WS (one was unable to record complete eye movement data in all experimental conditions due to a technical problem, and two were excluded as the individuals did not fixate the predefined area of interest in some experimental conditions) and 12 individuals among MA and CA participants (individual data for one MA were missing due to a technical problem, and data from one CA individual did not show fixation on the predefined area of interest in some experimental conditions).</p>
<p>We further analyzed the latencies of initial fixation on target facial expression or distractor faces in the target present condition (Fig. <xref ref-type="fig" rid="Fig5">5</xref>; a summary of the statistical analysis is shown in Table <xref ref-type="table" rid="Tab4">4</xref>). We first report the main effects of the analysis. We found significant main effects for the array size (<italic>p</italic> &lt; 0.01), group (<italic>p</italic> &lt; 0.01), and target or distractor faces (<italic>p</italic> &lt; 0.01). These results indicate that the latencies for the five-item condition were significantly faster than those for the nine-item condition (669.4 vs. 843.2 ms), and the latencies for the distractor faces were significantly faster than those for the target facial expression (433.3 vs. 1109.3 ms). Further, the latencies for both the WS and MA groups were significantly slower than those for the CA group (<italic>ps</italic> &lt; 0.01; WS 884.0 ms, MA 809.7 ms, CA 639.0 ms).<fig id="Fig5"><label>Fig. 5</label><caption><p>Saccade onset latency toward a target or a distractor face for the condition where the target is present (target present condition). <bold>a</bold>
<italic>Upright</italic>, target present condition. <bold>b</bold>
<italic>Inverted</italic>, target present condition. <bold>c</bold>
<italic>Upright</italic>, target absent condition. <bold>d</bold>
<italic>Inverted</italic>, target absent condition. Each <italic>color</italic> indicates a combination of target facial expression and array size as shown in the figure. <italic>Error bars</italic> indicate SEM</p></caption><graphic id="MO5" xlink:href="11689_2017_9190_Fig5_HTML"></graphic></fig>
<table-wrap id="Tab4"><label>Table 4</label><caption><p>The results of statistical analysis for the gaze behavior</p></caption><table frame="hsides" rules="groups"><thead><tr><th></th><th>Degrees of freedom</th><th>
<italic>F</italic> value</th><th>
<italic>p</italic> value</th><th>
<italic>η</italic>
<sub><italic>p</italic></sub>
<sup>2</sup>
</th></tr></thead><tbody><tr><td>Group</td><td>2, 31</td><td align="char" char=".">11.0</td><td align="char" char=".">0.001**</td><td align="char" char=".">0.42</td></tr><tr><td>Orientation</td><td>1, 31</td><td align="char" char=".">0.089</td><td align="char" char=".">0.77</td><td align="char" char=".">0.003</td></tr><tr><td>Orientation × group</td><td>2, 31</td><td align="char" char=".">0.13</td><td align="char" char=".">0.88</td><td align="char" char=".">0.008</td></tr><tr><td>Target facial expression</td><td>1, 31</td><td align="char" char=".">2.82</td><td align="char" char=".">0.10</td><td align="char" char=".">0.08</td></tr><tr><td>Target facial expression × group</td><td>2, 31</td><td align="char" char=".">0.46</td><td align="char" char=".">0.63</td><td align="char" char=".">0.03</td></tr><tr><td>Array size</td><td>1, 31</td><td align="char" char=".">40.9</td><td align="char" char=".">0.001**</td><td align="char" char=".">0.57</td></tr><tr><td>Array size × group</td><td>2, 31</td><td align="char" char=".">0.14</td><td align="char" char=".">0.87</td><td align="char" char=".">0.009</td></tr><tr><td>Target or distractor faces</td><td>1, 31</td><td align="char" char=".">628.9</td><td align="char" char=".">0.001**</td><td align="char" char=".">0.95</td></tr><tr><td>Target or distractor faces × group</td><td>2, 31</td><td align="char" char=".">7.17</td><td align="char" char=".">0.001**</td><td align="char" char=".">0.32</td></tr><tr><td>Orientation × target facial expression</td><td>1, 31</td><td align="char" char=".">1.00</td><td align="char" char=".">0.33</td><td align="char" char=".">0.03</td></tr><tr><td>Orientation × target facial expression × group</td><td>2, 31</td><td align="char" char=".">0.26</td><td align="char" char=".">0.77</td><td align="char" char=".">0.02</td></tr><tr><td>Orientation × array size</td><td>1, 31</td><td align="char" char=".">0.60</td><td align="char" char=".">0.44</td><td align="char" char=".">0.02</td></tr><tr><td>Orientation × array size × group</td><td>2, 31</td><td align="char" char=".">0.46</td><td align="char" char=".">0.64</td><td align="char" char=".">0.03</td></tr><tr><td>Target facial expression × array size</td><td>1, 31</td><td align="char" char=".">0.002</td><td align="char" char=".">0.97</td><td align="char" char=".">0.00</td></tr><tr><td>Target facial expression × array size × group</td><td>2, 31</td><td align="char" char=".">0.88</td><td align="char" char=".">0.42</td><td align="char" char=".">0.05</td></tr><tr><td>Orientation × target facial expression × array size</td><td>1, 31</td><td align="char" char=".">0.30</td><td align="char" char=".">0.59</td><td align="char" char=".">0.01</td></tr><tr><td>Orientation × target facial expression × array size × group</td><td>2, 31</td><td align="char" char=".">2.17</td><td align="char" char=".">0.13</td><td align="char" char=".">0.12</td></tr><tr><td>Orientation × target or distractor faces</td><td>1, 31</td><td align="char" char=".">3.38</td><td align="char" char=".">0.08</td><td align="char" char=".">0.10</td></tr><tr><td>Orientation × target or distractor faces × group</td><td>2, 31</td><td align="char" char=".">0.20</td><td align="char" char=".">0.82</td><td align="char" char=".">0.01</td></tr><tr><td>
<italic>Target facial expression</italic> × <italic>target or distractor faces</italic>
</td><td>
<italic>1</italic>, <italic>31</italic>
</td><td align="char" char=".">
<italic>4.39</italic>
</td><td align="char" char=".">
<italic>0.045</italic>*</td><td align="char" char=".">
<italic>0.12</italic>
</td></tr><tr><td>Target facial expression × target or distractor faces × group</td><td>2, 31</td><td align="char" char=".">0.41</td><td align="char" char=".">0.67</td><td align="char" char=".">0.03</td></tr><tr><td>Orientation × target facial expression × target or distractor faces</td><td>1, 31</td><td align="char" char=".">1.88</td><td align="char" char=".">0.18</td><td align="char" char=".">0.06</td></tr><tr><td>Orientation × target facial expression × target or distractor faces × group</td><td>2, 31</td><td align="char" char=".">0.50</td><td align="char" char=".">0.61</td><td align="char" char=".">0.03</td></tr><tr><td>Array size × target or distractor faces</td><td>1, 31</td><td align="char" char=".">47.1</td><td align="char" char=".">0.001**</td><td align="char" char=".">0.60</td></tr><tr><td>Array size × target or distractor faces × group</td><td>2, 31</td><td align="char" char=".">0.04</td><td align="char" char=".">0.97</td><td align="char" char=".">0.002</td></tr><tr><td>Orientation × array size × target or distractor faces</td><td>1, 31</td><td align="char" char=".">0.13</td><td align="char" char=".">0.73</td><td align="char" char=".">0.004</td></tr><tr><td>Orientation × array size × target or distractor faces × group</td><td>2, 31</td><td align="char" char=".">0.19</td><td align="char" char=".">0.81</td><td align="char" char=".">0.01</td></tr><tr><td>Target facial expression × array size × target or distractor faces</td><td>1, 31</td><td align="char" char=".">0.26</td><td align="char" char=".">0.62</td><td align="char" char=".">0.008</td></tr><tr><td>Target facial expression × array size × target or distractor faces × group</td><td>2, 31</td><td align="char" char=".">0.92</td><td align="char" char=".">0.41</td><td align="char" char=".">0.06</td></tr><tr><td>Orientation × target facial expression × array size × target or distractor faces</td><td>1, 31</td><td align="char" char=".">0.23</td><td align="char" char=".">0.63</td><td align="char" char=".">0.01</td></tr><tr><td>Orientation × target facial expression × array size × target or distractor faces × group</td><td>2, 31</td><td align="char" char=".">1.75</td><td align="char" char=".">0.19</td><td align="char" char=".">0.10</td></tr></tbody></table><table-wrap-foot><p>**<italic>p</italic> &lt; 0.01; *<italic>p</italic> &lt; 0.05</p><p>Italics indicate the significant effect involving the search asymmetry effect across all groups</p></table-wrap-foot></table-wrap>
</p>
</sec>
<sec id="Sec16">
<title>Search asymmetry effect across groups</title>
<p>As we are interested in whether the search asymmetry effect was observed in the WS group, we first focused on significant interactions that were involved in the target facial expression and group. With regard to the interaction, we found significant interactions of target facial expression × target or distractor faces (<italic>p</italic> &lt; 0.05), group × target or distractor faces (<italic>p</italic> &lt; 0.01), and array size × target (<italic>p</italic> &lt; 0.01).</p>
<p>To explore the nature of the interaction of target facial expression × target or distractor faces, tests of the simple main effect were performed. The simple main effect of the target facial expression was significant within the target face condition (<italic>p</italic> &lt; 0.01) but not within the distractor faces (<italic>p</italic> = 0.94). This suggests that the latency of the neutral target facial expression was significantly longer than that of the fearful target facial expression in all groups. For both the target facial expression conditions, the latency of the target face was significantly longer than that of the distractor faces in both the fearful (<italic>p</italic> &lt; 0.01) and neutral (<italic>p</italic> &lt; 0.01) target face conditions.</p>
</sec>
<sec id="Sec17">
<title>The effect of group depends on the presence of target</title>
<p>To explore the nature of the interaction of group × target or distractor faces, tests of the simple main effect were performed. The simple main effects of the target or distractor faces were significant within all groups (<italic>ps</italic> &lt; 0.01). This suggests that the latencies toward the target facial expression were significantly longer than those toward the distractor faces in all groups. The main effect of the group was significant within the target face (<italic>p</italic> &lt; 0.01) but not significant within the distractor faces (<italic>p</italic> = 0.10). This suggests that the latencies in both the WS and MA groups were significantly longer than those in the CA group toward a target face (<italic>ps</italic> &lt; 0.01), but the latencies between the WS and MA groups were not significant (<italic>p</italic> = 0.18).</p>
</sec>
<sec id="Sec18">
<title>The effect of the item size depends on the presence of the target</title>
<p>We further explored the nature of the interaction of the array size × target or distractor faces. The simple main effect of the target face was significant within the five-item (<italic>p</italic> &lt; 0.01) and the nine-item (<italic>p</italic> &lt; 0.01) conditions. This suggests that the latencies toward the distractor faces were significantly faster than those toward the target face in both array size conditions. Further, the simple main effect of the array size was significant within the target face (<italic>p</italic> &lt; 0.01) but not the distractor faces (<italic>p</italic> = 0.95). This indicates that the latencies for the nine-item condition were significantly longer than those for the five-item condition toward a target face.</p>
</sec>
</sec>
<sec id="Sec19" sec-type="discussion">
<title>Discussion</title>
<p>The current study was designed to test whether the detection mechanisms for fearful faces are preserved in individuals with WS by introducing a visual search paradigm. We assessed search asymmetry as an index by measuring both manual responses and gaze behaviors. Search asymmetry was defined to occur when a neutral face was displayed as a target facial expression among fearful faces; RT was longer compared to when a fearful face was the target among neutral faces. In line with previous behavioral studies on visual search study for emotional faces [<xref ref-type="bibr" rid="CR28">28</xref>, <xref ref-type="bibr" rid="CR30">30</xref>], search asymmetry was also found between fearful and neutral faces.</p>
<p>Overall, although reaction time was prolonged in both the WS and MA groups compared to the CA group, we did not find atypical search asymmetries in the WS group. This suggests that the cognitive mechanisms of detecting a fearful face can be preserved in the WS group when compared to the control groups. However, the effect of search asymmetry was slightly different in each group. For the WS group, we found a significant interaction of orientation × target facial expression, suggesting that the RT for neutral face detection was longer than that for fearful face detection only in the upright face condition, but this effect was diminished in the inverted face condition. It suggests that the search asymmetry holds only when the configural processing is preserved in the WS group. For the MA group, we found a significant interaction of orientation × target facial expression × size array, suggesting that search asymmetry was found only in the nine-item condition, not in the five-item condition for upright faces, and was not found in the inverted faces. This suggests that search asymmetry was prominent when the task was difficult. For the CA group, contrary to both the WS and MA groups, search asymmetry was found in both the upright and inverted conditions, irrespective of the array size. This suggests that local features of faces were used in the task.</p>
<p>In light of our initial hypotheses, if the amygdala account were true for explaining hypersociability observed in individuals with WS, we should expect search asymmetry to be diminished in individuals with WS. However, we observed search asymmetry in individuals with WS, suggesting that a fearful face is more salient than a neutral face. In light of the two accounts regarding hypersociability in individuals with WS, it is possible that the amygdala account does not fully fit current findings. One of the plausible reasons why we could not find the atypicality of the search asymmetry would be due to the task differences contrasting with previous studies. Most previous studies have introduced face “perception”/“recognition” tasks [<xref ref-type="bibr" rid="CR53">53</xref>] or matching tasks [<xref ref-type="bibr" rid="CR19">19</xref>] and have shown reduced neural activities in the amygdala region. In contrast with these experimental paradigms, the current visual search task we used might not capture the distinctive aspects of processing social affective information shown by individuals with WS.</p>
<p>The differential experimental paradigm might tap differential functional aspects of amygdala processing. A previous neuropsychological study has demonstrated that an individual with complete bilateral amygdala lesions who cannot recognize fear in faces nonetheless showed normal rapid detection and nonconscious processing of those same fearful faces [<xref ref-type="bibr" rid="CR20">20</xref>]. Other evidence has suggested that individuals with amygdala lesions detect emotional targets more efficiently than neutral targets when compared with healthy controls [<xref ref-type="bibr" rid="CR54">54</xref>]. It is likely that the amygdala is not necessary for emotion-guided visual search or is not essential for the early stage of fear processing. Rather, the amygdala may modulate later cognitive processes such as recognition and social judgment [<xref ref-type="bibr" rid="CR20">20</xref>]. If this view is true, it is possible that the ability to detect fearful faces to be preserved in individuals with WS even though several studies have demonstrated an atypical structural and functional neural activity of the amygdala in individuals with WS [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR19">19</xref>]. As the currently proposed amygdala theory does not fully distinguish atypicality between “detection” and “recognition” of fearful faces in individuals with WS, further studies should refine the amygdala account to explain which aspect of fear-related processing is atypical and lead to hypersociability in individuals with WS.</p>
<p>Because only fearful and neutral expressions were used in the current experiment, it is possible that the search asymmetries found may be related to distinguishing between (and detecting faster) emotional and neutral facial expressions. Therefore, it would not be specific to fear detection as a signal of threat. To verify this point, it is worthwhile to introduce the other types of facial expression as control. By introducing happy, fearful, and neutral facial expressions, Haas and colleagues [<xref ref-type="bibr" rid="CR53">53</xref>] have shown the amygdala reactivity to happy faces and absent or attenuated amygdala reactivity to fearful facial expressions. Moreover, the abnormal amygdala reactivity in WS might possibly function to increase attention to and encode happy facial expressions and decrease arousal to fearful expressions. As we did not include positive facial expressions such as happy faces in our current task, we cannot exclude the possibility of the atypical amygdala function in individuals with WS. As the increased amygdala responses to happy facial expressions in individuals with WS, it might represent several psychological processes linked to the amygdala, including attention, arousal, and anxiety. For example, the central nucleus of the amygdala has been strongly linked with attention [<xref ref-type="bibr" rid="CR55">55</xref>, <xref ref-type="bibr" rid="CR56">56</xref>]. Therefore, it would be beneficial to test whether the search asymmetry effect would be observed between happy and neutral faces as compared to fearful and neutral faces as the ones found in the current experiment.</p>
<p>Because we have introduced the visual search paradigm using both fearful and neutral faces to tap the function of the amygdala, we cannot directly test whether the alternative frontal lobe theory can account for the hypersociability reported in individuals with WS. However, we found that, overall, the reaction time was significantly longer than that for other control groups and the reaction time was prolonged as the set size increases in comparison with control groups. As the task difficulty of the visual search modulates the neural activities in the bilateral ventrolateral prefrontal cortex and right dorsolateral prefrontal cortex [<xref ref-type="bibr" rid="CR57">57</xref>], it seems that the functioning of the prefrontal cortex was not atypical in individuals with WS in the current experiment.</p>
<p>When faces were presented upside down, we found that search asymmetry was diminished in the WS group, contrasting with the performances in the CA group. This suggests that search asymmetry was not induced by the local elements of faces but by the processing of global configuration of faces. This view contrasts somewhat with previous findings that fail to obtain evidence for an inversion effect in individuals with WS [<xref ref-type="bibr" rid="CR31">31</xref>–<xref ref-type="bibr" rid="CR33">33</xref>]. Studies have also investigated this phenomenon using event-related potentials [<xref ref-type="bibr" rid="CR45">45</xref>] and evoked fields [<xref ref-type="bibr" rid="CR46">46</xref>]. These discrepancies may be explicable from task differences as the current task requires the identification of an emotional expression that seems to be preserved [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>].</p>
<p>As in our previous study [<xref ref-type="bibr" rid="CR47">47</xref>, <xref ref-type="bibr" rid="CR48">48</xref>], both coarse measures such as manual responses and fine measures such as eye movement were simultaneously recorded during visual search. In our previous experiment, eye movements reflected subtle atypical attentional properties; however, manual responses were unable to capture atypical attentional profiles toward upright faces in individuals with WS. Therefore, we measured both manual responses and gaze behaviors during the visual search task and found the effects of search asymmetry. Most previous studies have used a single modality, such as manual responses or eye movements, for measuring the attentional process in individuals with WS. We have further shown that both measures reflect search asymmetry. We believe that the measurements of both manual and eye movements are useful to validate the effect.</p>
<p>Although our current study provides new insights into the mechanisms underlying the detection of negative social stimuli in WS, there are several limitations. First, it is possible that the visual search task used does not capture the distinctive aspects of processing social affective information shown by individuals with WS. Because only fearful and neutral expressions were used in the experiment, it is possible that the search asymmetries found may be related to distinguishing between emotional facial expressions and neutral facial expressions. Therefore, it may not be specific to detection of fear as a signal of threat. Second, the number of participants was rather small for tracing developmental changes in individuals with WS. Further studies are needed to address the developmental changes in the performances of the search asymmetry. Third, we only analyzed (a minimum of) nine trials, as we introduced many experimental conditions in our current experiment. We think that further validation is needed to ascertain whether the effect will be observed.</p>
</sec>
<sec id="Sec20" sec-type="conclusion">
<title>Conclusions</title>
<p>In conclusion, we did not find any atypical visual search asymmetries in the search for fearful faces in measures of both manual response and eye movement in individuals with WS during a visual search task. This suggests that fearful faces were also salient stimuli compared to neutral faces in people with WS. Our current finding seems to contrast with previous neuroimaging findings regarding the atypical neural activities related to fearful face processing in individuals with WS. However, this finding can give a clue to formulate the atypical fear-related processing, such as differential processing, which could be involved in “detecting” and “recognizing” the processing of fearful faces in individuals with WS. We believe that our current findings will contribute to refining theoretical models to explain hypersociability in individuals with WS, particularly the amygdala account, from the viewpoint of conscious and nonconscious processing of fear-related information.</p>
</sec>
</body>
<back>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item>
<term>ANOVA</term>
<def>
<p>Analysis of variance</p>
</def>
</def-item>
<def-item>
<term>AOI</term>
<def>
<p>Area of interest</p>
</def>
</def-item>
<def-item>
<term>CA</term>
<def>
<p>Chronological age-matched</p>
</def>
</def-item>
<def-item>
<term>MA</term>
<def>
<p>Mental age-matched</p>
</def>
</def-item>
<def-item>
<term>RCPM</term>
<def>
<p>Raven’s Colored Progressive Matrices test</p>
</def>
</def-item>
<def-item>
<term>WS</term>
<def>
<p>Williams syndrome</p>
</def>
</def-item>
</def-list>
</glossary>
<ack>
<p>We are grateful to the Williams Syndrome Association (Elfin Chubu, Nagoya) for their support of this research, and we thank all participants, as well as their caregivers, for their participation.</p>
<sec id="FPar1">
<title>Funding</title>
<p>This work was supported by JSPS KAKENHI Grant Number 23830127, the grant in aid for Scientific Research on Innovative Areas 15H01585 “Constructive Developmental Science” from the Ministry of Education, Culture, Sports, Science and Technology, a Grant from the Daiko Foundation to MH, and by JSPS KAKENHI Grant Number 23119733 and 21119529 to MN. They had no role in the design, collection, analysis, and interpretation of the data and in writing the manuscript.</p>
</sec>
<sec id="FPar2">
<title>Availability of data and materials</title>
<p>All data is available upon request.</p>
</sec>
<sec id="FPar3">
<title>Authors’ contributions</title>
<p>MH conceived the study, designed the experiment, wrote programs, collected the data, analyzed the data, and wrote the manuscript. MN helped with conceptualizing the experiment and data collection. YM helped with the data collection. MN, YM, SM, NK, and HK were engaged in the diagnosis and follow-up of individuals with WS who participated in the study and helped write the manuscript. All authors read and approved the final manuscript.</p>
</sec>
<sec id="FPar4">
<title>Competing interests</title>
<p>The authors declare that they have no competing interests.</p>
</sec>
<sec id="FPar5">
<title>Consent for publication</title>
<p>Not applicable.</p>
</sec>
<sec id="FPar6">
<title>Ethics approval and consent to participate</title>
<p>All the children, their parents, and the adult participants provided informed consent to participate in the study, which was approved by the ethics committee at the Institute for Developmental Research at the Aichi Human Service Center (Reference Number: 04-08). All participants were capable of giving written informed consent and did so, after receiving full information on the study.</p>
</sec>
</ack>
<ref-list id="Bib1">
<title>References</title>
<ref id="CR1">
<label>1.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Stromme</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Bjornstad</surname>
<given-names>PG</given-names>
</name>
<name>
<surname>Ramstad</surname>
<given-names>K</given-names>
</name>
</person-group>
<article-title>Prevalence estimation of Williams syndrome</article-title>
<source/>J Child Neurol
          <year>2002</year>
<volume>17</volume>
<issue>4</issue>
<fpage>269</fpage>
<lpage>71</lpage>
<pub-id pub-id-type="doi">10.1177/088307380201700406</pub-id>
<pub-id pub-id-type="pmid">12088082</pub-id>
</element-citation>
</ref>
<ref id="CR2">
<label>2.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Meyer-Lindenberg</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Mervis</surname>
<given-names>CB</given-names>
</name>
<name>
<surname>Berman</surname>
<given-names>KF</given-names>
</name>
</person-group>
<article-title>Neural mechanisms in Williams syndrome: a unique window to genetic influences on cognition and behaviour</article-title>
<source/>Nat Rev Neurosci
          <year>2006</year>
<volume>7</volume>
<issue>5</issue>
<fpage>380</fpage>
<lpage>93</lpage>
<pub-id pub-id-type="doi">10.1038/nrn1906</pub-id>
<pub-id pub-id-type="pmid">16760918</pub-id>
</element-citation>
</ref>
<ref id="CR3">
<label>3.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jones</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Bellugi</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Lai</surname>
<given-names>Z</given-names>
</name>
<name>
<surname>Chiles</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Reilly</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Lincoln</surname>
<given-names>A</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Hypersociability in Williams Syndrome</article-title>
<source/>J Cogn Neurosci
          <year>2000</year>
<volume>12</volume>
<issue>Suppl 1</issue>
<fpage>30</fpage>
<lpage>46</lpage>
<pub-id pub-id-type="doi">10.1162/089892900561968</pub-id>
<pub-id pub-id-type="pmid">10953232</pub-id>
</element-citation>
</ref>
<ref id="CR4">
<label>4.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Riby</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Kirk</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Hanley</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Riby</surname>
<given-names>LM</given-names>
</name>
</person-group>
<article-title>Stranger danger awareness in Williams syndrome</article-title>
<source/>J Intellect Disabil Res
          <year>2014</year>
<volume>58</volume>
<issue>6</issue>
<fpage>572</fpage>
<lpage>82</lpage>
<pub-id pub-id-type="doi">10.1111/jir.12055</pub-id>
<pub-id pub-id-type="pmid">23718278</pub-id>
</element-citation>
</ref>
<ref id="CR5">
<label>5.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jarvinen-Pasley</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Adolphs</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Yam</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Hill</surname>
<given-names>KJ</given-names>
</name>
<name>
<surname>Grichanik</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Reilly</surname>
<given-names>J</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Affiliative behavior in Williams syndrome: social perception and real-life social behavior</article-title>
<source/>Neuropsychologia
          <year>2010</year>
<volume>48</volume>
<issue>7</issue>
<fpage>2110</fpage>
<lpage>9</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2010.03.032</pub-id>
<pub-id pub-id-type="pmid">20385151</pub-id>
</element-citation>
</ref>
<ref id="CR6">
<label>6.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Doyle</surname>
<given-names>TF</given-names>
</name>
<name>
<surname>Bellugi</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Korenberg</surname>
<given-names>JR</given-names>
</name>
<name>
<surname>Graham</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>“Everybody in the world is my friend” hypersociability in young children with Williams syndrome</article-title>
<source/>Am J Med Genet A
          <year>2004</year>
<volume>124A</volume>
<issue>3</issue>
<fpage>263</fpage>
<lpage>73</lpage>
<pub-id pub-id-type="doi">10.1002/ajmg.a.20416</pub-id>
<pub-id pub-id-type="pmid">14708099</pub-id>
</element-citation>
</ref>
<ref id="CR7">
<label>7.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Frigerio</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Burt</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Gagliardi</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Cioffi</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Martelli</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Perrett</surname>
<given-names>DI</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Is everybody always my friend? Perception of approachability in Williams syndrome</article-title>
<source/>Neuropsychologia
          <year>2006</year>
<volume>44</volume>
<issue>2</issue>
<fpage>254</fpage>
<lpage>9</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2005.05.008</pub-id>
<pub-id pub-id-type="pmid">16005478</pub-id>
</element-citation>
</ref>
<ref id="CR8">
<label>8.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Porter</surname>
<given-names>MA</given-names>
</name>
<name>
<surname>Coltheart</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Langdon</surname>
<given-names>R</given-names>
</name>
</person-group>
<article-title>The neuropsychological basis of hypersociability in Williams and Down syndrome</article-title>
<source/>Neuropsychologia
          <year>2007</year>
<volume>45</volume>
<issue>12</issue>
<fpage>2839</fpage>
<lpage>49</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2007.05.006</pub-id>
<pub-id pub-id-type="pmid">17597166</pub-id>
</element-citation>
</ref>
<ref id="CR9">
<label>9.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Little</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Riby</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Janes</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Clark</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Fleck</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Rodgers</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>Heterogeneity of social approach behaviour in Williams syndrome: the role of response inhibition</article-title>
<source/>Res Dev Disabil
          <year>2013</year>
<volume>34</volume>
<issue>3</issue>
<fpage>959</fpage>
<lpage>67</lpage>
<pub-id pub-id-type="doi">10.1016/j.ridd.2012.11.020</pub-id>
<pub-id pub-id-type="pmid">23291513</pub-id>
</element-citation>
</ref>
<ref id="CR10">
<label>10.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jawaid</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Riby</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Owens</surname>
<given-names>J</given-names>
</name>
<name>
<surname>White</surname>
<given-names>SW</given-names>
</name>
<name>
<surname>Tarar</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Schulz</surname>
<given-names>PE</given-names>
</name>
</person-group>
<article-title>‘Too withdrawn’ or ‘too friendly’: considering social vulnerability in two neuro-developmental disorders</article-title>
<source/>J Intellect Disabil Res
          <year>2012</year>
<volume>56</volume>
<issue>4</issue>
<fpage>335</fpage>
<lpage>50</lpage>
<pub-id pub-id-type="doi">10.1111/j.1365-2788.2011.01452.x</pub-id>
<pub-id pub-id-type="pmid">21801261</pub-id>
</element-citation>
</ref>
<ref id="CR11">
<label>11.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rhodes</surname>
<given-names>SM</given-names>
</name>
<name>
<surname>Riby</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Park</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Fraser</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Campbell</surname>
<given-names>LE</given-names>
</name>
</person-group>
<article-title>Executive neuropsychological functioning in individuals with Williams syndrome</article-title>
<source/>Neuropsychologia
          <year>2010</year>
<volume>48</volume>
<issue>5</issue>
<fpage>1216</fpage>
<lpage>26</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2009.12.021</pub-id>
<pub-id pub-id-type="pmid">20026085</pub-id>
</element-citation>
</ref>
<ref id="CR12">
<label>12.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Campbell</surname>
<given-names>LE</given-names>
</name>
<name>
<surname>Daly</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Toal</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Stevens</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Azuma</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Karmiloff-Smith</surname>
<given-names>A</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Brain structural differences associated with the behavioural phenotype in children with Williams syndrome</article-title>
<source/>Brain Res
          <year>2009</year>
<volume>1258</volume>
<fpage>96</fpage>
<lpage>107</lpage>
<pub-id pub-id-type="doi">10.1016/j.brainres.2008.11.101</pub-id>
<pub-id pub-id-type="pmid">19118537</pub-id>
</element-citation>
</ref>
<ref id="CR13">
<label>13.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rhodes</surname>
<given-names>SM</given-names>
</name>
<name>
<surname>Riby</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Matthews</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Coghill</surname>
<given-names>DR</given-names>
</name>
</person-group>
<article-title>Attention-deficit/hyperactivity disorder and Williams syndrome: shared behavioral and neuropsychological profiles</article-title>
<source/>J Clin Exp Neuropsychol
          <year>2011</year>
<volume>33</volume>
<issue>1</issue>
<fpage>147</fpage>
<lpage>56</lpage>
<pub-id pub-id-type="doi">10.1080/13803395.2010.495057</pub-id>
<pub-id pub-id-type="pmid">20700845</pub-id>
</element-citation>
</ref>
<ref id="CR14">
<label>14.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mobbs</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Eckert</surname>
<given-names>MA</given-names>
</name>
<name>
<surname>Mills</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Korenberg</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Bellugi</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Galaburda</surname>
<given-names>AM</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Frontostriatal dysfunction during response inhibition in Williams syndrome</article-title>
<source/>Biol Psychiatry
          <year>2007</year>
<volume>62</volume>
<issue>3</issue>
<fpage>256</fpage>
<lpage>61</lpage>
<pub-id pub-id-type="doi">10.1016/j.biopsych.2006.05.041</pub-id>
<pub-id pub-id-type="pmid">16996488</pub-id>
</element-citation>
</ref>
<ref id="CR15">
<label>15.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Adolphs</surname>
<given-names>R</given-names>
</name>
</person-group>
<article-title>Fear, faces, and the human amygdala</article-title>
<source/>Curr Opin Neurobiol
          <year>2008</year>
<volume>18</volume>
<issue>2</issue>
<fpage>166</fpage>
<lpage>72</lpage>
<pub-id pub-id-type="doi">10.1016/j.conb.2008.06.006</pub-id>
<pub-id pub-id-type="pmid">18655833</pub-id>
</element-citation>
</ref>
<ref id="CR16">
<label>16.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bellugi</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Adolphs</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Cassady</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Chiles</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>Towards the neural basis for hypersociability in a genetic syndrome</article-title>
<source/>Neuroreport
          <year>1999</year>
<volume>10</volume>
<issue>8</issue>
<fpage>1653</fpage>
<lpage>7</lpage>
<pub-id pub-id-type="doi">10.1097/00001756-199906030-00006</pub-id>
<pub-id pub-id-type="pmid">10501552</pub-id>
</element-citation>
</ref>
<ref id="CR17">
<label>17.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Martens</surname>
<given-names>MA</given-names>
</name>
<name>
<surname>Wilson</surname>
<given-names>SJ</given-names>
</name>
<name>
<surname>Dudgeon</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Reutens</surname>
<given-names>DC</given-names>
</name>
</person-group>
<article-title>Approachability and the amygdala: insights from Williams syndrome</article-title>
<source/>Neuropsychologia
          <year>2009</year>
<volume>47</volume>
<issue>12</issue>
<fpage>2446</fpage>
<lpage>53</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2009.04.017</pub-id>
<pub-id pub-id-type="pmid">19406143</pub-id>
</element-citation>
</ref>
<ref id="CR18">
<label>18.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Haas</surname>
<given-names>BW</given-names>
</name>
<name>
<surname>Hoeft</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Searcy</surname>
<given-names>YM</given-names>
</name>
<name>
<surname>Mills</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Bellugi</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Reiss</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Individual differences in social behavior predict amygdala response to fearful facial expressions in Williams syndrome</article-title>
<source/>Neuropsychologia
          <year>2010</year>
<volume>48</volume>
<issue>5</issue>
<fpage>1283</fpage>
<lpage>8</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2009.12.030</pub-id>
<pub-id pub-id-type="pmid">20036269</pub-id>
</element-citation>
</ref>
<ref id="CR19">
<label>19.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Meyer-Lindenberg</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Hariri</surname>
<given-names>AR</given-names>
</name>
<name>
<surname>Munoz</surname>
<given-names>KE</given-names>
</name>
<name>
<surname>Mervis</surname>
<given-names>CB</given-names>
</name>
<name>
<surname>Mattay</surname>
<given-names>VS</given-names>
</name>
<name>
<surname>Morris</surname>
<given-names>CA</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Neural correlates of genetically abnormal social cognition in Williams syndrome</article-title>
<source/>Nat Neurosci
          <year>2005</year>
<volume>8</volume>
<issue>8</issue>
<fpage>991</fpage>
<lpage>3</lpage>
<pub-id pub-id-type="doi">10.1038/nn1494</pub-id>
<pub-id pub-id-type="pmid">16007084</pub-id>
</element-citation>
</ref>
<ref id="CR20">
<label>20.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Tsuchiya</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Moradi</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Felsen</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Yamazaki</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Adolphs</surname>
<given-names>R</given-names>
</name>
</person-group>
<article-title>Intact rapid detection of fearful faces in the absence of the amygdala</article-title>
<source/>Nat Neurosci
          <year>2009</year>
<volume>12</volume>
<issue>10</issue>
<fpage>1224</fpage>
<lpage>5</lpage>
<pub-id pub-id-type="doi">10.1038/nn.2380</pub-id>
<pub-id pub-id-type="pmid">19718036</pub-id>
</element-citation>
</ref>
<ref id="CR21">
<label>21.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Treisman</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Gormican</surname>
<given-names>S</given-names>
</name>
</person-group>
<article-title>Feature analysis in early vision: evidence from search asymmetries</article-title>
<source/>Psychol Rev
          <year>1988</year>
<volume>95</volume>
<issue>1</issue>
<fpage>15</fpage>
<lpage>48</lpage>
<pub-id pub-id-type="doi">10.1037/0033-295X.95.1.15</pub-id>
<pub-id pub-id-type="pmid">3353475</pub-id>
</element-citation>
</ref>
<ref id="CR22">
<label>22.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Treisman</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Souther</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>Search asymmetry: a diagnostic for preattentive processing of separable features</article-title>
<source/>J Exp Psychol Gen
          <year>1985</year>
<volume>114</volume>
<issue>3</issue>
<fpage>285</fpage>
<lpage>310</lpage>
<pub-id pub-id-type="doi">10.1037/0096-3445.114.3.285</pub-id>
<pub-id pub-id-type="pmid">3161978</pub-id>
</element-citation>
</ref>
<ref id="CR23">
<label>23.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wolfe</surname>
<given-names>JM</given-names>
</name>
</person-group>
<article-title>Asymmetries in visual search: an introduction</article-title>
<source/>Percept Psychophys
          <year>2001</year>
<volume>63</volume>
<issue>3</issue>
<fpage>381</fpage>
<lpage>9</lpage>
<pub-id pub-id-type="doi">10.3758/BF03194406</pub-id>
<pub-id pub-id-type="pmid">11414127</pub-id>
</element-citation>
</ref>
<ref id="CR24">
<label>24.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>von Grunau</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Anston</surname>
<given-names>C</given-names>
</name>
</person-group>
<article-title>The detection of gaze direction: a stare-in-the-crowd effect</article-title>
<source/>Perception
          <year>1995</year>
<volume>24</volume>
<issue>11</issue>
<fpage>1297</fpage>
<lpage>313</lpage>
<pub-id pub-id-type="doi">10.1068/p241297</pub-id>
<pub-id pub-id-type="pmid">8643334</pub-id>
</element-citation>
</ref>
<ref id="CR25">
<label>25.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Senju</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Kikuchi</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Hasegawa</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Tojo</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Osanai</surname>
<given-names>H</given-names>
</name>
</person-group>
<article-title>Is anyone looking at me? Direct gaze detection in children with and without autism</article-title>
<source/>Brain Cogn
          <year>2008</year>
<volume>67</volume>
<issue>2</issue>
<fpage>127</fpage>
<lpage>39</lpage>
<pub-id pub-id-type="doi">10.1016/j.bandc.2007.12.001</pub-id>
<pub-id pub-id-type="pmid">18226847</pub-id>
</element-citation>
</ref>
<ref id="CR26">
<label>26.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wang</surname>
<given-names>Q</given-names>
</name>
<name>
<surname>Cavanagh</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Green</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>Familiarity and pop-out in visual search</article-title>
<source/>Percept Psychophys
          <year>1994</year>
<volume>56</volume>
<issue>5</issue>
<fpage>495</fpage>
<lpage>500</lpage>
<pub-id pub-id-type="doi">10.3758/BF03206946</pub-id>
<pub-id pub-id-type="pmid">7991347</pub-id>
</element-citation>
</ref>
<ref id="CR27">
<label>27.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wang</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Zhang</surname>
<given-names>K</given-names>
</name>
<name>
<surname>He</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Jiang</surname>
<given-names>Y</given-names>
</name>
</person-group>
<article-title>Searching for life motion signals: visual search asymmetry in local but not global biological-motion processing</article-title>
<source/>Psychol Sci
          <year>2010</year>
<volume>21</volume>
<issue>8</issue>
<fpage>1083</fpage>
<lpage>9</lpage>
<pub-id pub-id-type="doi">10.1177/0956797610376072</pub-id>
<pub-id pub-id-type="pmid">20581341</pub-id>
</element-citation>
</ref>
<ref id="CR28">
<label>28.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>LoBue</surname>
<given-names>V</given-names>
</name>
</person-group>
<article-title>More than just another face in the crowd: superior detection of threatening facial expressions in children and adults</article-title>
<source/>Dev Sci
          <year>2009</year>
<volume>12</volume>
<issue>2</issue>
<fpage>305</fpage>
<lpage>13</lpage>
<pub-id pub-id-type="doi">10.1111/j.1467-7687.2008.00767.x</pub-id>
<pub-id pub-id-type="pmid">19143803</pub-id>
</element-citation>
</ref>
<ref id="CR29">
<label>29.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>LoBue</surname>
<given-names>V</given-names>
</name>
<name>
<surname>DeLoache</surname>
<given-names>JS</given-names>
</name>
</person-group>
<article-title>Superior detection of threat-relevant stimuli in infancy</article-title>
<source/>Dev Sci
          <year>2010</year>
<volume>13</volume>
<issue>1</issue>
<fpage>221</fpage>
<lpage>8</lpage>
<pub-id pub-id-type="doi">10.1111/j.1467-7687.2009.00872.x</pub-id>
<pub-id pub-id-type="pmid">20121878</pub-id>
</element-citation>
</ref>
<ref id="CR30">
<label>30.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Schubo</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Gendolla</surname>
<given-names>GH</given-names>
</name>
<name>
<surname>Meinecke</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Abele</surname>
<given-names>AE</given-names>
</name>
</person-group>
<article-title>Detecting emotional faces and features in a visual search paradigm: are faces special?</article-title>
<source/>Emotion
          <year>2006</year>
<volume>6</volume>
<issue>2</issue>
<fpage>246</fpage>
<lpage>56</lpage>
<pub-id pub-id-type="doi">10.1037/1528-3542.6.2.246</pub-id>
<pub-id pub-id-type="pmid">16768557</pub-id>
</element-citation>
</ref>
<ref id="CR31">
<label>31.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Elgar</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Campbell</surname>
<given-names>R</given-names>
</name>
</person-group>
<article-title>Annotation: the cognitive neuroscience of face recognition: implications for developmental disorders</article-title>
<source/>J Child Psychol Psychiatry
          <year>2001</year>
<volume>42</volume>
<issue>6</issue>
<fpage>705</fpage>
<lpage>17</lpage>
<pub-id pub-id-type="doi">10.1111/1469-7610.00767</pub-id>
<pub-id pub-id-type="pmid">11583243</pub-id>
</element-citation>
</ref>
<ref id="CR32">
<label>32.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Deruelle</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Mancini</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Livet</surname>
<given-names>MO</given-names>
</name>
<name>
<surname>Casse-Perrot</surname>
<given-names>C</given-names>
</name>
<name>
<surname>de Schonen</surname>
<given-names>S</given-names>
</name>
</person-group>
<article-title>Configural and local processing of faces in children with Williams syndrome</article-title>
<source/>Brain Cogn
          <year>1999</year>
<volume>41</volume>
<issue>3</issue>
<fpage>276</fpage>
<lpage>98</lpage>
<pub-id pub-id-type="doi">10.1006/brcg.1999.1127</pub-id>
<pub-id pub-id-type="pmid">10585239</pub-id>
</element-citation>
</ref>
<ref id="CR33">
<label>33.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Karmiloff-Smith</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Crucial differences between developmental cognitive neuroscience and adult neuropsychology</article-title>
<source/>Dev Neuropsychol
          <year>1997</year>
<volume>13</volume>
<issue>4</issue>
<fpage>513</fpage>
<lpage>24</lpage>
<pub-id pub-id-type="doi">10.1080/87565649709540693</pub-id>
</element-citation>
</ref>
<ref id="CR34">
<label>34.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hoffman</surname>
<given-names>JE</given-names>
</name>
<name>
<surname>Landau</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Pagani</surname>
<given-names>B</given-names>
</name>
</person-group>
<article-title>Spatial breakdown in spatial construction: evidence from eye fixations in children with Williams syndrome</article-title>
<source/>Cogn Psychol
          <year>2003</year>
<volume>46</volume>
<issue>3</issue>
<fpage>260</fpage>
<lpage>301</lpage>
<pub-id pub-id-type="doi">10.1016/S0010-0285(02)00518-2</pub-id>
<pub-id pub-id-type="pmid">12694695</pub-id>
</element-citation>
</ref>
<ref id="CR35">
<label>35.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Nakamura</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Watanabe</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Matsumoto</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Yamanaka</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Kumagai</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Miyazaki</surname>
<given-names>S</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Williams syndrome and deficiency in visuospatial recognition</article-title>
<source/>Dev Med Child Neurol
          <year>2001</year>
<volume>43</volume>
<issue>9</issue>
<fpage>617</fpage>
<lpage>21</lpage>
<pub-id pub-id-type="doi">10.1017/S0012162201001128</pub-id>
<pub-id pub-id-type="pmid">11570631</pub-id>
</element-citation>
</ref>
<ref id="CR36">
<label>36.</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Bellugi</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Sabo</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Vaid</surname>
<given-names>J</given-names>
</name>
</person-group>
<person-group person-group-type="editor">
<name>
<surname>Stiles-Davis</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Kritchevshy</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Bellugi</surname>
<given-names>U</given-names>
</name>
</person-group>
<article-title>Spatial deficits in children with Williams syndrome</article-title>
<source/>Spatial cognition: Brain bases and development
          <year>1988</year>
<publisher-loc>Hillsdale, NJ</publisher-loc>
<publisher-name>Lawrence Erlbaum Associates, Inc.</publisher-name>
<fpage>273</fpage>
<lpage>97</lpage>
</element-citation>
</ref>
<ref id="CR37">
<label>37.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Leder</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Bruce</surname>
<given-names>V</given-names>
</name>
</person-group>
<article-title>When inverted faces are recognized: the role of configural information in face recognition</article-title>
<source/>Q J Exp Psychol A
          <year>2000</year>
<volume>53</volume>
<issue>2</issue>
<fpage>513</fpage>
<lpage>36</lpage>
<pub-id pub-id-type="doi">10.1080/713755889</pub-id>
<pub-id pub-id-type="pmid">10881616</pub-id>
</element-citation>
</ref>
<ref id="CR38">
<label>38.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Tanaka</surname>
<given-names>JW</given-names>
</name>
<name>
<surname>Farah</surname>
<given-names>MJ</given-names>
</name>
</person-group>
<article-title>Parts and wholes in face recognition</article-title>
<source/>Q J Exp Psychol A
          <year>1993</year>
<volume>46</volume>
<issue>2</issue>
<fpage>225</fpage>
<lpage>45</lpage>
<pub-id pub-id-type="doi">10.1080/14640749308401045</pub-id>
<pub-id pub-id-type="pmid">8316637</pub-id>
</element-citation>
</ref>
<ref id="CR39">
<label>39.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hochberg</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Galper</surname>
<given-names>RR</given-names>
</name>
</person-group>
<article-title>Recognition of faces: 1. An exploratory study</article-title>
<source/>Psychon Sci
          <year>1967</year>
<volume>9</volume>
<fpage>619</fpage>
<lpage>20</lpage>
<pub-id pub-id-type="doi">10.3758/BF03327918</pub-id>
</element-citation>
</ref>
<ref id="CR40">
<label>40.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Yin</surname>
<given-names>RK</given-names>
</name>
</person-group>
<article-title>Looking at upside-down faces</article-title>
<source/>J Exp Psychol
          <year>1969</year>
<volume>81</volume>
<fpage>141</fpage>
<lpage>5</lpage>
<pub-id pub-id-type="doi">10.1037/h0027474</pub-id>
</element-citation>
</ref>
<ref id="CR41">
<label>41.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rossion</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Gauthier</surname>
<given-names>I</given-names>
</name>
</person-group>
<article-title>How does the brain process upright and inverted faces?</article-title>
<source/>Behav Cogn Neurosci Rev
          <year>2002</year>
<volume>1</volume>
<issue>1</issue>
<fpage>63</fpage>
<lpage>75</lpage>
<pub-id pub-id-type="doi">10.1177/1534582302001001004</pub-id>
<pub-id pub-id-type="pmid">17715586</pub-id>
</element-citation>
</ref>
<ref id="CR42">
<label>42.</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Bellugi</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>PP</given-names>
</name>
<name>
<surname>Jernigan</surname>
<given-names>TL</given-names>
</name>
</person-group>
<person-group person-group-type="editor">
<name>
<surname>Broman</surname>
<given-names>SH</given-names>
</name>
<name>
<surname>Grafman</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>Williams syndrome: an unusual neuropsychological profile</article-title>
<source/>Atypical cognitive deficits in developmental disorders: implications for brain function
          <year>1994</year>
<publisher-loc>Hillsdale</publisher-loc>
<publisher-name>Erlbaum Associates</publisher-name>
<fpage>23</fpage>
<lpage>56</lpage>
</element-citation>
</ref>
<ref id="CR43">
<label>43.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rose</surname>
<given-names>FE</given-names>
</name>
<name>
<surname>Lincoln</surname>
<given-names>AJ</given-names>
</name>
<name>
<surname>Lai</surname>
<given-names>Z</given-names>
</name>
<name>
<surname>Ene</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Searcy</surname>
<given-names>YM</given-names>
</name>
<name>
<surname>Bellugi</surname>
<given-names>U</given-names>
</name>
</person-group>
<article-title>Orientation and affective expression effects on face recognition in Williams syndrome and autism</article-title>
<source/>J Autism Dev Disord
          <year>2007</year>
<volume>37</volume>
<issue>3</issue>
<fpage>513</fpage>
<lpage>22</lpage>
<pub-id pub-id-type="doi">10.1007/s10803-006-0200-4</pub-id>
<pub-id pub-id-type="pmid">16906460</pub-id>
</element-citation>
</ref>
<ref id="CR44">
<label>44.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Karmiloff-Smith</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Thomas</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Annaz</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Humphreys</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Ewing</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Brace</surname>
<given-names>N</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Exploring the Williams syndrome face-processing debate: the importance of building developmental trajectories</article-title>
<source/>J Child Psychol Psychiatry
          <year>2004</year>
<volume>45</volume>
<issue>7</issue>
<fpage>1258</fpage>
<lpage>74</lpage>
<pub-id pub-id-type="doi">10.1111/j.1469-7610.2004.00322.x</pub-id>
<pub-id pub-id-type="pmid">15335346</pub-id>
</element-citation>
</ref>
<ref id="CR45">
<label>45.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Grice</surname>
<given-names>SJ</given-names>
</name>
<name>
<surname>Spratling</surname>
<given-names>MW</given-names>
</name>
<name>
<surname>Karmiloff-Smith</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Halit</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Csibra</surname>
<given-names>G</given-names>
</name>
<name>
<surname>de Haan</surname>
<given-names>M</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Disordered visual processing and oscillatory brain activity in autism and Williams syndrome</article-title>
<source/>Neuroreport
          <year>2001</year>
<volume>12</volume>
<issue>12</issue>
<fpage>2697</fpage>
<lpage>700</lpage>
<pub-id pub-id-type="doi">10.1097/00001756-200108280-00021</pub-id>
<pub-id pub-id-type="pmid">11522950</pub-id>
</element-citation>
</ref>
<ref id="CR46">
<label>46.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Nakamura</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Watanabe</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Gunji</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Kakigi</surname>
<given-names>R</given-names>
</name>
</person-group>
<article-title>The magnetoencephalographic response to upright and inverted face stimuli in a patient with Williams syndrome</article-title>
<source/>Pediatr Neurol
          <year>2006</year>
<volume>34</volume>
<issue>5</issue>
<fpage>412</fpage>
<lpage>4</lpage>
<pub-id pub-id-type="doi">10.1016/j.pediatrneurol.2005.11.005</pub-id>
<pub-id pub-id-type="pmid">16648006</pub-id>
</element-citation>
</ref>
<ref id="CR47">
<label>47.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hirai</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Muramatsu</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Mizuno</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Kurahashi</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Kurahashi</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Nakamura</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>Intact attentional orienting towards inverted faces revealed by both manual responses and eye-movement measurement in individuals with Williams syndrome</article-title>
<source/>J Intellect Disabil Res
          <year>2016</year>
<volume>60</volume>
<fpage>969</fpage>
<lpage>81</lpage>
<pub-id pub-id-type="doi">10.1111/jir.12318</pub-id>
<pub-id pub-id-type="pmid">27476718</pub-id>
</element-citation>
</ref>
<ref id="CR48">
<label>48.</label>
<mixed-citation publication-type="other">Hirai M, Muramatsu Y, Mizuno S, Kurahashi H, Kurahashi N, Nakamura M. Typical visual search performance and atypical gaze behaviors in response to faces in Williams syndrome. J Neurodev Disord. in press.</mixed-citation>
</ref>
<ref id="CR49">
<label>49.</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Sugishita</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Yamazaki</surname>
<given-names>K</given-names>
</name>
</person-group>
<source/>Raven's coloured progressive matrices (in Japanese)
          <year>1993</year>
<publisher-loc>Tokyo</publisher-loc>
<publisher-name>Nihon Bunka Kagakusya</publisher-name>
</element-citation>
</ref>
<ref id="CR50">
<label>50.</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Raven</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Raven</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Court</surname>
<given-names>J</given-names>
</name>
</person-group>
<source/>Manual for Raven’s progressive matrices and vocabulary scales
          <year>1998</year>
<publisher-loc>Oxford</publisher-loc>
<publisher-name>Oxford Psychologists Press</publisher-name>
</element-citation>
</ref>
<ref id="CR51">
<label>51.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Willenbockel</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Sadr</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Fiset</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Horne</surname>
<given-names>GO</given-names>
</name>
<name>
<surname>Gosselin</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Tanaka</surname>
<given-names>JW</given-names>
</name>
</person-group>
<article-title>Controlling low-level image properties: the SHINE toolbox</article-title>
<source/>Behav Res Methods
          <year>2010</year>
<volume>42</volume>
<issue>3</issue>
<fpage>671</fpage>
<lpage>84</lpage>
<pub-id pub-id-type="doi">10.3758/BRM.42.3.671</pub-id>
<pub-id pub-id-type="pmid">20805589</pub-id>
</element-citation>
</ref>
<ref id="CR52">
<label>52.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Miller</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>A warning about median reaction time</article-title>
<source/>J Exp Psychol Hum Percept Perform
          <year>1988</year>
<volume>14</volume>
<issue>3</issue>
<fpage>539</fpage>
<lpage>43</lpage>
<pub-id pub-id-type="doi">10.1037/0096-1523.14.3.539</pub-id>
<pub-id pub-id-type="pmid">2971778</pub-id>
</element-citation>
</ref>
<ref id="CR53">
<label>53.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Haas</surname>
<given-names>BW</given-names>
</name>
<name>
<surname>Mills</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Yam</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Hoeft</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Bellugi</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Reiss</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Genetic influences on sociability: heightened amygdala reactivity and event-related responses to positive social stimuli in Williams syndrome</article-title>
<source/>J Neurosci
          <year>2009</year>
<volume>29</volume>
<issue>4</issue>
<fpage>1132</fpage>
<lpage>9</lpage>
<pub-id pub-id-type="doi">10.1523/JNEUROSCI.5324-08.2009</pub-id>
<pub-id pub-id-type="pmid">19176822</pub-id>
</element-citation>
</ref>
<ref id="CR54">
<label>54.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Piech</surname>
<given-names>RM</given-names>
</name>
<name>
<surname>McHugo</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Smith</surname>
<given-names>SD</given-names>
</name>
<name>
<surname>Dukic</surname>
<given-names>MS</given-names>
</name>
<name>
<surname>Van Der Meer</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Abou-Khalil</surname>
<given-names>B</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Fear-enhanced visual search persists after amygdala lesions</article-title>
<source/>Neuropsychologia
          <year>2010</year>
<volume>48</volume>
<issue>12</issue>
<fpage>3430</fpage>
<lpage>5</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2010.07.009</pub-id>
<pub-id pub-id-type="pmid">20637217</pub-id>
</element-citation>
</ref>
<ref id="CR55">
<label>55.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Holland</surname>
<given-names>PC</given-names>
</name>
<name>
<surname>Gallagher</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>Amygdala circuitry in attentional and representational processes</article-title>
<source/>Trends Cogn Sci
          <year>1999</year>
<volume>3</volume>
<issue>2</issue>
<fpage>65</fpage>
<lpage>73</lpage>
<pub-id pub-id-type="doi">10.1016/S1364-6613(98)01271-6</pub-id>
<pub-id pub-id-type="pmid">10234229</pub-id>
</element-citation>
</ref>
<ref id="CR56">
<label>56.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Maddux</surname>
<given-names>JM</given-names>
</name>
<name>
<surname>Kerfoot</surname>
<given-names>EC</given-names>
</name>
<name>
<surname>Chatterjee</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Holland</surname>
<given-names>PC</given-names>
</name>
</person-group>
<article-title>Dissociation of attention in learning and action: effects of lesions of the amygdala central nucleus, medial prefrontal cortex, and posterior parietal cortex</article-title>
<source/>Behav Neurosci
          <year>2007</year>
<volume>121</volume>
<issue>1</issue>
<fpage>63</fpage>
<lpage>79</lpage>
<pub-id pub-id-type="doi">10.1037/0735-7044.121.1.63</pub-id>
<pub-id pub-id-type="pmid">17324051</pub-id>
</element-citation>
</ref>
<ref id="CR57">
<label>57.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Nobre</surname>
<given-names>AC</given-names>
</name>
<name>
<surname>Coull</surname>
<given-names>JT</given-names>
</name>
<name>
<surname>Walsh</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Frith</surname>
<given-names>CD</given-names>
</name>
</person-group>
<article-title>Brain activations during visual search: contributions of search efficiency versus feature binding</article-title>
<source/>Neuroimage
          <year>2003</year>
<volume>18</volume>
<issue>1</issue>
<fpage>91</fpage>
<lpage>103</lpage>
<pub-id pub-id-type="doi">10.1006/nimg.2002.1329</pub-id>
<pub-id pub-id-type="pmid">12507447</pub-id>
</element-citation>
</ref>
</ref-list>
</back>
</article>
</pmc-articleset>