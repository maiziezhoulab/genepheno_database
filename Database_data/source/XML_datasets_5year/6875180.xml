<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="research-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">Comput Math Methods Med</journal-id>
<journal-id journal-id-type="iso-abbrev">Comput Math Methods Med</journal-id>
<journal-id journal-id-type="publisher-id">CMMM</journal-id>
<journal-title-group>
<journal-title>Computational and Mathematical Methods in Medicine</journal-title>
</journal-title-group>
<issn pub-type="ppub">1748-670X</issn>
<issn pub-type="epub">1748-6718</issn>
<publisher>
<publisher-name>Hindawi</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">31781290</article-id>
<article-id pub-id-type="pmc">6875180</article-id>
<article-id pub-id-type="doi">10.1155/2019/9108108</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Resting-State Functional Network Scale Effects and Statistical Significance-Based Feature Selection in Machine Learning Classification</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id authenticated="false" contrib-id-type="orcid">https://orcid.org/0000-0002-3463-5739</contrib-id>
<name>
<surname>Guo</surname>
<given-names>Hao</given-names>
</name>
<email>feiyu_guo@sina.com</email>
<xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id authenticated="false" contrib-id-type="orcid">https://orcid.org/0000-0001-7589-7244</contrib-id>
<name>
<surname>Li</surname>
<given-names>Yao</given-names>
</name>
<xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id authenticated="false" contrib-id-type="orcid">https://orcid.org/0000-0001-7157-8676</contrib-id>
<name>
<surname>Mensah</surname>
<given-names>Godfred Kim</given-names>
</name>
<xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Xu</surname>
<given-names>Yong</given-names>
</name>
<xref ref-type="aff" rid="I2">
<sup>2</sup>
</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id authenticated="false" contrib-id-type="orcid">https://orcid.org/0000-0001-8859-9393</contrib-id>
<name>
<surname>Chen</surname>
<given-names>Junjie</given-names>
</name>
<xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Xiang</surname>
<given-names>Jie</given-names>
</name>
<xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id authenticated="false" contrib-id-type="orcid">https://orcid.org/0000-0002-3509-0486</contrib-id>
<name>
<surname>Chen</surname>
<given-names>Dongwei</given-names>
</name>
<email>chendwzsc@zsc.edu.cn</email>
<xref ref-type="aff" rid="I1">
<sup>1</sup>
</xref>
<xref ref-type="aff" rid="I3">
<sup>3</sup>
</xref>
</contrib>
</contrib-group>
<aff id="I1">
<sup>1</sup>College of Information and Computer, Taiyuan University of Technology, Taiyuan, China</aff>
<aff id="I2">
<sup>2</sup>Department of Psychiatry, First Hospital of Shanxi Medical University, Taiyuan, China</aff>
<aff id="I3">
<sup>3</sup>School of Electronic Information Engineering, University of Electronic Science and Technology of China, Zhongshan Institute, Zhongshan, China</aff>
<author-notes>
<fn fn-type="other">
<p>Academic Editor: Jlenia Toppi</p>
</fn>
</author-notes>
<pub-date pub-type="collection">
<year>2019</year>
</pub-date>
<pub-date pub-type="epub">
<day>4</day>
<month>11</month>
<year>2019</year>
</pub-date>
<volume>2019</volume>
<elocation-id>9108108</elocation-id>
<history>
<date date-type="received">
<day>18</day>
<month>4</month>
<year>2019</year>
</date>
<date date-type="rev-recd">
<day>4</day>
<month>8</month>
<year>2019</year>
</date>
<date date-type="accepted">
<day>6</day>
<month>9</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-statement>Copyright © 2019 Hao Guo et al.</copyright-statement>
<copyright-year>2019</copyright-year>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/">
<license-p>This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
</license>
</permissions>
<abstract>
<p>In recent years, functional brain network topological features have been widely used as classification features. Previous studies have found that network node scale differences caused by different network parcellation definitions significantly affect the structure of the constructed network and its topological properties. However, we still do not know how network scale differences affect the classification accuracy, performance of classification features, and effectiveness of the feature selection strategy using <italic>P</italic> values in terms of the machine learning method. This study used five scale parcellations, involving 90, 256, 497, 1003, and 1501 nodes. Three local properties of resting-state functional brain networks were selected (degree, betweenness centrality, and nodal efficiency), and the support vector machine method was used to construct classifiers to identify patients with major depressive disorder. We analyzed the impact of the five scales on classification accuracy. In addition, the effectiveness and redundancy of features obtained by the different scale parcellations were compared. Finally, traditional statistical significance (<italic>P</italic> value) was verified as a feature selection criterion. The results showed that the feature effectiveness of different scales was similar; in other words, parcellation with more regions did not provide more effective discriminative features. Nevertheless, parcellation with more regions did provide a greater quantity of discriminative features, which led to an improvement in the accuracy of the classification. However, due to the close distance between brain regions, the redundancy of parcellation with more regions was also greater. The traditional <italic>P</italic> value feature selection strategy is feasible with different scales, but our analysis showed that the traditional <italic>P</italic> &lt; 0.05 threshold was too strict for feature selection. This study provides an important reference for the selection of network scales when applying topological properties of brain networks to machine learning methods.</p>
</abstract>
<funding-group>
<award-group>
<funding-source>National Natural Science Foundation of China</funding-source>
<award-id>61672374</award-id>
<award-id>61741212</award-id>
<award-id>61876124</award-id>
<award-id>61873178</award-id>
</award-group>
<award-group>
<funding-source>Natural Science Foundation of Shanxi Province</funding-source>
<award-id>201701D221119</award-id>
<award-id>201801D121135</award-id>
</award-group>
<award-group>
<funding-source>CERNET Innovation Project</funding-source>
<award-id>NGII20170712</award-id>
</award-group>
<award-group>
<funding-source>Key Research and Development (R&amp;D) Projects of Shanxi Province</funding-source>
<award-id>201803D31043</award-id>
</award-group>
</funding-group>
</article-meta>
</front>
<body>
<sec id="sec1">
<title>1. Introduction</title>
<p>Machine learning and pattern recognition methods have been widely used in functional magnetic resonance (fMRI) data analysis in studies of brain thinking and cognitive state (for review, see [<xref ref-type="bibr" rid="B1">1</xref>]). The classification features selected for fMRI analysis are mostly direct features of the blood oxygen level-dependent (BOLD) signal, including peak, peak time, and slope (for review, see [<xref ref-type="bibr" rid="B2">2</xref>]), regardless of whether the analysis involves task-state fMRI [<xref ref-type="bibr" rid="B3">3</xref>, <xref ref-type="bibr" rid="B4">4</xref>] or resting-state (rs) fMRI [<xref ref-type="bibr" rid="B5">5</xref>].</p>
<p>In recent years, with the development of functional brain network research, more and more researchers have found that the rich topological information of functional networks can be used as biological markers for various neuropsychiatric diseases [<xref ref-type="bibr" rid="B6">6</xref>–<xref ref-type="bibr" rid="B9">9</xref>]. The extracted network topological features are widely used in the construction of classification models to assist in the diagnosis of brain diseases (for review, see [<xref ref-type="bibr" rid="B10">10</xref>]).</p>
<p>The topological features selected have usually included global properties [<xref ref-type="bibr" rid="B11">11</xref>], local properties [<xref ref-type="bibr" rid="B12">12</xref>], community structures [<xref ref-type="bibr" rid="B13">13</xref>], and connections [<xref ref-type="bibr" rid="B14">14</xref>]. In recent years, researchers have proposed new methods for network feature analysis, which have been applied in brain disease machine learning research, such as hypergraph [<xref ref-type="bibr" rid="B15">15</xref>], high-order network [<xref ref-type="bibr" rid="B16">16</xref>], minimum spanning tree [<xref ref-type="bibr" rid="B17">17</xref>], and frequent subgraphs [<xref ref-type="bibr" rid="B18">18</xref>] methods. Brain network topological features provide a new perspective for combined research using fMRI and machine learning.</p>
<p>At present, this field is still in the exploration stage, and many methodological issues still need to be resolved. One of the important issues is how to make a reasonable parcellation selection to define network nodes. Previous studies have found that different network node scales (related to different brain network parcellation templates) significantly impact the structure of the constructed network and its topological properties [<xref ref-type="bibr" rid="B19">19</xref>, <xref ref-type="bibr" rid="B20">20</xref>], such as the network's small-world properties [<xref ref-type="bibr" rid="B19">19</xref>, <xref ref-type="bibr" rid="B21">21</xref>], local properties [<xref ref-type="bibr" rid="B19">19</xref>–<xref ref-type="bibr" rid="B21">21</xref>], functional connection strength [<xref ref-type="bibr" rid="B19">19</xref>], and network connectivity [<xref ref-type="bibr" rid="B19">19</xref>].</p>
<p>In addition, the impact of network node scale on the network is reflected in the classification features by network topology properties. When the discriminative features extracted from networks with a different number of nodes are applied to machine learning classifiers, they influence the classification accuracy. In a previous study, Jing et al. [<xref ref-type="bibr" rid="B22">22</xref>] used two scales of the Anatomical Automatic Labeling (AAL) atlas, AAL-90 (90 nodes), and AAL-1024 (1024 nodes) to study the identification of major depressive disorder (MDD) patients, and they found that the recognition performance of the AAL-1024 parcellation was better than that of the traditional AAL-90 parcellation. In another study, Ota et al. [<xref ref-type="bibr" rid="B23">23</xref>] used AAL (90 nodes) parcellation and LPBA40 (54 nodes) parcellation to study the impact of parcellation and discriminative feature selection on the prediction of Alzheimer's disease (AD), and they found that the classification accuracy was low when there was a small number of nodes. Mesrob et al. [<xref ref-type="bibr" rid="B24">24</xref>] used AAL (90 nodes) parcellation and 487ROI (487 nodes) parcellation for the identification of patients with AD/mild cognitive impairment. Abnormal properties were identified as classification features, and the accuracy of the classification features was higher for a large network than for a small network.</p>
<p>Previous studies have consistently verified that the network scale affects classification accuracy; the accuracy of parcellation with more regions is higher than that associated with fewer regions. However, a potential problem in the previous studies was that the number of parcellations used was few (only two mostly), which did not allow for much comparison. In addition, previous studies only analyzed the final classification accuracy and ignored the actual performance of the selected features.</p>
<p>Furthermore, in terms of the feature selection, many previous studies have used the statistical analysis <italic>P</italic> value as the feature selection criterion. A review was conducted of 76 recent studies on machine learning related to brain networks (Supplemental Material <xref ref-type="supplementary-material" rid="supplementary-material-1"></xref>). Some of these studies were cited in a 2016 review of the literature on machine learning and brain networks [<xref ref-type="bibr" rid="B25">25</xref>] and a 2016 review of the literature on depression and machine learning [<xref ref-type="bibr" rid="B26">26</xref>]. Additional studies published in the past three years (2016–2018) were included. The review showed that there were 31 (40.78%) studies that selected the <italic>P</italic> value or a combination of the <italic>P</italic> value and other metrics as the feature selection strategy. This result showed that the <italic>P</italic> value is one of the most common feature selection strategies in this field. However, there is a potential risk in that the threshold <italic>P</italic> value was always arbitrarily set as 0.05 or 0.01, ignoring the possible contribution of additional features to the classification.</p>
<p>At present, we still do not know precisely how network scale affects the performance of classification features and classification accuracy, and effectiveness of the feature selection strategy using <italic>P</italic> values. In this context, this study applied five different node parcellations to construct and analyze the resting-state functional brain network of a control group and a disease group (involving patients with depression). The local topological properties with significant between-group differences were then extracted as classification features and applied to the classifiers. Finally, we analyzed the classification accuracy, feature performance, and feature selection strategy. To be precise, the study had the following four objectives: (1) to define five scale parcellations, comprising 90, 256, 497, 1003, and 1501 nodes; (2) to analyze the effects of these five parcellations on classification accuracy; (3) to analyze and compare the feature effectiveness and redundancy among the different scales; and (4) to investigate the feasibility and reasonable threshold regarding the <italic>P</italic> value feature selection strategy. This study provides an important reference for selecting the network scale for future applications of brain network topological properties to machine learning methods.</p>
</sec>
<sec id="sec2">
<title>2. Materials and Methods</title>
<sec id="sec2.1">
<title>2.1. Proposed Framework</title>
<p>Data classification rs-fMRI methods usually include data preprocessing, construction of functional connectivity networks, feature selection, and classification. Specifically, the framework consists of the following steps:<list list-type="order"><list-item><p>Data acquisition and preprocessing.</p></list-item><list-item><p>Construction of functional connectivity networks.<list list-type="alpha-lower"><list-item><p>Definition of parcellations. Application of <italic>k</italic>-means clustering to subdivide brain regions based on the AAL atlas.</p></list-item><list-item><p>Connection definition and threshold selection. Using the Pearson correlation approach, calculating the degree of correlation of the average time series of each region. Sparsity <italic>S</italic> is used for the threshold setting.</p></list-item></list></p></list-item><list-item><p>Feature selection and classification model construction (applying five node parcellations).<list list-type="alpha-lower"><list-item><p>Calculation of basic local metrics: degree, betweenness centrality, and nodal efficiency for each node.</p></list-item><list-item><p>Use of the <italic>P</italic> value to select the discriminative features as classification features and constructing the classifier.</p></list-item><list-item><p>Use of cross-validation to test the constructed classifiers, obtaining the final classification results, and analysis of the effects of five scale parcellations on classification accuracy.</p></list-item></list></p></list-item><list-item><p>Feature effectiveness evaluation.<list list-type="alpha-lower"><list-item><p>Evaluation of the effectiveness of the selected features, adopting the minimum redundancy-maximum relevance (mRMR) method.</p></list-item><list-item><p>Investigation of the feasibility and reasonable threshold regarding the <italic>P</italic> value feature selection strategy.</p></list-item></list></p></list-item></list></p>
</sec>
<sec id="sec2.2">
<title>2.2. Subjects</title>
<p>In this study, 66 subjects were recruited, including 38 patients for the depression group and 28 age- and gender-matched healthy volunteers as a control group. All subjects were Han Chinese. Based on the Structured Clinical Interview for DSM-III-R Axis II Disorders (SCID-II) [<xref ref-type="bibr" rid="B27">27</xref>], no subjects in the control group had a history of mental or neurological disorders. All patients in the depression group were diagnosed with single-episode major depressive disorder, as defined by the Diagnostic and Statistical Manual of Mental Disorders Fourth Edition (DSM-IV) [<xref ref-type="bibr" rid="B28">28</xref>], at the Department of Mental Health, First Hospital of Shanxi Medical University, and all were medication naive. The severity of depression was assessed using the 24-item Hamilton Rating Scale for Depression (HRSD) [<xref ref-type="bibr" rid="B29">29</xref>] and Clinical Global Impression of Severity (CGI-S) [<xref ref-type="bibr" rid="B30">30</xref>]. Before scan, each subject provided written informed consent (the control group subjects provided consent by themselves and the depression group subjects provided consent with their family members). The demographic and clinical characteristics of the subjects are shown in <xref ref-type="table" rid="tab1">Table 1</xref>.</p>
</sec>
<sec id="sec2.3">
<title>2.3. Data Acquisition and Preprocessing</title>
<p>All subjects underwent rs-fMRI in a 3T magnetic resonance scanner (Siemens Trio 3-Tesla scanner, Siemens, Erlangen, Germany). Data collection and prepossessing were conducted at the First Hospital of Shanxi Medical University. All scans were performed by radiologists who were familiar with fMRI methods. During the scan, subjects were asked to relax and close their eyes but not fall asleep. Subjects were provided with soft earplugs and positioned carefully in the coil with comfortable support. Each scan consisted of 248 contiguous echo planar imaging (EPI) functional volumes (33 axial slices, repetition time [TR] = 2000 ms, echo time [TE] = 30 ms, thickness/skip = 4/0 mm, field of view [FOV] = 192 × 192 mm, matrix = 64 × 64 mm, and flip angle = 90°) and the first 10 volumes of time series data were discarded to allow for magnetization stabilization. See Supplemental <xref ref-type="supplementary-material" rid="supplementary-material-1"></xref> for detailed scanning parameters.</p>
<p>For the data preprocessing process, we followed the methods of one of our previous researches [<xref ref-type="bibr" rid="B31">31</xref>]. Data preprocessing was performed using Statistical Parametric Mapping (SPM8) software [<xref ref-type="bibr" rid="B32">32</xref>]. First, slice-timing correction and head motion correction were carried out. Three samples, exhibiting more than 3.0 mm of translation and 3.0° of rotation, were excluded, leaving a final dataset of 66 samples. The corrected images were then optimized using a 12-dimensional affine transformation and normalized to a voxel size of 3 × 3 × 3 mm in Montreal Neurological Institute (MNI) standard space [<xref ref-type="bibr" rid="B32">32</xref>]. Finally, linear detrending and bandpass filtering (0.01–0.10 Hz) were performed to reduce the effects of low-frequency drift and high-frequency physiological noise. Each regional mean time series was regressed against the mean cerebrospinal fluid and white matter signals as well as the six parameters from motion correction. The residuals of these regressions constituted a set of regional mean time series that were used for undirected graph analysis. Considering the debate regarding the validity of global signal regression in fMRI studies [<xref ref-type="bibr" rid="B33">33</xref>, <xref ref-type="bibr" rid="B34">34</xref>], we did not perform global signal regression during preprocessing.</p>
</sec>
<sec id="sec2.4">
<title>2.4. Definition of Parcellations</title>
<p>To achieve many different segmentation parcellations, we adopted the <italic>k</italic>-means clustering algorithm. Additionally, to avoid the influence of randomness in the initial seed set on the segmentation parcellation, we used a random seed set method. Thus, a random seed voxels method, based on <italic>k</italic>-means clustering, was used to subdivide brain regions based on the AAL atlas. We dynamically adjusted the location of the seed voxels to avoid a randomization impact on the node definition. The specific method was as follows. We tested 250, 500, 1000, and 1500 nodes, along with the definition of 90 nodes of the original AAL template, and a total of five parcellation templates were obtained. We calculated the total gray matter volume proportion, <italic>V</italic>, of each AAL node. We then determined the number of subregions as <italic>k</italic> = <italic>VN</italic> in each original region, such that the brain region (BR) was subdivided into <italic>k</italic> subregions under the <italic>N</italic> parcellation, where <italic>N</italic> is the expected number of nodes. Next, we designated <italic>k</italic> random seed voxels as <italic>S</italic> = <italic>s</italic><sub>1</sub>, <italic>s</italic><sub>2</sub>, <italic>s</italic><sub>3</sub>,…, <italic>s</italic><sub><italic>k</italic></sub> in the BR. In turn, we then calculated the Euclidean distance between all residual voxels and the <italic>s</italic><sub><italic>i</italic></sub> seed voxels. Thereafter, the current voxel, <italic>v</italic>, was combined with the nearest seed voxel, <italic>s</italic><sub><italic>i</italic></sub>, to define a new subregion, and the physical center of <italic>v</italic> and <italic>s</italic><sub><italic>i</italic></sub> was set as a new seed voxel. These steps were repeated until all voxels of the whole brain were divided. At this point, BR was divided into <italic>k</italic> subregions, and all brain regions after division showed the expected parcellation based on <italic>N</italic>.</p>
<p>It is worth noting that this method can only be applied to independent AAL brain regions when dividing brain regions. Voxels in adjacent brain regions of the AAL atlas remain separate at present, even if their Euclidean distance is small. In addition, the volume proportion, <italic>V</italic>, of the brain region is not always an integer, in which case, the values are rounded. This produces a slight deviation between the actual number of nodes and the expected number of nodes, <italic>N</italic>.</p>
<p>We tested <italic>N</italic> values of 250, 500, 1000, and 1500, comprising 256, 497, 1003, and 1501 regions, respectively. Including the original AAL template, this study thus defined five parcellations, designated AAL90, Parc256, Parc497, Parc1003, and Parc1501. The prefix AAL denoted the original AAL atlas. The prefix Parc denotes templates, which were determined using the algorithm described above (For an illustration of the five parcellations, see Supplemental Material <xref ref-type="supplementary-material" rid="supplementary-material-1"></xref>. For the Nii files, see Supplemental Material Digital Files <xref ref-type="supplementary-material" rid="supplementary-material-1"></xref>. For an illustration of the parcellation definitions, see Supplemental Material <xref ref-type="supplementary-material" rid="supplementary-material-1"></xref>).</p>
</sec>
<sec id="sec2.5">
<title>2.5. Connection Definition and Threshold Selection</title>
<p>For the connection definition and threshold selection, we followed the methods of one of our previous researches [<xref ref-type="bibr" rid="B31">31</xref>]. The Pearson correlation coefficient was used to define the network edge in this study. First, we calculated the mean time courses of each node and then performed multiple linear regression to remove the pseudodifferences caused by head movement. The residuals were used to compute the partial correlation, producing an <italic>N</italic> × <italic>N</italic> correlation matrix, where <italic>N</italic> represents the number of nodes in a given parcellation. According to the predetermined threshold, the correlation matrix was converted into a binary matrix (For the mathematical definition of the Pearson correlation coefficient, see Supplemental Material <xref ref-type="supplementary-material" rid="supplementary-material-1"></xref>).</p>
<p>Sparsity, <italic>S</italic>, which is the ratio of the number of real existing edges to the maximum possible number of existing edges [<xref ref-type="bibr" rid="B35">35</xref>], was used as the threshold setting. This method has been widely adopted in similar studies [<xref ref-type="bibr" rid="B36">36</xref>–<xref ref-type="bibr" rid="B39">39</xref>]. To ensure the comparability of results between the parcellations, the threshold space <italic>S</italic>∈(8%, 32%) of the AAL90 parcellation was used as the standard for all five parcellations, and the brain functional networks of all subjects were constructed with an <italic>S</italic> step size of 5% within the threshold space (For details of the threshold selection criteria, see Supplementary Material <xref ref-type="supplementary-material" rid="supplementary-material-1"></xref>).</p>
<p>To characterize the integrity properties of a metric in the complete sparsity space, we calculated the area under the curve (AUC) for each metric. AUC provides a method to assess the total change in the network node properties under different degrees of sparseness. This method has been applied in previous research, which showed that it represents a very sensitive method to assess changes in the topological properties of a brain network [<xref ref-type="bibr" rid="B21">21</xref>].</p>
</sec>
<sec id="sec2.6">
<title>2.6. Network Metrics and Statistical Analysis</title>
<p>Network metrics can characterize the topological properties of a network [<xref ref-type="bibr" rid="B40">40</xref>]. We chose three basic local metrics: degree, betweenness centrality, and nodal efficiency (For the mathematical definitions and interpretation of these network metrics, see Supplementary Material <xref ref-type="supplementary-material" rid="supplementary-material-1"></xref>).</p>
<p>The nonparametric Kolmogorov–Smirnov test was to determine whether there were significant differences in the network metrics for each brain region between the depression and normal groups [<xref ref-type="bibr" rid="B41">41</xref>]. Thereafter, the Benjamini &amp; Hochberg false-discovery rate (FDR) method (<italic>q</italic> = 0.05) was used. This FDR method, which retains strong control over type 1 errors in the context of multiple comparisons, is considered appropriate to correct the comparative results of small samples [<xref ref-type="bibr" rid="B42">42</xref>].</p>
</sec>
<sec id="sec2.7">
<title>2.7. Feature Selection and Classification</title>
<p>The process of feature selection and cross-validation included the following steps: (1) calculating three local properties (degree, betweenness centrality, and nodal efficiency) at each scale; (2) performing the Kolmogorov–Smirnov test for each property at each scale; (3) selecting the properties with significant between-group differences as discriminative features to construct feature subsets (<italic>P</italic> &lt; 0.05, FDR corrected) at each scale separately; and (4) conducting cross-validation (10-fold, 100 times) at each scale separately.</p>
<p>The support vector machine (SVM) method was used to construct the classifiers, which has been frequently used in previous research [<xref ref-type="bibr" rid="B43">43</xref>–<xref ref-type="bibr" rid="B46">46</xref>]. In particular, the SVM method exhibits a good classification effect for small sample data [<xref ref-type="bibr" rid="B47">47</xref>]. The LIBSVM Toolkit (<ext-link ext-link-type="uri" xlink:href="http://www.csie.ntu.edu.tw/~cjlin/libsvm">http://www.csie.ntu.edu.tw/∼cjlin/libsvm</ext-link>) was used, and the SVM parameter settings were as follows: kernel function = linear; stopping criteria = 1 × 10<sup>−3</sup>; regression precision = 0.1; bias = 0; and degree = 3.</p>
<p>Selecting the kernel function in the classification is the key. Linear kernel function was used for classification, and 10-fold cross-validation [<xref ref-type="bibr" rid="B48">48</xref>] was used to evaluate the classifier performance (it was repeated 100 times to obtain more accurate results). For cross-validation, the data were randomly divided into two sets: a training set and a test set. The training set was used to estimate the model parameters, and the test set was used to evaluate the model. More precisely, the subjects were randomly divided into ten equal parts, of which nine represented the training set, and the remaining one represented the test set.</p>
</sec>
<sec id="sec2.8">
<title>2.8. Classification Feature Evaluation</title>
<p>To evaluate the effectiveness of the selected features, we adopted the mRMR method [<xref ref-type="bibr" rid="B49">49</xref>]. Using this method, mutual information was used to evaluate the degree of correlation between the features and groups (i.e., depression and control groups). This method can also assess the similarity between selected features. Metric mutual information difference (MID) represents the difference between the maximum correlation value and minimum redundancy value; in other words, the information gap. Metric redundancy (<italic>R</italic>) represents the dependency relationship between the discriminative features. The correlation between each of the discriminative features should be minimal; that is, the principle of minimum redundancy. For the mathematical definitions of these metrics, see <xref ref-type="table" rid="tab2">Table 2</xref>. For details of mRMR, see Supplemental Material <xref ref-type="supplementary-material" rid="supplementary-material-1"></xref>. We used the mRMR Toolkit (<ext-link ext-link-type="uri" xlink:href="http://home.penglab.com/proj/mRMR/">http://home.penglab.com/proj/mRMR/</ext-link>) to calculate the MID and <italic>R</italic> values.</p>
</sec>
</sec>
<sec id="sec3">
<title>3. Results</title>
<sec id="sec3.1">
<title>3.1. Feature Selection and Classification Based on <italic>P</italic> &lt; 0.05</title>
<p>We constructed functional networks with five scales and calculated three local topological properties (degree, betweenness centrality, and nodal efficiency). The AUC method was performed to unify local properties among different sparsities. The total number of features were 270 (AAL90), 768 (Parc256), 1491 (Parc497), 3009 (Parc1003), and 4503 (Parc1501). The <italic>P</italic> value was used as the feature selection criterion, and local topological properties with significant between-group differences (<italic>P</italic> &lt; 0.05, FDR corrected) were used as discriminative features. The results showed that as the number of network nodes increased, the number of discriminative features for each local property increased; the classification accuracy of the classifier also rose (<xref ref-type="table" rid="tab3">Table 3</xref>).</p>
<p>To eliminate the influence of the number of features, the same number of features was selected among different scales, and the classifiers were reconstructed (including 10-fold cross-validation with 100 repeats). Specific classification steps were descripted in <xref ref-type="sec" rid="sec2.7">Section 2.7</xref>. The results showed that the higher the number of nodes, the higher the classification accuracy (<xref ref-type="fig" rid="fig1">Figure 1(a)</xref>). Additionally, the classification feature performance of a large network was better than that of a small network with the same number of features (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Here, in Figures <xref ref-type="fig" rid="fig1">1</xref> and <xref ref-type="fig" rid="fig2">2</xref>, the number of features, 16, 48, 95, 186, 240 in <italic>x</italic> axis, was defined by the number of discriminative features obtained at each node scale (corresponding with AAL90, Parc256, Parc497, Parc1003, and Parc1501). The histogram with bar with an abscissa of 16 indicates the classification accuracy of the selected top 16 discriminative features sorted by the <italic>P</italic> value from lowest to highest at each scale. It should be noted that the histogram with bar with an abscissa of 48 represents the accuracy of 48 discriminative features at each scale except AAL90. Because when the node scale is 90, the number of discriminative features is not enough (only 16). The classification accuracy of discriminative features obtained from AAL90 is not listed at the abscissa of 48. Other numbers of features were similar.</p>
<p>Furthermore, in order to verify whether there was overfitting problem at each node scale, we calculated the training accuracy and performed the regression analysis between training accuracy and test accuracy at each node scale (<xref ref-type="fig" rid="fig1">Figure 1(b)</xref>). Specifically, similar to the test accuracy, 10-fold cross-validation with 100 times was performed to calculate training accuracy, whose arithmetic mean was used as the final training accuracy. The results show that the difference between the training accuracy and the corresponding test accuracy at each feature scale is not very large and is about 2%–4%. Moreover, regression analysis was performed between the training accuracy and test accuracy at each node scale. The results showed that at each node scale, regardless of which feature numbers, the training accuracy was positively correlated with the test accuracy, that is, the higher the training accuracy, the higher the test accuracy. It can be seen that the classification of different feature numbers was not affected by overfitting significantly. A more detailed discussion about overfitting problem can be seen in <xref ref-type="sec" rid="sec4.5">Section 4.5</xref>.</p>
</sec>
<sec id="sec3.2">
<title>3.2. Effectiveness Analysis of all Features</title>
<p>To illustrate the classification performance of all features for the five scales, we calculated the effectiveness of each feature and then analyzed the proportion and frequency distributions. The results showed that the distributions of all five scales were Gaussian (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The larger the network, the greater the number of features (<xref ref-type="fig" rid="fig3">Figure 3(a)</xref>). In addition, the frequency distribution showed that the feature-fit curves of the five scales overlapped (<xref ref-type="fig" rid="fig3">Figure 3(b)</xref>), suggesting that an increase or decrease in the number of network nodes did not directly affect the effectiveness of the features.</p>
<p>Previous research used <italic>P</italic> values as feature selection criteria [<xref ref-type="bibr" rid="B42">42</xref>]. To study the change in effectiveness for all features under this standard, we sorted the features by <italic>P</italic> value (small to large), performed feature selection (taking three features as the step size), and then calculated the mean MID value for all the feature subset (<xref ref-type="fig" rid="fig4">Figure 4</xref>). The results showed that the MID values of the five scales were consistent and conformed to the exponential decay function (<xref ref-type="fig" rid="fig4">Figure 4(a)</xref>). Proportion analysis showed that the distribution functions of the five scales were very close (<xref ref-type="fig" rid="fig4">Figure 4(b)</xref>).</p>
</sec>
<sec id="sec3.3">
<title>3.3. <italic>P</italic> Value: the Feature Selection Criterion</title>
<p>To verify the performance of the <italic>P</italic> value as the feature selection criterion among the five parcellations, we analyzed the correlation between the <italic>P</italic> value and the MID value for each scale by linear regression. The results showed that there was a significant negative correlation between these parameters (<italic>P</italic> &lt; 0.01), regardless of the scale (<xref ref-type="fig" rid="fig5">Figure 5</xref>). It should be noted that all the significant correlation were weak (the adjusted <italic>R</italic> square values were around 0.16) except for AAL90 parcellation (the adjusted <italic>R</italic> square values was 0.461). In addition, to identify the optimal feature subset, we analyzed the classification performance of all the features. All the features were sorted by <italic>P</italic> value and feature subsets were then selected in turn using three as the step size. The feature subsets were then used to train the classification model in sequence. In consideration of computational consumption issues, classification with each feature subset was repeated five times. <xref ref-type="fig" rid="fig6"> Figure 6</xref> shows the change in the mean classification accuracy with an increasing number of features at the five scales. The results showed that all scales exhibited a similar trend. In the beginning, the accuracy of classification increased as the number of features increased. Then, as the effectiveness of the added features decreases, the classification accuracy also gradually decreases. In particular, when all features of each scale were selected as classifier features, the accuracy was approximately 50%. This means that the classifier degenerated into random classification.</p>
<p>In addition, the results of the five scales showed that accuracy was not optimal when the <italic>P</italic> value was set at 0.05. The classification results of the five scales all showed the same phenomenon, which suggested that 0.05 was not the optimal <italic>P</italic> value threshold when filtering classification features. When the <italic>P</italic> value was 0.05, the classification accuracy rate was still increasing, regardless of the scale. The number of features/approximate <italic>P</italic> values corresponding to the highest accuracy for the five scales were as follows: 39/0.162, 111/0.119, 204/0.115, 324/0.096, and 654/0.126. This result implies that the feature selection criterion of <italic>P</italic> &lt; 0.05 is too strict to ensure the highest accuracy.</p>
</sec>
<sec id="sec3.4">
<title>3.4. Feature Redundancy Analysis</title>
<p>When evaluating feature performance, besides the effectiveness of selected features, the similarity between features should also be evaluated; in other words, feature redundancy, <italic>R</italic> (the mathematical definition of which is shown in <xref ref-type="table" rid="tab2">Table 2</xref>). The redundancy between each feature pair at all five scales was calculated separately (considering the computational consumption, only the feature subset associated with the <italic>P</italic> &lt; 0.05 criterion was selected). The results showed that the redundancy between the discriminative features gradually increased as the number of nodes increased (<xref ref-type="fig" rid="fig7">Figure 7</xref>). This suggested that although parcellations with more regions provided more discriminative features, the redundancy between these features was also strong; that is, the similarity between features was high.</p>
<p>We speculated that the increased redundancy between discriminative features may have been caused by the shorter anatomical distance between brain regions. To verify this conjecture, we performed a correlation analysis between the redundancy and the Euclidean distance between the corresponding brain region pairs (<xref ref-type="fig" rid="fig8">Figure 8</xref>), which identified a significant negative correlation. This suggested that a parcellation with more regions, which would have a shorter mean anatomical distance between regions, would have increased redundancy between the discriminative features of corresponding regions. This implied that the network topological properties of regions with a short anatomical distance were similar.</p>
</sec>
</sec>
<sec id="sec4">
<title>4. Discussion</title>
<p>The brain network method has provided novel viewpoints and ideas for studying the human brain from the perspective of complex networks. The definition of nodes is an extremely important issue when using this method. Different node definitions will result in different network node scales. Previous studies have shown that network node scale impacts network topological structure and classification accuracy [<xref ref-type="bibr" rid="B22">22</xref>–<xref ref-type="bibr" rid="B24">24</xref>]. Our study focused on feature performance analysis and feature selection criteria at different scales. The results showed that the performances of all the classification features associated with different network scales were similar. Parcellation with more regions provided a larger number of discriminative features. However, due to the shorter distance between brain regions, the redundancy of features in the large networks was also higher. At the same time, use of traditional feature selection criterion, the <italic>P</italic> value, is feasible at different scales, but the threshold of 0.05 is too strict.</p>
<sec id="sec4.1">
<title>4.1. Feature Selection Based on <italic>P</italic> &lt; 0.05</title>
<p>The <italic>P</italic> value, as the most commonly used feature selection criterion, has been widely used in machine learning research based on image data [<xref ref-type="bibr" rid="B1">1</xref>], including machine learning brain network studies (for review, see [<xref ref-type="bibr" rid="B10">10</xref>]). Our study applied this common method and adopted 0.05 as a threshold to carry out feature selection and classification. The results showed that the greater the number of network nodes, the higher the number of discriminative features. This indicates that an increase in the network scale affected the number of discriminative features. This result is consistent with the results of similar studies [<xref ref-type="bibr" rid="B22">22</xref>, <xref ref-type="bibr" rid="B50">50</xref>]. In addition, classification performance analysis showed that a large network significantly improved the accuracy compared with a small network (<xref ref-type="table" rid="tab3">Table 3</xref>). This result is also consistent with the results of previous studies [<xref ref-type="bibr" rid="B22">22</xref>–<xref ref-type="bibr" rid="B24">24</xref>].</p>
<p>Based on the <italic>P</italic> &lt; 0.05 criterion, different parcellations generated a different number of features. To remove the influence of the number of features on classification accuracy, we selected the same number of discriminative features from different scales and applied them to the classifier. The results were consistent with the earlier results (<xref ref-type="fig" rid="fig1">Figure 1</xref>). This indicated that the improvement in accuracy was not only caused by an increase in the number of features. Furthermore, after evaluating the performance of the selected discriminative features, it was found that the larger the network, the better the performance, which could lead to the improvement of classification accuracy (<xref ref-type="fig" rid="fig2">Figure 2</xref>). This implies that, when we want to control the quantity of features, the features provided by parcellation with more regions are more effective and more beneficial regarding classification accuracy improvement.</p>
</sec>
<sec id="sec4.2">
<title>4.2. Analysis of All Features Based on Five Parcellations</title>
<p>The <italic>P</italic> value feature selection strategy only focuses on features with significant between-group differences, but it ignores other features; this approach is not, therefore, appropriate for a comparative study of features. Therefore, we analyzed all features obtained based on the five scales. Obviously, the larger networks had a greater number of local features. Classification performance analysis showed that the MID value distributions of the five scales were all consistently Gaussian (<xref ref-type="fig" rid="fig3">Figure 3(a)</xref>). Moreover, their proportional distribution functions were very similar (<xref ref-type="fig" rid="fig3">Figure 3(b)</xref>).</p>
<p>Furthermore, features were sorted by <italic>P</italic> value (from small to large), feature subsets were generated using three as the step size, and the mean MID value of each feature subset was calculated. The results showed that the mean MID values were higher for large networks compared to small networks when the number of features remained the same. This conclusion was consistent with the conclusion obtained using a feature subset associated with the <italic>P</italic> &lt; 0.05 criterion. The trends in MID values for the five scales were consistent (as they were all in line with exponential decay) (<xref ref-type="fig" rid="fig4">Figure 4(a)</xref>); similar results were obtained in the proportion analysis (<xref ref-type="fig" rid="fig4">Figure 4(b)</xref>). Therefore, we can conclude that network scale did not affect the classification performance of the generated features, and that the effectiveness of the features obtained using different scales was similar.</p>
</sec>
<sec id="sec4.3">
<title>4.3. Is <italic>P</italic> &lt; 0.05 the Best Choice?</title>
<p>Two methods were used for feature evaluation: <italic>P</italic> values and MID values. Correlation analysis was performed between these two parameters, which showed that there were significant correlations, regardless of the scale. This also indicated that discriminative feature selection using <italic>P</italic> values was effective, and the effectiveness was not affected by differences of network scale. However, it is worth noting that regarding optimal feature subset selection, the threshold of 0.05 is arbitrary. Clearly, <italic>P</italic> &lt; 0.05 can ensure the statistical significance of the selected features. However, this criterion appeared to be too strict for the selection of classification features. The full-feature classification results at the five scales showed that the change in the classification accuracy as the number of features (sorted by <italic>P</italic> value) increased involved two stages (<xref ref-type="fig" rid="fig6">Figure 6</xref>). First, there was a rising stage resulting from an increase in the number of effective discriminative features. Second, there was a declining stage caused by the reduction in MID values of newly added features. The results showed that the &lt;0.05 criterion just fitted into the rising stage for all five scales. This indicated that this criterion is too strict as it leads to insufficient selection of features for the feature subset, thus reducing classification accuracy. The number of features/<italic>P</italic> values associated with the peak accuracy for each scale was as follows: 39/0.162 (AAL90), 111/0.119 (Parc256), 204/0.115 (Parc497), 324/0.096 (Parc1003), and 654/0.126 (Parc1501). Therefore, it could be worth considering setting the <italic>P</italic> value threshold for feature selection at 0.090–0.170 to improve the classification accuracy.</p>
<p>The construction of an optimal feature subset is a complex problem, involving the number of features, method of feature selection and effectiveness of the features [<xref ref-type="bibr" rid="B51">51</xref>]. The number of features plays an important role in the performance of the classifier [<xref ref-type="bibr" rid="B48">48</xref>, <xref ref-type="bibr" rid="B51">51</xref>–<xref ref-type="bibr" rid="B53">53</xref>]. From a statistical point of view, a threshold of <italic>P</italic> &lt; 0.05 ensured that the selected features were statistically significant. However, we also found that this criterion was too strict from the point of view of machine learning and led to fewer discriminative features being selected. It is therefore important to consider less strict criteria.</p>
</sec>
<sec id="sec4.4">
<title>4.4. Feature Redundancy</title>
<p>Collectively, our results showed that large networks provide a larger number of discriminative features. We also need to pay attention to the redundancy between features, that is, the similarity between features. Similar features make similar contributions in classifiers [<xref ref-type="bibr" rid="B53">53</xref>]. If there are a large number of redundant features in the feature subset, the performance of the classifier is barely improved, even if these redundant features are discriminative features [<xref ref-type="bibr" rid="B54">54</xref>]. The redundancy analysis between the discriminative features of different scales showed that the redundancy was higher for a large network compared to a small network (considering the computational consumption, we only carried out the analysis for the feature subset associated with the <italic>P</italic> &lt; 0.05 criterion). We believe that this was caused by the short anatomical distance between nodes for parcellations with more regions (<xref ref-type="fig" rid="fig8">Figure 8</xref>); this natural problem is unavoidable.</p>
</sec>
<sec id="sec4.5">
<title>4.5. Issue of Overfitting</title>
<p>The overfitting problem refers to the fact that the machine learning model may perfectly predict the training set but fail to predict the new data very well if there are too many features, that is, the model is overfitted regarding the training data without considering its generalization ability. High-dimensional features can cause an overfitting problem.</p>
<p>Machine learning has been widely applied to extract information from fMRI data and predict pathology progression [<xref ref-type="bibr" rid="B55">55</xref>, <xref ref-type="bibr" rid="B56">56</xref>]. From among the large number of machine learning methods, the classification method is particularly useful in pathology [<xref ref-type="bibr" rid="B57">57</xref>]. Moreover, research suggests that the SVM method is one of the most popular classification methods in machine learning involving neuroimaging data [<xref ref-type="bibr" rid="B58">58</xref>]. The SVM algorithm allows the classification of individual samples into distinct groups based on data in high-dimensional space according to the structural risk minimization principle [<xref ref-type="bibr" rid="B56">56</xref>]. In addition, SVM computational complexity is determined by the number of samples rather than the number of features, which is beneficial in high-dimensional settings. Regarding the problem of the data dimension exceeding the number of samples, SVM can always find the linear decision boundary to completely separate the data (via linear kernel) [<xref ref-type="bibr" rid="B56">56</xref>]. Therefore, SVM does not require many training samples to avoid overfitting [<xref ref-type="bibr" rid="B59">59</xref>]. Accordingly, SVM has attracted attention from neuroimaging researchers and has been used to extract meaningful information from high-dimensional fMRI data [<xref ref-type="bibr" rid="B56">56</xref>, <xref ref-type="bibr" rid="B60">60</xref>].</p>
<p>The penalty parameter, <italic>C</italic>, using the training data optimization algorithm is included in the SVM model. The selection of appropriate parameters allows corresponding control over the overfitting phenomenon. <italic>C</italic> is used to control the tradeoff between model complexity and approximation error. If <italic>C</italic> is too large, the data fit and the complexity of the learning machine will be too high. Avoiding overfitting is a necessary process when designing a classifier. Conversely, if <italic>C</italic> is too small, the penalty for empirical error will be smaller, and the machine's learning complexity and data fit will be low. When there is overfitting or underfitting, the classifier will have a poor generalization ability and poor classification performance [<xref ref-type="bibr" rid="B61">61</xref>]. Thus, it is very important to choose a suitable <italic>C</italic> value, which would avoid the overfitting problem to a certain extent.</p>
<p>Furthermore, we assessed the issue of overfitting in our results. A linear kernel function was used for classification, and 10-fold cross-validation was used to evaluate the classification performance. Analysis in <xref ref-type="sec" rid="sec3.1">Section 3.1</xref> showed that our results were not significantly affected by overfitting problem at all five parcellations in which training set and test set were set a ratio of 9 : 1. In order to avoid the effect of different proportion of the training and test set, in this section, we adopted a different ratio setting, which is 7 : 3. Specifically, we randomly divided the dataset into a training dataset and a test dataset in a 7 : 3 ratio, where 70% of the data were used as training data, and the remainder was not involved in model training. Furthermore, the training dataset was subjected to 10-fold cross-validation. That is to say, the training dataset was randomly divided into ten equal parts, one of which was used as the validation set (Sn) and the remainder as the training set (S-n). S-n was then divided into two parts (training set B and test set <italic>C</italic>). Using training set B, classifiers were constructed by choosing different <italic>C</italic> values, and the <italic>C</italic> value that gave the highest classification accuracy regarding training set B was determined to be the best parameter. In this way, ten different models were built, and the accuracy of each model was calculated. Next, the test set <italic>C</italic> was subjected to each model separately, and the associated accuracy was calculated to prove the generalization ability of the model.</p>
<p>Because the feature dimension was higher than the number of samples, it is easier to determine the linear decision boundary to completely separate the data in the SVM training model process. This made the fitting difficulty relatively low. Moreover, the number of samples in this study was small, owing to the difficulty of data acquisition, so the learning curve of a model did not show a significant rise during multiple training processes and converged quickly. Therefore, the statistical of learning curves may not be obvious to illustrate the issues. Thus, we randomly selected a training set and test set at a 7 : 3 ratio 100 times and calculated the validation accuracy and test accuracy after 10-fold cross-validation every time for each scale. In addition, different SVM parameter settings led to different results. In the training model, the penalty parameter, <italic>C</italic>, was set in the [−5, 5] range with a step size of 1 because the classification result was the best in this range. Five parcellations were validated respectively. Correlation analysis was performed between validation accuracy and test accuracy (Supplemental Material <xref ref-type="supplementary-material" rid="supplementary-material-1"></xref>). The results showed that the validation accuracy of the three parcellations significantly positively correlated with test accuracy. The corresponding adjusted <italic>R</italic><sup>2</sup>/<italic>P</italic> values were as follows: 0.271/&lt;0.0001 (AAL90), 0.229/&lt;0.0001 (Parc256), 0.194/&lt;0.0001 (Parc497), 0.152/&lt;0.0001 (Parc1003), and 0.091/0013 (Parc1501). This suggested that the overfitting effect was not significant.</p>
<p>However, it should be noted that the adjusted <italic>R</italic><sup>2</sup> values decreased and the <italic>P</italic> values increased gradually with the increase in the number of nodes. This phenomenon suggested that we cannot rule out the influence of overfitting on the results with further increases in the number of features. This issue should be focused on by researchers in the future. In the latest related studies, to improve classification accuracy, many different complex network construction and feature extraction methods have been applied [<xref ref-type="bibr" rid="B62">62</xref>–<xref ref-type="bibr" rid="B64">64</xref>]. However, if the SVM classifier is selected, the overfitting problem in the face of high-dimensional features must be taken into account. Therefore, if a higher number of brain nodes are defined, necessary feature dimension reduction methods, such as the principal component analysis method [<xref ref-type="bibr" rid="B65">65</xref>], need to be implemented to avoid the overfitting problem in future studies.</p>
</sec>
<sec id="sec4.6">
<title>4.6. Limitations</title>
<p>Our study showed that large networks yield a larger number of discriminative features, thus improving the accuracy of classification. However, we cannot ignore the greater time consumption caused by constructing and analyzing large networks. In addition to network scale, time consumption is affected by a variety of factors such as algorithms and hardware configurations. Consequently, we need to establish a balance between classification accuracy and acceptable time consumption.</p>
<p>In addition, we concede that our choice of methods in the current study, including node definitions, classifiers, feature selection strategy, performance evaluation indicators, and so on, are not the best in the field. They have their own problems and there will be better methods to replace them. However, the focus of our research was not to find the optimal classification model construction method, but to prove that a change in the network scale impacts feature selection and classification performance. Thus, in the process of constructing classification models, we chose the most common methods, even though these methods were not the best choice. This makes our research more comparable to other related studies.</p>
<p>There are several other limitations that need to be considered. First, because of the difficulties of sample collection, the number of subjects in similar studies is often insufficient, especially when the subjects are patients. Second, only one segmentation parcellation template was used for each scale. This means that our results cannot completely exclude the impact of randomness caused by the seed set settings, although we did adopt a dynamic adjustment strategy. Third, only one feature selection strategy was adopted. To ensure the generalizability of the results, more feature selection criteria should be considered in follow-up studies. Fourth, only one classifier was used for classification, which prevented comparisons between classifiers. Fifth, although we evaluated feature redundancy, we did not further optimize the feature subset; this will be the focus of our follow-up study. Sixth, although there was no significant overfitting phenomenon in this study, we cannot rule out the influence of overfitting on the results when the number of features is further increased. Finally, we did not optimize the classification parameters. The application of a parameter optimization strategy would improve the classifier performance.</p>
</sec>
</sec>
<sec id="sec5">
<title>5. Conclusion</title>
<p>This study analyzed how network scale affected classification performance, and classification accuracy and effectiveness of the feature selection strategies using <italic>P</italic> values in terms of machine learning methods. When using <italic>P</italic> &lt; 0.05 as the feature selection threshold, we found that the classification accuracy of a larger network was higher than that of a smaller network. This finding is consistent with the findings of similar studies. Further analysis showed that improvements in the accuracy of parcellation with more regions were not caused by the increase in the number of features alone. When the number of features remained the same, parcellation with more regions still provided better accuracy because of the more efficient combination of features. Therefore, when the number of features needs to be controlled, selecting a parcellation with more regions improves the classification performance.</p>
<p>After analyzing all of the features, we found that the effectiveness related to the different scales was quite similar. This implies that changes in scale did not affect feature effectiveness. In other words, parcellation with a greater number of regions did not lead to features that were more effective. However, parcellation with a greater number of regions provided a greater quantity of discriminative features, which led to an improvement in classification accuracy. Furthermore, the feature redundancy was higher for parcellation with more regions than parcellation with fewer regions because of the shorter anatomical distance between brain regions in the former.</p>
<p>Application of the traditional <italic>P</italic> value feature selection strategy was feasible with different network scales and was further verified in this study. It is worth noting that although the threshold of <italic>P</italic> &lt; 0.05 fully guaranteed statistically significant between-group differences in the selected features, it was too strict from a machine learning point of view, leading to a lack of discriminative features. Thus, a more relaxed threshold should be considered.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>This study was supported by research grants from the National Natural Science Foundation of China (nos. 61672374, 61741212, 61876124, and 61873178), Natural Science Foundation of Shanxi Province (201701D221119 and 201801D121135), CERNET Innovation Project (NGII20170712), and Key Research and Development (R&amp;D) Projects of Shanxi Province (201803D31043).</p>
</ack>
<sec sec-type="data-availability">
<title>Data Availability</title>
<p>The image data used to support the findings of this study were supplied by Taiyuan University of Technology and First Hospital of Shanxi Medical University under license and so cannot be made freely available. Requests for access to these data should be made to the corresponding author.</p>
</sec>
<sec>
<title>Ethical Approval</title>
<p>This study was reviewed and approved by the medical ethics committee of Shanxi Province (reference number: 2012013).</p>
</sec>
<sec>
<title>Consent</title>
<p>All subjects gave written informed consent in accordance with the Declaration of Helsinki.</p>
</sec>
<sec>
<title>Disclosure</title>
<p>The sponsors had no role in the design or execution of the study, the collection, management, analysis, and interpretation of the data, or the preparation, review, and approval of the manuscript.</p>
</sec>
<sec sec-type="COI-statement">
<title>Conflicts of Interest</title>
<p>All the authors have read the manuscript, approved it for publication, and declare that this study does not have any commercial or associative interest that represents a conflict of interest in connection with the work submitted. Hao Guo had full access to all of the data in the study and takes responsibility for its integrity and the accuracy of the data analysis.</p>
</sec>
<sec>
<title>Authors' Contributions</title>
<p>HG was responsible for the study design and writing the manuscript. YL, GKM, and JX performed the statistical analysis. YX provided and integrated the experimental data. JC supervised the paper. HG and DC provided conception and design of the work. All authors approved the final version of the manuscript.</p>
</sec>
<sec id="supplementary-material-1" sec-type="supplementary-material">
<title>Supplementary Materials</title>
<supplementary-material content-type="local-data" id="supp-1">
<label>Supplementary Materials</label>
<caption>
<p>Supplemental Text S1. Image Acquisition. Supplemental Text S2. Mathematical Definition of Pearson Correlation Coefficient. Supplemental Text S3. Threshold Selection Criteria. Supplemental Text S4. Mathematical Definitions of Selected Network Metrics. Supplemental Text S5. Minimum Redundancy-Maximum Relevance Algorithm. Supplemental Figure S1. Illustration of Five Parcellations. Supplemental Figure S2. Illustration of Parcellation Definitions. Supplemental Figure S3. Correlation Analysis between Validation Accuracy and Test Accuracy. Supplemental Table S1. Comparison with Similar Researches. Supplemental Digital File S1. Nii Files of Five Parcellations.</p>
</caption>
<media xlink:href="9108108.f1.zip">
<caption>
<p>Click here for additional data file.</p>
</caption>
</media>
</supplementary-material>
</sec>
<ref-list>
<ref id="B1">
<label>1</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Pereira</surname>
<given-names>F.</given-names>
</name>
<name>
<surname>Mitchell</surname>
<given-names>T.</given-names>
</name>
<name>
<surname>Botvinick</surname>
<given-names>M.</given-names>
</name>
</person-group>
<article-title>Machine learning classifiers and fMRI: a tutorial overview</article-title>
<source/>
<italic toggle="yes">NeuroImage</italic>
<year>2009</year>
<volume>45</volume>
<issue>1</issue>
<fpage>S199</fpage>
<lpage>S209</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.11.007</pub-id>
<pub-id pub-id-type="other">2-s2.0-65549168742</pub-id>
<pub-id pub-id-type="pmid">19070668</pub-id>
</element-citation>
</ref>
<ref id="B2">
<label>2</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>O’Toole</surname>
<given-names>A. J.</given-names>
</name>
<name>
<surname>Jiang</surname>
<given-names>F.</given-names>
</name>
<name>
<surname>Abdi</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Pénard</surname>
<given-names>N.</given-names>
</name>
<name>
<surname>Dunlop</surname>
<given-names>J. P.</given-names>
</name>
<name>
<surname>Parent</surname>
<given-names>M. A.</given-names>
</name>
</person-group>
<article-title>Theoretical, statistical, and practical perspectives on pattern-based classification approaches to the analysis of functional neuroimaging data</article-title>
<source/>
<italic toggle="yes">Journal of Cognitive Neuroscience</italic>
<year>2007</year>
<volume>19</volume>
<issue>11</issue>
<fpage>1735</fpage>
<lpage>1752</lpage>
<pub-id pub-id-type="doi">10.1162/jocn.2007.19.11.1735</pub-id>
<pub-id pub-id-type="other">2-s2.0-35748950120</pub-id>
<pub-id pub-id-type="pmid">17958478</pub-id>
</element-citation>
</ref>
<ref id="B3">
<label>3</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fu</surname>
<given-names>C. H. Y.</given-names>
</name>
<name>
<surname>Mourao-Miranda</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Costafreda</surname>
<given-names>S. G.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Pattern classification of sad facial processing: toward the development of neurobiological markers in depression</article-title>
<source/>
<italic toggle="yes">Biological Psychiatry</italic>
<year>2008</year>
<volume>63</volume>
<issue>7</issue>
<fpage>656</fpage>
<lpage>662</lpage>
<pub-id pub-id-type="doi">10.1016/j.biopsych.2007.08.020</pub-id>
<pub-id pub-id-type="other">2-s2.0-40149084821</pub-id>
<pub-id pub-id-type="pmid">17949689</pub-id>
</element-citation>
</ref>
<ref id="B4">
<label>4</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hahn</surname>
<given-names>T.</given-names>
</name>
<name>
<surname>Marquand</surname>
<given-names>A. F.</given-names>
</name>
<name>
<surname>Ehlis</surname>
<given-names>A. C</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Integrating neurobiological markers of depression</article-title>
<source/>
<italic toggle="yes">Archives of General Psychiatry</italic>
<year>2011</year>
<volume>68</volume>
<issue>4</issue>
<fpage>361</fpage>
<lpage>8</lpage>
<pub-id pub-id-type="doi">10.1001/archgenpsychiatry.2010.178</pub-id>
<pub-id pub-id-type="other">2-s2.0-79953761839</pub-id>
<pub-id pub-id-type="pmid">21135315</pub-id>
</element-citation>
</ref>
<ref id="B5">
<label>5</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mulders</surname>
<given-names>P. C.</given-names>
</name>
<name>
<surname>van Eijndhoven</surname>
<given-names>P. F.</given-names>
</name>
<name>
<surname>Schene</surname>
<given-names>A. H.</given-names>
</name>
<name>
<surname>Beckmann</surname>
<given-names>C. F.</given-names>
</name>
<name>
<surname>Tendolkar</surname>
<given-names>I.</given-names>
</name>
</person-group>
<article-title>Resting-state functional connectivity in major depressive disorder: a review</article-title>
<source/>
<italic toggle="yes">Neuroscience &amp; Biobehavioral Reviews</italic>
<year>2015</year>
<volume>56</volume>
<fpage>330</fpage>
<lpage>344</lpage>
<pub-id pub-id-type="pmid">26234819</pub-id>
</element-citation>
</ref>
<ref id="B6">
<label>6</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ball</surname>
<given-names>G.</given-names>
</name>
<name>
<surname>Pazderova</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Chew</surname>
<given-names>A.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Thalamocortical connectivity predicts cognition in children born preterm</article-title>
<source/>
<italic toggle="yes">Cerebral Cortex</italic>
<year>2015</year>
<volume>25</volume>
<issue>11</issue>
<fpage>4310</fpage>
<lpage>4318</lpage>
<pub-id pub-id-type="doi">10.1093/cercor/bhu331</pub-id>
<pub-id pub-id-type="other">2-s2.0-84954243130</pub-id>
<pub-id pub-id-type="pmid">25596587</pub-id>
</element-citation>
</ref>
<ref id="B7">
<label>7</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Han</surname>
<given-names>K.</given-names>
</name>
<name>
<surname>Mac Donald</surname>
<given-names>C. L.</given-names>
</name>
<name>
<surname>Johnson</surname>
<given-names>A. M.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Disrupted modular organization of resting-state cortical functional connectivity in U.S. military personnel following concussive “mild” blast-related traumatic brain injury</article-title>
<source/>
<italic toggle="yes">NeuroImage</italic>
<year>2014</year>
<volume>84</volume>
<fpage>76</fpage>
<lpage>96</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.017</pub-id>
<pub-id pub-id-type="other">2-s2.0-84883607768</pub-id>
<pub-id pub-id-type="pmid">23968735</pub-id>
</element-citation>
</ref>
<ref id="B8">
<label>8</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rudie</surname>
<given-names>J. D.</given-names>
</name>
<name>
<surname>Brown</surname>
<given-names>J. A.</given-names>
</name>
<name>
<surname>Beck-Pancer</surname>
<given-names>D.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Altered functional and structural brain network organization in autism</article-title>
<source/>
<italic toggle="yes">NeuroImage: Clinical</italic>
<year>2013</year>
<volume>2</volume>
<issue>2</issue>
<fpage>79</fpage>
<lpage>94</lpage>
<pub-id pub-id-type="doi">10.1016/j.nicl.2012.11.006</pub-id>
<pub-id pub-id-type="other">2-s2.0-84871230004</pub-id>
</element-citation>
</ref>
<ref id="B9">
<label>9</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Roberts</surname>
<given-names>G.</given-names>
</name>
<name>
<surname>Lord</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Frankland</surname>
<given-names>A.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Functional dysconnection of the inferior frontal gyrus in young people with bipolar disorder or at genetic high risk</article-title>
<source/>
<italic toggle="yes">Biological Psychiatry</italic>
<year>2017</year>
<volume>81</volume>
<issue>8</issue>
<fpage>718</fpage>
<lpage>727</lpage>
<pub-id pub-id-type="doi">10.1016/j.biopsych.2016.08.018</pub-id>
<pub-id pub-id-type="other">2-s2.0-85006074469</pub-id>
<pub-id pub-id-type="pmid">28031150</pub-id>
</element-citation>
</ref>
<ref id="B10">
<label>10</label>
<element-citation publication-type="other">
<person-group person-group-type="author">
<name>
<surname>Brown</surname>
<given-names>C. J.</given-names>
</name>
<name>
<surname>Hamarneh</surname>
<given-names>G.</given-names>
</name>
</person-group>
<article-title>Machine learning on human connectome data from MRI</article-title>
<year>2016</year>
<comment>
<ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1611.08699">https://arxiv.org/abs/1611.08699</ext-link>
</comment>
</element-citation>
</ref>
<ref id="B11">
<label>11</label>
<element-citation publication-type="confproc">
<person-group person-group-type="author">
<name>
<surname>Sacchet</surname>
<given-names>M. D.</given-names>
</name>
</person-group>
<article-title>Elucidating brain connectivity networks in major depressive disorder using classification-based scoring</article-title>
<conf-name>Proceedings of the 2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI)</conf-name>
<conf-date>April-May 2014</conf-date>
<conf-loc>Beijing, China</conf-loc>
<publisher-name>IEEE</publisher-name>
</element-citation>
</ref>
<ref id="B12">
<label>12</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Guo</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Cao</surname>
<given-names>X.</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>Z.</given-names>
</name>
<name>
<surname>Li</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Zhang</surname>
<given-names>K.</given-names>
</name>
</person-group>
<article-title>Machine learning classifier using abnormal brain network topological metrics in major depressive disorder</article-title>
<source/>
<italic toggle="yes">NeuroReport</italic>
<year>2012</year>
<volume>23</volume>
<issue>17</issue>
<fpage>1006</fpage>
<lpage>1011</lpage>
<pub-id pub-id-type="doi">10.1097/wnr.0b013e32835a650c</pub-id>
<pub-id pub-id-type="other">2-s2.0-84869508879</pub-id>
<pub-id pub-id-type="pmid">23044496</pub-id>
</element-citation>
</ref>
<ref id="B13">
<label>13</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lord</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Horn</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Breakspear</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Walter</surname>
<given-names>M.</given-names>
</name>
</person-group>
<article-title>Changes in community structure of resting state functional connectivity in unipolar depression</article-title>
<source/>
<italic toggle="yes">PLoS One</italic>
<year>2012</year>
<volume>7</volume>
<issue>8</issue>
<pub-id pub-id-type="publisher-id">e41282</pub-id>
<pub-id pub-id-type="doi">10.1371/journal.pone.0041282</pub-id>
<pub-id pub-id-type="other">2-s2.0-84865159740</pub-id>
</element-citation>
</ref>
<ref id="B14">
<label>14</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Cao</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Guo</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Xue</surname>
<given-names>Z.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Aberrant functional connectivity for diagnosis of major depressive disorder: a discriminant analysis</article-title>
<source/>
<italic toggle="yes">Psychiatry and Clinical Neurosciences</italic>
<year>2014</year>
<volume>68</volume>
<issue>2</issue>
<fpage>110</fpage>
<lpage>119</lpage>
<pub-id pub-id-type="doi">10.1111/pcn.12106</pub-id>
<pub-id pub-id-type="other">2-s2.0-84907866047</pub-id>
<pub-id pub-id-type="pmid">24552631</pub-id>
</element-citation>
</ref>
<ref id="B15">
<label>15</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jie</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Wee</surname>
<given-names>C.-Y.</given-names>
</name>
<name>
<surname>Shen</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Zhang</surname>
<given-names>D.</given-names>
</name>
</person-group>
<article-title>Hyper-connectivity of functional networks for brain disease diagnosis</article-title>
<source/>
<italic toggle="yes">Medical Image Analysis</italic>
<year>2016</year>
<volume>32</volume>
<fpage>84</fpage>
<lpage>100</lpage>
<pub-id pub-id-type="doi">10.1016/j.media.2016.03.003</pub-id>
<pub-id pub-id-type="other">2-s2.0-84962434232</pub-id>
<pub-id pub-id-type="pmid">27060621</pub-id>
</element-citation>
</ref>
<ref id="B16">
<label>16</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Cheng</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Cao</surname>
<given-names>X.</given-names>
</name>
<name>
<surname>Guo</surname>
<given-names>H.</given-names>
</name>
</person-group>
<article-title>Comparison of local information indices applied in resting state functional brain network connectivity prediction</article-title>
<source/>
<italic toggle="yes">Frontiers in Neuroscience</italic>
<year>2016</year>
<volume>10</volume>
<fpage>p. 585</fpage>
<pub-id pub-id-type="doi">10.3389/fnins.2016.00585</pub-id>
<pub-id pub-id-type="other">2-s2.0-85009727142</pub-id>
<pub-id pub-id-type="pmid">28082859</pub-id>
</element-citation>
</ref>
<ref id="B17">
<label>17</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Tewarie</surname>
<given-names>P.</given-names>
</name>
<name>
<surname>Hillebrand</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Schoonheim</surname>
<given-names>M. M.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Functional brain network analysis using minimum spanning trees in multiple sclerosis: an MEG source-space study</article-title>
<source/>
<italic toggle="yes">NeuroImage</italic>
<year>2014</year>
<volume>88</volume>
<fpage>308</fpage>
<lpage>318</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.10.022</pub-id>
<pub-id pub-id-type="other">2-s2.0-84896694559</pub-id>
<pub-id pub-id-type="pmid">24161625</pub-id>
</element-citation>
</ref>
<ref id="B18">
<label>18</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jie</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Zhang</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Gao</surname>
<given-names>W.</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>Q.</given-names>
</name>
<name>
<surname>Wee</surname>
<given-names>C. Y.</given-names>
</name>
<name>
<surname>Shen</surname>
<given-names>D.</given-names>
</name>
</person-group>
<article-title>Integration of network topological and connectivity properties for neuroimaging classification</article-title>
<source/>
<italic toggle="yes">IEEE Transactions on Biomedical Engineering</italic>
<year>2014</year>
<volume>61</volume>
<issue>2</issue>
<fpage>576</fpage>
<lpage>589</lpage>
<pub-id pub-id-type="doi">10.1109/TBME.2013.2284195</pub-id>
<pub-id pub-id-type="other">2-s2.0-84893330870</pub-id>
<pub-id pub-id-type="pmid">24108708</pub-id>
</element-citation>
</ref>
<ref id="B19">
<label>19</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fornito</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Zalesky</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Bullmore</surname>
<given-names>E. T.</given-names>
</name>
</person-group>
<article-title>Network scaling effects in graph analytic studies of human resting-state fMRI data</article-title>
<source/>
<italic toggle="yes">Frontiers in Systems Neuroscience</italic>
<year>2010</year>
<volume>4</volume>
<issue>22</issue>
<pub-id pub-id-type="doi">10.3389/fnsys.2010.00022</pub-id>
<pub-id pub-id-type="other">2-s2.0-78149420706</pub-id>
</element-citation>
</ref>
<ref id="B20">
<label>20</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zalesky</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Fornito</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Harding</surname>
<given-names>I. H.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Whole-brain anatomical networks: does the choice of nodes matter?</article-title>
<source/>
<italic toggle="yes">NeuroImage</italic>
<year>2010</year>
<volume>50</volume>
<issue>3</issue>
<fpage>970</fpage>
<lpage>983</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.12.027</pub-id>
<pub-id pub-id-type="other">2-s2.0-77349095673</pub-id>
<pub-id pub-id-type="pmid">20035887</pub-id>
</element-citation>
</ref>
<ref id="B21">
<label>21</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wang</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Zang</surname>
<given-names>Y.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Parcellation-dependent small-world brain functional networks: a resting-state fMRI study</article-title>
<source/>
<italic toggle="yes">Human Brain Mapping</italic>
<year>2009</year>
<volume>30</volume>
<issue>5</issue>
<fpage>1511</fpage>
<lpage>1523</lpage>
<pub-id pub-id-type="doi">10.1002/hbm.20623</pub-id>
<pub-id pub-id-type="other">2-s2.0-66149131099</pub-id>
<pub-id pub-id-type="pmid">18649353</pub-id>
</element-citation>
</ref>
<ref id="B22">
<label>22</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jing</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Long</surname>
<given-names>Z.</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>H.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Identifying current and remitted major depressive disorder with the Hurst exponent: a comparative study on two automated anatomical labeling atlases</article-title>
<source/>
<italic toggle="yes">Oncotarget</italic>
<year>2017</year>
<volume>8</volume>
<issue>52</issue>
<fpage>90452</fpage>
<lpage>90464</lpage>
<pub-id pub-id-type="doi">10.18632/oncotarget.19860</pub-id>
<pub-id pub-id-type="other">2-s2.0-85032273305</pub-id>
<pub-id pub-id-type="pmid">29163844</pub-id>
</element-citation>
</ref>
<ref id="B23">
<label>23</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ota</surname>
<given-names>K.</given-names>
</name>
<name>
<surname>Oishi</surname>
<given-names>N.</given-names>
</name>
<name>
<surname>Ito</surname>
<given-names>K.</given-names>
</name>
<name>
<surname>Fukuyama</surname>
<given-names>H.</given-names>
</name>
</person-group>
<article-title>Effects of imaging modalities, brain atlases and feature selection on prediction of Alzheimer’s disease</article-title>
<source/>
<italic toggle="yes">Journal of Neuroscience Methods</italic>
<year>2015</year>
<volume>256</volume>
<fpage>168</fpage>
<lpage>183</lpage>
<pub-id pub-id-type="doi">10.1016/j.jneumeth.2015.08.020</pub-id>
<pub-id pub-id-type="other">2-s2.0-84942673380</pub-id>
<pub-id pub-id-type="pmid">26318777</pub-id>
</element-citation>
</ref>
<ref id="B24">
<label>24</label>
<element-citation publication-type="confproc">
<person-group person-group-type="author">
<name>
<surname>Mesrob</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Magnin</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Colliot</surname>
<given-names>O.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Identification of atrophy patterns in Alzheimer’s disease based on SVM feature selection and anatomical parcellation</article-title>
<conf-name>Proceedings of the Medical Imaging and Augmented Reality, International Workshop, MIAR 2008</conf-name>
<conf-date>August-2008</conf-date>
<conf-loc>Tokyo, Japan</conf-loc>
</element-citation>
</ref>
<ref id="B25">
<label>25</label>
<element-citation publication-type="other">
<person-group person-group-type="author">
<name>
<surname>Brown</surname>
<given-names>C. J.</given-names>
</name>
<name>
<surname>Hamarneh</surname>
<given-names>G.</given-names>
</name>
</person-group>
<article-title>Machine learning on human connectome data from MRI</article-title>
<year>2016</year>
<comment>
<ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1611.08699">https://arxiv.org/abs/1611.08699</ext-link>
</comment>
</element-citation>
</ref>
<ref id="B26">
<label>26</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Patel</surname>
<given-names>M. J.</given-names>
</name>
<name>
<surname>Khalaf</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Aizenstein</surname>
<given-names>H. J.</given-names>
</name>
</person-group>
<article-title>Studying depression using imaging and machine learning methods</article-title>
<source/>
<italic toggle="yes">NeuroImage: Clinical</italic>
<year>2016</year>
<volume>10</volume>
<issue>4</issue>
<fpage>115</fpage>
<lpage>123</lpage>
<pub-id pub-id-type="doi">10.1016/j.nicl.2015.11.003</pub-id>
<pub-id pub-id-type="other">2-s2.0-84949505803</pub-id>
<pub-id pub-id-type="pmid">26759786</pub-id>
</element-citation>
</ref>
<ref id="B27">
<label>27</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dreessen</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Hildebrand</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Arntz</surname>
<given-names>A.</given-names>
</name>
</person-group>
<article-title>Patient-informant concordance on the structured clinical interview for DSM-III-R personality disorders (SCID-II)</article-title>
<source/>
<italic toggle="yes">Journal of Personality Disorders</italic>
<year>1998</year>
<volume>12</volume>
<issue>2</issue>
<fpage>149</fpage>
<lpage>161</lpage>
<pub-id pub-id-type="doi">10.1521/pedi.1998.12.2.149</pub-id>
<pub-id pub-id-type="other">2-s2.0-0031872487</pub-id>
<pub-id pub-id-type="pmid">9661101</pub-id>
</element-citation>
</ref>
<ref id="B28">
<label>28</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>First</surname>
<given-names>M. B.</given-names>
</name>
<name>
<surname>Gibbon</surname>
<given-names>M.</given-names>
</name>
</person-group>
<source/>
<italic toggle="yes">User’s Guide for the Structured Clinical Interview for DSM-IV axis I Disorders: SCID-1 Clinician Version</italic>
<year>1997</year>
<publisher-loc>Washington, DC, USA</publisher-loc>
<publisher-name>American Psychiatric Publishing</publisher-name>
</element-citation>
</ref>
<ref id="B29">
<label>29</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Williams</surname>
<given-names>J. B. W.</given-names>
</name>
</person-group>
<article-title>A structured interview guide for the Hamilton depression Rating Scale</article-title>
<source/>
<italic toggle="yes">Archives of General Psychiatry</italic>
<year>1988</year>
<volume>45</volume>
<issue>8</issue>
<fpage>p. 742</fpage>
<pub-id pub-id-type="doi">10.1001/archpsyc.1988.01800320058007</pub-id>
<pub-id pub-id-type="other">2-s2.0-0023681619</pub-id>
<pub-id pub-id-type="pmid">3395203</pub-id>
</element-citation>
</ref>
<ref id="B30">
<label>30</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Guy</surname>
<given-names>W.</given-names>
</name>
</person-group>
<source/>
<italic toggle="yes">ECDEU Assessment Manual for Psychopharmacology</italic>
<year>1976</year>
<publisher-loc>Washington, DC, USA</publisher-loc>
<publisher-name>USDHEW</publisher-name>
</element-citation>
</ref>
<ref id="B31">
<label>31</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Guo</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Yan</surname>
<given-names>P.</given-names>
</name>
<name>
<surname>Cheng</surname>
<given-names>C.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>fMRI classification method with multiple feature fusion based on minimum spanning tree analysis</article-title>
<source/>
<italic toggle="yes">Psychiatry Research: Neuroimaging</italic>
<year>2018</year>
<volume>277</volume>
<fpage>14</fpage>
<lpage>27</lpage>
<pub-id pub-id-type="doi">10.1016/j.pscychresns.2018.05.001</pub-id>
<pub-id pub-id-type="other">2-s2.0-85048791474</pub-id>
<pub-id pub-id-type="pmid">29793077</pub-id>
</element-citation>
</ref>
<ref id="B32">
<label>32</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Tzourio-Mazoyer</surname>
<given-names>N.</given-names>
</name>
<name>
<surname>Landeau</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Papathanassiou</surname>
<given-names>D.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title>
<source/>
<italic toggle="yes">NeuroImage</italic>
<year>2002</year>
<volume>15</volume>
<issue>1</issue>
<fpage>273</fpage>
<lpage>289</lpage>
<pub-id pub-id-type="doi">10.1006/nimg.2001.0978</pub-id>
<pub-id pub-id-type="other">2-s2.0-0036322886</pub-id>
<pub-id pub-id-type="pmid">11771995</pub-id>
</element-citation>
</ref>
<ref id="B33">
<label>33</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Handwerker</surname>
<given-names>D. A.</given-names>
</name>
<name>
<surname>Birn</surname>
<given-names>R. M.</given-names>
</name>
<name>
<surname>Murphy</surname>
<given-names>K.</given-names>
</name>
<name>
<surname>Bandettini</surname>
<given-names>P. A.</given-names>
</name>
</person-group>
<article-title>Properties of anti-correlated resting-state networks with and without global signal regression</article-title>
<source/>
<italic toggle="yes">NeuroImage</italic>
<year>2009</year>
<volume>47</volume>
<issue>1</issue>
<fpage>p. S61</fpage>
<pub-id pub-id-type="doi">10.1016/s1053-8119(09)70279-4</pub-id>
</element-citation>
</ref>
<ref id="B34">
<label>34</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Murphy</surname>
<given-names>K.</given-names>
</name>
<name>
<surname>Birn</surname>
<given-names>R. M.</given-names>
</name>
<name>
<surname>Handwerker</surname>
<given-names>D. A.</given-names>
</name>
<name>
<surname>Jones</surname>
<given-names>T. B.</given-names>
</name>
<name>
<surname>Bandettini</surname>
<given-names>P. A.</given-names>
</name>
</person-group>
<article-title>The impact of global signal regression on resting state correlations: are anti-correlated networks introduced?</article-title>
<source/>
<italic toggle="yes">NeuroImage</italic>
<year>2009</year>
<volume>44</volume>
<issue>3</issue>
<fpage>893</fpage>
<lpage>905</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.09.036</pub-id>
<pub-id pub-id-type="other">2-s2.0-57649158932</pub-id>
<pub-id pub-id-type="pmid">18976716</pub-id>
</element-citation>
</ref>
<ref id="B35">
<label>35</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rubinov</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Sporns</surname>
<given-names>O.</given-names>
</name>
</person-group>
<article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>
<source/>
<italic toggle="yes">NeuroImage</italic>
<year>2010</year>
<volume>52</volume>
<issue>3</issue>
<fpage>1059</fpage>
<lpage>1069</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.10.003</pub-id>
<pub-id pub-id-type="other">2-s2.0-77954385460</pub-id>
<pub-id pub-id-type="pmid">19819337</pub-id>
</element-citation>
</ref>
<ref id="B36">
<label>36</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Liao</surname>
<given-names>W.</given-names>
</name>
<name>
<surname>Zhang</surname>
<given-names>Z.</given-names>
</name>
<name>
<surname>Pan</surname>
<given-names>Z.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Altered functional connectivity and small-world in mesial temporal lobe epilepsy</article-title>
<source/>
<italic toggle="yes">PLoS One</italic>
<year>2010</year>
<volume>5</volume>
<issue>1</issue>
<pub-id pub-id-type="publisher-id">e8525</pub-id>
<pub-id pub-id-type="doi">10.1371/journal.pone.0008525</pub-id>
<pub-id pub-id-type="other">2-s2.0-77649119460</pub-id>
</element-citation>
</ref>
<ref id="B37">
<label>37</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Liu</surname>
<given-names>Y.</given-names>
</name>
<name>
<surname>Liang</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Zhou</surname>
<given-names>Y.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Disrupted small-world networks in schizophrenia</article-title>
<source/>
<italic toggle="yes">Brain</italic>
<year>2008</year>
<volume>131</volume>
<issue>4</issue>
<fpage>945</fpage>
<lpage>961</lpage>
<pub-id pub-id-type="doi">10.1093/brain/awn018</pub-id>
<pub-id pub-id-type="other">2-s2.0-41849126709</pub-id>
<pub-id pub-id-type="pmid">18299296</pub-id>
</element-citation>
</ref>
<ref id="B38">
<label>38</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Yu</surname>
<given-names>Q.</given-names>
</name>
<name>
<surname>Sui</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Rachakonda</surname>
<given-names>S.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Altered topological properties of functional network connectivity in schizophrenia during resting state: a small-world brain network study</article-title>
<source/>
<italic toggle="yes">PLoS One</italic>
<year>2011</year>
<volume>6</volume>
<issue>9</issue>
<pub-id pub-id-type="publisher-id">e25423</pub-id>
<pub-id pub-id-type="doi">10.1371/journal.pone.0025423</pub-id>
<pub-id pub-id-type="other">2-s2.0-80053248508</pub-id>
</element-citation>
</ref>
<ref id="B39">
<label>39</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>He</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Sui</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Yu</surname>
<given-names>Q.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Altered small-world brain networks in schizophrenia patients during working memory performance</article-title>
<source/>
<italic toggle="yes">PLoS One</italic>
<year>2012</year>
<volume>7</volume>
<issue>6</issue>
<pub-id pub-id-type="publisher-id">e38195</pub-id>
<pub-id pub-id-type="doi">10.1371/journal.pone.0038195</pub-id>
<pub-id pub-id-type="other">2-s2.0-84862003022</pub-id>
</element-citation>
</ref>
<ref id="B40">
<label>40</label>
<element-citation publication-type="confproc">
<person-group person-group-type="author">
<name>
<surname>Munarini</surname>
<given-names>G.</given-names>
</name>
</person-group>
<article-title>Presentazione articolo: complex network measures of brain connectivity uses and interpretations</article-title>
<conf-name>Proceedings of the Corso Psicologia Matematica</conf-name>
<conf-date>December 2013</conf-date>
<conf-loc>Cattolica, Italy</conf-loc>
</element-citation>
</ref>
<ref id="B41">
<label>41</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Massey</surname>
<given-names>E. J.</given-names>
</name>
</person-group>
<article-title>The Kolmogorov-Smirnov test of goodness of fit</article-title>
<source/>
<italic toggle="yes">Journal of the American Statistical Association</italic>
<year>1951</year>
<volume>46</volume>
<issue>253</issue>
<fpage>68</fpage>
<lpage>78</lpage>
<pub-id pub-id-type="doi">10.1080/01621459.1951.10500769</pub-id>
<pub-id pub-id-type="other">2-s2.0-84941871856</pub-id>
</element-citation>
</ref>
<ref id="B42">
<label>42</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Benjamini</surname>
<given-names>Y.</given-names>
</name>
<name>
<surname>Hochberg</surname>
<given-names>Y.</given-names>
</name>
</person-group>
<article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title>
<source/>
<italic toggle="yes">Journal of the Royal Statistical Society: Series B (Methodological)</italic>
<year>1995</year>
<volume>57</volume>
<issue>1</issue>
<fpage>289</fpage>
<lpage>300</lpage>
<pub-id pub-id-type="doi">10.1111/j.2517-6161.1995.tb02031.x</pub-id>
</element-citation>
</ref>
<ref id="B43">
<label>43</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Brown</surname>
<given-names>C. J.</given-names>
</name>
<name>
<surname>Miller</surname>
<given-names>S. P.</given-names>
</name>
<name>
<surname>Booth</surname>
<given-names>B. G.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Prediction of motor function in very preterm infants using connectome features and local synthetic instances</article-title>
<source/>
<italic toggle="yes">Lecture Notes in Computer Science</italic>
<year>2015</year>
<publisher-loc>Berlin, Gramny</publisher-loc>
<publisher-name>Springer International Publishing</publisher-name>
<fpage>69</fpage>
<lpage>76</lpage>
</element-citation>
</ref>
<ref id="B44">
<label>44</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Cuingnet</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Rosso</surname>
<given-names>C.</given-names>
</name>
<name>
<surname>Chupin</surname>
<given-names>M.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Spatial regularization of SVM for the detection of diffusion alterations associated with stroke outcome</article-title>
<source/>
<italic toggle="yes">Medical Image Analysis</italic>
<year>2011</year>
<volume>15</volume>
<issue>5</issue>
<fpage>729</fpage>
<lpage>737</lpage>
<pub-id pub-id-type="doi">10.1016/j.media.2011.05.007</pub-id>
<pub-id pub-id-type="other">2-s2.0-80052141596</pub-id>
<pub-id pub-id-type="pmid">21752695</pub-id>
</element-citation>
</ref>
<ref id="B45">
<label>45</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ou</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Xie</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Li</surname>
<given-names>X.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Atomic connectomics signatures for characterization and differentiation of mild cognitive impairment</article-title>
<source/>
<italic toggle="yes">Brain Imaging and Behavior</italic>
<year>2015</year>
<volume>9</volume>
<issue>4</issue>
<fpage>663</fpage>
<lpage>677</lpage>
<pub-id pub-id-type="doi">10.1007/s11682-014-9320-1</pub-id>
<pub-id pub-id-type="other">2-s2.0-84948428370</pub-id>
<pub-id pub-id-type="pmid">25355371</pub-id>
</element-citation>
</ref>
<ref id="B46">
<label>46</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ziv</surname>
<given-names>E.</given-names>
</name>
<name>
<surname>Tymofiyeva</surname>
<given-names>O.</given-names>
</name>
<name>
<surname>Ferriero</surname>
<given-names>D. M.</given-names>
</name>
<name>
<surname>Barkovich</surname>
<given-names>A. J.</given-names>
</name>
<name>
<surname>Hess</surname>
<given-names>C. P.</given-names>
</name>
<name>
<surname>Xu</surname>
<given-names>D.</given-names>
</name>
</person-group>
<article-title>A machine learning approach to automated structural network analysis: application to neonatal encephalopathy</article-title>
<source/>
<italic toggle="yes">PLoS One</italic>
<year>2013</year>
<volume>8</volume>
<issue>11</issue>
<pub-id pub-id-type="publisher-id">e78824</pub-id>
<pub-id pub-id-type="doi">10.1371/journal.pone.0078824</pub-id>
<pub-id pub-id-type="other">2-s2.0-84894362985</pub-id>
</element-citation>
</ref>
<ref id="B47">
<label>47</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Burges</surname>
<given-names>C. J. C.</given-names>
</name>
</person-group>
<article-title>A tutorial on support vector machines for pattern recognition</article-title>
<source/>
<italic toggle="yes">Data Mining and Knowledge Discovery</italic>
<year>1998</year>
<volume>2</volume>
<issue>2</issue>
<fpage>121</fpage>
<lpage>167</lpage>
</element-citation>
</ref>
<ref id="B48">
<label>48</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Beheshti</surname>
<given-names>I.</given-names>
</name>
<name>
<surname>Demirel</surname>
<given-names>H.</given-names>
</name>
</person-group>
<article-title>Feature-ranking-based Alzheimer’s disease classification from structural MRI</article-title>
<source/>
<italic toggle="yes">Magnetic Resonance Imaging</italic>
<year>2016</year>
<volume>34</volume>
<issue>3</issue>
<fpage>252</fpage>
<lpage>263</lpage>
<pub-id pub-id-type="doi">10.1016/j.mri.2015.11.009</pub-id>
<pub-id pub-id-type="other">2-s2.0-84957958378</pub-id>
<pub-id pub-id-type="pmid">26657976</pub-id>
</element-citation>
</ref>
<ref id="B49">
<label>49</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Peng</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Long</surname>
<given-names>F.</given-names>
</name>
<name>
<surname>Ding</surname>
<given-names>C.</given-names>
</name>
</person-group>
<article-title>Feature selection based on mutual information: criteria of max-dependency, max-relevance, and min-redundancy</article-title>
<source/>
<italic toggle="yes">IEEE Transactions on Pattern Analysis and Machine Intelligence</italic>
<year>2005</year>
<volume>27</volume>
<issue>8</issue>
<fpage>1226</fpage>
<lpage>1238</lpage>
<pub-id pub-id-type="doi">10.1109/tpami.2005.159</pub-id>
<pub-id pub-id-type="other">2-s2.0-24344458137</pub-id>
<pub-id pub-id-type="pmid">16119262</pub-id>
</element-citation>
</ref>
<ref id="B50">
<label>50</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Min</surname>
<given-names>R.</given-names>
</name>
<name>
<surname>Wu</surname>
<given-names>G.</given-names>
</name>
<name>
<surname>Cheng</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>Q.</given-names>
</name>
<name>
<surname>Shen</surname>
<given-names>D.</given-names>
</name>
</person-group>
<article-title>Multi-atlas based representations for Alzheimer’s disease diagnosis</article-title>
<source/>
<italic toggle="yes">Human Brain Mapping</italic>
<year>2014</year>
<volume>35</volume>
<issue>10</issue>
<fpage>5052</fpage>
<lpage>5070</lpage>
<pub-id pub-id-type="doi">10.1002/hbm.22531</pub-id>
<pub-id pub-id-type="other">2-s2.0-84927578310</pub-id>
<pub-id pub-id-type="pmid">24753060</pub-id>
</element-citation>
</ref>
<ref id="B51">
<label>51</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Baig</surname>
<given-names>M. Z.</given-names>
</name>
<name>
<surname>Aslam</surname>
<given-names>N.</given-names>
</name>
<name>
<surname>Aslam</surname>
<given-names>H. P. H.</given-names>
</name>
<name>
<surname>Zhang</surname>
<given-names>L.</given-names>
</name>
</person-group>
<article-title>Differential evolution algorithm as a tool for optimal feature subset selection in motor imagery EEG</article-title>
<source/>
<italic toggle="yes">Expert Systems with Applications</italic>
<year>2017</year>
<volume>90</volume>
<fpage>184</fpage>
<lpage>195</lpage>
<pub-id pub-id-type="doi">10.1016/j.eswa.2017.07.033</pub-id>
<pub-id pub-id-type="other">2-s2.0-85027505525</pub-id>
</element-citation>
</ref>
<ref id="B52">
<label>52</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jie</surname>
<given-names>N.-F.</given-names>
</name>
<name>
<surname>Zhu</surname>
<given-names>M.-H.</given-names>
</name>
<name>
<surname>Ma</surname>
<given-names>X.-Y.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Discriminating bipolar disorder from major depression based on SVM-FoBa: efficient feature selection with multimodal brain imaging data</article-title>
<source/>
<italic toggle="yes">IEEE Transactions on Autonomous Mental Development</italic>
<year>2015</year>
<volume>7</volume>
<issue>4</issue>
<fpage>320</fpage>
<lpage>331</lpage>
<pub-id pub-id-type="doi">10.1109/tamd.2015.2440298</pub-id>
<pub-id pub-id-type="other">2-s2.0-84961801436</pub-id>
<pub-id pub-id-type="pmid">26858825</pub-id>
</element-citation>
</ref>
<ref id="B53">
<label>53</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mundra</surname>
<given-names>P. A.</given-names>
</name>
<name>
<surname>Rajapakse</surname>
<given-names>J. C.</given-names>
</name>
</person-group>
<article-title>SVM-RFE with MRMR filter for gene selection</article-title>
<source/>
<italic toggle="yes">IEEE Transactions on Nanobioscience</italic>
<year>2010</year>
<volume>9</volume>
<issue>1</issue>
<fpage>31</fpage>
<lpage>37</lpage>
<pub-id pub-id-type="doi">10.1109/tnb.2009.2035284</pub-id>
<pub-id pub-id-type="other">2-s2.0-77950538864</pub-id>
<pub-id pub-id-type="pmid">19884101</pub-id>
</element-citation>
</ref>
<ref id="B54">
<label>54</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Asim</surname>
<given-names>Y.</given-names>
</name>
<name>
<surname>Raza</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Kamran Malik</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Rathore</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Hussain</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Iftikhar</surname>
<given-names>M. A.</given-names>
</name>
</person-group>
<article-title>A multi-modal, multi-atlas-based approach for Alzheimer detection via machine learning</article-title>
<source/>
<italic toggle="yes">International Journal of Imaging Systems &amp; Technology</italic>
<year>2018</year>
<volume>28</volume>
<issue>2</issue>
<fpage>113</fpage>
<lpage>123</lpage>
<pub-id pub-id-type="doi">10.1002/ima.22263</pub-id>
<pub-id pub-id-type="other">2-s2.0-85040196830</pub-id>
</element-citation>
</ref>
<ref id="B55">
<label>55</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Klöppel</surname>
<given-names>S.</given-names>
</name>
<name>
<surname>Abdulkadir</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Jack</surname>
<given-names>C. R.</given-names>
</name>
<name>
<surname>Koutsouleris</surname>
<given-names>N.</given-names>
</name>
<name>
<surname>Mourão-Miranda</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Vemuri</surname>
<given-names>P.</given-names>
</name>
</person-group>
<article-title>Diagnostic neuroimaging across diseases</article-title>
<source/>
<italic toggle="yes">NeuroImage</italic>
<year>2012</year>
<volume>61</volume>
<issue>2</issue>
<fpage>457</fpage>
<lpage>463</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.11.002</pub-id>
<pub-id pub-id-type="other">2-s2.0-84860734393</pub-id>
<pub-id pub-id-type="pmid">22094642</pub-id>
</element-citation>
</ref>
<ref id="B56">
<label>56</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Orrù</surname>
<given-names>G.</given-names>
</name>
<name>
<surname>Pettersson-Yeo</surname>
<given-names>W.</given-names>
</name>
<name>
<surname>Marquand</surname>
<given-names>A. F.</given-names>
</name>
<name>
<surname>Sartori</surname>
<given-names>G.</given-names>
</name>
<name>
<surname>Mechelli</surname>
<given-names>A.</given-names>
</name>
</person-group>
<article-title>Using support vector machine to identify imaging biomarkers of neurological and psychiatric disease: a critical review</article-title>
<source/>
<italic toggle="yes">Neuroscience &amp; Biobehavioral Reviews</italic>
<year>2012</year>
<volume>36</volume>
<issue>4</issue>
<fpage>1140</fpage>
<lpage>1152</lpage>
<pub-id pub-id-type="doi">10.1016/j.neubiorev.2012.01.004</pub-id>
<pub-id pub-id-type="other">2-s2.0-84857000430</pub-id>
<pub-id pub-id-type="pmid">22305994</pub-id>
</element-citation>
</ref>
<ref id="B57">
<label>57</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Retico</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Bosco</surname>
<given-names>P.</given-names>
</name>
<name>
<surname>Cerello</surname>
<given-names>P.</given-names>
</name>
<name>
<surname>Fiorina</surname>
<given-names>E.</given-names>
</name>
<name>
<surname>Chincarini</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Fantacci</surname>
<given-names>M. E.</given-names>
</name>
</person-group>
<article-title>Predictive models based on support vector machines: whole-brain versus regional analysis of structural MRI in the Alzheimer’s disease</article-title>
<source/>
<italic toggle="yes">Journal of Neuroimaging</italic>
<year>2015</year>
<volume>25</volume>
<issue>4</issue>
<fpage>552</fpage>
<lpage>563</lpage>
<pub-id pub-id-type="doi">10.1111/jon.12163</pub-id>
<pub-id pub-id-type="other">2-s2.0-84937073920</pub-id>
<pub-id pub-id-type="pmid">25291354</pub-id>
</element-citation>
</ref>
<ref id="B58">
<label>58</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhang</surname>
<given-names>Y.</given-names>
</name>
<name>
<surname>Dong</surname>
<given-names>Z.</given-names>
</name>
<name>
<surname>Phillips</surname>
<given-names>P.</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Detection of subjects and brain regions related to Alzheimer’s disease using 3D MRI scans based on eigenbrain and machine learning</article-title>
<source/>
<italic toggle="yes">Frontiers in Computational Neuroscience</italic>
<year>2015</year>
<volume>9</volume>
<issue>9</issue>
<fpage>p. 66</fpage>
<pub-id pub-id-type="doi">10.3389/fncom.2015.00066</pub-id>
</element-citation>
</ref>
<ref id="B59">
<label>59</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Li</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Yang</surname>
<given-names>W.</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>S.</given-names>
</name>
</person-group>
<article-title>Classification of foreign fibers in cotton lint using machine vision and multi-class support vector machine</article-title>
<source/>
<italic toggle="yes">Computers and Electronics in Agriculture</italic>
<year>2010</year>
<volume>74</volume>
<issue>2</issue>
<fpage>274</fpage>
<lpage>279</lpage>
<pub-id pub-id-type="doi">10.1016/j.compag.2010.09.002</pub-id>
<pub-id pub-id-type="other">2-s2.0-78049254875</pub-id>
</element-citation>
</ref>
<ref id="B60">
<label>60</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Sundermann</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Herr</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Schwindt</surname>
<given-names>W.</given-names>
</name>
<name>
<surname>Pfleiderer</surname>
<given-names>B.</given-names>
</name>
</person-group>
<article-title>Multivariate classification of blood oxygen level-dependent FMRI data with diagnostic intention: a clinical perspective</article-title>
<source/>
<italic toggle="yes">American Journal of Neuroradiology</italic>
<year>2014</year>
<volume>35</volume>
<issue>5</issue>
<fpage>848</fpage>
<lpage>855</lpage>
<pub-id pub-id-type="doi">10.3174/ajnr.a3713</pub-id>
<pub-id pub-id-type="other">2-s2.0-84901041663</pub-id>
<pub-id pub-id-type="pmid">24029388</pub-id>
</element-citation>
</ref>
<ref id="B61">
<label>61</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Herr</surname>
<given-names>H.</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Xu</surname>
<given-names>Y.</given-names>
</name>
<name>
<surname>Jie</surname>
<given-names>X.</given-names>
</name>
</person-group>
<article-title>Alzheimer classification using a minimum spanning tree of high-order functional network on fMRI dataset</article-title>
<source/>
<italic toggle="yes">Frontiers in Neuroscience</italic>
<year>2017</year>
<volume>11</volume>
<fpage>p. 639</fpage>
<pub-id pub-id-type="doi">10.3389/fnins.2017.00639</pub-id>
<pub-id pub-id-type="other">2-s2.0-85036545558</pub-id>
</element-citation>
</ref>
<ref id="B62">
<label>62</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wang</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Hao</surname>
<given-names>X.</given-names>
</name>
<name>
<surname>Huang</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Shao</surname>
<given-names>W.</given-names>
</name>
<name>
<surname>Zhang</surname>
<given-names>D.</given-names>
</name>
</person-group>
<article-title>Discovering network phenotype between genetic risk factors and disease status via diagnosis-aligned multi-modality regression method in Alzheimer’s disease</article-title>
<source/>
<italic toggle="yes">Bioinformatics</italic>
<year>2019</year>
<volume>35</volume>
<issue>11</issue>
<fpage>1984</fpage>
<lpage>1957</lpage>
<pub-id pub-id-type="doi">10.1093/bioinformatics/bty911</pub-id>
</element-citation>
</ref>
<ref id="B63">
<label>63</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jie</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>M.</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Shen</surname>
<given-names>D.</given-names>
</name>
</person-group>
<article-title>Sub-network kernels for measuring similarity of brain connectivity networks in disease diagnosis</article-title>
<source/>
<italic toggle="yes">IEEE Transactions on Image Processing</italic>
<year>2018</year>
<volume>27</volume>
<issue>5</issue>
<fpage>2340</fpage>
<lpage>2353</lpage>
<pub-id pub-id-type="doi">10.1109/tip.2018.2799706</pub-id>
<pub-id pub-id-type="other">2-s2.0-85041391129</pub-id>
<pub-id pub-id-type="pmid">29470170</pub-id>
</element-citation>
</ref>
<ref id="B64">
<label>64</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhang</surname>
<given-names>D.</given-names>
</name>
<name>
<surname>Huang</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Jie</surname>
<given-names>B.</given-names>
</name>
<name>
<surname>Du</surname>
<given-names>J.</given-names>
</name>
<name>
<surname>Tu</surname>
<given-names>L.</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>M.</given-names>
</name>
</person-group>
<article-title>Ordinal pattern: a new descriptor for brain connectivity networks</article-title>
<source/>
<italic toggle="yes">IEEE Transactions on Medical Imaging</italic>
<year>2018</year>
<volume>37</volume>
<issue>7</issue>
<fpage>1711</fpage>
<lpage>1722</lpage>
<pub-id pub-id-type="doi">10.1109/tmi.2018.2798500</pub-id>
<pub-id pub-id-type="other">2-s2.0-85041010143</pub-id>
<pub-id pub-id-type="pmid">29969421</pub-id>
</element-citation>
</ref>
<ref id="B65">
<label>65</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Artoni</surname>
<given-names>F.</given-names>
</name>
<name>
<surname>Delorme</surname>
<given-names>A.</given-names>
</name>
<name>
<surname>Makeig</surname>
<given-names>S.</given-names>
</name>
</person-group>
<article-title>Applying dimension reduction to EEG data by principal component analysis reduces the quality of its subsequent independent component decomposition</article-title>
<source/>
<italic toggle="yes">NeuroImage</italic>
<year>2018</year>
<volume>175</volume>
<fpage>176</fpage>
<lpage>187</lpage>
<pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.03.016</pub-id>
<pub-id pub-id-type="other">2-s2.0-85045101890</pub-id>
<pub-id pub-id-type="pmid">29526744</pub-id>
</element-citation>
</ref>
</ref-list>
</back>
<floats-group>
<fig id="fig1" orientation="portrait" position="float">
<label>Figure 1</label>
<caption>
<p>Mean accuracy associated with the same number of discriminative features at five scales. The color map shows the statistical significance between each scale pair.</p>
</caption>
<graphic xlink:href="CMMM2019-9108108.001"></graphic>
</fig>
<fig id="fig2" orientation="portrait" position="float">
<label>Figure 2</label>
<caption>
<p>MID values associated with same number of discriminative features at five scales.</p>
</caption>
<graphic xlink:href="CMMM2019-9108108.002"></graphic>
</fig>
<fig id="fig3" orientation="portrait" position="float">
<label>Figure 3</label>
<caption>
<p>Frequency and proportion distribution of MID values for all features at five scales. (a) Frequency distribution. (b) Proportional distribution. Adj_<italic>R</italic><sub>sqr</sub>, adjusted <italic>R</italic><sup>2</sup>.</p>
</caption>
<graphic xlink:href="CMMM2019-9108108.003"></graphic>
</fig>
<fig id="fig4" orientation="portrait" position="float">
<label>Figure 4</label>
<caption>
<p>Frequency and proportion distribution of mean MID values as the features increased at five scales. (a) Frequency distribution. (b) Proportion distribution. Features were sorted by <italic>P</italic> value (from small to large) and the step size was three. Adj_<italic>R</italic><sub>sqr</sub>, adjusted <italic>R</italic><sup>2</sup>.</p>
</caption>
<graphic xlink:href="CMMM2019-9108108.004"></graphic>
</fig>
<fig id="fig5" orientation="portrait" position="float">
<label>Figure 5</label>
<caption>
<p>Correlation analysis between <italic>P</italic> values and MID values. (a–e) Correlation data for each of the five scales. <italic>F</italic> Correlation of all discriminative features. Adj_<italic>R</italic><sub>sqr</sub>, adjusted <italic>R</italic><sup>2</sup>.</p>
</caption>
<graphic xlink:href="CMMM2019-9108108.005"></graphic>
</fig>
<fig id="fig6" orientation="portrait" position="float">
<label>Figure 6</label>
<caption>
<p>Classification accuracy with an increasing number of features at five scales. The black dotted line indicates the position where <italic>P</italic> ≈ 0.05; the red solid line with a red circle indicates the peak value. ACC<sub>0.05</sub>, classification accuracy at <italic>P</italic> ≈ 0.05; NoF, number of features; ACC<sub>max</sub>, peak classification accuracy.</p>
</caption>
<graphic xlink:href="CMMM2019-9108108.006"></graphic>
</fig>
<fig id="fig7" orientation="portrait" position="float">
<label>Figure 7</label>
<caption>
<p>Redundancy between features at five scales. The color map shows the statistical significance of redundancy between each scale pair. <italic>R</italic>, redundancy. Error bars show the standard deviation.</p>
</caption>
<graphic xlink:href="CMMM2019-9108108.007"></graphic>
</fig>
<fig id="fig8" orientation="portrait" position="float">
<label>Figure 8</label>
<caption>
<p>Correlation analysis between the anatomical distance of brain regions and redundancy. (a–e) Correlation data for each of the five scales. (<italic>F</italic>) Correlation for all five scales. <italic>R</italic>, redundancy. Adj_<italic>R</italic><sub>sqr</sub>, adjusted <italic>R</italic><sup>2</sup>.</p>
</caption>
<graphic xlink:href="CMMM2019-9108108.008"></graphic>
</fig>
<table-wrap id="tab1" orientation="portrait" position="float">
<label>Table 1</label>
<caption>
<p>Demographic and clinical characteristics of the participants.</p>
</caption>
<table frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" colspan="1" rowspan="1"> </th>
<th align="center" colspan="1" rowspan="1">NC (<italic>n</italic> = 28)</th>
<th align="center" colspan="1" rowspan="1">MDD (<italic>n</italic> = 38)</th>
<th align="center" colspan="1" rowspan="1">
<italic>P</italic> value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="2">Age (years)</td>
<td align="center" colspan="1" rowspan="1">17–51</td>
<td align="center" colspan="1" rowspan="1">17–49</td>
<td align="center" colspan="1" rowspan="1">
<italic>t</italic> = 0.76<sup>a</sup></td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(26.6 ± 9.35)</td>
<td align="center" colspan="1" rowspan="1">(28.4 ± 8.99)</td>
<td align="center" colspan="1" rowspan="1">
<italic>P</italic> = 0.41<sup>a</sup></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="2">Gender (male/female)</td>
<td align="center" colspan="1" rowspan="2">13/15</td>
<td align="center" colspan="1" rowspan="2">15/23</td>
<td align="center" colspan="1" rowspan="1">
<sup><italic>χ</italic>2</sup> = 0.31<sup>b</sup></td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">
<italic>P</italic> = 0.55<sup>b</sup></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Handedness (<italic>R</italic>/<italic>L</italic>)</td>
<td align="center" colspan="1" rowspan="1">28/0</td>
<td align="center" colspan="1" rowspan="1">38/0</td>
<td align="center" colspan="1" rowspan="1">—</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">HAMD</td>
<td align="center" colspan="1" rowspan="1">NA</td>
<td align="center" colspan="1" rowspan="1">15–42 (22.8 ± 13.19)</td>
<td align="center" colspan="1" rowspan="1">—</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn>
<p>Data are presented as range (mean ± SD) or frequency. HAMD, Hamilton depression rating scale; MDD, major depressive disorder; NA, not applicable; NC, normal controls; <sup>a</sup>the <italic>t</italic> and <italic>P</italic> values were obtained by a two-sample two-tailed <italic>t</italic>-test; <sup>b</sup>the <italic>χ</italic><sup>2</sup> and <italic>P</italic> values were obtained by a two-tailed Pearson's <italic>χ</italic><sup>2</sup>-test.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="tab2" orientation="portrait" position="float">
<label>Table 2</label>
<caption>
<p>Maximum relevance-minimum redundancy terms.</p>
</caption>
<table frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" colspan="1" rowspan="1">Term</th>
<th align="center" colspan="1" rowspan="1">Abbreviation</th>
<th align="center" colspan="1" rowspan="1">Formula</th>
<th align="center" colspan="1" rowspan="1">Interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Dependency</td>
<td align="center" colspan="1" rowspan="1">
<italic>D</italic>
</td>
<td align="center" colspan="1" rowspan="1">
<italic>D</italic>=(1/|<italic>S</italic>|)∑<sub><italic>i</italic>∈<italic>S</italic></sub><italic>I</italic>(<italic>h</italic>, <italic>i</italic>)</td>
<td align="center" colspan="1" rowspan="1">Discriminating features are highly correlated with groups, and the most relevant features of the selection and categorization variables are selected. That is, the feature can reflect information relating to the groups to the greatest extent</td>
</tr>
<tr>
<td align="left" colspan="4" rowspan="1">
<hr/>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Redundancy</td>
<td align="center" colspan="1" rowspan="1">
<italic>R</italic>
</td>
<td align="center" colspan="1" rowspan="1">
<italic>R</italic>=(1/|<italic>S</italic>|<sup>2</sup>)∑<sub><italic>i</italic>,<italic>j</italic>∈<italic>S</italic></sub><italic>I</italic>(<italic>i</italic>, <italic>j</italic>)</td>
<td align="center" colspan="1" rowspan="1">Description of the dependency relationship between discriminative features. Minimal relevance between each discriminative feature is required; that is, the principle of minimum redundancy</td>
</tr>
<tr>
<td align="left" colspan="4" rowspan="1">
<hr/>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mutual information difference</td>
<td align="center" colspan="1" rowspan="1">MID</td>
<td align="center" colspan="1" rowspan="1">(<italic>D</italic> − <italic>R</italic>)</td>
<td align="center" colspan="1" rowspan="1">Difference between the maximum relevance and minimum redundancy, represented by the two optimization conditions</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn>
<p>
<italic>I</italic> refers to the mutual information value between two features (<italic>i</italic> and <italic>j</italic>). <italic>D</italic> refers to the mutual information value between the discriminative feature and the category (groups). <italic>h</italic> refers to the groups of the dataset. |<italic>S</italic>| refers to the number of feature sets. <italic>R</italic> refers to the redundancy between the features.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="tab3" orientation="portrait" position="float">
<label>Table 3</label>
<caption>
<p>Multinode scaling effects regarding the number of discriminative features and classifier performance.</p>
</caption>
<table frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" colspan="1" rowspan="1">Parcellation</th>
<th align="center" colspan="1" rowspan="1">AAL90</th>
<th align="center" colspan="1" rowspan="1">Parc256</th>
<th align="center" colspan="1" rowspan="1">Parc497</th>
<th align="center" colspan="1" rowspan="1">Parc1003</th>
<th align="center" colspan="1" rowspan="1">Parc1501</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Features (<italic>D</italic>/NE/BC)</td>
<td align="center" colspan="1" rowspan="1">5/4/7</td>
<td align="center" colspan="1" rowspan="1">16/13/19</td>
<td align="center" colspan="1" rowspan="1">31/28/36</td>
<td align="center" colspan="1" rowspan="1">55/71/60</td>
<td align="center" colspan="1" rowspan="1">82/77/81</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> Total</td>
<td align="center" colspan="1" rowspan="1">16</td>
<td align="center" colspan="1" rowspan="1">48</td>
<td align="center" colspan="1" rowspan="1">95</td>
<td align="center" colspan="1" rowspan="1">186</td>
<td align="center" colspan="1" rowspan="1">240</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Accuracy (%)</td>
<td align="center" colspan="1" rowspan="1">74.3</td>
<td align="center" colspan="1" rowspan="1">82.7</td>
<td align="center" colspan="1" rowspan="1">83.5</td>
<td align="center" colspan="1" rowspan="1">87.5</td>
<td align="center" colspan="1" rowspan="1">88.5</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Sensitivity (%)</td>
<td align="center" colspan="1" rowspan="1">79.3</td>
<td align="center" colspan="1" rowspan="1">89.3</td>
<td align="center" colspan="1" rowspan="1">92.0</td>
<td align="center" colspan="1" rowspan="1">87.3</td>
<td align="center" colspan="1" rowspan="1">91.9</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Specificity (%)</td>
<td align="center" colspan="1" rowspan="1">66.3</td>
<td align="center" colspan="1" rowspan="1">74.0</td>
<td align="center" colspan="1" rowspan="1">75.2</td>
<td align="center" colspan="1" rowspan="1">88.2</td>
<td align="center" colspan="1" rowspan="1">83.6</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn>
<p>
<italic>D</italic>, degree; NE, nodal efficiency; BC, betweenness centrality.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</floats-group>
</article>
</pmc-articleset>