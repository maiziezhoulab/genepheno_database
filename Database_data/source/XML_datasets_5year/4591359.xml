<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="research-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
<journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLoS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">26426329</article-id>
<article-id pub-id-type="pmc">4591359</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0139319</article-id>
<article-id pub-id-type="publisher-id">PONE-D-14-58540</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Concurrent Relations between Face Scanning and Language: A Cross-Syndrome Infant Study</article-title>
<alt-title alt-title-type="running-head">Face Scanning and Language in Three Neurodevelopmental Syndromes</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>D’Souza</surname>
<given-names>Dean</given-names>
</name>
<xref ref-type="aff" rid="aff001">
<sup>1</sup>
</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>D’Souza</surname>
<given-names>Hana</given-names>
</name>
<xref ref-type="aff" rid="aff002">
<sup>2</sup>
</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Johnson</surname>
<given-names>Mark H.</given-names>
</name>
<xref ref-type="aff" rid="aff001">
<sup>1</sup>
</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Karmiloff-Smith</surname>
<given-names>Annette</given-names>
</name>
<xref ref-type="aff" rid="aff001">
<sup>1</sup>
</xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Centre for Brain and Cognitive Development, Department of Psychological Sciences, Birkbeck, University of London, London, United Kingdom</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Experimental Psychology, University of Oxford, Oxford, United Kingdom</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor">
<name>
<surname>De Smedt</surname>
<given-names>Bert</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"></xref>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University of Leuven, BELGIUM</addr-line>
</aff>
<author-notes>
<fn fn-type="COI-statement" id="coi001">
<p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: AKS DD MHJ. Performed the experiments: DD HD. Analyzed the data: DD HD. Contributed reagents/materials/analysis tools: MHJ. Wrote the paper: DD HD AKS.</p>
</fn>
<corresp id="cor001">* E-mail: <email>a.karmiloff-smith@bbk.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>1</day>
<month>10</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="collection">
<year>2015</year>
</pub-date>
<volume>10</volume>
<issue>10</issue>
<elocation-id>e0139319</elocation-id>
<history>
<date date-type="received">
<day>31</day>
<month>12</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>12</day>
<month>9</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-statement>© 2015 D’Souza et al</copyright-statement>
<copyright-year>2015</copyright-year>
<copyright-holder>D’Souza et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/">
<license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="pone.0139319.pdf" xlink:type="simple"></self-uri>
<abstract>
<p>Typically developing (TD) infants enhance their learning of spoken language by observing speakers’ mouth movements. Given the fact that word learning is seriously delayed in most children with neurodevelopmental disorders, we hypothesized that this delay partly results from differences in visual face scanning, e.g., focusing attention away from the mouth. To test this hypothesis, we used an eye tracker to measure visual attention in 95 infants and toddlers with Down syndrome (DS), fragile X syndrome (FXS), and Williams syndrome (WS), and compared their data to 25 chronological- and mental-age matched 16-month-old TD controls. We presented participants with two talking faces (one on each side of the screen) and a sound (/ga/). One face (the congruent face) mouthed the syllable that the participants could hear (i.e., /ga/), while the other face (the incongruent face) mouthed a different syllable (/ba/) from the one they could hear. As expected, we found that TD children with a relatively large vocabulary made more fixations to the mouth region of the incongruent face than elsewhere. However, toddlers with FXS or WS who had a relatively large receptive vocabulary made more fixations to the <italic>eyes</italic> (rather than the mouth) of the incongruent face. In DS, by contrast, fixations to the speaker’s overall face (rather than to her eyes or mouth) predicted vocabulary size. These findings suggest that, at some point in development, different processes or strategies relating to visual attention are involved in language acquisition in DS, FXS, and WS. This knowledge may help further explain why language is delayed in children with neurodevelopmental disorders. It also raises the possibility that syndrome-specific interventions should include an early focus on efficient face-scanning behaviour.</p>
</abstract>
<funding-group>
<funding-statement>The authors are very grateful for the contributions families have made towards this study. The participation of the TD control participants in the research was supported by awards from the BASIS funding consortium led by Autistica (<ext-link ext-link-type="uri" xlink:href="http://www.basisnetwork.org">www.basisnetwork.org</ext-link>) and from the United Kingdom Medical Research Council (G0701484). The BASIS Team consists of (in alphabetical order): Tony Charman, Simon Baron-Cohen, Patrick Bolton, Kim Davies, Janice Fernandes, Jeanne Guiraud, Mark H. Johnson, Helen Maris, Helena Ribeiro and Leslie Tucker. The participation of participants with neurodevelopmental disorders was funded by the Waterloo Foundation (<ext-link ext-link-type="uri" xlink:href="http://www.waterloofoundation.org.uk/">http://www.waterloofoundation.org.uk/</ext-link>), Williams Syndrome Foundation United Kingdom (<ext-link ext-link-type="uri" xlink:href="http://www.williams-syndrome.org.uk/">http://www.williams-syndrome.org.uk/</ext-link>), Autour des Williams France (<ext-link ext-link-type="uri" xlink:href="http://www.autourdeswilliams.org/">http://www.autourdeswilliams.org/</ext-link>), and a Wellcome Trust Strategic Award (grant number: 098330/Z/12/Z). The recruiting of participants was supported by the Williams Syndrome Foundation, the Down Syndrome Association, and Down Syndrome Education International. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="13"></fig-count>
<table-count count="4"></table-count>
<page-count count="26"></page-count>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Due to ethical restrictions, the raw data cannot be made publicly available. All interested parties will be able to obtain the data upon request to <email>a.karmiloff-smith@bbk.ac.uk</email>, <email>dean.dsouza@ymail.com</email>, or <email>d.d’souza@ucl.ac.uk</email>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<title>Data Availability</title>
<p>Due to ethical restrictions, the raw data cannot be made publicly available. All interested parties will be able to obtain the data upon request to <email>a.karmiloff-smith@bbk.ac.uk</email>, <email>dean.dsouza@ymail.com</email>, or <email>d.d’souza@ucl.ac.uk</email>.</p>
</notes>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>From birth, infants are exposed to a socially rich environment, frequently seeing and hearing talking faces. Moreover, early on they show biases that orient them towards socially-relevant information such as face-like stimuli [<xref ref-type="bibr" rid="pone.0139319.ref001">1</xref>–<xref ref-type="bibr" rid="pone.0139319.ref002">2</xref>] and speech-like sounds [<xref ref-type="bibr" rid="pone.0139319.ref003">3</xref>–<xref ref-type="bibr" rid="pone.0139319.ref005">5</xref>]. Through their massive experience with talking faces, infants develop the capacity to detect face-voice synchrony [<xref ref-type="bibr" rid="pone.0139319.ref006">6</xref>–<xref ref-type="bibr" rid="pone.0139319.ref010">10</xref>], to match lip movements to speech sounds [<xref ref-type="bibr" rid="pone.0139319.ref011">11</xref>–<xref ref-type="bibr" rid="pone.0139319.ref013">13</xref>], and to use visual speech cues to enhance their speech perception [<xref ref-type="bibr" rid="pone.0139319.ref014">14</xref>–<xref ref-type="bibr" rid="pone.0139319.ref018">18</xref>]. Moreover, they learn to use visual speech cues even in the absence of auditory speech information. For instance, when presented with silent video clips of speakers reciting sentences, 4- and 6-month-olds can visually discriminate their native language from an unfamiliar one [<xref ref-type="bibr" rid="pone.0139319.ref019">19</xref>].</p>
<p>Although much research has focused on the infant’s ability to process auditory speech [<xref ref-type="bibr" rid="pone.0139319.ref020">20</xref>], and while some has examined how infants extract visual information from talking faces [<xref ref-type="bibr" rid="pone.0139319.ref019">19</xref>] and integrate auditory/visual speech input (e.g., [<xref ref-type="bibr" rid="pone.0139319.ref014">14</xref>]), little is known about how these basic-level abilities are used to construct higher-level language skills. This is because few studies have explored the link between face scanning and language ability. One study, involving typically developing (TD) infants and infants at high risk of developing autism, used growth curve analyses to demonstrate that 6-month-olds who fixated more on their mother’s mouth during live mother-child interaction develop language at significantly higher rates and have significantly higher expressive scores at 24 months than infants who fixated more on their mother’s eyes [<xref ref-type="bibr" rid="pone.0139319.ref021">21</xref>]. This effect amounted to a difference of more than 4 months in developmental age, which suggests that gaze to mouth is a useful predictor of individual differences in language development. Importantly, no differences were found between the high-risk infants and TD controls. The finding was also independent of autism diagnosis at outcome. Thus, the authors concluded that their finding reveals a <italic>normative</italic> mechanism of language development. Because an infant’s ability to perceive phonemes facilitates his or her acquisition of language [<xref ref-type="bibr" rid="pone.0139319.ref022">22</xref>], Young and colleagues [<xref ref-type="bibr" rid="pone.0139319.ref021">21</xref>] hypothesise that any developmental phenomenon—including visual attention to the mouth—that facilitates speech perception will also facilitate later language development. Furthermore, adult research by Schwartz, Berthommier, and Savariaux [<xref ref-type="bibr" rid="pone.0139319.ref023">23</xref>] has shown that viewing a speaker’s mouth improves the intelligibility of their speech when embedded in noise. In other words, not only does visual input from the mouth contribute to infants’ learning of auditory phoneme categories [<xref ref-type="bibr" rid="pone.0139319.ref024">24</xref>]—and thus to their ability to acquire language—but it may be especially helpful at all ages for speech perception under noisy conditions [<xref ref-type="bibr" rid="pone.0139319.ref025">25</xref>].</p>
<p>The adult findings of Schwartz et al. [<xref ref-type="bibr" rid="pone.0139319.ref023">23</xref>] have yet to be demonstrated in TD children. However, the findings of Young et al. [<xref ref-type="bibr" rid="pone.0139319.ref021">21</xref>] have received support from an event-related potentials (ERP) study. Key, Stone, and Williams [<xref ref-type="bibr" rid="pone.0139319.ref026">26</xref>] presented 9-month-old infants with photographs of an unfamiliar face. On 30% of the trials, they replaced the eyes or mouth of the face with the corresponding parts (eyes, mouth) of a different face. Whereas eye changes only had an effect on face perception mechanisms (as reflected by a larger occipito-temporal N290 ERP component with short latency), the N290 response to mouth changes was also correlated with a parent-report measure of receptive communication. In other words, the size of the N290 brain response to visual changes in the mouth region of a face was positively correlated with language ability in a group of TD 9-month-olds. Thus, observing lip movements provides speech-related information and plays an important role in communication (see also [<xref ref-type="bibr" rid="pone.0139319.ref027">27</xref>–<xref ref-type="bibr" rid="pone.0139319.ref029">29</xref>]).</p>
<p>Conversely, Reid and Striano [<xref ref-type="bibr" rid="pone.0139319.ref030">30</xref>] suggest that focusing on the <italic>eyes</italic> (i.e., rather than the mouth) is crucial for language development, because eye gaze is a precursor to complex joint attention skills, imitation, and acquiring new knowledge and skills (see also [<xref ref-type="bibr" rid="pone.0139319.ref031">31</xref>]). For example, children acquire expressive labels for objects partly by following another person’s gaze to an object while that person provides the corresponding label. Indeed, in line with Reid and Striano’s prediction, greater attention to eyes in 6-month-olds has been associated with better joint attention skills at 8 and 12 months [<xref ref-type="bibr" rid="pone.0139319.ref032">32</xref>], and gaze following in 6-month-olds has been positively associated with vocabulary size at 18 months [<xref ref-type="bibr" rid="pone.0139319.ref033">33</xref>–<xref ref-type="bibr" rid="pone.0139319.ref034">34</xref>].</p>
<p>Why is there disagreement over whether the eyes or the mouth are more important as the focus of attention for language development? We suggest that the importance of mouth gaze versus eye gaze may change as a function of developmental time. According to the literature, eye gaze is important for joint attention, triadic attention, emotional face processing, imitation, etc., but mouth gaze may play a critical role in extracting visual information (e.g., lip reading) that facilitates understanding of unfamiliar, noisy, or confusing (auditory) speech. Indeed, the infant’s focus of attention to features in talking faces changes over the course of the first year of life. Lewkowicz and Hansen-Tift [<xref ref-type="bibr" rid="pone.0139319.ref035">35</xref>] presented 4-, 6-, 8-, 10-, and 12-month-old English-learners with video clips of a female speaking either the infants’ native (English) or a non-native (Spanish) language. Irrespective of language familiarity, 4-month-olds looked longer at the eyes, 6-month-olds looked equally long at the eyes and the mouth, and 8- and 9-month-olds looked longer at the mouth area. Twelve-month-olds looked equally long at the eyes and mouth when native speech was spoken, whereas they maintained their looking towards the mouth area for the non-native language. The authors argue that expertise (e.g., perceptual narrowing) explains this behaviour: non-native speech requires complementary audio-visual cues from the mouth region. Although Lewkowicz and Hansen-Tift did not measure language ability in the studied children, they concluded that—from around 8 months of age—attention to a speaker’s mouth “corresponds to the emergence of speech production during typical development and, thus, suggests that access to the redundant audiovisual cues available in the mouth is critical for normal development” (p.1435).</p>
<p>From this literature, we hypothesized that face-scanning patterns would be associated with language ability and, in particular, would change over developmental time. Such findings could have important implications for atypical development. Children with neurodevelopmental disorders often present with language delay [<xref ref-type="bibr" rid="pone.0139319.ref036">36</xref>]. Could their language delay be partly explained by atypical face scanning patterns? Interestingly, there is some evidence that visual scanning patterns differ across atypical populations [<xref ref-type="bibr" rid="pone.0139319.ref037">37</xref>]. For instance, individuals with Williams syndrome (a rare genetic disorder) spend significantly more time looking at the eyes of a face than TD controls [<xref ref-type="bibr" rid="pone.0139319.ref038">38</xref>–<xref ref-type="bibr" rid="pone.0139319.ref041">41</xref>], whereas those with fragile X syndrome (a different, more common genetic disorder) often avoid eye contact altogether [<xref ref-type="bibr" rid="pone.0139319.ref042">42</xref>]. (To our knowledge, the relationship between eye gaze aversion in FXS and language ability has never hitherto been explored.)</p>
<p>To address our question (‘Could language delay be partly explained by atypical face scanning?’), in the present study we decided to investigate the face-scanning patterns of infants and toddlers with different neurodevelopmental disorders (Down syndrome [DS], fragile X syndrome [FXS], Williams syndrome [WS]; see <xref ref-type="table" rid="pone.0139319.t001">Table 1</xref>). These particular disorders were selected because their pathology (aetiology, pathogenesis, morphologic changes, clinical manifestations) is well defined; other disorders, e.g., autism, are multifactorial syndromes, with many causes, many subtypes, and no clear unifying mechanisms at either the molecular, cellular, or systems level. Our aim was to ascertain whether face-scanning patterns relate to language ability–and if so, <italic>how</italic> they relate to it.</p>
<table-wrap id="pone.0139319.t001" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.t001</object-id>
<label>Table 1</label>
<caption>
<title>A brief description of three neurodevelopmental disorders.</title>
</caption>
<alternatives>
<graphic id="pone.0139319.t001g" xlink:href="pone.0139319.t001"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="1">Group</th>
<th align="left" colspan="1" rowspan="1">Description</th>
<th align="left" colspan="1" rowspan="1">References</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Down syndrome (DS)</td>
<td align="left" colspan="1" rowspan="1">The most common chromosome abnormality, DS is caused by the trisomy of chromosome 21. It is characterised by mild to moderate intellectual disability, decelerated maturation (neoteny), and a number of other physical, cognitive, and behavioural atypicalities, including poor verbal working memory and language delay.</td>
<td align="left" colspan="1" rowspan="1">[<xref ref-type="bibr" rid="pone.0139319.ref043">43</xref>–<xref ref-type="bibr" rid="pone.0139319.ref044">44</xref>]</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Fragile X syndrome (FXS)</td>
<td align="left" colspan="1" rowspan="1">The most common form of inherited intellectual disability in males, FXS is caused by an expansion of the unstable CGG repeat within the FMR1 gene. Affected individuals often present with an attentional deficit, anxiety, gaze aversion, and language delay.</td>
<td align="left" colspan="1" rowspan="1">[<xref ref-type="bibr" rid="pone.0139319.ref045">45</xref>–<xref ref-type="bibr" rid="pone.0139319.ref046">46</xref>]</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Williams syndrome (WS)</td>
<td align="left" colspan="1" rowspan="1">A rare genetic disorder, caused by a hemizygotic microdeletion of approximately 1.6 Mb containing ~28 genes on chromosome 7 (7q11.23). WS is characterized by an uneven cognitive profile with particularly weak visuo-spatial construction abilities. Affected individuals are often hyper-social and attracted to faces. Although language ability is a relative strength in later development, they present with language delay in early development.</td>
<td align="left" colspan="1" rowspan="1">[<xref ref-type="bibr" rid="pone.0139319.ref047">47</xref>–<xref ref-type="bibr" rid="pone.0139319.ref048">48</xref>]</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>We presented participants with two talking faces (one on each side of a screen) and a sound (/ga/). One face (the congruent face) mouthed the syllable that the participants could hear (/ga/), while the other face (the incongruent face) mouthed a different syllable (/ba/) from the one they could hear (/ga/). If mouth gaze does indeed play a role in extracting visual information that facilitates understanding of unfamiliar or confusing (auditory) speech, then we should expect that the children who focus their attention towards the mouth of the incongruent face will have relatively larger vocabularies than those who direct their attention elsewhere.</p>
<p>Based on the results of Lewkowicz and Hansen-Tift [<xref ref-type="bibr" rid="pone.0139319.ref035">35</xref>] and others [<xref ref-type="bibr" rid="pone.0139319.ref021">21</xref>, <xref ref-type="bibr" rid="pone.0139319.ref023">23</xref>, <xref ref-type="bibr" rid="pone.0139319.ref026">26</xref>], we predicted that the 16-month-old TD controls would focus more on the incongruent than congruent face and that those whose focus was more on the mouth region of the incongruent speaking face would have a larger vocabulary. We also predicted no correlation between gaze towards the eyes and vocabulary size. This is because, though eye gaze is important for cognitive and social development, it is not relevant for children in this particular experimental context. That is, although children may show a general bias towards the eyes, the eyes provide no useful information in this context. So, unlike gaze to the mouth, there should be no relationship between gaze to the eyes and vocabulary size. Finally, we hypothesized that infants and toddlers with WS would fixate for longer on the eyes (as the previous literature suggests [<xref ref-type="bibr" rid="pone.0139319.ref038">38</xref>]) than the other groups, and hence obtain less visual cue information from the mouth. In other words, we predicted that they would not use visual mouth cues. Given the current state of the literature, no a priori predictions could be made with respect to the DS and FXS groups. Although we expected toddlers with FXS to avoid fixating on the eyes, it was impossible to predict whether they would focus on the visual mouth cues or avoid the face altogether (see <xref ref-type="table" rid="pone.0139319.t002">Table 2</xref> for a summary of the predictions).</p>
<table-wrap id="pone.0139319.t002" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.t002</object-id>
<label>Table 2</label>
<caption>
<title>Summary of predictions.</title>
</caption>
<alternatives>
<graphic id="pone.0139319.t002g" xlink:href="pone.0139319.t002"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="1">Group</th>
<th align="left" colspan="1" rowspan="1">Prediction</th>
<th align="left" colspan="1" rowspan="1">Reason</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Typical development (TD)</td>
<td align="left" colspan="1" rowspan="1">TD children who more often fixate on the mouth in the incongruent face will have larger vocabularies than those who fixate elsewhere.</td>
<td align="left" colspan="1" rowspan="1">Mouth movements provide visual information that may facilitate understanding [<xref ref-type="bibr" rid="pone.0139319.ref014">14</xref>–<xref ref-type="bibr" rid="pone.0139319.ref018">18</xref>].</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Down syndrome (DS)</td>
<td align="left" colspan="1" rowspan="1">No a priori predictions were made.</td>
<td align="left" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Fragile X syndrome (FXS)</td>
<td align="left" colspan="1" rowspan="1">No specific predictions were made. However, it was expected that the toddlers with FXS would not fixate on the eyes of either face.</td>
<td align="left" colspan="1" rowspan="1">Gaze aversion is a characteristic of FXS [<xref ref-type="bibr" rid="pone.0139319.ref042">42</xref>].</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Williams syndrome (WS)</td>
<td align="left" colspan="1" rowspan="1">Children with WS will fixate on the eyes of both faces. They will make few fixations to the mouth of either face, and thus no relationship between mouth gaze and vocabulary will be detected.</td>
<td align="left" colspan="1" rowspan="1">Individuals with WS are drawn to eyes [<xref ref-type="bibr" rid="pone.0139319.ref038">38</xref>].</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec003">
<title>Participants</title>
<p>A total of 95 infants (around 15 months of age) and toddlers (around 30 months of age) from the three neurodevelopmental disorders were tested: 22 infants and 21 toddlers with DS, 14 toddlers with FXS (too few infants being available for testing), and 12 infants and 26 toddlers with WS. It was not possible to match infants with FXS on chronological age, because FXS is often diagnosed later in development. The mean age of diagnosis is around 3 years for boys with FXS and 3.5 years for girls with FXS [<xref ref-type="bibr" rid="pone.0139319.ref049">49</xref>]. The participants had been clinically diagnosed and/or genetically tested respectively for full trisomy 21, mutation of the FMR1 gene, or deletion of the ELN gene. Data collected from these children were compared with data from 25 typically developing (TD) controls. Data from these controls were made available through the British Autism Study of Infant Siblings (BASIS, <ext-link ext-link-type="uri" xlink:href="http://www.basisnetwork.org/">www.basisnetwork.org</ext-link>; NHS NRES London REC 08/H0718/76) who had been tested with the same materials and procedure. These TD controls did not have a sibling with autism. We did not include data from children at risk of developing autism. For all participants included in the present study, we verified that the primary language spoken in the home was English, even though a few of the children were exposed to more than one language. The race and ethnicity of the participants reflected the race and ethnicity of the general population. For instance, in each group the majority of participants (over 75%) were “White” or “White British”, while fewer than 10% were “non-White” and fewer than 15% were “British Mixed”.</p>
<p>Because children with DS, FXS, or WS have a mental age (MA) of approximately half their chronological age (CA), data from the TD control group were compared with data from MA-matched groups as well as CA-matched groups. Participants’ mental ages were obtained for the purpose of comparison, using the Mullen Scales of Infant Learning (MSEL [<xref ref-type="bibr" rid="pone.0139319.ref050">50</xref>]). Data from one participant with WS were excluded from all analyses, because the 37-month-old had a (relatively) high MA (31.25 months) that was 2.76 standard deviations (SD) above the group mean.</p>
<p>
<xref ref-type="table" rid="pone.0139319.t003">Table 3</xref> displays mean CA for each CA-matched group (<italic>TD controls</italic>, <italic>DS infants</italic>, <italic>WS infants</italic>). A one-way ANOVA shows that the CA-matched groups did not significantly differ on CA, <italic>F</italic>
<sub>2,56</sub> = 1.60, <italic>p</italic> = .212. Because the distribution of CA data in the WS and TD control groups looked slightly bimodal, an Independent-samples Kruskal-Wallis test was also carried out to confirm the results of the ANOVA. This non-parametric test also yielded no significant difference between the groups on CA, <italic>H</italic>(2) = 1.32, <italic>p</italic> = .516.</p>
<table-wrap id="pone.0139319.t003" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.t003</object-id>
<label>Table 3</label>
<caption>
<title>Mean chronological age (CA) and mental age (MA) for each group.</title>
</caption>
<alternatives>
<graphic id="pone.0139319.t003g" xlink:href="pone.0139319.t003"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="1">Group</th>
<th align="center" colspan="1" rowspan="1">
<italic>N</italic>
</th>
<th align="center" colspan="1" rowspan="1">CA in months <italic>(SD)</italic>
</th>
<th align="center" colspan="1" rowspan="1">MA in months <italic>(SD)</italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">TD controls</td>
<td align="center" colspan="1" rowspan="1">25</td>
<td align="center" colspan="1" rowspan="1">15.48 <italic>(0</italic>.<italic>82)</italic>
</td>
<td align="center" colspan="1" rowspan="1">16.60 <italic>(2</italic>.<italic>50)</italic>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DS infants<xref ref-type="table-fn" rid="t003fn001">
<sup>a</sup>
</xref>
</td>
<td align="center" colspan="1" rowspan="1">22</td>
<td align="center" colspan="1" rowspan="1">16.23 <italic>(1</italic>.<italic>81)</italic>
</td>
<td align="center" colspan="1" rowspan="1">8.46 <italic>(2</italic>.<italic>45)</italic>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">WS infants<xref ref-type="table-fn" rid="t003fn001">
<sup>a</sup>
</xref>
</td>
<td align="center" colspan="1" rowspan="1">12</td>
<td align="center" colspan="1" rowspan="1">16.13 <italic>(2</italic>.<italic>00)</italic>
</td>
<td align="center" colspan="1" rowspan="1">8.71 <italic>(1</italic>.<italic>89)</italic>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DS toddlers<xref ref-type="table-fn" rid="t003fn002">
<sup>b</sup>
</xref>
</td>
<td align="center" colspan="1" rowspan="1">21</td>
<td align="center" colspan="1" rowspan="1">28.83 <italic>(6</italic>.<italic>86)</italic>
</td>
<td align="center" colspan="1" rowspan="1">15.86 <italic>(4</italic>.<italic>52)</italic>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FXS toddlers<xref ref-type="table-fn" rid="t003fn002">
<sup>b</sup>
</xref>
</td>
<td align="center" colspan="1" rowspan="1">14</td>
<td align="center" colspan="1" rowspan="1">34.39 <italic>(8</italic>.<italic>32)</italic>
</td>
<td align="center" colspan="1" rowspan="1">15.34 <italic>(4</italic>.<italic>42)</italic>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">WS toddlers<xref ref-type="table-fn" rid="t003fn002">
<sup>b</sup>
</xref>
</td>
<td align="center" colspan="1" rowspan="1">25<xref ref-type="table-fn" rid="t003fn003">
<sup>c</sup>
</xref>
</td>
<td align="center" colspan="1" rowspan="1">30.14 <italic>(8</italic>.<italic>23)</italic>
</td>
<td align="center" colspan="1" rowspan="1">16.11 <italic>(4</italic>.<italic>53)</italic>
</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001">
<p>
<sup>a</sup> These two groups were CA-matched to the TD control group</p>
</fn>
<fn id="t003fn002">
<p>
<sup>b</sup> These three groups were MA-matched to the TD control group</p>
</fn>
<fn id="t003fn003">
<p>
<sup>c</sup> This table does not include the participant who was excluded from the analyses for having a relatively high MA (see main text).</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>MA data were normally distributed. A one-way ANOVA revealed that MA did not differ significantly across the MA-matched groups (<italic>TD controls</italic>, <italic>DS toddlers</italic>, <italic>FXS toddlers</italic>, <italic>WS toddlers</italic>), <italic>F</italic>
<sub>3,80</sub> = 0.32, <italic>p</italic> = .809 (<xref ref-type="table" rid="pone.0139319.t003">Table 3</xref>).</p>
</sec>
<sec id="sec004">
<title>Ethics Statement</title>
<p>The study was explained to participants’ caregivers beforehand, and written consent from them on behalf of their infants/toddlers was obtained. All experimental procedures were in accordance with the Declaration of Helsinki (<ext-link ext-link-type="uri" xlink:href="http://www.wma.net/en/30publications/10policies/b3/">www.wma.net/en/30publications/10policies/b3/</ext-link>), and were approved by the ethics committees of the Department of Psychological Sciences (Birkbeck, University of London), and the National Research Ethics Service (UK Health Research Authority).</p>
</sec>
<sec id="sec005">
<title>Design</title>
<p>The design was adapted from [<xref ref-type="bibr" rid="pone.0139319.ref014">14</xref>] and [<xref ref-type="bibr" rid="pone.0139319.ref051">51</xref>]. Two adult female faces, with moving lips, were presented side-by-side on a screen (<xref ref-type="fig" rid="pone.0139319.g001">Fig 1</xref>), with loudspeakers placed behind it. There were two trials. In each trial, the participants were presented with two talking faces (one on each side of the screen) and a sound. In one trial, the left-hand face mouthed the syllable /ba/ and the right-hand face mouthed the syllable /ga/, while the sound /ga/ was simultaneously heard. In the other trial, the left-hand face mouthed the syllable /ga/ and the right-hand face mouthed the syllable /ba/, while the sound /ga/ was heard throughout. Thus, in each trial, one speaking face was <italic>congruent</italic> (i.e., the visual stimulus matched the auditory stimulus) and the other speaking face was <italic>incongruent</italic> (i.e., there was a mismatch between the visual stimulus and the auditory stimulus). The two trials (i.e., the position of the faces) were counterbalanced. There were two other conditions, in which the sound /ba/ (rather than /ga/) was heard. Thus, all participants took part in four counterbalanced conditions in total. However, the visual /ga/ and the auditory /ba/ produce an illusory percept (the McGurk effect) that will be reported elsewhere.</p>
<fig id="pone.0139319.g001" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g001</object-id>
<label>Fig 1</label>
<caption>
<title>An example of the visual stimuli used in the experiment, including the positioning and sizes in visual angle of the Areas-Of-Interest (eyes, face, and mouth).</title>
</caption>
<graphic xlink:href="pone.0139319.g001"></graphic>
</fig>
</sec>
<sec id="sec006">
<title>Materials</title>
<p>The same stimuli were used as in Kushnerenko et al. ([<xref ref-type="bibr" rid="pone.0139319.ref014">14</xref>]; see also [<xref ref-type="bibr" rid="pone.0139319.ref051">51</xref>–<xref ref-type="bibr" rid="pone.0139319.ref052">52</xref>]). The stimuli consisted of two 12-second video clips of two speaking faces, side-by-side, of the same female native English speaker articulating either the /ba/ or /ga/ syllable against a black background (see <xref ref-type="fig" rid="pone.0139319.g001">Fig 1</xref> for an example of the visual stimuli, including the positioning and sizes in visual angle of the Areas-of-Interest). In one video clip, the left-hand face articulated the /ba/ syllable, while the right-hand face articulated the /ga/ syllable. In the other video clip, the left-hand face articulated the /ga/ syllable, while the right-hand face articulated the /ba/ syllable. In both video clips, the sound /ga/ was played. The faces were approximately life size. The video clips and stereo soundtracks were digitised at a rate of 25 frames per second and 44.1 kHz with 16-bit resolution.</p>
<p>Each 12 s video clip started with lips fully closed, with the face being silent for the first nine frames (360 ms). The subsequent voiced section lasted for seven frames, followed by three frames of the mouth closing. Thus, sound onset began 360 ms after the onset of the two visual face stimuli, and the voiced section lasted for 280 ms. The mouth opening for the visual /ga/ stimulus started about 260 ms prior to sound onset. For the visual /ba/, it started simultaneously with sound onset, with the lips pressing together around 280 ms prior to sound onset. Total duration of the stimulus (i.e., one mouth movement and a simultaneous sound) was 760 ms, and stimulus onset asynchrony (SOA) was 760 ms, with each video clip (15 repetitions of mouth movements and a simultaneous sound) being 12 s long.</p>
<p>In other words, there were two video clips (two conditions). Each video clip lasted 12 seconds. Each video clip included 15 repetitions of mouth movements and a simultaneous sound (/ga/). Each repetition (which included the opening and closing of the mouth) lasted for 760 ms. Each repetition included the sound (/ga/), which lasted for 280 ms. Incongruent face stimuli were created by dubbing the auditory /ga/ onto the visual /ba/. The consonantal burst in the audio file was aligned with the consonantal burst in the video file.</p>
<p>A Tobii T120 remote eye tracker (Tobii Technology AB) was used to capture moment-to-moment point of gaze at a sampling rate of 120 Hz, with measurement accuracy of about 0.5°. The visual stimuli were presented on a 34 x 27 cm TFT liquid crystal display monitor, with a resolution of 1280 x 1024 pixels and a response rate of 4 ms. The tracking equipment and stimulus presentation were controlled using Tobii Studio 2.1.14. A camera mounted directly above the horizontal midpoint of the screen was used to monitor and record infant behaviour. Auditory stimuli were delivered via two speakers positioned behind the display monitor and facing the participant.</p>
<sec id="sec007">
<title>Measuring vocabulary levels</title>
<p>The MacArthur-Bates Communicative Developmental Inventory (<italic>CDI</italic> [<xref ref-type="bibr" rid="pone.0139319.ref053">53</xref>]) was used to assess language in the infants and toddlers. The CDI is a standardised parent report measure of vocabulary size (comprehension and production). It comes in two forms: <italic>Gestures and words</italic> and <italic>Words and sentences</italic>. The CDI <italic>Gestures and words</italic> scale covers the period from 8 to 16 months; the CDI <italic>Words and sentences</italic> scale from 16 to 30 months.</p>
<p>In the current study, parents were given the CDI <italic>Gestures and words</italic> scale. Although the chronological age of some of our participants was above that of the ceiling (16 months) of this younger scale of the CDI, language delay is common among those with neurodevelopmental disorders and, indeed, no atypical participant in our study was at ceiling. The word list consists of 396 words in 19 semantic categories. For each word, the questionnaire measures whether the child only understands the word or whether the child both understands and produces the word.</p>
<p>For the analyses, raw scores (i.e., the number of words the child understands and the number of words the child both understands and says) rather than standardized/normalized scores were used. This is because tests such as the CDI are only standardized for TD children and thus lack sensitivity at the extreme ends of the normal distribution. Yet infants and toddlers with neurodevelopmental disorders often score below the lowest percentile provided for the norms included in the CDI and similar tests.</p>
</sec>
</sec>
<sec id="sec008">
<title>Procedure</title>
<p>The questionnaire was posted to parents prior to the day of testing and completed within two weeks of their visit to the laboratory (where the experimental task was carried out). The parents were instructed to mark down which words their child could understand and which words their child could both understand and say.</p>
<p>For the experimental task, the same procedure was used as in [<xref ref-type="bibr" rid="pone.0139319.ref014">14</xref>] and [<xref ref-type="bibr" rid="pone.0139319.ref052">52</xref>], i.e., infants sat on their parent’s lap, in a dimly lit featureless room, facing the stimulus-presentation screen, with their eyes at a distance of approximately 60 cm from the screen. The experimenter sat behind a curtain and observed the infant, using Tobii Studio LiveViewer via a camera that was positioned centrally above the screen. The infants’ eye movements were recorded using Tobii Studio 2.1.14. Caregivers were asked to close their eyes during the experiment. Calibration was carried out using 5 points: one in each corner of the screen and one in the centre of the screen. Before each trial, a colour animation and interesting sounds were played to attract the infant’s attention to the centre of the screen. Once the child’s attention was focused on the screen centre, the attention grabber was terminated and the trial was started simultaneously. The total duration of the experimental procedure did not exceed 10 minutes.</p>
</sec>
<sec id="sec009">
<title>Analysis</title>
<p>For each participant, the quality of recording was measured as a percentage (the number of eye tracking samples that were correctly identified, divided by the number of attempts, so 50% means that one eye was found for the full recording or that both eyes were found for half the time. The eyes cannot be detected when a participant is looking away from the screen; this will result in a lower percentage). The quality of recording was at least 25% in all participants. The quality of recordings did not significantly differ across CA- or MA-matched groups, <italic>H</italic>(2) = 4.76, <italic>p</italic> = .093, <italic>F</italic>
<sub>3,81</sub> = 0.90, <italic>p</italic> = .448, respectively (see <xref ref-type="table" rid="pone.0139319.t004">Table 4</xref>). A non-parametric test was used for the CA-comparison because the data in the WS infant group had a continuous (rather than a normal) distribution.</p>
<table-wrap id="pone.0139319.t004" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.t004</object-id>
<label>Table 4</label>
<caption>
<title>Quality of data for each group.</title>
</caption>
<alternatives>
<graphic id="pone.0139319.t004g" xlink:href="pone.0139319.t004"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="1">Group</th>
<th align="center" colspan="1" rowspan="1">
<italic>N</italic>
</th>
<th align="center" colspan="1" rowspan="1">Mean (%)</th>
<th align="center" colspan="1" rowspan="1">
<italic>SD</italic>
</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">TD controls</td>
<td align="center" colspan="1" rowspan="1">25</td>
<td align="center" colspan="1" rowspan="1">82.2</td>
<td align="center" colspan="1" rowspan="1">12.7</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DS infants<xref ref-type="table-fn" rid="t004fn001">
<sup>a</sup>
</xref>
</td>
<td align="center" colspan="1" rowspan="1">22</td>
<td align="center" colspan="1" rowspan="1">80.1</td>
<td align="center" colspan="1" rowspan="1">14.3</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">WS infants<xref ref-type="table-fn" rid="t004fn001">
<sup>a</sup>
</xref>
</td>
<td align="center" colspan="1" rowspan="1">12</td>
<td align="center" colspan="1" rowspan="1">63.4</td>
<td align="center" colspan="1" rowspan="1">25.1</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DS toddlers<xref ref-type="table-fn" rid="t004fn002">
<sup>b</sup>
</xref>
</td>
<td align="center" colspan="1" rowspan="1">21</td>
<td align="center" colspan="1" rowspan="1">75.3</td>
<td align="center" colspan="1" rowspan="1">13.1</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FXS toddlers<xref ref-type="table-fn" rid="t004fn002">
<sup>b</sup>
</xref>
</td>
<td align="center" colspan="1" rowspan="1">14</td>
<td align="center" colspan="1" rowspan="1">80.1</td>
<td align="center" colspan="1" rowspan="1">12.8</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">WS toddlers<xref ref-type="table-fn" rid="t004fn002">
<sup>b</sup>
</xref>
</td>
<td align="center" colspan="1" rowspan="1">25<sup>c</sup>
</td>
<td align="center" colspan="1" rowspan="1">77.4</td>
<td align="center" colspan="1" rowspan="1">19.4</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t004fn001">
<p>
<sup>a</sup> These two groups were CA-matched to the TD control group</p>
</fn>
<fn id="t004fn002">
<p>
<sup>b</sup> These three groups were MA-matched to the TD control group</p>
</fn>
</table-wrap-foot>
</table-wrap>
<p>Areas-Of-Interest (AOIs) were delineated around the eyes and mouth (<xref ref-type="fig" rid="pone.0139319.g001">Fig 1</xref>). These were defined before data were collected [<xref ref-type="bibr" rid="pone.0139319.ref051">51</xref>–<xref ref-type="bibr" rid="pone.0139319.ref052">52</xref>]. Duration of fixations and fixation count were calculated off-line using Tobii Studio and Tobii fixation filter (Tobii Inc.). <italic>Duration of fixations</italic> is the total duration (in seconds) of all fixations within an AOI. We decided to look also at fixation count, because there is evidence that it is positively correlated with at least some aspects of language acquisition [<xref ref-type="bibr" rid="pone.0139319.ref054">54</xref>]. <italic>Fixation count</italic> is the number of times the participant fixated on an AOI. It is a useful measure of attention-holding mechanisms [<xref ref-type="bibr" rid="pone.0139319.ref055">55</xref>–<xref ref-type="bibr" rid="pone.0139319.ref058">58</xref>], because it tells us something about how a stimulus <italic>maintains</italic> infants’ attention when other (conflicting) stimuli are also vying to capture attention [<xref ref-type="bibr" rid="pone.0139319.ref056">56</xref>].</p>
<p>All data were tested for normality. Data values that were above or below 2 standard deviations from the group mean were judged <italic>a priori</italic> to be outliers, and hence removed from the analysis (unless the data were transformed–see below). This decision was based on the literature [<xref ref-type="bibr" rid="pone.0139319.ref059">59</xref>]. If the data were non-normal (i.e., if <italic>Z</italic>
<sub><italic>Skewness</italic></sub> &gt; ±2 and Kolmogorov-Smirnov <italic>p</italic> &lt; .05), then they were transformed (log 10, reflected log 10, or arcsine, as appropriate). If the transformed data were non-normal (e.g., bimodal), then the untransformed data were analysed using the appropriate non-parametric test (e.g., Mann-Whitney).</p>
</sec>
</sec>
<sec id="sec010" sec-type="results">
<title>Results</title>
<p>First, we decided to characterise looking patterns across the different groups. To do so, we analysed where on the face each group was looking. Specifically, for each AOI (eyes/mouth, congruent/incongruent) we analysed duration and number of fixations.</p>
<sec id="sec011">
<title>CA-matched infant comparison (N.B. no infants with FXS participated)</title>
<sec id="sec012">
<title>Looking patterns–duration of fixations</title>
<p>Four fixation duration measures were taken: <italic>eyes in the congruent face</italic>, <italic>eyes in the incongruent face</italic>, <italic>mouth in the congruent face</italic>, and <italic>mouth in the incongruent face</italic>. These measures were re-coded as <italic>percentages</italic>, i.e., fixation durations to the eyes/mouth AOIs as a percentage of fixation durations to the face AOI, for each group (TD, DS, WS) and face (congruent, incongruent) (see <xref ref-type="fig" rid="pone.0139319.g002">Fig 2</xref>).</p>
<fig id="pone.0139319.g002" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Fixation durations to eyes/mouth AOIs as a percentage of fixation durations to the face AOI, for each group (TD, DS, WS) and face (congruent, incongruent).</title>
<p>Eyes-Con = eyes AOI in the congruent face. Eyes-Incong = eyes AOI in the incongruent face. Mouth-Con = mouth AOI in the congruent face. Mouth-Incong = mouth AOI in the incongruent face. TD controls fixated for longer at the mouth AOIs than infants with DS or WS (all, <italic>p</italic> &lt; .01). Error bars represent one standard error of the mean.</p>
</caption>
<graphic xlink:href="pone.0139319.g002"></graphic>
</fig>
<p>Because some of the data were positively skewed while some were negatively skewed (<italic>Z</italic>
<sub>Skewness</sub> &gt; ±2), nonparametric tests were carried out. Friedman’s ANOVAs revealed significant differences between the four measures in each of the three groups, <italic>χ</italic>
<sup>2</sup>(3) = 54.04, <italic>p</italic> &lt; .001 (TD), <italic>χ</italic>
<sup>2</sup>(3) = 42.61, <italic>p</italic> &lt; .001 (DS), <italic>χ</italic>
<sup>2</sup>(3) = 17.00, <italic>p</italic> = .001 (WS). Wilcoxon tests were used to follow up this finding. Bonferroni corrections were applied. Therefore, all effects are reported at a .008 level of significance. TD controls fixated significantly more on the mouth (relative to the entire face) than on the eyes (relative to the entire face) (all, <italic>p</italic> &lt; .001, <italic>r</italic> &gt;-.76). No significant differences were found between the mouths in both faces, nor between the eyes in both faces (both, <italic>p</italic> &gt; .906). The same pattern emerged in DS (i.e., for all comparisons <italic>p</italic> &lt; .001, <italic>r</italic> &gt;-.59, except for comparisons between both mouth AOIs [<italic>p</italic> = .391] and between both eyes AOIs [<italic>p</italic> = .540]). However, this pattern may be weaker in WS, because although the infants with WS fixated less on the eyes in the incongruent face than on the mouth in either face (both, <italic>p</italic> = .001, <italic>r</italic> = -.76), comparisons between the eyes in the congruent face and the mouth AOIs did not survive the Bonferroni correction (both, <italic>p</italic> = .030, <italic>r</italic> = -.48).</p>
<p>Furthermore, Kruskal-Wallis tests revealed significant differences between the groups in fixation percentages to the eyes in the congruent face (<italic>H</italic>(2) = 12.71, <italic>p</italic> = .002, but not in the incongruent face <italic>p</italic> = .066) and to the mouth in both the Congruent and Incongruent faces (<italic>H</italic>(2) = 12.02, <italic>p</italic> = .002, <italic>H</italic>(2) = 15.73, <italic>p</italic> &lt; .001, respectively). These findings were followed up with pairwise comparisons. Bonferroni corrections were applied. Therefore, all effects are reported at a .017 level of significance. The TD controls looked significantly less at the eyes in the congruent face than the infants with DS, <italic>Z</italic> = -3.56, <italic>p</italic> &lt; .001, <italic>r</italic> = .53. The TD controls also looked more at the mouth in the congruent and incongruent faces than the infants with DS (<italic>Z</italic> = 2.42, <italic>p</italic> = .016, <italic>r</italic> = -.39, <italic>Z</italic> = 3.36, <italic>p</italic> = .001, <italic>r</italic> = -.52, respectively) or WS (<italic>Z</italic> = 3.24, <italic>p</italic> = .001, <italic>r</italic> = -.49, <italic>Z</italic> = 3.30, <italic>p</italic> = .001, <italic>r</italic> = -.52, respectively).</p>
<p>In other words, TD controls fixated for longer at the mouth AOIs than infants with both forms of neurodevelopmental disabilities.</p>
</sec>
<sec id="sec013">
<title>Looking patterns–number of fixations</title>
<p>To further characterise looking patterns in the three groups, we analysed number of fixations: <italic>eyes in the congruent face</italic>, <italic>eyes in the incongruent face</italic>, <italic>mouth in the congruent face</italic>, and <italic>mouth in the incongruent face</italic>. <xref ref-type="fig" rid="pone.0139319.g003">Fig 3</xref> shows number of fixations to eyes/mouth AOIs for each group (TD, DS, WS) and face (congruent, incongruent).</p>
<fig id="pone.0139319.g003" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Number of fixations to eyes/mouth AOIs for each group (TD, DS, WS) and face (congruent, incongruent).</title>
<p>Eyes-Con = eyes AOI in the congruent face. Eyes-Incong = eyes AOI in the incongruent face. Mouth-Con = mouth AOI in the congruent face. Mouth-Incong = mouth AOI in the incongruent face. Infants with WS made fewer fixations at the mouth AOIs than infants with DS or TD controls. Error bars represent one standard error of the mean.</p>
</caption>
<graphic xlink:href="pone.0139319.g003"></graphic>
</fig>
<p>Because some of the data were positively skewed (even when transformed, <italic>Z</italic>
<sub>Skewness</sub> &gt; ±2), nonparametric tests were carried out on the (untransformed) data. Friedman’s ANOVAs revealed significant differences between the four measures in each of the three groups, <italic>χ</italic>
<sup>2</sup>(3) = 50.88, <italic>p</italic> &lt; .001 (TD), <italic>χ</italic>
<sup>2</sup>(3) = 24.21, <italic>p</italic> &lt; .001 (DS), <italic>χ</italic>
<sup>2</sup>(3) = 17.06, <italic>p</italic> = .001 (WS). Wilcoxon tests were used to follow up this finding. Bonferroni corrections were applied. Therefore, all effects are reported at a .008 level of significance. TD controls made significantly more fixations to the mouths than to the eyes (all, <italic>p</italic> &lt; .001, <italic>r</italic> &gt;-.59). No significant differences were found between the mouths in both faces, or between the eyes in both faces (both, <italic>p</italic> &gt; .239). The same pattern was found in DS and WS (i.e., for all comparisons <italic>p</italic> &lt; .01, <italic>r</italic> &gt;-.77, except for comparisons between both mouth AOIs [both, <italic>p</italic> &gt; .868] and between both eyes AOIs [both, <italic>p</italic> &gt; .583]).</p>
<p>Furthermore, Kruskal-Wallis Tests revealed significant differences between the groups in number of fixations to the eyes in both the Congruent and Incongruent face (<italic>H</italic>(2) = 10.44, <italic>p</italic> = .005, <italic>H</italic>(2) = 7.20, <italic>p</italic> = .027, respectively), and to the mouth in both the Congruent and Incongruent face (<italic>H</italic>(2) = 6.79, <italic>p</italic> = .034, <italic>H</italic>(2) = 10.78, <italic>p</italic> = .005, respectively). These findings were followed up using pairwise comparisons. Bonferroni corrections were applied. Therefore, all effects are reported at a .017 level of significance. The TD controls made significantly fewer fixations at the eyes in the congruent and incongruent faces than the infants with DS, <italic>Z</italic> = -3.22, <italic>p</italic> = .001, <italic>Z</italic> = -2.60, <italic>p</italic> = .009. The TD controls also made more fixations at the mouth AOIs in the congruent and incongruent faces than the infants with WS (<italic>Z</italic> = 2.47, <italic>p</italic> = .014, <italic>Z</italic> = 2.81, <italic>p</italic> = .005, respectively). Infants with DS made more fixations to the mouth than infants with WS in the incongruent face (<italic>Z</italic> = 3.13, <italic>p</italic> = .002) but not in the congruent face <italic>Z</italic> = 2.24, <italic>p</italic> = .025 [this did not survive the Bonferroni correction) (see <xref ref-type="fig" rid="pone.0139319.g003">Fig 3</xref>).</p>
<p>In other words, infants with WS made fewer fixations to the mouth than both TD controls and infants with DS.</p>
</sec>
<sec id="sec014">
<title>Predicting language</title>
<p>Analyses were carried out to ascertain whether the group differences in visual scanning had any relation with receptive or expressive language. Our sample was too small for us to run statistical tests such as ‘multiple regression’. However, our <italic>N</italic> was large enough for simple regressions. Because we predicted that looking at the <italic>mouth</italic> in the incongruent face would correlate with greater language ability, and because the TD infants looked more at the mouth than the eyes, we decided to ascertain whether it predicts language ability.</p>
<p>In TD controls, fixation duration to the mouth in the incongruent face (as a percentage of fixation durations to the entire incongruent face) predicted expressive language (<italic>B</italic> = 0.57, <italic>SE B</italic> = 0.26, β = .46, <italic>p</italic> = .038 [which explains 21% of the variance]) but not receptive language (<italic>p</italic> = .107). Conversely, number of fixations to the mouth in the incongruent face predicted receptive language (<italic>B</italic> = 8.68, <italic>SE B</italic> = 4.06, β = .42, <italic>p</italic> = .044, [17% of the variance]) but not expressive language (<italic>p</italic> = .850) in TD controls.</p>
<p>However, neither fixation duration nor number of fixations predicted receptive/expressive language in the two atypically developing groups (all, <italic>p</italic> = ns). But because these groups did not focus attention on the mouth AOIs to the same extent as the TD controls, and because they made a lot of fixations to the eyes, we decided to see whether fixations to the <italic>eyes</italic> predict language ability in these children. The results were surprising. Although fixation duration to the eyes in the incongruent face (as a percentage of fixation durations to the entire incongruent face) did not predict language ability in any group (all, <italic>p</italic> = ns), <italic>number of fixations to the eyes</italic> in the incongruent face predicted receptive language in infants with WS (<italic>B</italic> = -17.36, <italic>SE B</italic> = 5.53, β = -.79, <italic>p</italic> = .020 [which explains 62% of the variance]) but not in DS or TD controls (both, <italic>p</italic> = ns).</p>
<p>Nevertheless, number of fixations to the eyes did not predict expressive language in any of the groups (all, <italic>p</italic> = ns). Intrigued, we delved deeper and found that the measure does, however, predict both receptive and expressive language in WS (<italic>B</italic> = -1.83, <italic>SE B</italic> = 0.70, β = -.64, <italic>p</italic> = .026 [41% of the variance], <italic>B</italic> = -2.69, <italic>SE B</italic> = 0.95, β = -.67, <italic>p</italic> = .018 [44% of the variance], respectively), when language was assessed by the experimenters using the Mullen, a live test, rather than the CDI, a parental questionnaire. We reanalysed fixation duration percentage and found that it also predicted receptive and expressive language in WS as evaluated using the Mullen, <italic>B</italic> = -0.11, <italic>SE B</italic> = 0.05, β = -.63, <italic>p</italic> = .038 (40% of the variance), <italic>B</italic> = -0.20, <italic>SE B</italic> = 0.06, β = -.77, <italic>p</italic> = .006 (59% of the variance), respectively. This was not observed in the other two groups [all <italic>p</italic> = ns].)</p>
<p>Looking at the eyes in the incongruent face was thus important for the infants with WS, whereas it was the mouth region that was important for the TD controls. But did it matter what face (incongruent, congruent) the eyes or mouth were in? To explore this, we decided first to compare fixation counts (FC) at the eyes AOIs (i.e., FC<sub>EYE</sub> = incongruent eyes/[incongruent eyes + congruent eyes]), and then FC at the mouth AOIs (FC<sub>MOUTH</sub> = incongruent mouth/[incongruent mouth + congruent mouth]). Regression analyses were again used to ascertain whether FC<sub>EYES</sub> or FC<sub>MOUTH</sub> predict language ability in these children (for these final sets of analyses, we decided to focus on <italic>receptive language</italic> which, as mentioned earlier, was found to be dependent on fixation count in the TD controls).</p>
</sec>
<sec id="sec015">
<title>Eyes</title>
<p>FC<sub>EYES</sub> did not predict receptive language in any of the groups (all <italic>p</italic> &gt; .05), although there was a trend in the WS group, <italic>B</italic> = -31.76, <italic>SE B</italic> = 13.45, <italic>β</italic> = -.73 (<italic>R</italic>
<sup>2</sup> = .53, <italic>p</italic> = .065; see <xref ref-type="fig" rid="pone.0139319.g004">Fig 4</xref>).</p>
<fig id="pone.0139319.g004" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Proportion of fixations on the eyes of the Incongruent face relative to the eyes of both Incongruent and Congruent faces, organised by Group (TD control, DS, WS).</title>
</caption>
<graphic xlink:href="pone.0139319.g004"></graphic>
</fig>
</sec>
<sec id="sec016">
<title>Mouth</title>
<p>FC<sub>MOUTH</sub> was a significant predictor of receptive language and accounted for 20% of its variability in the TD control group, <italic>B</italic> = 235.23, <italic>SE B</italic> = 105.04, <italic>β</italic> = .45 (<italic>R</italic>
<sup>2</sup> = .20, <italic>p</italic> = .037) (see <xref ref-type="fig" rid="pone.0139319.g005">Fig 5</xref>). This indicates that the more fixations to the mouth in the Incongruent face, relative to the mouths in both faces, the greater is the child’s receptive vocabulary (for every .1, the infant understands an extra 24 words on average; see <xref ref-type="fig" rid="pone.0139319.g006">Fig 6</xref> for an example TD participant’s gaze pattern). By contrast, FC<sub>MOUTH</sub> did not predict receptive language in infants in the two atypical groups (both, <italic>p</italic> &gt; .10).</p>
<fig id="pone.0139319.g005" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Proportion of fixations on the mouth of the Incongruent face relative to the mouths of both Incongruent and Congruent faces, organised by Group (TD control, DS, WS).</title>
</caption>
<graphic xlink:href="pone.0139319.g005"></graphic>
</fig>
<fig id="pone.0139319.g006" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g006</object-id>
<label>Fig 6</label>
<caption>
<title>The face-scanning patterns of two typically developing (TD) children: the blue path represents the scanning pattern of a child with a receptive vocabulary of 213 words; the red path represents the scanning pattern of a child with a receptive vocabulary of 8 words.</title>
<p>TD infants who focused on the incongruent mouth had a larger vocabulary than those who focused on the congruent mouth. The incongruent mouth is the one on the left.</p>
</caption>
<graphic xlink:href="pone.0139319.g006"></graphic>
</fig>
</sec>
</sec>
<sec id="sec017">
<title>MA-matched toddler comparison (this time including also a group with FXS)</title>
<sec id="sec018">
<title>Looking patterns–duration of fixations</title>
<p>Four fixation duration measures were analysed: <italic>eyes in the congruent face</italic>, <italic>eyes in the incongruent face</italic>, <italic>the mouth in the congruent face</italic>, and <italic>the mouth AOI in the incongruent face</italic>. These measures were re-coded as <italic>percentages</italic>. <xref ref-type="fig" rid="pone.0139319.g007">Fig 7</xref> shows fixation durations to eyes/mouth AOIs as a percentage of fixation durations to the face AOI, for each group (TD, DS, FXS, WS) and face (congruent, incongruent).</p>
<fig id="pone.0139319.g007" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Fixation durations to eyes/mouth AOIs as a percentage of fixation durations to the face AOI, for each group (TD, DS, FXS, WS) and face (congruent, incongruent).</title>
<p>Eyes-Con = eyes AOI in the congruent face. Eyes-Incon = eyes AOI in the incongruent face. Mouth-Con = mouth AOI in the congruent face. Mouth-Incon = mouth AOI in the incongruent face. Error bars represent one standard error of the mean.</p>
</caption>
<graphic xlink:href="pone.0139319.g007"></graphic>
</fig>
<p>Because some of the data were positively skewed while some were negatively skewed (<italic>Z</italic>
<sub>Skewness</sub> &gt; ±2), nonparametric tests were carried out. Friedman’s ANOVAs revealed significant differences between the four measures in each of the four groups, <italic>χ</italic>
<sup>2</sup>(3) = 54.04, <italic>p</italic> &lt; .001 (TD), <italic>χ</italic>
<sup>2</sup>(3) = 25.95, <italic>p</italic> &lt; .001 (DS), <italic>χ</italic>
<sup>2</sup>(3) = 15.19, <italic>p</italic> = .002 (FXS), <italic>χ</italic>
<sup>2</sup>(3) = 52.05, <italic>p</italic> &lt; .001 (WS). Wilcoxon tests were used to follow up this finding. Bonferroni corrections were applied. Therefore, all effects are reported at a .008 level of significance. TD controls fixated significantly more on the mouth (relative to the entire face) than on the eyes (relative to the entire face) (all, <italic>p</italic> &lt; .001, <italic>r</italic> &gt;-.76). No significant differences were found between the mouths in both faces, nor between the eyes in both faces (both, <italic>p</italic> &gt; .906). The same pattern emerged in DS and WS (i.e., for all comparisons <italic>p</italic> &lt; .005, <italic>r</italic> &gt;-.46, except for comparisons between both mouth AOIs [both, <italic>p</italic> &gt; .378] and between both eyes AOIs [both, <italic>p</italic> &gt; .705]). However, this pattern may be weaker in FXS, because although the toddlers with FXS fixated less on the eyes in the congruent face than on the mouth in either face (both, <italic>p</italic> &lt; .01, <italic>r</italic> = -.55), and less on the eyes in the incongruent face than the mouth in the congruent face (p = .008, r = -.52), the comparison between the eyes and the mouth in the incongruent face again did not survive the Bonferroni correction (<italic>p</italic> = .012).</p>
<p>Furthermore, Kruskal-Wallis tests revealed significant differences between the groups in fixation percentages to the eyes in the Congruent and Incongruent faces (<italic>H</italic>(3) = 13.02, <italic>p</italic> = .005, <italic>H</italic>(3) = 16.03, <italic>p</italic> = .001, respectively) and to the mouth in both the Congruent and Incongruent faces (<italic>H</italic>(3) = 16.18, <italic>p</italic> = .001, <italic>H</italic>(3) = 17.08, <italic>p</italic> = .001, respectively). These findings were followed up with pairwise comparisons. Bonferroni corrections were applied. Therefore, all effects are reported at a .017 level of significance. The TD controls looked significantly more at the mouth AOIs than toddlers with DS or FXS in both incongruent and congruent faces (all, <italic>Z</italic> &gt; 3.00, <italic>p</italic> &lt; .017). The toddlers with WS looked less at the eyes in the congruent face than toddlers with DS (<italic>Z</italic> = 2.89, <italic>p</italic> = .004) and less at the eyes in the incongruent face than both toddlers with DS or FXS (both, <italic>Z</italic> &gt; 3.10, <italic>p</italic> &lt; .003).</p>
</sec>
<sec id="sec019">
<title>Looking patterns–number of fixations</title>
<p>We examined four ‘number of fixations’ measures: <italic>eyes in the congruent face</italic>, <italic>eyes in the incongruent face</italic>, <italic>mouth in the congruent face</italic>, and <italic>mouth in the incongruent face</italic>. <xref ref-type="fig" rid="pone.0139319.g008">Fig 8</xref> shows number of fixations to eyes/mouth for each group (TD, DS, FXS, WS) and face (congruent, incongruent).</p>
<fig id="pone.0139319.g008" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Number of fixations to eyes/mouth AOIs for each group (TD, DS, WS) and face (congruent, incongruent).</title>
<p>Eyes-Con = eyes AOI in the congruent face. Eyes-Incon = eyes AOI in the incongruent face. Mouth-Con = mouth AOI in the congruent face. Mouth-Incon = mouth AOI in the incongruent face. Error bars represent one standard error of the mean.</p>
</caption>
<graphic xlink:href="pone.0139319.g008"></graphic>
</fig>
<p>Because some of the data were positively skewed (even when transformed, <italic>Z</italic>
<sub>Skewness</sub> &gt; ±2), nonparametric tests were carried out on the (untransformed) data. Friedman’s ANOVAs revealed significant differences between the four measures in some—but not all—groups, <italic>χ</italic>
<sup>2</sup>(3) = 50.88, <italic>p</italic> &lt; .001 (TD), <italic>χ</italic>
<sup>2</sup>(3) = 16.86, <italic>p</italic> = .001 (DS), <italic>χ</italic>
<sup>2</sup>(3) = 4.15, <italic>p</italic> = .246 (FXS), <italic>χ</italic>
<sup>2</sup>(3) = 49.49, <italic>p</italic> &lt; .001 (WS). Wilcoxon tests were then used to follow up this finding. Bonferroni corrections were applied. Therefore, all effects are reported at a .008 level of significance. TD controls made significantly more fixations to the mouths than to the eyes (all, <italic>p</italic> &lt; .001, <italic>r</italic> &gt;-.59). No significant differences were found between the mouths in both faces, nor between the eyes in both faces (both, <italic>p</italic> &gt; .239). The same pattern emerged in WS (i.e., for all comparisons <italic>p</italic> &lt; .001, <italic>r</italic> &gt;-.66, except for comparisons between both mouth AOIs [<italic>p</italic> = .521] and between both eyes AOIs [<italic>p</italic> = .770]). Toddlers with DS made significantly more fixations at the mouth in the congruent face than at the eyes in either face (both, <italic>p</italic> &lt; .005, <italic>r</italic> &gt;-.53), but no other differences survived the Bonferroni correction.</p>
<p>Furthermore, Kruskal-Wallis Tests revealed significant differences between the groups in number of fixations to the eyes in both the Congruent and Incongruent face (<italic>H</italic>(3) = 13.88, <italic>p</italic> = .003, <italic>H</italic>(3) = 18.19, <italic>p</italic> &lt; .001, respectively), and to the mouth in the Congruent, but not the Incongruent, face (<italic>H</italic>(3) = 11.75, <italic>p</italic> = .008, <italic>H</italic>(3) = 7.56, <italic>p</italic> = .056, respectively). These findings were then followed up with pairwise comparisons. Bonferroni corrections were applied. Therefore, all effects are reported at a .017 level of significance. The TD controls made significantly more fixations at the mouth in the congruent face than the toddlers with FXS, <italic>Z</italic> = 3.37, <italic>p</italic> = .001. The toddlers with DS made more fixations to the eyes than the toddlers with WS and TD controls (both, <italic>Z</italic> &gt; 2.73, <italic>p</italic> &lt; .007) in the congruent face. The toddlers with DS also made more fixations to the eyes than toddlers with WS in the incongruent face (<italic>Z</italic> = 3.15, <italic>p</italic> = .002). Finally toddlers with FXS made more fixations to the eyes in the incongruent face than toddlers with WS and TD controls (both, <italic>Z</italic> &gt; 2.81, <italic>p</italic> &lt; .006).</p>
</sec>
<sec id="sec020">
<title>Predicting language</title>
<p>As with the infant groups, neither fixation duration nor number of fixations (i.e., to the mouth in the incongruent face) predicted receptive/expressive language in the three atypically developing toddler groups (all, <italic>p</italic> = ns).</p>
<p>Nevertheless, because these groups did not focus their attention on the mouth AOIs to the same extent as the TD controls, and because they made a lot of fixations to the eyes, we decided to see whether fixation to the <italic>eyes</italic> predicted language ability.</p>
<p>Fixation duration to the eyes in the incongruent face (as a percentage of fixation durations to the entire incongruent face) predicted receptive language in the FXS and WS groups ((<italic>B</italic> = -2.51, <italic>SE B</italic> = 0.72, β = -.82, <italic>p</italic> = .013 [which explains 67% of the variance]), <italic>B</italic> = 6.89, <italic>SE B</italic> = 3.16, β = .47, <italic>p</italic> = .044 [which explains 22% of the variance], respectively). Fixation duration to the eyes in the incongruent face also predicted expressive language in WS (<italic>B</italic> = 6.81, <italic>SE B</italic> = 2.20, β = .61, <italic>p</italic> = .007 [which explains 38% of the variance]).).</p>
<p>Furthermore, number of fixations to the eyes in the incongruent face predicted receptive language in the FXS group (<italic>B</italic> = -23.03, <italic>SE B</italic> = 6.48, β = -.80, <italic>p</italic> = .009 [which explains 64% of the variance]) and expressive language in the WS group (<italic>B</italic> = 35.96, <italic>SE B</italic> = 13.51, β = .54, <italic>p</italic> = .016 [which explains 29% of the variance]).</p>
<p>Again, to explore whether it was important which face (congruent, incongruent) the toddlers focused on, we ran regression analyses to ascertain whether FC<sub>EYES</sub> or FC<sub>MOUTH</sub> predict receptive language.</p>
</sec>
<sec id="sec021">
<title>Eyes</title>
<p>FC<sub>EYES</sub> was a significant predictor of receptive language and accounted for 61% of its variability in the FXS group, <italic>B</italic> = 190.49, <italic>SE B</italic> = 62.85, <italic>β</italic> = .78 (<italic>R</italic>
<sup>2</sup> = .61, <italic>p</italic> = .023), and 38% in the WS group, <italic>B</italic> = 126.37, <italic>SE B</italic> = 41.69, <italic>β</italic> = .62 (<italic>R</italic>
<sup>2</sup> = .38, <italic>p</italic> = .008) (see <xref ref-type="fig" rid="pone.0139319.g009">Fig 9</xref>). FC<sub>EYE</sub> did not predict receptive language in the TD control or DS groups, <italic>B</italic> = 9.72, <italic>SE B</italic> = 32.98, <italic>β</italic> = .07 (<italic>p</italic> = .772), <italic>B</italic> = 58.73, <italic>SE B</italic> = 97.42, <italic>β</italic> = .20 (<italic>p</italic> = .562), respectively. This suggests that the more fixations to the eyes in the Incongruent face, relative to the eyes in both faces, the greater is the child’s receptive vocabulary (for every .1, the toddler with FXS understands an extra 19 words on average, while the toddler with WS understands an extra 13 words on average [see Figs <xref ref-type="fig" rid="pone.0139319.g010">10</xref>, <xref ref-type="fig" rid="pone.0139319.g011">11</xref> and <xref ref-type="fig" rid="pone.0139319.g012">12</xref> for example of gaze patterns in participants with DS, FXS, and WS]).</p>
<fig id="pone.0139319.g009" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Proportion of fixations on the eyes of the Incongruent face relative to the eyes of both Incongruent and Congruent faces, organised by Group (TD control, DS, FXS, WS).</title>
</caption>
<graphic xlink:href="pone.0139319.g009"></graphic>
</fig>
<fig id="pone.0139319.g010" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g010</object-id>
<label>Fig 10</label>
<caption>
<title>The face-scanning patterns of two toddlers with Down syndrome (DS): the blue path represents the scanning pattern of a child with a receptive vocabulary of 115 words; the red path represents the scanning pattern of a child with a receptive vocabulary of 55 words.</title>
<p>No relationship was found in DS between face scanning and language ability. The incongruent face is the one on the left.</p>
</caption>
<graphic xlink:href="pone.0139319.g010"></graphic>
</fig>
<fig id="pone.0139319.g011" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g011</object-id>
<label>Fig 11</label>
<caption>
<title>The face-scanning patterns of two toddlers with fragile X syndrome (FXS): the blue path represents the scanning pattern of a child with a receptive vocabulary of 176 words; the red path represents the scanning pattern of a child with a receptive vocabulary of 5 words.</title>
<p>Toddlers with FXS who focused more on the eyes in the incongruent display had a larger vocabulary than those who focused more on the eyes in the congruent display. The eyes in the incongruent face are on the left.</p>
</caption>
<graphic xlink:href="pone.0139319.g011"></graphic>
</fig>
<fig id="pone.0139319.g012" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g012</object-id>
<label>Fig 12</label>
<caption>
<title>The face-scanning patterns of two toddlers with Williams syndrome: the blue path represents the scanning pattern of a child with a receptive vocabulary of 246 words; the red path represents the scanning pattern of a child with a receptive vocabulary of 23 words.</title>
<p>Toddlers with WS who focused more on the eyes in the incongruent display had a larger vocabulary than those who focused more on the eyes in the congruent display. The eyes in the incongruent face are on the left.</p>
</caption>
<graphic xlink:href="pone.0139319.g012"></graphic>
</fig>
</sec>
<sec id="sec022">
<title>Mouth</title>
<p>FC<sub>MOUTH</sub> was a significant predictor of receptive language in toddlers and accounted for 20% of its variability in the TD control group, <italic>B</italic> = 235.23, <italic>SE B</italic> = 105.04, <italic>β</italic> = .45 (<italic>R</italic>
<sup>2</sup> = .20, <italic>p</italic> = .037; <xref ref-type="fig" rid="pone.0139319.g013">Fig 13</xref>). This indicates that the more fixations to the mouth in the Incongruent face, relative to the mouths in both faces, the greater is the child’s receptive vocabulary (for every .1, the TD child understands an extra 24 words on average). FC<sub>MOUTH</sub> did not predict receptive language in any of the atypical groups (all, <italic>p</italic> &gt; .10).</p>
<fig id="pone.0139319.g013" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0139319.g013</object-id>
<label>Fig 13</label>
<caption>
<title>Proportion of fixations on the mouth of the Incongruent face relative to the mouths of both Incongruent and Congruent faces, organised by Group (TD control, DS, FXS, WS).</title>
</caption>
<graphic xlink:href="pone.0139319.g013"></graphic>
</fig>
</sec>
</sec>
<sec id="sec023">
<title>Why does greater attention to the eyes positively correlate with language ability in FXS and WS, but not in DS or TD?</title>
<p>One reason why looking at the eyes is correlated with language ability in children with FXS and WS is that language ability is correlated with looking at the face more generally in these children. To test this hypothesis, we carried out further analyses to ascertain whether any of the following predicts language ability: (1) proportion of target looking; i.e., fixation duration to the incongruent face as a proportion of fixation duration to both incongruent and congruent faces), (2) <italic>total looking time</italic> at both the incongruent and congruent faces, (3) <italic>total number of fixations</italic> to both incongruent and congruent faces. We would expect proportion of target looking (which demonstrates an ability to discriminate between stimuli) to be correlated with greater receptive/expressive vocabulary. We would also expect longer looking time or more fixations to the faces to correlate with language ability.</p>
<p>All data (for both CA- and MA-comparisons) were normally distributed (Kolmogorov-Smirnov test: all, <italic>p</italic> &gt; .05; <italic>Z</italic>
<sub>skewness</sub> &lt; 2). For the CA-comparison, while proportion of target looking did not significantly differ across groups (<italic>F</italic>
<sub>2,54</sub> = 0.22, <italic>p</italic> = .808), total duration and total number of fixations significantly varied across groups (<italic>F</italic>
<sub>2,55</sub> = 12.29, <italic>p</italic> &lt; .001, <italic>F</italic>
<sub>2,53</sub> = 24.53, <italic>p</italic> &lt; .001, respectively). Contrary to expectations, infants with WS looked significantly less at the faces than infants with DS and TD controls (both, <italic>p</italic> &lt; .005, Bonferroni corrected). Perhaps participants with WS are more likely to turn away from the computer face stimuli in favour of their caregiver’s face. Infants with DS made significantly more fixations than infants with WS and TD controls (both, <italic>p</italic> &lt; .001, Bonferroni corrected). Total duration was a significant predictor of expressive language in DS (<italic>B</italic> = -0.48, <italic>SE B</italic> = 0.18, β = -.68, <italic>p</italic> = .030 [which explains 47% of the variance]), but importantly, no variables predicted either receptive or expressive language in any of the other groups (all, <italic>p</italic> = ns).</p>
<p>For the MA-comparison, proportion of target looking did not significantly differ across groups (<italic>p</italic> = ns). However, total duration and total number of fixations to both faces did differ across groups, <italic>F</italic>
<sub>3,76</sub> = 13.58, <italic>p</italic> &lt; .001, <italic>F</italic>
<sub>3,78</sub> = 7.51, <italic>p</italic> &lt; .001, respectively. Post hoc tests revealed that the toddlers with DS looked longer at the faces and made more fixations than the other groups (all, <italic>p</italic> &lt; .005, Bonferroni-corrected). Crucially, none of the variables predicted receptive or expressive language in any of the groups (all, <italic>p</italic> = ns).</p>
<p>In other words, general looking at faces was not predictive of language ability in FXS or WS, but was in the DS group.</p>
</sec>
</sec>
<sec id="sec024" sec-type="conclusions">
<title>Discussion</title>
<p>The aim of the present study was to investigate the face scanning patterns of infants and toddlers with different neurodevelopmental disorders, and to ascertain whether such patterns relate to language ability in any of the groups. Specifically, we argued that if gaze to the mouth plays an important role in extracting visual information that facilitates understanding of unfamiliar or confusing (auditory) speech, then children who focus their attention towards the mouth of an incongruent talking face would have relatively larger vocabularies than those who direct their attention elsewhere. This is indeed what we found for the TD controls. The number of times and duration a TD child looked at the mouth region of a speaking face that was incongruent with the audible sound, the more likely it was that s/he had a relatively large receptive or expressive vocabulary. This makes sense, because watching lip movements influences auditory perception (e.g., phoneme discrimination [<xref ref-type="bibr" rid="pone.0139319.ref014">14</xref>–<xref ref-type="bibr" rid="pone.0139319.ref018">18</xref>, <xref ref-type="bibr" rid="pone.0139319.ref060">60</xref>]), and auditory perception is an important precursor to learning spoken language [<xref ref-type="bibr" rid="pone.0139319.ref061">61</xref>–<xref ref-type="bibr" rid="pone.0139319.ref062">62</xref>].</p>
<p>By contrast, no relationship was found between gaze to the mouth and language ability in any of the three atypically developing groups. However, the number of times a toddler with FXS or WS looked at the <italic>eyes</italic> of a speaking face that was incongruent with the audible sound, the more likely it was that s/he had a relatively large receptive or expressive vocabulary. This is an unexpected finding–in part because children with FXS present with social anxiety and shyness that often result in aversion to eye contact [<xref ref-type="bibr" rid="pone.0139319.ref042">42</xref>]. It is not surprising that the participants with FXS did look at the eyes AOI, though. Unlike children with autism spectrum disorder, individuals with FXS are not often <italic>uninterested</italic> in social interactions; they avert their gaze only because they are initially shy and anxious when meeting strangers [<xref ref-type="bibr" rid="pone.0139319.ref042">42</xref>]. In the present study, the toddlers with FXS had no reason to avert their gaze–because we used video clips of a speaker rather than live human interaction. We would still expect them to have developed a mouth-gaze strategy—or rely solely on auditory information—to learn language. However, our results suggest that toddlers with FXS, as well as those with WS, rely on visual input from the eyes rather than from the mouths. It is important to note that at a distance of 60 cm, the infants and toddlers in our study would be able to see the entire face in their periphery. Nevertheless, these are unexpected findings. They may reflect a lack of developing expertise (see <xref ref-type="sec" rid="sec001">Introduction</xref>). From as early as 2 months of age [<xref ref-type="bibr" rid="pone.0139319.ref063">63</xref>–<xref ref-type="bibr" rid="pone.0139319.ref064">64</xref>], TD infants focus on the eyes. This helps them to master joint attention, imitation, the reading of emotions, and so on. However, from around 8 months of age, a shift occurs whereby TD infants begin to look longer at the mouth [<xref ref-type="bibr" rid="pone.0139319.ref035">35</xref>]. We speculate that this developmental shift may not occur in FXS or WS. It is possible that those with a larger vocabulary and also FXS or WS may make a few important fixations on the mouth but turn their attention to the eyes rather than the mouth of the Incongruent face. At the very least, these data suggest that the children with FXS or WS are using a different learning strategy from the one employed by TD infants.</p>
<p>With respect to the DS group, fixation count did not predict receptive vocabulary, which raises the possibility that children with DS do not use precise audiovisual speech cues to bootstrap language acquisition. Indeed, overall looking at the face in general (i.e., duration of fixations) predicted expressive language in DS. Note that many of the participants with DS are being taught a signed language called Makaton. We speculate that early in development infants with DS rely more on hand movements than facial movements to learn language. Further investigation is needed to unravel this.</p>
<p>The strength of the current study is that it used an eye tracker to measure precisely how many times TD infants and children with different neurodevelopmental disorders fixate on two different areas of interest within the face (eyes, mouth), and that we identified interesting associations between this measure and language ability. An eye tracker is more sensitive than simple observation, and the stimuli were presented in a carefully controlled environment. However, it was beyond the scope of this paradigm to establish a causal relationship between visual scanning of faces and language development. Firstly, we studied matching of only a single syllable (/ga/). Before firm conclusions can be drawn about face scanning and language, participants need to be tested on other speech samples, including more naturalistic fluent speech. Moreover, our participants could only visually explore, not interact with, the talking faces. The children may behave differently in a more naturalistic (albeit less controlled) environment.</p>
<p>Nevertheless, our study provides evidence that visual scanning patterns are related to language development. We have shown that TD children who use gaze to the mouth have greater vocabularies than those who do not. Moreover, some children (namely, those with DS, FXS, and WS), known to present with language delay, failed to use gaze to the mouth when processing our stimuli. These findings raise important questions: Why do children with neurodevelopmental disorders not benefit from directing their visual attention to the mouth of a speaker? Why do the children with FXS or WS who focus on the eyes of a speaker tend to have larger vocabularies? Should interventions encourage infants with these neurodevelopmental disorders to focus more on the face in general or specific parts of the face, and should this differ across different syndromes? Is it important to know why children with neurodevelopmental disorder do not focus on the mouth like TD children? Indeed, could this knowledge help clinicians to design syndrome-specific interventions that improve language ability indirectly through methods that modify face-scanning behaviour?</p>
<p>In summary, our findings reveal an important association between face scanning and language ability which points to intervention strategies for language delay outside language itself. Furthermore, we demonstrated that different attentional processes underpin word learning across the different groups. TD children with a relatively large vocabulary make more fixations to the speaker’s mouth, while those with FXS or WS who also have a relatively large vocabulary make more fixations to the eyes. By contrast, in children with DS fixation count to either the eyes or the mouth failed to account for individual differences in language ability. But infants with DS who spent more time looking at the overall face had larger vocabularies than those who spent less time looking at the face. These findings indicate that different processes or strategies are likely involved in language acquisition across these neurodevelopmental disorders, at least at certain points in development, processes or strategies that future studies will need to elucidate further. It may also be useful to ascertain whether training children with neurodevelopmental disorders on precisely where to look for visual input would facilitate their understanding and learning of spoken language.</p>
</sec>
</body>
<back>
<ack>
<p>We are very grateful for the contributions that families have made towards this study. The participation of the TD control participants in the research was supported by awards from the BASIS funding consortium led by Autistica (<ext-link ext-link-type="uri" xlink:href="http://www.basisnetwork.org/">www.basisnetwork.org</ext-link>) and from the UK Medical Research Council. The BASIS Team consists of (in alphabetical order): Tony Charman, Simon Baron-Cohen, Patrick Bolton, Kim Davies, Janice Fernandes, Jeanne Guiraud, Mark H. Johnson, Helen Maris, Helena Ribeiro and Leslie Tucker. The participation of participants with neurodevelopmental disorders was funded by the Waterloo Foundation, Williams Syndrome Foundation UK, Autour des Williams France, and a Wellcome Trust Strategic Award. The recruiting of participants was supported by the Williams Syndrome Foundation, the Fragile X Society, the Down Syndrome Association, and Down Syndrome Education International. We thank two anonymous reviewers for their insightful comments.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0139319.ref001">
<label>1</label>
<mixed-citation publication-type="journal">
<name><surname>Fantz</surname><given-names>RL</given-names></name>. <article-title>The origin of form perception</article-title>. <source/>Sci Am. <year>1961</year>; <volume>204</volume>(<issue>5</issue>): <fpage>66</fpage>–<lpage>72</lpage>.<pub-id pub-id-type="pmid">13698138</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref002">
<label>2</label>
<mixed-citation publication-type="journal">
<name><surname>Morton</surname><given-names>J</given-names></name>, <name><surname>Johnson</surname><given-names>MH</given-names></name>. <article-title>CONSPEC and CONLERN: A two-process theory of infant face recognition</article-title>. <source/>Psychol Rev. <year>1991</year>; <volume>98</volume>(<issue>2</issue>): <fpage>164</fpage>–<lpage>181</lpage>.
<pub-id pub-id-type="pmid">2047512</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref003">
<label>3</label>
<mixed-citation publication-type="journal">
<name><surname>Vouloumanos</surname><given-names>A</given-names></name>, <name><surname>Gelfand</surname><given-names>HM</given-names></name>. <article-title>Infant perception of atypical speech signals</article-title>. <source/>Dev Psychol. <year>2004</year>; <volume>49</volume>(<issue>5</issue>): <fpage>815</fpage>–<lpage>824</lpage>. <pub-id pub-id-type="doi">10.1037/a0029055</pub-id>
</mixed-citation>
</ref>
<ref id="pone.0139319.ref004">
<label>4</label>
<mixed-citation publication-type="journal">
<name><surname>Vouloumanos</surname><given-names>A</given-names></name>, <name><surname>Werker</surname><given-names>JF</given-names></name>. <article-title>Tuned to the signal: The privileged status of speech for young infants</article-title>. <source/>Dev Sci. <year>2004</year>; <volume>7</volume>: <fpage>270</fpage>–<lpage>276</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-7687.2004.00345.x</pub-id>
<pub-id pub-id-type="pmid">15595367</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref005">
<label>5</label>
<mixed-citation publication-type="journal">
<name><surname>Vouloumanos</surname><given-names>A</given-names></name>, <name><surname>Werker</surname><given-names>JF</given-names></name>. <article-title>Listening to language at birth: Evidence for a bias for speech in neonates</article-title>. <source/>Dev Sci. <year>2007</year>; <volume>10</volume>: <fpage>159</fpage>–<lpage>164</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-7687.2007.00549.x</pub-id>
<pub-id pub-id-type="pmid">17286838</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref006">
<label>6</label>
<mixed-citation publication-type="journal">
<name><surname>Dodd</surname><given-names>B</given-names></name>. <article-title>Lip reading in infants: Attention to speech presented in-and out-of-synchrony</article-title>. <source/>Cogn Psychol. <year>1979</year>; <volume>11</volume>(<issue>4</issue>): <fpage>478</fpage>–<lpage>484</lpage>.
<pub-id pub-id-type="pmid">487747</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref007">
<label>7</label>
<mixed-citation publication-type="journal">
<name><surname>Lewkowicz</surname><given-names>DJ</given-names></name>. <article-title>Infant perception of audio-visual speech synchrony</article-title>. <source/>Dev Psychol. <year>2010</year>; <volume>46</volume>(<issue>1</issue>): <fpage>66</fpage>
<pub-id pub-id-type="doi">10.1037/a0015579</pub-id>
<pub-id pub-id-type="pmid">20053007</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref008">
<label>8</label>
<mixed-citation publication-type="journal">
<name><surname>Lewkowicz</surname><given-names>DJ</given-names></name>, <name><surname>Leo</surname><given-names>I</given-names></name>, <name><surname>Simion</surname><given-names>F</given-names></name>. <article-title>Intersensory perception at birth: Newborns match nonhuman primate faces and voices</article-title>. <source/>Infancy. <year>2010</year>; <volume>15</volume>(<issue>1</issue>): <fpage>46</fpage>–<lpage>60</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref009">
<label>9</label>
<mixed-citation publication-type="journal">
<name><surname>Morrongiello</surname><given-names>BA</given-names></name>, <name><surname>Fenwick</surname><given-names>KD</given-names></name>, <name><surname>Chance</surname><given-names>G</given-names></name>. <article-title>Crossmodal learning in newborn infants: Inferences about properties of auditory-visual events</article-title>. <source/>Infant Behav Dev. <year>1998</year>; <volume>21</volume>(<issue>4</issue>): <fpage>543</fpage>–<lpage>553</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref010">
<label>10</label>
<mixed-citation publication-type="journal">
<name><surname>Vouloumanos</surname><given-names>A</given-names></name>, <name><surname>Druhen</surname><given-names>MJ</given-names></name>, <name><surname>Hauser</surname><given-names>MD</given-names></name>, <name><surname>Huizink</surname><given-names>AT</given-names></name>. <article-title>Five-month-old infants’ identification of the sources of vocalizations</article-title>. <source/>Proc Natl Acad Sci U S A. <year>2009</year>; <volume>106</volume>: <fpage>18867</fpage>–<lpage>18872</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0906049106</pub-id>
<pub-id pub-id-type="pmid">19846770</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref011">
<label>11</label>
<mixed-citation publication-type="journal">
<name><surname>Kuhl</surname><given-names>PK</given-names></name>, <name><surname>Meltzoff</surname><given-names>AN</given-names></name>. <article-title>The bimodal perception of speech in infancy</article-title>. <source/>Science. <year>1982</year>; <volume>218</volume>(<issue>4577</issue>): <fpage>1138</fpage>–<lpage>1141</lpage>.
<pub-id pub-id-type="pmid">7146899</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref012">
<label>12</label>
<mixed-citation publication-type="journal">
<name><surname>Kuhl</surname><given-names>PK</given-names></name>, <name><surname>Williams</surname><given-names>KA</given-names></name>, <name><surname>Meltzoff</surname><given-names>AN</given-names></name>. <article-title>Cross-modal speech perception in adults and infants using nonspeech auditory stimuli</article-title>. <source/>J Exp Psychol Hum Percept Perform. <year>1991</year>; <volume>17</volume>(<issue>3</issue>): <fpage>829</fpage>
<pub-id pub-id-type="pmid">1834794</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref013">
<label>13</label>
<mixed-citation publication-type="journal">
<name><surname>Patterson</surname><given-names>ML</given-names></name>, <name><surname>Werker</surname><given-names>JF</given-names></name>. <article-title>Two-month-old infants match phonetic information in lips and voice</article-title>. <source/>Dev Sci. <year>2003</year>; <volume>6</volume>(<issue>2</issue>): <fpage>191</fpage>–<lpage>196</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref014">
<label>14</label>
<mixed-citation publication-type="journal">
<name><surname>Kushnerenko</surname><given-names>E</given-names></name>, <name><surname>Teinonen</surname><given-names>T</given-names></name>, <name><surname>Volein</surname><given-names>A</given-names></name>, <name><surname>Csibra</surname><given-names>G</given-names></name>. <article-title>Electrophysiological evidence of illusory audiovisual speech percept in human infants</article-title>. <source/>Proc Natl Acad Sci U S A. <year>2008</year>; <volume>105</volume>(<issue>32</issue>): <fpage>32</fpage>–<lpage>35</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref015">
<label>15</label>
<mixed-citation publication-type="journal">
<name><surname>Alsius</surname><given-names>A</given-names></name>, <name><surname>Navarra</surname><given-names>J</given-names></name>, <name><surname>Campbell</surname><given-names>R</given-names></name>, <name><surname>Soto-Faraco</surname><given-names>S</given-names></name>. <article-title>Audiovisual integration of speech falters under high attention demands</article-title>. <source/>Curr Biol. <year>2005</year>; <volume>15</volume>: <fpage>839</fpage>–<lpage>843</lpage>.
<pub-id pub-id-type="pmid">15886102</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref016">
<label>16</label>
<mixed-citation publication-type="journal">
<name><surname>Burnham</surname><given-names>D</given-names></name>, <name><surname>Dodd</surname><given-names>B</given-names></name>. <article-title>Auditory-visual speech integration by prelinguistic infants: Perception of an emergent consonant in the McGurk effect</article-title>. <source/>Dev Psychobiol. <year>2004</year>; <volume>45</volume>(<issue>4</issue>): <fpage>204</fpage>–<lpage>220</lpage>.
<pub-id pub-id-type="pmid">15549685</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref017">
<label>17</label>
<mixed-citation publication-type="journal">
<name><surname>McGurk</surname><given-names>H</given-names></name>, <name><surname>MacDonald</surname><given-names>J</given-names></name>. <article-title>Hearing lips and seeing voices</article-title>. <source/>Nature. <year>1976</year>; <volume>264</volume>(<issue>5588</issue>): <fpage>746</fpage>–<lpage>748</lpage>.
<pub-id pub-id-type="pmid">1012311</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref018">
<label>18</label>
<mixed-citation publication-type="journal">
<name><surname>Rosenblum</surname><given-names>LD</given-names></name>, <name><surname>Schmuckler</surname><given-names>MA</given-names></name>, <name><surname>Johnson</surname><given-names>JA</given-names></name>. <article-title>The McGurk effect in infants</article-title>. <source/>Percept Psychophys. <year>1997</year>; <volume>59</volume>(<issue>3</issue>): <fpage>347</fpage>–<lpage>357</lpage>.
<pub-id pub-id-type="pmid">9136265</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref019">
<label>19</label>
<mixed-citation publication-type="journal">
<name><surname>Weikum</surname><given-names>WM</given-names></name>, <name><surname>Vouloumanos</surname><given-names>A</given-names></name>, <name><surname>Navarra</surname><given-names>J</given-names></name>, <name><surname>Soto-Faraco</surname><given-names>S</given-names></name>, <name><surname>Sebastián-Gallés</surname><given-names>N</given-names></name>, <name><surname>Werker</surname><given-names>JF</given-names></name>. <article-title>Visual language discrimination in infancy</article-title>. <source/>Science. <year>2007</year>; <volume>316</volume>(<issue>5828</issue>): <fpage>1159</fpage>
<pub-id pub-id-type="pmid">17525331</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref020">
<label>20</label>
<mixed-citation publication-type="journal">
<name><surname>Werker</surname><given-names>JF</given-names></name>, <name><surname>Tees</surname><given-names>RC</given-names></name>. <article-title>Influences on infant speech processing: Toward a new synthesis</article-title>. <source/>Ann Rev Psychol. <year>1999</year>; <volume>50</volume>(<issue>1</issue>): <fpage>509</fpage>–<lpage>535</lpage>.<pub-id pub-id-type="pmid">10074686</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref021">
<label>21</label>
<mixed-citation publication-type="journal">
<name><surname>Young</surname><given-names>GS</given-names></name>, <name><surname>Merin</surname><given-names>N</given-names></name>, <name><surname>Rogers</surname><given-names>SJ</given-names></name>, <name><surname>Ozonoff</surname><given-names>S</given-names></name>. <article-title>Gaze behaviour and affect at 6 months: Predicting clinical outcomes and language development in typically developing infants and infants at risk for autism</article-title>. <source/>Dev Sci. <year>2009</year>; <volume>12</volume>: <fpage>798</fpage>–<lpage>814</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-7687.2009.00833.x</pub-id>
<pub-id pub-id-type="pmid">19702771</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref022">
<label>22</label>
<mixed-citation publication-type="journal">
<name><surname>Maye</surname><given-names>J</given-names></name>, <name><surname>Werker</surname><given-names>JF</given-names></name>, <name><surname>Gerken</surname><given-names>LA</given-names></name>. <article-title>Infant sensitivity to distributional information can affect phonetic discrimination</article-title>. <source/>Cognition. <year>2002</year>; <volume>82</volume>: <fpage>B101</fpage>–<lpage>B111</lpage>
<pub-id pub-id-type="pmid">11747867</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref023">
<label>23</label>
<mixed-citation publication-type="journal">
<name><surname>Schwartz</surname><given-names>JL</given-names></name>, <name><surname>Berthommier</surname><given-names>F</given-names></name>, <name><surname>Savariaux</surname><given-names>C</given-names></name>. <article-title>Seeing to hear better: Evidence for early audio-visual interactions in speech identification</article-title>. <source/>Cognition. <year>2004</year>; <volume>93</volume>: <fpage>B69</fpage>–<lpage>B78</lpage>.
<pub-id pub-id-type="pmid">15147940</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref024">
<label>24</label>
<mixed-citation publication-type="journal">
<name><surname>Teinonen</surname><given-names>T</given-names></name>, <name><surname>Aslin</surname><given-names>RN</given-names></name>, <name><surname>Alku</surname><given-names>P</given-names></name>, <name><surname>Csibra</surname><given-names>G</given-names></name>. <article-title>Visual speech contributes to phonetic learning in 6-month-old infants</article-title>. <source/>Cognition. <year>2008</year>; <volume>108</volume>(<issue>3</issue>): <fpage>850</fpage>–<lpage>855</lpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2008.05.009</pub-id>
<pub-id pub-id-type="pmid">18590910</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref025">
<label>25</label>
<mixed-citation publication-type="journal">
<name><surname>Sumby</surname><given-names>WH</given-names></name>, <name><surname>Pollack</surname><given-names>I</given-names></name>. <article-title>Visual contribution to speech intelligibility in noise</article-title>. <source/>J Acoust Soc Am.
<year>1954</year>; <volume>26</volume>(<issue>2</issue>): <fpage>212</fpage>–<lpage>215</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref026">
<label>26</label>
<mixed-citation publication-type="journal">
<name><surname>Key</surname><given-names>APF</given-names></name>, <name><surname>Stone</surname><given-names>W</given-names></name>, <name><surname>Williams</surname><given-names>S</given-names></name>. <article-title>What do infants see in faces? ERP evidence of different roles of eyes and mouth for face perception in 9-month-old infants</article-title>. <source/>Infant Child Dev. <year>2009</year>; <volume>162</volume>: <fpage>149</fpage>–<lpage>162</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref027">
<label>27</label>
<mixed-citation publication-type="journal">
<name><surname>Ludman</surname><given-names>CN</given-names></name>, <name><surname>Summerfield</surname><given-names>AQ</given-names></name>, <name><surname>Hall</surname><given-names>D</given-names></name>, <name><surname>Elliot</surname><given-names>M</given-names></name>, <name><surname>Foster</surname><given-names>J</given-names></name>, <name><surname>Hykin</surname><given-names>JL</given-names></name>, <etal>et al</etal>
<article-title>Lip-reading ability and patterns of cortical activation studied using fMRI</article-title>. <source/>Brit J Audiology. <year>2000</year>; <volume>34</volume>(<issue>4</issue>): <fpage>225</fpage>–<lpage>230</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref028">
<label>28</label>
<mixed-citation publication-type="journal">
<name><surname>Summerfield</surname><given-names>Q</given-names></name>. <article-title>Lipreading and audio-visual speech perception</article-title>. <source/>Philos Trans R Soc Lond B Biol Sci. <year>1992</year>; <volume>335</volume>(<issue>1273</issue>): <fpage>71</fpage>–<lpage>78</lpage>.
<pub-id pub-id-type="pmid">1348140</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref029">
<label>29</label>
<mixed-citation publication-type="journal">
<name><surname>Vatikiotis-Bateson</surname><given-names>E</given-names></name>, <name><surname>Eigsti</surname><given-names>I-M</given-names></name>, <name><surname>Yano</surname><given-names>S</given-names></name>, <name><surname>Munhall</surname><given-names>KG</given-names></name>. <article-title>Eye movement of perceivers during audiovisual speech perception</article-title>. <source/>Percept Psychophys. <year>1998</year>; <volume>60</volume>(<issue>6</issue>): <fpage>926</fpage>–<lpage>940</lpage>.
<pub-id pub-id-type="pmid">9718953</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref030">
<label>30</label>
<mixed-citation publication-type="journal">
<name><surname>Reid</surname><given-names>VM</given-names></name>, <name><surname>Striano</surname><given-names>T</given-names></name>. <article-title>Adult gaze influences infant attention and object processing: Implications for cognitive neuroscience</article-title>. <source/>Eur J Neurosci. <year>2005</year>; <volume>21</volume>(<issue>6</issue>): <fpage>1763</fpage>–<lpage>1766</lpage>.
<pub-id pub-id-type="pmid">15845105</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref031">
<label>31</label>
<mixed-citation publication-type="journal">
<name><surname>Brenner</surname><given-names>LA</given-names></name>, <name><surname>Turner</surname><given-names>KC</given-names></name>, <name><surname>Muller</surname><given-names>RA</given-names></name>. <article-title>Eye movement and visual search: Are there elementary abnormalities in autism?</article-title>
<source/>J Autism Dev Disord. <year>2007</year>; <volume>37</volume>(<issue>7</issue>): <fpage>1289</fpage>–<lpage>1309</lpage>.
<pub-id pub-id-type="pmid">17120149</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref032">
<label>32</label>
<mixed-citation publication-type="journal">
<name><surname>Schietecatte</surname><given-names>I</given-names></name>, <name><surname>Roeyers</surname><given-names>H</given-names></name>, <name><surname>Warreyn</surname><given-names>P</given-names></name>. <article-title>Can infants’ orientation to social stimuli predict later joint attention skills?</article-title>
<source/>Brit J Dev Psychol. <year>2012</year>; <volume>30</volume>: <fpage>267</fpage>–<lpage>282</lpage>.<pub-id pub-id-type="pmid">22550948</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref033">
<label>33</label>
<mixed-citation publication-type="journal">
<name><surname>Morales</surname><given-names>M</given-names></name>, <name><surname>Mundy</surname><given-names>P</given-names></name>, <name><surname>Delgado</surname><given-names>CE</given-names></name>, <name><surname>Yale</surname><given-names>M</given-names></name>, <name><surname>Neal</surname><given-names>R</given-names></name>, <name><surname>Schwartz</surname><given-names>HK</given-names></name>. <article-title>Gaze following, temperament, and language development in 6-month-olds: A replication and extension</article-title>. <source/>Infant Behav Dev. <year>2000</year>; <volume>23</volume>(<issue>2</issue>): <fpage>231</fpage>–<lpage>236</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref034">
<label>34</label>
<mixed-citation publication-type="journal">
<name><surname>Morales</surname><given-names>M</given-names></name>, <name><surname>Mundy</surname><given-names>P</given-names></name>, <name><surname>Rojas</surname><given-names>J</given-names></name>. <article-title>Following the direction of gaze and language development in 6-month-olds</article-title>. <source/>Infant Behav Dev. <year>1998</year>; <volume>21</volume>(<issue>2</issue>): <fpage>373</fpage>–<lpage>377</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref035">
<label>35</label>
<mixed-citation publication-type="journal">
<name><surname>Lewkowicz</surname><given-names>DJ</given-names></name>, <name><surname>Hansen-Tift</surname><given-names>AM</given-names></name>. <article-title>Infants deploy selective attention to the mouth of a talking face when learning speech</article-title>. <source/>Proc Natl Acad Sci U S A. <year>2012</year>; <volume>109</volume>: <fpage>1431</fpage>–<lpage>1436</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1114783109</pub-id>
<pub-id pub-id-type="pmid">22307596</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref036">
<label>36</label>
<mixed-citation publication-type="journal">
<name><surname>Paterson</surname><given-names>SJ</given-names></name>, <name><surname>Brown</surname><given-names>JH</given-names></name>, <name><surname>Gsodl</surname><given-names>MK</given-names></name>, <name><surname>Johnson</surname><given-names>MH</given-names></name>, <name><surname>Karmiloff-Smith</surname><given-names>A</given-names></name>. <article-title>Cognitive modularity and genetic disorders</article-title>. <source/>Science. <year>1999</year>; <volume>286</volume>(<issue>5448</issue>): <fpage>2355</fpage>–<lpage>2358</lpage>.
<pub-id pub-id-type="pmid">10600749</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref037">
<label>37</label>
<mixed-citation publication-type="journal">
<name><surname>Karmiloff-Smith</surname><given-names>A</given-names></name>, <name><surname>D’Souza</surname><given-names>D</given-names></name>, <name><surname>Dekker</surname><given-names>TM</given-names></name>, <name><surname>Van Herwegen</surname><given-names>J</given-names></name>, <name><surname>Xu</surname><given-names>F</given-names></name>, <name><surname>Rodic</surname><given-names>M</given-names></name>, <name><surname>Ansari</surname><given-names>D</given-names></name>. <article-title>Genetic and environmental vulnerabilities in children with neurodevelopmental disorders</article-title>. <source/>Proc Natl Acad Sci U S A. <year>2012</year>; <volume>109</volume>(<issue>Supplement 2</issue>): <fpage>17261</fpage>–<lpage>17265</lpage>.<pub-id pub-id-type="pmid">23045661</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref038">
<label>38</label>
<mixed-citation publication-type="journal">
<name><surname>Porter</surname><given-names>MA</given-names></name>, <name><surname>Shaw</surname><given-names>TA</given-names></name>, <name><surname>Marsh</surname><given-names>PJ</given-names></name>. <article-title>An unusual attraction to the eyes in Williams-Beuren syndrome: A manipulation of facial affect while measuring face scanpaths</article-title>. <source/>Cogn Neuropsychiatry. <year>2010</year>; <volume>15</volume>(<issue>6</issue>): <fpage>505</fpage>–<lpage>530</lpage>. <pub-id pub-id-type="doi">10.1080/13546801003644486</pub-id>
<pub-id pub-id-type="pmid">20432078</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref039">
<label>39</label>
<mixed-citation publication-type="journal">
<name><surname>Riby</surname><given-names>DM</given-names></name>, <name><surname>Hancock</surname><given-names>PJB</given-names></name>. <article-title>Viewing it differently: Social scene perception in Williams syndrome and autism</article-title>. <source/>Neuropsychologia. <year>2008</year>; <volume>46</volume>(<issue>11</issue>): <fpage>2855</fpage>–<lpage>2860</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2008.05.003</pub-id>
<pub-id pub-id-type="pmid">18561959</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref040">
<label>40</label>
<mixed-citation publication-type="journal">
<name><surname>Riby</surname><given-names>DM</given-names></name>, <name><surname>Hancock</surname><given-names>PJB</given-names></name>. <article-title>Do faces capture the attention of individuals with Williams syndrome or Autism? Evidence from tracking eye movements</article-title>. <source/>J Autism Dev Disord. <year>2009</year>; <volume>39</volume>(<issue>3</issue>): <fpage>421</fpage>–<lpage>431</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-008-0641-z</pub-id>
<pub-id pub-id-type="pmid">18787936</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref041">
<label>41</label>
<mixed-citation publication-type="journal">
<name><surname>Riby</surname><given-names>DM</given-names></name>, <name><surname>Hancock</surname><given-names>PJB</given-names></name>. <article-title>Looking at movies and cartoons: Eye-tracking evidence from Williams syndrome and autism</article-title>. <source/>J Intellect Disabil Res. <year>2009</year>; <volume>53</volume>(<issue>2</issue>): <fpage>169</fpage>–<lpage>181</lpage>. <pub-id pub-id-type="doi">10.1111/j.1365-2788.2008.01142.x</pub-id>
<pub-id pub-id-type="pmid">19192099</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref042">
<label>42</label>
<mixed-citation publication-type="journal">
<name><surname>Hall</surname><given-names>S</given-names></name>, <name><surname>DeBernardis</surname><given-names>M</given-names></name>, <name><surname>Reiss</surname><given-names>A</given-names></name>. <article-title>Social escape behaviors in children with fragile X syndrome</article-title>. <source/>J Autism Dev Disord. <year>2006</year>; <volume>36</volume>: <fpage>935</fpage>–<lpage>947</lpage>.
<pub-id pub-id-type="pmid">16897394</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref043">
<label>43</label>
<mixed-citation publication-type="journal">
<name><surname>Jarrold</surname><given-names>C</given-names></name>, <name><surname>Baddeley</surname><given-names>AD</given-names></name>, <name><surname>Phillips</surname><given-names>CE</given-names></name>. <article-title>Verbal short-term memory in Down syndrome: A problem of memory, audition, or speech?</article-title>
<source/>J Speech Lang Hear Res. <year>2002</year>; <volume>45</volume>: <fpage>531</fpage>–<lpage>544</lpage>.
<pub-id pub-id-type="pmid">12069005</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref044">
<label>44</label>
<mixed-citation publication-type="journal">
<name><surname>Laws</surname><given-names>G</given-names></name>, <name><surname>Gunn</surname><given-names>D</given-names></name>. <article-title>Phonological memory as a predictor of language comprehension in Down syndrome: A five-year follow-up study</article-title>. <source/>J Child Psychol Psychiatry. <year>2004</year>; <volume>45</volume>(<issue>2</issue>): <fpage>326</fpage>–<lpage>337</lpage>.
<pub-id pub-id-type="pmid">14982246</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref045">
<label>45</label>
<mixed-citation publication-type="journal">
<name><surname>Cornish</surname><given-names>KM</given-names></name>, <name><surname>Turk</surname><given-names>J</given-names></name>, <name><surname>Wilding</surname><given-names>J</given-names></name>, <name><surname>Sudhalter</surname><given-names>V</given-names></name>, <name><surname>Munir</surname><given-names>F</given-names></name>, <name><surname>Kooy</surname><given-names>F</given-names></name>, <name><surname>Hagerman</surname><given-names>R</given-names></name>. <article-title>Annotation: Deconstructing the attention deficit in fragile X syndrome: a developmental neuropsychological approach</article-title>. <source/>J Child Psychol Psychiatry. <year>2004</year>; <volume>45</volume>(<issue>6</issue>): <fpage>1042</fpage>–<lpage>1053</lpage>.
<pub-id pub-id-type="pmid">15257661</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref046">
<label>46</label>
<mixed-citation publication-type="journal">
<name><surname>Terracciano</surname><given-names>A</given-names></name>, <name><surname>Chiurazzi</surname><given-names>P</given-names></name>, <name><surname>Neri</surname><given-names>G</given-names></name>. <article-title>Fragile X syndrome</article-title>. <source/>Am J Med Genet C Semin Med Genet. <year>2005</year>; <volume>137C</volume>(<issue>1</issue>): <fpage>32</fpage>–<lpage>37</lpage>.
<pub-id pub-id-type="pmid">16010677</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref047">
<label>47</label>
<mixed-citation publication-type="journal">
<name><surname>Donnai</surname><given-names>D</given-names></name>, <name><surname>Karmiloff-Smith</surname><given-names>A</given-names></name>. <article-title>Williams syndrome: From genotype through to the cognitive phenotype</article-title>. <source/>Am J Med Genet C Semin Med Genet. <year>2000</year>; <volume>97</volume>(<issue>2</issue>): <fpage>164</fpage>–<lpage>171</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref048">
<label>48</label>
<mixed-citation publication-type="journal">
<name><surname>Pober</surname><given-names>BR</given-names></name>. <article-title>Williams-Beuren syndrome</article-title>. <source/>N Engl J Med. <year>2010</year>; <volume>362</volume>: <fpage>239</fpage>–<lpage>252</lpage>. <pub-id pub-id-type="doi">10.1056/NEJMra0903074</pub-id>
<pub-id pub-id-type="pmid">20089974</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref049">
<label>49</label>
<mixed-citation publication-type="journal">
<name><surname>Bailey</surname><given-names>DB</given-names></name>, <name><surname>Raspa</surname><given-names>M</given-names></name>, <name><surname>Bishop</surname><given-names>E</given-names></name>, <name><surname>Holiday</surname><given-names>DB</given-names></name>. <article-title>No change in the age of diagnosis for fragile X syndrome: Findings from a national parent survey</article-title>. <source/>Pediatr. <year>2009</year>; <volume>124</volume>: <fpage>527</fpage>–<lpage>533</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref050">
<label>50</label>
<mixed-citation publication-type="book">
<name><surname>Mullen</surname><given-names>E</given-names></name>. <source/>Mullen Scales of Early Learning (<edition>AGS ed.</edition>). <publisher-loc>Circle Pines, MN</publisher-loc>: <publisher-name>American Guidance Service</publisher-name>; <year>1995</year>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref051">
<label>51</label>
<mixed-citation publication-type="journal">
<name><surname>Tomalski</surname><given-names>P</given-names></name>, <name><surname>Ribeiro</surname><given-names>H</given-names></name>, <name><surname>Ballieux</surname><given-names>H</given-names></name>, <name><surname>Axelsson</surname><given-names>EL</given-names></name>, <name><surname>Murphy</surname><given-names>E</given-names></name>, <name><surname>Moore</surname><given-names>DG</given-names></name>, <name><surname>Kushnerenko</surname><given-names>E</given-names></name>. <article-title>Exploring early developmental changes in face scanning patterns during the perception of audiovisual mismatch of speech cues</article-title>. <source/>Eur J Dev Psychol. <year>2013</year>; <volume>10</volume>(<issue>5</issue>): <fpage>611</fpage>–<lpage>624</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref052">
<label>52</label>
<mixed-citation publication-type="journal">
<name><surname>Guiraud</surname><given-names>JA</given-names></name>, <name><surname>Tomalski</surname><given-names>P</given-names></name>, <name><surname>Kushnerenko</surname><given-names>E</given-names></name>, <name><surname>Ribeiro</surname><given-names>H</given-names></name>, <name><surname>Davies</surname><given-names>K</given-names></name>, <name><surname>Charman</surname><given-names>T</given-names></name>, <etal>et al</etal>
<article-title>Atypical audiovisual speech integration in infants at risk for autism</article-title>. <source/>PLoS One. <year>2012</year>; <volume>7</volume>(<issue>5</issue>): <fpage>e36428</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0036428</pub-id>
<pub-id pub-id-type="pmid">22615768</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref053">
<label>53</label>
<mixed-citation publication-type="book">
<name><surname>Fenson</surname><given-names>L</given-names></name>, <name><surname>Dale</surname><given-names>PS</given-names></name>, <name><surname>Reznick</surname><given-names>JS</given-names></name>, <name><surname>Thal</surname><given-names>D</given-names></name>, <name><surname>Bates</surname><given-names>E</given-names></name>, <name><surname>Hartung</surname><given-names>JP</given-names></name>, <etal>et al</etal>
<source/>The MacArthur Communicative Development Inventories: User’s guide and technical manual. <publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Singular Publishing Group</publisher-name>; <year>1993</year>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref054">
<label>54</label>
<mixed-citation publication-type="other">Crumrine D, Owens J, Adams M, Salamone L. A preliminary investigation of eye gaze patterns on fast-mapping abilities of children with ASD. In: Proceedings of the 6<sup>th</sup> Annual GRASP Symposium. Wichita, KS: Wichita State University; 2010. pp. 93–94.</mixed-citation>
</ref>
<ref id="pone.0139319.ref055">
<label>55</label>
<mixed-citation publication-type="journal">
<name><surname>Amso</surname><given-names>D</given-names></name>, <name><surname>Haas</surname><given-names>S</given-names></name>, <name><surname>Markant</surname><given-names>J</given-names></name>. <article-title>An eye tracking investigation of developmental change in bottom-up attention orienting to faces in cluttered natural scenes</article-title>. <source/>PLoS One. <year>2014</year>; <volume>9</volume>(<issue>1</issue>): <fpage>e85701</fpage>, 1–7. <pub-id pub-id-type="doi">10.1371/journal.pone.0085701</pub-id>
<pub-id pub-id-type="pmid">24465653</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref056">
<label>56</label>
<mixed-citation publication-type="journal">
<name><surname>Gliga</surname><given-names>T</given-names></name>, <name><surname>Elsabbagh</surname><given-names>M</given-names></name>, <name><surname>Andravizou</surname><given-names>A</given-names></name>, <name><surname>Johnson</surname><given-names>M</given-names></name>. <article-title>Faces attract infants’ attention in complex displays</article-title>. <source/>Infancy. <year>2009</year>; <volume>14</volume>(<issue>5</issue>): <fpage>550</fpage>–<lpage>562</lpage>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref057">
<label>57</label>
<mixed-citation publication-type="journal">
<name><surname>Guastella</surname><given-names>AJ</given-names></name>, <name><surname>Mitchell</surname><given-names>PB</given-names></name>, <name><surname>Dadds</surname><given-names>MR</given-names></name>. <article-title>Oxytocin increases gaze to the eye region of human faces</article-title>. <source/>Biol Psychiatry. <year>2008</year>; <volume>63</volume>: <fpage>3</fpage>–<lpage>5</lpage>.
<pub-id pub-id-type="pmid">17888410</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref058">
<label>58</label>
<mixed-citation publication-type="book">
<name><surname>Poole</surname><given-names>A</given-names></name>, <name><surname>Ball</surname><given-names>LJ</given-names></name>, <name><surname>Phillips</surname><given-names>P</given-names></name>. <chapter-title>In search of salience: A response time and eye movement analysis of bookmark recognition</chapter-title> In: <name><surname>Fincher</surname><given-names>S</given-names></name>, <name><surname>Markopolous</surname><given-names>P</given-names></name>, <name><surname>Moore</surname><given-names>D</given-names></name>, <name><surname>Ruddle</surname><given-names>R</given-names></name>, editors. <source/>People and computers XVIII-design for life: Proceedings of HCI 2004. <publisher-loc>London</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>
<year>2004</year>
</mixed-citation>
</ref>
<ref id="pone.0139319.ref059">
<label>59</label>
<mixed-citation publication-type="book">
<name><surname>Field</surname><given-names>A</given-names></name>. <source/>Discovering statistics using IBM SPSS statistics. <publisher-loc>London, UK</publisher-loc>: <publisher-name>Sage</publisher-name>; <year>2013</year>.</mixed-citation>
</ref>
<ref id="pone.0139319.ref060">
<label>60</label>
<mixed-citation publication-type="journal">
<name><surname>Yeung</surname><given-names>HH</given-names></name>, <name><surname>Werker</surname><given-names>JF</given-names></name>. <article-title>Lip movements affect infants’ audiovisual speech perception</article-title>. <source/>Psychol Sci. <year>2013</year>; <volume>24</volume>(<issue>5</issue>): <fpage>603</fpage>–<lpage>612</lpage>. <pub-id pub-id-type="doi">10.1177/0956797612458802</pub-id>
<pub-id pub-id-type="pmid">23538910</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref061">
<label>61</label>
<mixed-citation publication-type="journal">
<name><surname>Mueller</surname><given-names>JL</given-names></name>, <name><surname>Friederici</surname><given-names>AD</given-names></name>, <name><surname>Männel</surname><given-names>C</given-names></name>. <article-title>Auditory perception at the root of language learning</article-title>. <source/>Proc Natl Acad Sci U S A. <year>2012</year>; <volume>109</volume>(<issue>39</issue>): <fpage>15953</fpage>–<lpage>15958</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1204319109</pub-id>
<pub-id pub-id-type="pmid">23019379</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref062">
<label>62</label>
<mixed-citation publication-type="journal">
<name><surname>Tsao</surname><given-names>FM</given-names></name>, <name><surname>Liu</surname><given-names>HM</given-names></name>, <name><surname>Kuhl</surname><given-names>PK</given-names></name>. <article-title>Speech perception in infancy predicts language development in the second year of life: A longitudinal study</article-title>. <source/>Child Dev. <year>2004</year>; <volume>75</volume>: <fpage>1067</fpage>–<lpage>1084</lpage>.
<pub-id pub-id-type="pmid">15260865</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref063">
<label>63</label>
<mixed-citation publication-type="journal">
<name><surname>Haith</surname><given-names>MM</given-names></name>, <name><surname>Bergman</surname><given-names>T</given-names></name>, <name><surname>Moore</surname><given-names>MJ</given-names></name>. <article-title>Eye contact and face scanning in early infancy</article-title>. <source/>Science. <year>1977</year>; <volume>198</volume>: <fpage>853</fpage>–<lpage>855</lpage>.
<pub-id pub-id-type="pmid">918670</pub-id></mixed-citation>
</ref>
<ref id="pone.0139319.ref064">
<label>64</label>
<mixed-citation publication-type="journal">
<name><surname>Maurer</surname><given-names>D</given-names></name>, <name><surname>Salapatek</surname><given-names>P</given-names></name>. <article-title>Developmental changes in the scanning of faces by young infants</article-title>. <source/>Child Dev. <year>1976</year>; <volume>47</volume>: <fpage>523</fpage>–<lpage>527</lpage>.
<pub-id pub-id-type="pmid">1269319</pub-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
</pmc-articleset>