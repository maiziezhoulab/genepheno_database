<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="research-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
<journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosone</journal-id>
<journal-title-group>
<journal-title>PLoS ONE</journal-title>
</journal-title-group>
<issn pub-type="epub">1932-6203</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">29095904</article-id>
<article-id pub-id-type="pmc">5667738</article-id>
<article-id pub-id-type="doi">10.1371/journal.pone.0187371</article-id>
<article-id pub-id-type="publisher-id">PONE-D-17-27548</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Biology and Life Sciences</subject>
<subj-group>
<subject>Psychology</subject>
<subj-group>
<subject>Developmental Psychology</subject>
<subj-group>
<subject>Pervasive Developmental Disorders</subject>
<subj-group>
<subject>Autism Spectrum Disorder</subject>
<subj-group>
<subject>Autism</subject>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Social Sciences</subject>
<subj-group>
<subject>Psychology</subject>
<subj-group>
<subject>Developmental Psychology</subject>
<subj-group>
<subject>Pervasive Developmental Disorders</subject>
<subj-group>
<subject>Autism Spectrum Disorder</subject>
<subj-group>
<subject>Autism</subject>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Biology and Life Sciences</subject>
<subj-group>
<subject>Neuroscience</subject>
<subj-group>
<subject>Developmental Neuroscience</subject>
<subj-group>
<subject>Neurodevelopmental Disorders</subject>
<subj-group>
<subject>Autism</subject>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Medicine and Health Sciences</subject>
<subj-group>
<subject>Neurology</subject>
<subj-group>
<subject>Neurodevelopmental Disorders</subject>
<subj-group>
<subject>Autism</subject>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Biology and Life Sciences</subject>
<subj-group>
<subject>Genetics</subject>
<subj-group>
<subject>Gene Expression</subject>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Computer and Information Sciences</subject>
<subj-group>
<subject>Artificial Intelligence</subject>
<subj-group>
<subject>Machine Learning</subject>
<subj-group>
<subject>Support Vector Machines</subject>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Computer and Information Sciences</subject>
<subj-group>
<subject>Information Technology</subject>
<subj-group>
<subject>Data Reduction</subject>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Research and Analysis Methods</subject>
<subj-group>
<subject>Bioassays and Physiological Analysis</subject>
<subj-group>
<subject>Microarrays</subject>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Physical Sciences</subject>
<subj-group>
<subject>Mathematics</subject>
<subj-group>
<subject>Applied Mathematics</subject>
<subj-group>
<subject>Algorithms</subject>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Research and Analysis Methods</subject>
<subj-group>
<subject>Simulation and Modeling</subject>
<subj-group>
<subject>Algorithms</subject>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Biology and Life Sciences</subject>
<subj-group>
<subject>Psychology</subject>
<subj-group>
<subject>Developmental Psychology</subject>
<subj-group>
<subject>Pervasive Developmental Disorders</subject>
<subj-group>
<subject>Autism Spectrum Disorder</subject>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Social Sciences</subject>
<subj-group>
<subject>Psychology</subject>
<subj-group>
<subject>Developmental Psychology</subject>
<subj-group>
<subject>Pervasive Developmental Disorders</subject>
<subj-group>
<subject>Autism Spectrum Disorder</subject>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
</subj-group>
<subj-group subj-group-type="Discipline-v3">
<subject>Physical Sciences</subject>
<subj-group>
<subject>Mathematics</subject>
<subj-group>
<subject>Optimization</subject>
</subj-group>
</subj-group>
</subj-group>
</article-categories>
<title-group>
<article-title>Selection and classification of gene expression in autism disorder: Use of a combination of statistical filters and a GBPSO-SVM algorithm</article-title>
<alt-title alt-title-type="running-head">Selection and classification of genes in autism</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Hameed</surname>
<given-names>Shilan S.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001">
<sup>1</sup>
</xref>
<xref ref-type="aff" rid="aff002">
<sup>2</sup>
</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hassan</surname>
<given-names>Rohayanti</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff003">
<sup>3</sup>
</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4563-9671</contrib-id>
<name>
<surname>Muhammad</surname>
<given-names>Fahmi F.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff004">
<sup>4</sup>
</xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label>
<addr-line>Department of Computer Science, Faculty of Computing, Universiti Teknologi Malaysia, Johor Bahru, Malaysia</addr-line></aff>
<aff id="aff002"><label>2</label>
<addr-line>Department of Software and Informatics Engineering, College of Engineering, Salahaddin University, Erbil, Kurdistan Region, Iraq</addr-line></aff>
<aff id="aff003"><label>3</label>
<addr-line>Department of Software Engineering, Faculty of Computing, Universiti Teknologi Malaysia, Johor Bahru, Malaysia</addr-line></aff>
<aff id="aff004"><label>4</label>
<addr-line>Department of Physics, Faculty of Science &amp; Health, Koya University, Koya, Kurdistan Region, Iraq</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor">
<name>
<surname>Liu</surname>
<given-names>Bin</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"></xref>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Harbin Institute of Technology Shenzhen Graduate School, CHINA</addr-line>
</aff>
<author-notes>
<fn fn-type="COI-statement" id="coi001">
<p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email>fahmi.fariq@koyauniversity.org</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>2</day>
<month>11</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="collection">
<year>2017</year>
</pub-date>
<volume>12</volume>
<issue>11</issue>
<elocation-id>e0187371</elocation-id>
<history>
<date date-type="received">
<day>23</day>
<month>7</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>18</day>
<month>10</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-statement>© 2017 Hameed et al</copyright-statement>
<copyright-year>2017</copyright-year>
<copyright-holder>Hameed et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="pone.0187371.pdf"></self-uri>
<abstract>
<p>In this work, gene expression in autism spectrum disorder (ASD) is analyzed with the goal of selecting the most attributed genes and performing classification. The objective was achieved by utilizing a combination of various statistical filters and a wrapper-based geometric binary particle swarm optimization-support vector machine (GBPSO-SVM) algorithm. The utilization of different filters was accentuated by incorporating a mean and median ratio criterion to remove very similar genes. The results showed that the most discriminative genes that were identified in the first and last selection steps included the presence of a repetitive gene (CAPS2), which was assigned as the gene most highly related to ASD risk. The merged gene subset that was selected by the GBPSO-SVM algorithm was able to enhance the classification accuracy.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100005417</institution-id>
<institution>Universiti Teknologi Malaysia</institution>
</institution-wrap>
</funding-source>
<award-id>Vot number 11H84</award-id>
<principal-award-recipient>
<name>
<surname>Hassan</surname>
<given-names>Rohayanti</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>Koya University</institution>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4563-9671</contrib-id>
<name>
<surname>Muhammad</surname>
<given-names>Fahmi F.</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was financially supported in part by the UTM Research University Grant Scheme (Vot number 11H84) and in part by Koya University.</funding-statement>
</funding-group>
<counts>
<fig-count count="12"></fig-count>
<table-count count="5"></table-count>
<page-count count="25"></page-count>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<title>Data Availability</title>
<p>All relevant data are within the paper and its Supporting Information files.</p>
</notes>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Autism spectrum disorder (ASD) is a neurodevelopmental disorder that is defined by weakened social interactions, impaired verbal and non-verbal communication and repetitive actions [<xref ref-type="bibr" rid="pone.0187371.ref001">1</xref>, <xref ref-type="bibr" rid="pone.0187371.ref002">2</xref>]. ASD affects more than 1% of the population, and males are four times more vulnerable to the disorder than females [<xref ref-type="bibr" rid="pone.0187371.ref003">3</xref>]. Although environmental factors are believed to contribute to autism, researchers believe that genetic factors play a major role in the occurrence of the disorder [<xref ref-type="bibr" rid="pone.0187371.ref004">4</xref>]. In a study of twins, the presence of high similarity in the features of autistic twins was noticed [<xref ref-type="bibr" rid="pone.0187371.ref005">5</xref>]. It was observed that the genetic similarity among identical twins who are from the same developmental environment and have the same parental chromosomes is high. In these contexts, biologists have attempted to identify the most relevant genes that can be utilized as biomarkers for tracing the disorder. The attribution of a role of specific genes in the development of autism enables us to understand the mechanism of development of the disorder and hence predict its serious consequences. To date, there is a lack of treatment for the major symptoms of autism, and no accurate biomarkers have been identified because the etiology of autism is not clearly known [<xref ref-type="bibr" rid="pone.0187371.ref006">6</xref>]. Although approximately 70% to 90% of cases of autism are thought to be related to heritable causes, the variable phenotype of the disease and the complex architecture of its genetics have made it difficult to identify specific genes that are associated with susceptibility to autism [<xref ref-type="bibr" rid="pone.0187371.ref007">7</xref>]. It has been claimed that the aggregate action of multiple genes is necessary to produce autism disorder, a feature that adds complexity to genomic investigations [<xref ref-type="bibr" rid="pone.0187371.ref008">8</xref>]. The pioneer work of Gregg <italic>et al</italic>. [<xref ref-type="bibr" rid="pone.0187371.ref009">9</xref>], which was based upon genomic profiling of whole blood, revealed differences in gene expression in autistic and healthy children. Moreover, these authors observed variations in gene expression at the early onset stage of the disease in individuals with different subtypes of autism such as autism with regression and autism without regression. Because of these variations, the identification of genes related to autism presents a difficult problem. It is quite reasonable to use gene expression data to relate the phenotypes of diseases to their attributed biomarkers [<xref ref-type="bibr" rid="pone.0187371.ref010">10</xref>].</p>
<p>Computer models can be used to study autism through the use of microarray gene expression data. A microarray is a tool that is used to estimate whether mutations in specific genes are present in a particular individual. The most common type of microarray is utilized to measure gene expression; in this type of microarray, the expression values of thousands of genes are calculated from the microarray sample [<xref ref-type="bibr" rid="pone.0187371.ref011">11</xref>]. Along this line, the techniques of machine learning and data mining are considered effective tools in the application of genomic medicine, which uses computational methods and genomic datasets to predict phenotypes [<xref ref-type="bibr" rid="pone.0187371.ref012">12</xref>]. Machine learning is valuable in the interpretation of large datasets of genomic data, and it has also been successfully utilized to annotate the wide diversity of elements in genomic sequences [<xref ref-type="bibr" rid="pone.0187371.ref013">13</xref>]. Genome sequence analysis has also received considerable attention. In recent years, very useful computational tools were proposed in an open-source Python package designed to formulate comprehensive built-in and user-defined features for DNA, RNA and protein sequences; these are known as representations of DNA (repDNA) [<xref ref-type="bibr" rid="pone.0187371.ref014">14</xref>], repRNA [<xref ref-type="bibr" rid="pone.0187371.ref015">15</xref>] and Pse-in-One [<xref ref-type="bibr" rid="pone.0187371.ref016">16</xref>], respectively. The repDNA tool was used to develop powerful computational predictors for use in identifying the biological features or attributes of DNAs by generating widely used features that reflect the physicochemical properties and sequence-order effects of DNAs and nucleotides [<xref ref-type="bibr" rid="pone.0187371.ref014">14</xref>]. This model includes three groups of features that can be used for different analysis purposes. In regard to RNA analysis, a new repRNA was developed to meet the increasing demands and to speed up the genome analyses [<xref ref-type="bibr" rid="pone.0187371.ref015">15</xref>]. The features of this model can be represented by 11 different modes of feature vectors, thereby exceeding the limitations of existing machine-learning methods such as SVM and KNN that use only vectors and not sequences. Pse-in-one [<xref ref-type="bibr" rid="pone.0187371.ref016">16</xref>] was proposed as an effective tool that can handle the analysis of more than one type of sample; however, it is utilization is maximized to work on DNA, RNA and protein as well. The feature vectors of Pse-in-one can be easily combined with machine-learning algorithms for use in developing computational predictors and analysis methods for various tasks in bioinformatics and systems biology. Furthermore, studies in the field of cancer informatics have shown an interesting contribution of data mining and machine learning to finding related genes [<xref ref-type="bibr" rid="pone.0187371.ref017">17</xref>–<xref ref-type="bibr" rid="pone.0187371.ref019">19</xref>]. However, gene expression in autism displays some specific characteristics that make gene selection, model creation and prediction more challenging than gene expression analysis of cancers.</p>
<p>The major problem in the gene expression analysis of ASD is the difficulty in selection and identification of the genes that are most relevant to autism. This problem exists because the gene expression levels in autism disorder show considerable fluctuation among individuals and because the sequences of several of these genes are highly variable [<xref ref-type="bibr" rid="pone.0187371.ref020">20</xref>]. In general, noise in gene expression level data usually occurs due to variations associated with the experiments or the existence of alterations in the genes [<xref ref-type="bibr" rid="pone.0187371.ref021">21</xref>, <xref ref-type="bibr" rid="pone.0187371.ref022">22</xref>]. In the case of autism, the extra variance may be linked to the presence of alterations in many genes. Another reason for this difficulty is the limited number of observations (in the range of hundreds) that have been made in comparison to the very large number of genes (in the range of tens of thousands). In machine learning, this feature is known as high dimensionality, and sophisticated methods are required to handle it. High dimensionality also exists in genome sequence analysis data, where it poses computational challenges despite the important contribution of high-throughput sequencing technology, which greatly increases the amount of available data for discriminative motif discovery (DMD) [<xref ref-type="bibr" rid="pone.0187371.ref023">23</xref>, <xref ref-type="bibr" rid="pone.0187371.ref024">24</xref>]. DMD methods usually have to sacrifice accuracy and may fail to fully leverage the potential of large datasets. Hence, researchers have proposed the large margin motif optimizer (LMMO) [<xref ref-type="bibr" rid="pone.0187371.ref023">23</xref>] for refining regulatory motifs and a novel approach referred to as discriminative motif learning via AUC (DiscMLA) to identify motifs in high-throughput datasets [<xref ref-type="bibr" rid="pone.0187371.ref024">24</xref>]. To further reduce computational time, some researchers have combined the proposed models with various techniques for improving the scalability of large-margin type algorithms and to accelerate DiscMLA.</p>
<p>The foregoing shows that it is not an easy or a straightforward task to find the attributed genes of autism unless a careful analysis and investigation is made of the microarray dataset. Gene selection methods are classified into two main types: filter-based methods and wrapper-based methods [<xref ref-type="bibr" rid="pone.0187371.ref021">21</xref>, <xref ref-type="bibr" rid="pone.0187371.ref025">25</xref>]. Because filter-based methods usually work without using a classifier, they are efficient with respect to computational time. They are preferable for use in analyzing the high-dimensional data of microarray datasets [<xref ref-type="bibr" rid="pone.0187371.ref026">26</xref>]. The drawback of filter-based methods is that the selected features may not have relationships to each other, and the appearance of redundant features is possible. This may decrease the accuracy of the classifier when the gene selection results are directly applied to the learning algorithm [<xref ref-type="bibr" rid="pone.0187371.ref021">21</xref>]. For this reason, the best choice is to use filters in the first selection process and to apply another feature selection approach that depends on classifier accuracy to choose the attributed genes in later steps. Wrappers tend to perform better in selecting discriminative genes since they take the model hypothesis into account by training and testing in the gene space [<xref ref-type="bibr" rid="pone.0187371.ref021">21</xref>]. When dealing with high-dimensional data such as microarray datasets, wrapper-based methods tend to be the worst choice if applied to the data directly without any preprocessing because this leads to overfitting [<xref ref-type="bibr" rid="pone.0187371.ref027">27</xref>]. This is because the wrapper acts by searching and comparing the performance of each gene subset with the classification algorithm prior to estimating the best subset of genes [<xref ref-type="bibr" rid="pone.0187371.ref028">28</xref>]. However, if wrappers are used after the application of filter methods, they require less computational time and hence work more efficiently [<xref ref-type="bibr" rid="pone.0187371.ref029">29</xref>]. Conventional wrappers use search algorithms to find subsets of genes through adding or removing the best features to the space based on the fitness criteria [<xref ref-type="bibr" rid="pone.0187371.ref030">30</xref>]. Hence, the problems of large-scale feature selection are not efficiently solved by using conventional optimization algorithms [<xref ref-type="bibr" rid="pone.0187371.ref031">31</xref>]. Therefore, to address the feature selection problems effectively, meta-heuristic algorithms are being adopted. There are various meta-heuristic algorithms that can be used to address feature selection issues; these include the genetic algorithm (GA) [<xref ref-type="bibr" rid="pone.0187371.ref032">32</xref>], ant colony optimization [<xref ref-type="bibr" rid="pone.0187371.ref033">33</xref>], simulated annealing [<xref ref-type="bibr" rid="pone.0187371.ref034">34</xref>], and particle swarm optimization (PSO) [<xref ref-type="bibr" rid="pone.0187371.ref035">35</xref>]. PSO and GA are two common evolutionary algorithms that are usually applied in the form of wrapper methods [<xref ref-type="bibr" rid="pone.0187371.ref031">31</xref>, <xref ref-type="bibr" rid="pone.0187371.ref036">36</xref>]. Comparably, PSO is efficient and simple; only a few parameters are required to perform its adjustment, and hence it is a memory-enabled algorithm. Binary PSO is a modified version of the standard PSO introduced by Kennedy and Eberhart [<xref ref-type="bibr" rid="pone.0187371.ref037">37</xref>] to handle variables with discrete design. BPSO was shown to outperform GA when used for feature selection using the same fitness function [<xref ref-type="bibr" rid="pone.0187371.ref038">38</xref>]. In another study [<xref ref-type="bibr" rid="pone.0187371.ref039">39</xref>], BPSO was used in feature selection such that the fitness function was designed based on the rough set. BPSO was also applied to various optimization problems [<xref ref-type="bibr" rid="pone.0187371.ref017">17</xref>, <xref ref-type="bibr" rid="pone.0187371.ref040">40</xref>, <xref ref-type="bibr" rid="pone.0187371.ref041">41</xref>]. In addition, a new discrete form of the PSO, the DPSO algorithm, which is based on the particle’s best position (pbDPSO) and global best position (gbDPSO), was adopted to find the global optimal solution for a high-dimensional grid system; in this way, a reduction in the minimum computation time and an energy improvement of up to 28% were achieved [<xref ref-type="bibr" rid="pone.0187371.ref042">42</xref>]. Recently, a new modified version of PSO known as geometric PSO (GPSO) was proposed by Moraglio <italic>et al</italic>. [<xref ref-type="bibr" rid="pone.0187371.ref043">43</xref>] and utilized for gene selection in cancer classification by Alba <italic>et al</italic>. [<xref ref-type="bibr" rid="pone.0187371.ref036">36</xref>]. In the current work, a combination of statistical filters and wrapper algorithms incorporating GBPSO is employed for gene selection and classification in autism disorder. This is achieved through the application of various filters in parallel with a GBPSO wrapper and a support vector machine (SVM) classifier (GBPSO-SVM algorithm). Prior to the selection process, specific pre-processing operations are performed on the dataset in a creative way to remove the most similar genes. The presented results were found to improve the accuracy of gene classification in autism disorder.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec003">
<title>Experimental overview</title>
<p>The experimental procedure of the current work was implemented in three basic steps; these are briefly described below, and the details of each step are given in the following subsections.</p>
<p>First step: in this stage, the whole dataset was checked for the similarity of gene expression in the control and autism classes. Genes with mean or median ratios close to unity (equal to or greater than 0.95) were removed; in this way, the number of genes in the dataset was reduced from 54,613 to 9454.</p>
<p>Second step: in this stage, the reduced dataset was divided into two parts, 85% of which was used in the process of model training and validation (testing); the 15% non-involved set was set aside to be used as a new real-world dataset against the gene classification based on the pre-defined model. Later on, three filters, namely, the t-test (TT), feature correlation (COR) and the Wilcoxon Rank Sum test (WRS), were initially applied in parallel to select the 200 most discriminative genes using a 10-fold run evaluation.</p>
<p>Third step: in this stage, the final most discriminative subsets of genes were selected by the GBPSO-SVM algorithm, and classification was performed based on the resulting genes. Furthermore, a merged set of genes was generated from the combination of these three final subsets based on their frequencies of appearance in the 10-fold selection process. Consequently, the selected genes were used in training and validation performed with the SVM classifier in the 10-fold cross-validation scheme. Finally, the non-involved dataset mentioned in step two was used as a new real-world dataset to further test and generalize the applied model. The complete methodology of the current work is illustrated in <xref ref-type="fig" rid="pone.0187371.g001">Fig 1</xref>, and the implementation steps of the codes are given in (<ext-link ext-link-type="uri" xlink:href="https://github.com/fahmi982/Implementation-Steps">https://github.com/fahmi982/Implementation-Steps</ext-link>).</p>
<fig id="pone.0187371.g001" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Experimental setup used to select autism-related genes and to perform classification.</title>
</caption>
<graphic xlink:href="pone.0187371.g001"></graphic>
</fig>
</sec>
<sec id="sec004">
<title>Autism dataset</title>
<p>The experimental data used in the analysis comprised an autism microarray dataset that was downloaded from the well-known public repository GEO (NCBI) [<xref ref-type="bibr" rid="pone.0187371.ref044">44</xref>]. The dataset consists of 146 observations (samples) and 54,613 genes (features). The observations are divided into two classes, a control class containing 69 observations and an autism class containing 77 observations. Samples from autistic and control individuals were collected from persons in the Phoenix area. Blood drawing for the observations was conducted in the spring and summer of 2004. Total RNA was extracted for microarray experiments, which were performed using Affymetrix Human U133 Plus 2.0 39 Expression Arrays. The autistic patients who provided the samples were diagnosed by medical professionals (developmental pediatricians and psychologists) according to the DSM-IV criteria, and the diagnosis was confirmed on the basis of the ADOS and ADI-R criteria [<xref ref-type="bibr" rid="pone.0187371.ref045">45</xref>]. Samples from individuals with non-classic higher functioning forms of autism, regression and Asperger’s syndrome were not included in the dataset. Each sample was subjected to normal high-resolution chromosome analysis and had a negative result on the Fragile X DNA test.</p>
</sec>
<sec id="sec005">
<title>Pre-selection operations</title>
<p>High variance is one of the most apparent problems in the autism gene expression dataset used in this study; the high variance may be due to the nature of the data [<xref ref-type="bibr" rid="pone.0187371.ref046">46</xref>]. Moreover, the fact that the high-dimensional data in this set consisted of 54,613 genes and only 146 samples emphasizes the existence of similar expression of autism-related and non-autism-related genes. Statistical theories [<xref ref-type="bibr" rid="pone.0187371.ref047">47</xref>] indicate that the genes that show similar expression in both sets of individuals are not useful and that they do not include the discriminant genes. For this reason, removing very similar genes facilitates the subsequent steps in the proposed method, especially the steps involving feature selection. This is because the presence of similar genes, particularly those with high variance, affects the mean and median values for the expression of individual genes, thereby affecting the next filter steps. In a previous study [<xref ref-type="bibr" rid="pone.0187371.ref048">48</xref>], the ratio of the mean was used as a basis for removing similar genes. It has been proven that when there are outliers in the features, the application of the median criterion is a better choice than the application of the mean criterion since the mean values of gene expression are affected by the variance. However, the median is not a strong statistical criterion to depend on throughout the experiments, and it is not popular. Therefore, in this study, a new approach was taken in which genes whose expression showed very high variance were identified among the genes in each class. Since high variance leads to mean values that do not reliably present the population, it creates a non-desirable result with respect to feature selection. To avoid this problem and to facilitate the next steps in the analysis, in this study the mean and median ratios are applied in different contexts. The ratio of the mean values is used in the case of genes whose expression values do not show high variance within the class, whereas for genes with high variance within the class the ratio of the median values is applied. This strategy is used in a creative way to overcome the problems associated with the variance of the dataset. In this approach, the features in each class are divided into two groups according to their variance. A set of high-variance features (variance &gt;15%) are separated from those with low variance (variance = &lt;15%). The median ratio criterion is then applied to the high- variance group, and the mean ratio criterion is used for the rest. This is performed similarly for both classes of observations. The next step in the analysis reduces the high-dimensional features of the dataset by removing genes that have quite similar medians in both classes as well as those that have quite similar means in both classes. In this step, features for which the median and mean ratios for both classes are between 0.95 and 1/0.95 are removed from the dataset. This threshold range is chosen intentionally to remove the non-significant genes from the whole dataset as well as to reduce the effect of high-variance genes, hence making the next steps of the analysis smoother. By following this procedure, the number of genes in the dataset is significantly reduced.</p>
</sec>
<sec id="sec006">
<title>Selection using statistical filters</title>
<p>The reduced set of genes identified in the previous steps is used as input for three gene selection methods that are based on the filter approach. The statistical filters are the two-sample t-test (TT), feature correlation with class (COR) and the Wilcoxon rank sum test (WRS). Each of these depends on a specific statistical criterion for feature selection. The reason for choosing more than one filter is that, because the methods have different relative power, the use of a combination of these methods might yield better selection performance than the use of a single filter [<xref ref-type="bibr" rid="pone.0187371.ref032">32</xref>, <xref ref-type="bibr" rid="pone.0187371.ref048">48</xref>]. Prior to the application of the filters, the dataset was divided into two parts; one part consisted of 85% of the data and was used in the process of model training and validation (testing); the other part, which consisted of 15% of the data, was set apart as a non-involved set to be used as a new real-world dataset for gene classification based on the predefined model. This was done because researchers in the field of data science have recently recommended that the whole process should be divided into three main steps, namely, training, validation and testing [<xref ref-type="bibr" rid="pone.0187371.ref049">49</xref>]. The best approach is to apply training and 10-fold validation to avoid overfitting. Hence, the last step in the process would involve generalizing the model against new datasets that may be obtained in the future. Since in our study no new separate dataset was available, we set aside a portion of the data to be used at the last step of the analysis as a new real-world case study. Moreover, utilization of the whole dataset for feature selection produces a biased result that does not demonstrate the real ability of the model during the test phase. Therefore, the statistical filtering was repeated in 10-fold runs on the trained dataset. In each method, the positions of the filtered genes in all the runs were compared based on their position weights. Next, the weight values were summed, and the genes were ordered from most attributed to least attributed according to the final ranks achieved within the 10-fold runs. The equation used in this calculation is a global weight equation that is given by
<disp-formula id="pone.0187371.e001"><alternatives><graphic id="pone.0187371.e001g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0187371.e001.jpg"></graphic><mml:math id="M1"><mml:mi>w</mml:mi><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(1)</label></disp-formula>
where each <italic>i</italic> in <italic>K</italic> = the number of current fold iterations in the whole 10-fold run.</p>
<p>The first applied filter was the t-test, which is a univariate filter feature selection that is often employed in binary class applications [<xref ref-type="bibr" rid="pone.0187371.ref050">50</xref>, <xref ref-type="bibr" rid="pone.0187371.ref051">51</xref>]. The common assumption of the t-test is that the values for the two compared groups of genes are normally distributed. The null hypothesis of the t-test assumes equal means and equal variances, and the alternative hypothesis rejects this assumption. The equation of the t-test is
<disp-formula id="pone.0187371.e002"><alternatives><graphic id="pone.0187371.e002g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0187371.e002.jpg"></graphic><mml:math id="M2"><mml:mi>t</mml:mi><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow></mml:mfrac></mml:math></alternatives><label>(2)</label></disp-formula>
where <italic>n</italic> and <italic>m</italic> denote the population sizes of the first and second classes, respectively. The result of the assessment calls <italic>t</italic>, which is equal to 1 or 0; 1 represents the rejection of the null hypothesis at the 5% significance level and 0 denotes the acceptance of the null hypothesis at the same significance level. The p-value is also returned by the test; a small value of <italic>p</italic> indicates a significant difference among the compared samples. For the autism dataset, a normal distribution of the expressed genes is not guaranteed due to the presence of outliers. Therefore, the non-parametric version of the t-test was considered in MATLAB programming by assuming unequal variances in the two classes. This method was adopted to provide a more accurate measurement. The t-test has long been used in the application of microarray feature selection [<xref ref-type="bibr" rid="pone.0187371.ref050">50</xref>]. It has powerful scalability when the number of features is high [<xref ref-type="bibr" rid="pone.0187371.ref051">51</xref>]. Some studies used filters such as the t-test as the only feature selection step followed by direct application of the classification algorithms [<xref ref-type="bibr" rid="pone.0187371.ref052">52</xref>, <xref ref-type="bibr" rid="pone.0187371.ref053">53</xref>]. In the current work, the t-test is used as a filter followed by wrapper-based gene selection; after this, the classification algorithm is applied.</p>
<p>The second applied filter method was feature correlation with class (COR), a univariate filter feature selection method that can be used as a pre-selection step in microarray gene selection [<xref ref-type="bibr" rid="pone.0187371.ref054">54</xref>, <xref ref-type="bibr" rid="pone.0187371.ref055">55</xref>]. The value of feature discrimination, <italic>S(f)</italic>, is expressed by
<disp-formula id="pone.0187371.e003"><alternatives><graphic id="pone.0187371.e003g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0187371.e003.jpg"></graphic><mml:math id="M3"><mml:mrow><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(3)</label></disp-formula>
where <italic>c</italic> is the mean value for the gene among both classes, <italic>c</italic><sub><italic>k</italic></sub> is the mean value for the <italic>k</italic><sup><italic>th</italic></sup> class gene, <italic>σ</italic><sup>2</sup>(<italic>f</italic>) is the gene variance, and <italic>P</italic><sub><italic>k</italic></sub> is the probability of appearance of the <italic>k</italic><sup><italic>th</italic></sup> class in the dataset. A high value of <italic>S(f)</italic> represents good discrimination capability of feature <italic>f</italic> in distinguishing a particular class from other K classes. Here, the number of classes is two, so K = 2.</p>
<p>The third applied filter method was the Wilcoxon rank sum (WRS) test. Because the WRS test is a non-parametric filter method [<xref ref-type="bibr" rid="pone.0187371.ref056">56</xref>], it is not necessary for the gene expression data in the classes to be normally distributed. Hence, at first glance, it appears more appropriate to apply the WRS test to the present dataset. The rank sum test is also known as the Mann-Whitney test [<xref ref-type="bibr" rid="pone.0187371.ref057">57</xref>, <xref ref-type="bibr" rid="pone.0187371.ref058">58</xref>]. To distinguish between the two classes, the criterion used by this test is based on the median value. The test compares the medians of the samples and produces the result as a ranking instead of as numerical values [<xref ref-type="bibr" rid="pone.0187371.ref059">59</xref>]. By arranging the results in ascending order, the rank and the index value of the arrangement are determined. The WRS test considers as the null hypothesis the hypothesis that all genes originate from one class. The statistical formula of the Wilcoxon rank sum is as follows [<xref ref-type="bibr" rid="pone.0187371.ref060">60</xref>]:
<disp-formula id="pone.0187371.e004"><alternatives><graphic id="pone.0187371.e004g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0187371.e004.jpg"></graphic><mml:math id="M4"><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">g</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">g</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives><label>(4)</label></disp-formula>
where <italic>I</italic> is the function used to distinguish the classes. If the logical expression <inline-formula id="pone.0187371.e005"><alternatives><graphic id="pone.0187371.e005g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0187371.e005.jpg"></graphic><mml:math id="M5"><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">g</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">g</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:math></alternatives></inline-formula> is true, <italic>I</italic> is 1; otherwise, it is 0. <inline-formula id="pone.0187371.e006"><alternatives><graphic id="pone.0187371.e006g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0187371.e006.jpg"></graphic><mml:math id="M6"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">g</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is the expression value of gene <italic>g</italic> in sample <italic>I</italic>, <italic>N</italic><sub><italic>0</italic></sub> and <italic>N</italic><sub><italic>1</italic></sub> represent the number of observations in each of the two classes, respectively, and <italic>s(g)</italic> denotes the difference in the expression of the gene in the two classes. Based on whether <italic>s(g)</italic> becomes 0 or reaches the maximum of <italic>N</italic><sub><italic>0</italic></sub>
<italic>× N</italic><sub><italic>1</italic></sub>, the considered gene is ranked in importance in the classification process. The following equation is used to calculate the gene’s importance:
<disp-formula id="pone.0187371.e007"><alternatives><graphic id="pone.0187371.e007g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0187371.e007.jpg"></graphic><mml:math id="M7"><mml:mi>q</mml:mi><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mtext>max</mml:mtext><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:math></alternatives><label>(5)</label></disp-formula></p>
<p>This method was used in the literature for the pre-selection of genes [<xref ref-type="bibr" rid="pone.0187371.ref060">60</xref>, <xref ref-type="bibr" rid="pone.0187371.ref061">61</xref>], and it was shown to produce a powerful statistical result, especially when the data are severely skewed and approximately symmetric [<xref ref-type="bibr" rid="pone.0187371.ref062">62</xref>]. Usually, at the end of the analysis, WRS will give the rank of the genes, beginning with the most discriminative genes and proceeding to the less discriminative ones.</p>
</sec>
<sec id="sec007">
<title>Selection using a wrapper-based GBPSO-SVM algorithm</title>
<p>The last step in the selection of discriminative genes was conducted using geometric binary particle swarm optimization (GBPSO) in wrapper form with the support vector machines (SVM) algorithm; in this method, the GBPSO uses the accuracy prediction of the SVM to choose the best subset of genes. GBPSO begins with a random number of selected genes and searches for the optimal subset of genes in each iteration. The SVM classifier is used to evaluate the performance of each candidate subset using 10-fold cross-validation. The GBPSO algorithm leads to the selection of an optimal subset of genes that provides the best classification accuracy. Furthermore, it chooses the most discriminative genes to contribute to the next generation of gene subsets. Thus, each new candidate subset of genes is usually better than the previous subset.</p>
<p>Particle swarm optimization (PSO) is a stochastic population-based optimization technique that was first suggested by Kennedy and Eberhart (1995). PSO has received a great deal of attention from researchers in various fields due to the simplicity of its implementation and its rapid convergence towards acceptable solutions [<xref ref-type="bibr" rid="pone.0187371.ref035">35</xref>, <xref ref-type="bibr" rid="pone.0187371.ref036">36</xref>, <xref ref-type="bibr" rid="pone.0187371.ref063">63</xref>]. The PSO algorithm was inspired by the social behavior of birds flocking and fish schooling. The prototype algorithm of PSO comprises three steps: generating the positions and velocities of particles, updating their velocities, and finally updating their positions [<xref ref-type="bibr" rid="pone.0187371.ref037">37</xref>]. In PSO, a swarm is made up of individuals known as particles that communicate with each other through iterations to search for optimal solutions while they are moving in the search space [<xref ref-type="bibr" rid="pone.0187371.ref035">35</xref>]. <xref ref-type="fig" rid="pone.0187371.g002">Fig 2</xref> shows the principle of particle movement in PSO. In each iteration, a particle velocity is updated according to the personal best (<italic>p</italic><sub><italic>best</italic></sub>) and the global best (<italic>g</italic><sub><italic>best</italic></sub>), where <italic>p</italic><sub><italic>best</italic></sub> is the best position that the particle has explored and <italic>g</italic><sub><italic>best</italic></sub> is the best position among all particles in the swarm. By assuming a search space having <italic>D</italic> dimensions, the <italic>i</italic><sup>th</sup> swarm particle can have a <italic>D</italic>-dimensional position vector represented by <italic>X</italic><sub>i</sub> = [<italic>x</italic><sub><italic>i</italic>1</sub>, <italic>x</italic><sub><italic>i</italic>2</sub>, …; <italic>x</italic><sub><italic>iD</italic></sub>]. The velocity of the <italic>i</italic><sup><italic>th</italic></sup> particle is therefore denoted by <italic>V</italic><sub>i</sub> = [<italic>v</italic><sub><italic>i</italic>1</sub>, <italic>v</italic><sub><italic>i</italic>2</sub>, …; <italic>v</italic><sub><italic>iD</italic></sub>]. It is also considered that the visited position that produces the best fitness value for the particle is <italic>P</italic><sub><italic>B</italic>i</sub> = [<italic>p</italic><sub><italic>bi</italic>1</sub>, <italic>p</italic><sub><italic>bi</italic>2</sub>, …; <italic>p</italic><sub><italic>biD</italic></sub>], while the best explored position so far is <italic>G</italic><sub><italic>B</italic></sub>
<italic>=</italic> [<italic>g</italic><sub><italic>b</italic>1</sub>, <italic>g</italic><sub><italic>b</italic>2</sub>, …; <italic>g</italic><sub><italic>bD</italic></sub>]. Thus, each particle’s velocity is updated based on the following equation:
<disp-formula id="pone.0187371.e008"><alternatives><graphic id="pone.0187371.e008g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0187371.e008.jpg"></graphic><mml:math id="M8"><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mi mathvariant="normal"> </mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mi>w</mml:mi><mml:mo>.</mml:mo><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mo>…</mml:mo><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mo>…</mml:mo><mml:mo>)</mml:mo><mml:mo>×</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives><label>(6)</label></disp-formula>
where <italic>d = 1</italic>, <italic>2</italic>…, <italic>D</italic>, <italic>c</italic><sub><italic>1</italic></sub> is the cognitive learning factor and <italic>c</italic><sub><italic>2</italic></sub> is the social learning factor. The inertia weight (<italic>w</italic>) acts to reduce the particle’s velocity in steps and hence controls the swarms. The <italic>w</italic> value is usually between 0.4 and 0.9, whereas the random variables <italic>rand</italic><sub><italic>1</italic></sub> and <italic>rand</italic><sub><italic>2</italic></sub> have values that are uniformly distributed between 0 and 1 [<xref ref-type="bibr" rid="pone.0187371.ref035">35</xref>].</p>
<fig id="pone.0187371.g002" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Illustration of the PSO principle.</title>
</caption>
<graphic xlink:href="pone.0187371.g002"></graphic>
</fig>
<p>Consequently, the particles’ velocities are bounded within the range [<italic>v</italic><sub><italic>min</italic></sub>, <italic>v</italic><sub><italic>max</italic></sub>]. These bounds maintain the vector function of the velocity to avoid very abrupt movements of particles in the search space. The formula that is used to update the particle’s position is
<disp-formula id="pone.0187371.e009"><alternatives><graphic id="pone.0187371.e009g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0187371.e009.jpg"></graphic><mml:math id="M9"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives><label>(7)</label></disp-formula>
where <italic>d</italic> = 1, 2, …. <italic>D</italic>, <italic>i</italic> = 1, 2, ….. <italic>N</italic>, and <italic>N</italic> is the size of the swarm.</p>
<p>Binary PSO (BPSO) is a modified version of standard PSO that was developed to handle variables with discrete design [<xref ref-type="bibr" rid="pone.0187371.ref037">37</xref>], whereas the original PSO was proposed for continuous variables. When BPSO is used for gene selection, a gene subset is expressed by a string vector of <italic>n</italic> binary bits <italic>X</italic><sub><italic>i</italic></sub> = (<italic>x</italic><sub><italic>1</italic></sub>, <italic>x</italic><sub><italic>2</italic></sub>,…<italic>x</italic><sub><italic>n</italic></sub>) comprising ‘0’ and ‘1’. Consequently, if <italic>x</italic><sub><italic>id</italic></sub> is ‘0’, then the <italic>d</italic><sup><italic>th</italic></sup> gene is not selected in this subset, and an <italic>x</italic><sub><italic>id</italic></sub> of ‘1’ is alternatively chosen in the subset. In this regard, each binary string vector (<italic>X</italic><sub><italic>i</italic></sub>) defines the particle’s position in BPSO. For instance, a particle with seven genes is encoded as ‘0100010’, implying that the second and sixth genes are selected. Therefore, the length of each particle is initially the same as the number of genes in the dataset.</p>
<p>The population of particles is randomly initialized. However, it is effective to initialize the particles in such a way as to produce better selection results. In the geometric version of BPSO, the particle’s current position, its <italic>p</italic><sub><italic>best</italic></sub> and its <italic>g</italic><sub><italic>best</italic></sub> are used as the three parents in a three-parent mask-based crossover operator (3PMBCX) to create a new position for the particle instead of using velocity. The equation for position updating is as follows [<xref ref-type="bibr" rid="pone.0187371.ref036">36</xref>, <xref ref-type="bibr" rid="pone.0187371.ref043">43</xref>]:
<disp-formula id="pone.0187371.e010"><alternatives><graphic id="pone.0187371.e010g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0187371.e010.jpg"></graphic><mml:math id="M10"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msubsup><mml:mi mathvariant="normal"> </mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives><label>(8)</label></disp-formula>
where, for each element in the crossover mask, <italic>w</italic><sub><italic>1</italic></sub>, <italic>w</italic><sub><italic>2</italic></sub> and <italic>w</italic><sub><italic>3</italic></sub> indicate the weight values associated with each parent represented by <inline-formula id="pone.0187371.e011"><alternatives><graphic id="pone.0187371.e011g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0187371.e011.jpg"></graphic><mml:math id="M11"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0187371.e012"><alternatives><graphic id="pone.0187371.e012g" mimetype="image" orientation="portrait" position="anchor" xlink:href="pone.0187371.e012.jpg"></graphic><mml:math id="M12"><mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, respectively. A condition is that the geometric crossover forces <italic>w</italic><sub><italic>1</italic></sub>, <italic>w</italic><sub><italic>2</italic></sub> and <italic>w</italic><sub><italic>3</italic></sub> must be non-negative and must sum to one. In addition, an operator with a probability value of 0.01 is added to take care of bit-flip. This is to avoid early convergence. The advantage of this version of GBPSO is that it enables the generalization of PSO to virtually any solution representation in a natural and straightforward way [<xref ref-type="bibr" rid="pone.0187371.ref036">36</xref>]. The key issue of the GBPSO is the concept of particle movement. In this approach, instead of the notion of velocity added to the position, a three-parent mask-based crossover (3PMBCX) operator is applied to each particle to move it. According to the definition of 3PMBCX [<xref ref-type="bibr" rid="pone.0187371.ref043">43</xref>], given three parents a, b and c in {0, 1}<sup>n</sup>, a random crossover mask of length <italic>n</italic> with symbols from the alphabet {a, b, c} is generated. The offspring filling each element with the bit from the parent appearing in the crossover mask at the position is then built. The detailed parameters of the GBPSO model are illustrated in <xref ref-type="table" rid="pone.0187371.t001">Table 1</xref>.</p>
<table-wrap id="pone.0187371.t001" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.t001</object-id>
<label>Table 1</label>
<caption>
<title>Detailed parameters of the GBPSO model.</title>
</caption>
<alternatives>
<graphic id="pone.0187371.t001g" xlink:href="pone.0187371.t001"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="1"></th>
<th align="left" colspan="1" rowspan="1">Individual weight</th>
<th align="left" colspan="1" rowspan="1">Inertia weight</th>
<th align="left" colspan="1" rowspan="1">Social weight</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>3PMBCX parameters</bold>
</td>
<td align="left" colspan="1" rowspan="1">0.34</td>
<td align="left" colspan="1" rowspan="1">0.33</td>
<td align="left" colspan="1" rowspan="1">0.33</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Mutation probability</bold>
</td>
<td align="left" colspan="3" rowspan="1">0.01</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>In the current work, GBPSO is used as a wrapper feature selection method with a support vector machine (SVM). The support vector machine (SVM) algorithm is used because it is able to provide reasonable classification accuracy for high-dimensional data despite the availability of limited training samples.</p>
<p>Support vector machines are a group of supervised machine-learning methods known as a support vector network; they were developed by Vapnik [<xref ref-type="bibr" rid="pone.0187371.ref064">64</xref>]. The forms of this algorithm are widely applied in a variety of real-world problem domains [<xref ref-type="bibr" rid="pone.0187371.ref018">18</xref>, <xref ref-type="bibr" rid="pone.0187371.ref036">36</xref>, <xref ref-type="bibr" rid="pone.0187371.ref063">63</xref>], especially for gene classification of diseases [<xref ref-type="bibr" rid="pone.0187371.ref065">65</xref>–<xref ref-type="bibr" rid="pone.0187371.ref067">67</xref>]. Furthermore, the LIBSVM algorithm, which is a type of software for SVM classification and regression, was utilized by Liu et al. [<xref ref-type="bibr" rid="pone.0187371.ref068">68</xref>] for effective identification of human pre-microRNAs and hence to discriminate real pre-miRNAs from false ones. Moreover, SVM can perform both linear and nonlinear separable data classification. In the linear case, the boundary of linear decision is performed such that the smallest distance between the training samples and the boundary (margin) is maximized. The training data samples near the class boundary and along the hyperplanes are known as support vectors [<xref ref-type="bibr" rid="pone.0187371.ref018">18</xref>]. Nonlinear data can be handled by SVM upon mapping the gene space of low dimensionality extracted from the input space into a gene space of high dimensionality to achieve efficient classification. A cost is involved to consider the wrongly classified examples if there are linearly inseparable mapped data points, while the margin is maximized along with minimization of the cost [<xref ref-type="bibr" rid="pone.0187371.ref066">66</xref>]. Another property of SVM is that the number of coefficients to be determined is essentially dependent on the number of samples rather than on the number of genes. This is a useful characteristic of SVM for microarray data due to the presence of a low ratio of samples to genes in this type of dataset. However, it has been shown that decreasing the number of genes increases SVM performance [<xref ref-type="bibr" rid="pone.0187371.ref036">36</xref>, <xref ref-type="bibr" rid="pone.0187371.ref069">69</xref>]. To utilize SVM as a classification algorithm in gene expression and sequence datasets, kernel functions are usually used. This allows the user to obtain an orthogonal hyperplane to distinguish the genes in a specific dimension. A number of research works have used SVM for gene selection or classification or both using different types of kernels [<xref ref-type="bibr" rid="pone.0187371.ref036">36</xref>, <xref ref-type="bibr" rid="pone.0187371.ref070">70</xref>, <xref ref-type="bibr" rid="pone.0187371.ref071">71</xref>]. This is because each type of kernel is suitable for different data. However, because it is not initially known which kernel is best for a specific set of data, it may be necessary to test multiple SVM types. Liu et al. [<xref ref-type="bibr" rid="pone.0187371.ref072">72</xref>] employed LIBSVM in a python package for DNA/RNA and protein/peptide sequence analysis based on pseudo components and kernel methods. In their studies, the kernel function of the radial basis function (RBF) was used to train the SVM classifier; in the current study, the polynomial kernel is applied owing to its higher classification accuracy for our dataset. Following further optimization of the kernel parameters, the identification of DNA-binding proteins by incorporating amino acid distance-pairs and reduced alphabet profile into the general pseudo amino acid composition upon a new predictor (iDNA-Prot|dis) outperformed the existing predictors for the same purpose [<xref ref-type="bibr" rid="pone.0187371.ref073">73</xref>]. Liu et al. also reported that each kernel contains different discriminative information and that combining the kernels automatically is, therefore, a promising way to improve the performance of the model. Consequently, the combination of sequence-based kernels with evolutionary information extracted from frequency profiles, in which three top-performing sequence-based kernels (SVM-Ngram, SVM-pairwise and SVM-LA) were combined with the profile-based protein representation, was proposed to predict protein remote homology [<xref ref-type="bibr" rid="pone.0187371.ref074">74</xref>]. In this study, SVM was applied using the polynomial kernel because this kernel method showed the highest classification accuracy.</p>
<p>The fitness function in GBPSO is used as an evaluator to select the best subsets of features, which are constructed based on the accuracy so far obtained by the SVM classifier. The particles having the best fitness values are recorded to maintain the optimal solution for a given population. This defines the best subset of genes and gives better accuracy. This is applied in 10-fold cross-validation such that the entire training set can be used in the process of finding the best genes. <xref ref-type="fig" rid="pone.0187371.g003">Fig 3</xref> shows the operation principle of the GBPSO-SVM method, in which the genes are expressed from the dataset and the best subset of genes is selected. The PSO particles are represented by vectors of bits, where each bit corresponds to a specific gene. A gene is retained in the subset if it holds an encode value of 1 and is not included in the subset if it holds an encode value of 0. Hence, the number of genes in the dataset determines the length of each particle.</p>
<fig id="pone.0187371.g003" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Application of GBPSO-SVM in gene selection.</title>
</caption>
<graphic xlink:href="pone.0187371.g003"></graphic>
</fig>
</sec>
</sec>
<sec id="sec008">
<title>Results and discussion</title>
<sec id="sec009">
<title>Dataset reduction</title>
<p>Despite the presence of a high-dimensional dataset from autistic individuals, most of the features appeared as outliers, indicating that the gene expression values in the observations are highly varied. It was noted that the gene expression values of both classes exhibited a high variance, as shown in <xref ref-type="fig" rid="pone.0187371.g004">Fig 4</xref>. The deviation of the expression value of a gene from its mean value is statistically explained in terms of variance. It is certainly true that not every single gene is responsible for autism disorder or can be used as a discriminative biomarker. Therefore, to identify the attributed genes, the genes with similar mean values in the two datasets, i.e., those with mean ratios close to unity, should be removed. However, this approach does not yield an accurate result if it is directly applied to the current dataset. This is because several genes show high variance among both classes. Consequently, the utilization of the mean ratio criterion alone to remove the genes unrelated to autism from the two classes does not provide a reliable result. It was reported that due to the high variance in the expression of genes related to autism, the median ratio can be considered as an alternative to the mean ratio for removing similar genes [<xref ref-type="bibr" rid="pone.0187371.ref070">70</xref>]. Again, using the median ratio only is not a reliable approach since genes with low variance will be negatively affected under this reduction process.</p>
<fig id="pone.0187371.g004" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Expression of a representative gene in samples from control and autistic individuals.</title>
</caption>
<graphic xlink:href="pone.0187371.g004"></graphic>
</fig>
<p>The absolute value of the difference between the mean and the median of the expression of individual genes was measured to determine the strength of outliers, as shown in Figs <xref ref-type="fig" rid="pone.0187371.g005">5</xref> and <xref ref-type="fig" rid="pone.0187371.g006">6</xref>. It was seen that this variation is larger in the autism group than in the control group, implying that there are some alterations in the gene expression values in the autistic group. Upon close inspection of the figures, it is clear that this variance is not associated with only one gene or with a small group of genes but with a wide range of genes. This can be regarded as another confirmation of the fact that autism is a spectrum disorder and that several genes may contribute to the occurrence of the disorder.</p>
<fig id="pone.0187371.g005" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Absolute values of the differences between the mean and median values of gene expression for the autism observations.</title>
</caption>
<graphic xlink:href="pone.0187371.g005"></graphic>
</fig>
<fig id="pone.0187371.g006" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Absolute values of the differences between the mean and median values of gene expression for the control observations.</title>
</caption>
<graphic xlink:href="pone.0187371.g006"></graphic>
</fig>
<p>It is seen that genes with high variance are more tolerated when the median ratio is applied, and vice versa. Therefore, to remove the most similar genes and to reduce the dataset, an alternative strategy was followed in this work. This strategy relied on the fact that genes with high variance in expression can be treated according to the median ratio criterion, whereas those with low variance can be treated according to the mean ratio criterion. In this way, among the genes that present variance of 15% and higher, the median ratio was applied to remove similar genes, and for genes with a variance of 15% or smaller the mean ratio was applied. Hence, genes with median ratios or mean ratios of 0.95 or greater were removed from both classes, as illustrated in <xref ref-type="fig" rid="pone.0187371.g007">Fig 7</xref>. Based on this removal process, the number of genes was reduced from 54,613 to 9454. The reduced dataset that was obtained at this stage is provided in the supplementary information as the <xref ref-type="supplementary-material" rid="pone.0187371.s001">S1 Dataset</xref>. It will be shown later that this reduction process improves the accuracy of the SVM classifier at threshold ratio of 0.95. In other studies [<xref ref-type="bibr" rid="pone.0187371.ref048">48</xref>, <xref ref-type="bibr" rid="pone.0187371.ref070">70</xref>], a mean or median ratio threshold of 0.96 was used separately to reduce the dataset to 17,831 or 16,230 genes. In yet another study, a mean ratio of 0.98 was applied as a threshold to reduce the dataset to 16,230 [<xref ref-type="bibr" rid="pone.0187371.ref032">32</xref>]. In comparison, our reduced dataset of 9454 genes could help improve classification accuracy and reduce memory complexity.</p>
<fig id="pone.0187371.g007" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Illustration of the discriminative regions and removal of similarly expressed genes from both classes of observations.</title>
</caption>
<graphic xlink:href="pone.0187371.g007"></graphic>
</fig>
</sec>
<sec id="sec010">
<title>First stage of selection</title>
<p>The reduced dataset resulting from the reduction step is not satisfactory for direct application in the classification process or as a basis for building the model since, with 9454 genes, its dimensionality is still high, and not all of the genes are discriminant. Hence, further reduction is conducted using the three filtering methods TT, COR and WRS in parallel to select the most discriminative genes. It was observed that each filtering method identifies different sets of genes with a specific repetition of the discriminative genes among them (see <xref ref-type="supplementary-material" rid="pone.0187371.s002">S2</xref>–<xref ref-type="supplementary-material" rid="pone.0187371.s004">S4</xref> Datasets). This is due to the high variance of several genes in the samples from individuals with autism disorder, indicating the necessity of using further selection steps. In this stage, the 200 most discriminative genes were selected based on their rank positions in descending order. <xref ref-type="table" rid="pone.0187371.t002">Table 2</xref> shows the percentage of similar genes that were selected by each method. The greatest similarity (93%) between the sets of 200 selected genes occurred between TT and COR, whereas WRS showed 69% similar genes with both TT and COR. It is noteworthy that the repetitive genes that appeared in the three filtered sets were not assigned the same ranking positions. The three discriminative genes that were assigned the highest rankings among 30 sets of filtered genes, i.e., within a 10-fold run for each filter, were ZSCAN18, CFC1B and CAPS2.</p>
<table-wrap id="pone.0187371.t002" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.t002</object-id>
<label>Table 2</label>
<caption>
<title>Similarity percentages for sets of 200 discriminative genes selected by various filtering methods.</title>
</caption>
<alternatives>
<graphic id="pone.0187371.t002g" xlink:href="pone.0187371.t002"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="1">Filtering method</th>
<th align="left" colspan="1" rowspan="1">TT</th>
<th align="left" colspan="1" rowspan="1">COR</th>
<th align="left" colspan="1" rowspan="1">WRS</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>TT</bold>
</td>
<td align="left" colspan="1" rowspan="1">100</td>
<td align="left" colspan="1" rowspan="1">93</td>
<td align="left" colspan="1" rowspan="1">69</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>COR</bold>
</td>
<td align="left" colspan="1" rowspan="1">93</td>
<td align="left" colspan="1" rowspan="1">100</td>
<td align="left" colspan="1" rowspan="1">69</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>WRS</bold>
</td>
<td align="left" colspan="1" rowspan="1">69</td>
<td align="left" colspan="1" rowspan="1">69</td>
<td align="left" colspan="1" rowspan="1">100</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>To determine the discriminative ability of the genes identified in the filtration process, three selected genes were examined using matrix scatter plots. Figs <xref ref-type="fig" rid="pone.0187371.g008">8</xref>–<xref ref-type="fig" rid="pone.0187371.g010">10</xref> show a qualitative assessment of the genes obtained from the initial reduced dataset (before using filters) and of the genes obtained using the TT and COR filters, respectively. The significant impact of the filtration process on the selection of attributed genes, in which the expression values of the autism-related genes are clustered apart from those of the non-autism-related genes, is readily apparent in Figs <xref ref-type="fig" rid="pone.0187371.g009">9</xref> and <xref ref-type="fig" rid="pone.0187371.g010">10</xref>. However, no such clustering occurs in the matrix plot of the genes extracted from the non-filtered dataset; in that plot, the expressed genes are uniformly distributed in the whole space without any pronounced clustering between the two classes of observation.</p>
<fig id="pone.0187371.g008" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Matrix plots for three representative selected genes from the reduced dataset before the application of filter methods.</title>
</caption>
<graphic xlink:href="pone.0187371.g008"></graphic>
</fig>
<fig id="pone.0187371.g009" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Matrix plots for three representative selected genes from the 200 genes filtered by the TT method.</title>
</caption>
<graphic xlink:href="pone.0187371.g009"></graphic>
</fig>
<fig id="pone.0187371.g010" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Matrix plots for three representative selected genes from the 200 genes filtered by the COR method.</title>
</caption>
<graphic xlink:href="pone.0187371.g010"></graphic>
</fig>
<p>Another method of estimating the impact of filtration on the selection of discriminative genes in autism disorder used an Andrews plot. Figs <xref ref-type="fig" rid="pone.0187371.g011">11</xref> and <xref ref-type="fig" rid="pone.0187371.g012">12</xref> show Andrews plots for three genes selected from the initial reduced dataset (before using filters) and the dataset obtained using the WRS filter, respectively. In <xref ref-type="fig" rid="pone.0187371.g011">Fig 11</xref>, the gene expression for the non-filtered dataset appears as a wide bundle with no distinguishable separation between the two classes. It is worth noting that the filtration process narrowed and aggregated the expression bundle of the filtered genes, as shown in <xref ref-type="fig" rid="pone.0187371.g012">Fig 12</xref>, in which the autistic class of genes is separable from the non-autistic class.</p>
<fig id="pone.0187371.g011" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Andrews plot for three representative selected genes from the reduced dataset before the application of filter methods.</title>
</caption>
<graphic xlink:href="pone.0187371.g011"></graphic>
</fig>
<fig id="pone.0187371.g012" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.g012</object-id>
<label>Fig 12</label>
<caption>
<title>Andrews plot for three representative selected genes from the 200 genes filtered by the WRS method.</title>
</caption>
<graphic xlink:href="pone.0187371.g012"></graphic>
</fig>
</sec>
<sec id="sec011">
<title>Classifier assignment</title>
<p>One of the most important tasks in conducting gene expression analysis using machine-learning algorithms is the building of a classification model that recognizes the discriminative genes with the highest possible accuracy. However, not every classifier works effectively on all datasets. For each dataset, a unique classifier or a limited number of classifiers typically work best. To explore this, the discriminative genes identified using different filtration methods were analyzed using six different classifiers, and the performance of each classifier was noted. <xref ref-type="table" rid="pone.0187371.t003">Table 3</xref> shows the accuracy of each classifier; of the tested classifiers, SVM had the highest accuracy.</p>
<table-wrap id="pone.0187371.t003" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.t003</object-id>
<label>Table 3</label>
<caption>
<title>Accuracy percentages of six different classifiers used after the first selection stage in 10-fold cross-validation.</title>
</caption>
<alternatives>
<graphic id="pone.0187371.t003g" xlink:href="pone.0187371.t003"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="1">Classifier</th>
<th align="left" colspan="1" rowspan="1">TT filter</th>
<th align="left" colspan="1" rowspan="1">COR filter</th>
<th align="left" colspan="1" rowspan="1">WRS filter</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Decision Tree</td>
<td align="char" char="." colspan="1" rowspan="1">62.9</td>
<td align="char" char="." colspan="1" rowspan="1">65.3</td>
<td align="char" char="." colspan="1" rowspan="1">57.3</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Discriminant Analysis</td>
<td align="char" char="." colspan="1" rowspan="1">75.0</td>
<td align="char" char="." colspan="1" rowspan="1">72.6</td>
<td align="char" char="." colspan="1" rowspan="1">74.2</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Logistic Regression</td>
<td align="char" char="." colspan="1" rowspan="1">46.8</td>
<td align="char" char="." colspan="1" rowspan="1">41.9</td>
<td align="char" char="." colspan="1" rowspan="1">52.4</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SVM</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>86.3</bold>
</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>81.8</bold>
</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>83.8</bold>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">K-Nearest Neighbor</td>
<td align="char" char="." colspan="1" rowspan="1">73.4</td>
<td align="char" char="." colspan="1" rowspan="1">74.2</td>
<td align="char" char="." colspan="1" rowspan="1">76.6</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Ensemble Bagged Trees</td>
<td align="char" char="." colspan="1" rowspan="1">71.0</td>
<td align="char" char="." colspan="1" rowspan="1">69.4</td>
<td align="char" char="." colspan="1" rowspan="1">69.4</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Based on the classification results, SVM was chosen as the ultimate classifier to be combined with the GBPSO algorithm in wrapper form to perform the final stage of the gene selection and classification process, as will be discussed later. Further analysis was also conducted to elucidate the impact of dataset reduction on the accuracy of the SVM classifier. The details of this analysis are provided in <xref ref-type="table" rid="pone.0187371.t004">Table 4</xref>. It was observed that the utilization of a combined mean and median ratio as a reduction criterion to remove the most similar genes results in remarkable improvement in the classifier accuracy. Furthermore, this combination was found to outperform the results obtained using the mean ratio or the median ratio alone. Using this method, the initial selection results showed better classification accuracy and less computational complexity, and the dimensionality of the dataset was reduced from 54,613 genes to 9454 genes. As such, the best classification accuracy of the SVM for the TT filtered genes in this stage was found to be 86.3%, higher than the values previously reported (of about 86.1% and 78.4%) for fused genes of eight filter methods [<xref ref-type="bibr" rid="pone.0187371.ref032">32</xref>, <xref ref-type="bibr" rid="pone.0187371.ref048">48</xref>]. The improvement in the accuracy of the SVM classifier is attributed to the impact of the threshold value of mean and median ratio that is defined and used to remove the most similar genes.</p>
<table-wrap id="pone.0187371.t004" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.t004</object-id>
<label>Table 4</label>
<caption>
<title>Accuracy percentage of the SVM classifier at different stages of removal of similar genes and applied filtration results for 200 discriminative genes.</title>
</caption>
<alternatives>
<graphic id="pone.0187371.t004g" xlink:href="pone.0187371.t004"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" colspan="1" rowspan="1">Reduction criterion</th>
<th align="left" colspan="1" rowspan="1">Genes, #</th>
<th align="left" colspan="1" rowspan="1">TT filter</th>
<th align="left" colspan="1" rowspan="1">COR filter</th>
<th align="left" colspan="1" rowspan="1">WRS filter</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Without reduction</td>
<td align="left" colspan="1" rowspan="1">54,613</td>
<td align="char" char="." colspan="1" rowspan="1">72.7</td>
<td align="char" char="." colspan="1" rowspan="1">75.0</td>
<td align="char" char="." colspan="1" rowspan="1">68.2</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mean &amp; Median ratio 0.99</td>
<td align="left" colspan="1" rowspan="1">37,125</td>
<td align="char" char="." colspan="1" rowspan="1">72.7</td>
<td align="char" char="." colspan="1" rowspan="1">75.0</td>
<td align="char" char="." colspan="1" rowspan="1">68.2</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mean &amp; Median ratio 0.98</td>
<td align="left" colspan="1" rowspan="1">26,644</td>
<td align="char" char="." colspan="1" rowspan="1">72.7</td>
<td align="char" char="." colspan="1" rowspan="1">75.0</td>
<td align="char" char="." colspan="1" rowspan="1">68.2</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mean &amp; Median ratio 0.97</td>
<td align="left" colspan="1" rowspan="1">18,975</td>
<td align="char" char="." colspan="1" rowspan="1">75.0</td>
<td align="char" char="." colspan="1" rowspan="1">75.0</td>
<td align="char" char="." colspan="1" rowspan="1">70.5</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mean &amp; Median ratio 0.96</td>
<td align="left" colspan="1" rowspan="1">13,470</td>
<td align="char" char="." colspan="1" rowspan="1">77.3</td>
<td align="char" char="." colspan="1" rowspan="1">75.0</td>
<td align="char" char="." colspan="1" rowspan="1">77.7</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mean &amp; Median ratio 0.95</td>
<td align="left" colspan="1" rowspan="1">
<bold>9454</bold>
</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>86.3</bold>
</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>81.8</bold>
</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>83.8</bold>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mean &amp; Median ratio 0.94</td>
<td align="left" colspan="1" rowspan="1">6655</td>
<td align="char" char="." colspan="1" rowspan="1">80.4</td>
<td align="char" char="." colspan="1" rowspan="1">78.5</td>
<td align="char" char="." colspan="1" rowspan="1">82.5</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mean &amp; Median ratio 0.93</td>
<td align="left" colspan="1" rowspan="1">4606</td>
<td align="char" char="." colspan="1" rowspan="1">76.4</td>
<td align="char" char="." colspan="1" rowspan="1">75.4</td>
<td align="char" char="." colspan="1" rowspan="1">75.4</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mean &amp; Median ratio 0.92</td>
<td align="left" colspan="1" rowspan="1">3231</td>
<td align="char" char="." colspan="1" rowspan="1">73.5</td>
<td align="char" char="." colspan="1" rowspan="1">74.5</td>
<td align="char" char="." colspan="1" rowspan="1">73.5</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mean &amp; Median ratio 0.91</td>
<td align="left" colspan="1" rowspan="1">2165</td>
<td align="char" char="." colspan="1" rowspan="1">69.6</td>
<td align="char" char="." colspan="1" rowspan="1">70.5</td>
<td align="char" char="." colspan="1" rowspan="1">70.6</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mean &amp; Median ratio 0.90</td>
<td align="left" colspan="1" rowspan="1">1490</td>
<td align="char" char="." colspan="1" rowspan="1">72.5</td>
<td align="char" char="." colspan="1" rowspan="1">69.6</td>
<td align="char" char="." colspan="1" rowspan="1">71.5</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mean ratio 0.95</td>
<td align="left" colspan="1" rowspan="1">13,324</td>
<td align="char" char="." colspan="1" rowspan="1">75.0</td>
<td align="char" char="." colspan="1" rowspan="1">77.3</td>
<td align="char" char="." colspan="1" rowspan="1">72.7</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Median ratio 0.95</td>
<td align="left" colspan="1" rowspan="1">14,440</td>
<td align="char" char="." colspan="1" rowspan="1">77.3</td>
<td align="char" char="." colspan="1" rowspan="1">77.3</td>
<td align="char" char="." colspan="1" rowspan="1">75.0</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec012">
<title>Final stage of selection and classification</title>
<p>The last step of gene selection was conducted using the GBPSO optimization algorithm wrapped with the SVM classifier; in this step, those particles (gene subsets) having the best values of fitness were recorded to maintain a better solution at given population. As such, the best subset of genes that provided the highest classification accuracy was identified and returned. <xref ref-type="table" rid="pone.0187371.t005">Table 5</xref> shows the classification accuracy (10-fold cross-validation) as well as the prediction accuracy for the new dataset using the model. Gene subsets #1, #2 and #3 correspond to the sets of discriminative genes that were identified using the TT, COR and WRS filters, respectively (see <xref ref-type="supplementary-material" rid="pone.0187371.s005">S5</xref>–<xref ref-type="supplementary-material" rid="pone.0187371.s007">S7</xref> Datasets). It is worth noting that the merged form of these subsets (the <xref ref-type="supplementary-material" rid="pone.0187371.s008">S8 Dataset</xref>) produced the highest classification accuracy of 92.1%, which is higher than previously reported classification accuracies [<xref ref-type="bibr" rid="pone.0187371.ref032">32</xref>, <xref ref-type="bibr" rid="pone.0187371.ref048">48</xref>, <xref ref-type="bibr" rid="pone.0187371.ref070">70</xref>]. The inclusion of the genes in each GBPSO-SVM branch and in the fused set was based on the number of times that gene was repeated in the 10-fold selection. Genes with repeatability of less than 7-fold were not included in the sets. The improvement in classification accuracy may be due to the effect of stepwise selection procedures that were followed during the pre-selection operations as well as the incorporation of a relatively high number of filtered genes (200 genes) at the final stage of selection by the GBPSO-SVM algorithm. In previous studies [<xref ref-type="bibr" rid="pone.0187371.ref075">75</xref>], superior performance of PSO over GA in terms of accuracy was reported. To determine the real difference between the time taken by GA and GBPSO, in this study GA was tested against GBPSO. It was observed that the time required for feature selection by the GBPSO method is one-third of that required by the GA method. Moreover, GBPSO involves fewer steps and requires less memory to perform feature selection. The ten most frequent repetitive and/or similar genes in the 10-fold selection among the three achieved subsets were FKBP4, RHPN2, SEMA6B, ZNF230, LARS, LOC283075, CAPS2, ANKUB1, B3GNT7, and CASP2. A comparison between the most discriminative genes that were chosen during the initial and last selection steps identified a common gene, CAPS2. Therefore, it might be possible for us to assign this gene as one of the most important ASD risk genes. It was reported that the Ca<sup>2+</sup>-dependent activator protein for the CAPS family of secretory proteins regulates neuropeptide-containing dense-core vesicles (DCVs) at sites of secretion such as nerve terminals [<xref ref-type="bibr" rid="pone.0187371.ref076">76</xref>]. It was also claimed that genes associated with autism are responsible for Ca<sup>2+</sup> regulation in brain membranes, and CAPS2 is one of the genes that contribute to the regulation of Ca<sup>2+</sup> levels [<xref ref-type="bibr" rid="pone.0187371.ref077">77</xref>]. Consistent with our observations, a recent study showed that CAPS2 may be a risk factor for autism [<xref ref-type="bibr" rid="pone.0187371.ref078">78</xref>].</p>
<table-wrap id="pone.0187371.t005" orientation="portrait" position="float">
<object-id pub-id-type="doi">10.1371/journal.pone.0187371.t005</object-id>
<label>Table 5</label>
<caption>
<title>Accuracy percentage of the SVM classifier at the final stage of gene selection by the GBPSO-SVM algorithm in 10-fold cross-validation and the accuracy of the new dataset in terms of the model.</title>
</caption>
<alternatives>
<graphic id="pone.0187371.t005g" xlink:href="pone.0187371.t005"></graphic>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
<col align="left" span="1" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center" colspan="1" rowspan="2">Dataset</th>
<th align="center" colspan="4" rowspan="1">Classification accuracy, %</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">Gene subset #1</th>
<th align="left" colspan="1" rowspan="1">Gene subset #2</th>
<th align="left" colspan="1" rowspan="1">Gene subset #3</th>
<th align="left" colspan="1" rowspan="1">Merged set</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Validation/testing set</td>
<td align="char" char="." colspan="1" rowspan="1">91.1</td>
<td align="char" char="." colspan="1" rowspan="1">89.5</td>
<td align="char" char="." colspan="1" rowspan="1">87.3</td>
<td align="char" char="." colspan="1" rowspan="1">
<bold>92.1</bold>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Non-involved set</td>
<td align="char" char="." colspan="1" rowspan="1">83.2</td>
<td align="char" char="." colspan="1" rowspan="1">80.1</td>
<td align="char" char="." colspan="1" rowspan="1">82.5</td>
<td align="char" char="." colspan="1" rowspan="1">84.7</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
</sec>
<sec id="sec013" sec-type="conclusions">
<title>Conclusions</title>
<p>The gene expression values of autism spectrum disorder (ASD) were successfully analyzed with the goal of improving the selection and classification process. This was accomplished using a combination of statistical filters and a wrapper-based GBPSO-SVM algorithm. It was noted that the expression of genes potentially associated with ASD varies greatly among the observations; hence, the utilization of the mean ratio criterion alone to remove similar genes does not provide a reliable result. Instead, both the mean and median ratio should be utilized simultaneously. It was shown that the pre-reduction process improves the accuracy of the SVM classifier. The results showed that each filter method identifies different sets of genes with a specific repetition of the discriminative genes among them. This is due to the high variance of several genes in autism disorder and necessitates the use of additional selection steps. During the filtration stage, the three most discriminative genes that received the highest repetition ranking among 30 sets of filtered genes were found to be ZSCAN18, CFC1B and CAPS2, whereas after further gene selection using GBPSO-SVM, a set of ten genes, namely FKBP4, RHPN2, SEMA6B, ZNF230, LARS, LOC283075, CAPS2, ANKUB1, B3GNT7, and CASP2, was selected. A comparison of the most discriminative genes identified during the initial and final selection steps pointed to the existence of a common gene (CAPS2), which was designated as the gene that showed the greatest association with ASD risk. The merged forms of the gene subsets that were selected by the GBPSO-SVM wrapper produced an improved classification accuracy of 92.1%, higher than those reported previously, in spite of its improved efficiency. This enhancement was attributed to the effect of using GBPSO-SVM as an accurate and fast algorithm.</p>
</sec>
<sec id="sec014" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material content-type="local-data" id="pone.0187371.s001">
<label>S1 Dataset</label>
<caption>
<title>The reduced dataset.</title>
<p>The dataset contains 146 observations and 9454 genes.</p>
<p>(CSV)</p>
</caption>
<media xlink:href="pone.0187371.s001.csv">
<caption>
<p>Click here for additional data file.</p>
</caption>
</media>
</supplementary-material>
<supplementary-material content-type="local-data" id="pone.0187371.s002">
<label>S2 Dataset</label>
<caption>
<title>The dataset selected by the TT filter.</title>
<p>This dataset contains 124 observations and 200 genes.</p>
<p>(CSV)</p>
</caption>
<media xlink:href="pone.0187371.s002.csv">
<caption>
<p>Click here for additional data file.</p>
</caption>
</media>
</supplementary-material>
<supplementary-material content-type="local-data" id="pone.0187371.s003">
<label>S3 Dataset</label>
<caption>
<title>The dataset selected by the COR filter.</title>
<p>This dataset contains 124 observations and 200 genes.</p>
<p>(CSV)</p>
</caption>
<media xlink:href="pone.0187371.s003.csv">
<caption>
<p>Click here for additional data file.</p>
</caption>
</media>
</supplementary-material>
<supplementary-material content-type="local-data" id="pone.0187371.s004">
<label>S4 Dataset</label>
<caption>
<title>The dataset selected by the WRS filter.</title>
<p>This dataset contains 124 observations and 200 genes.</p>
<p>(CSV)</p>
</caption>
<media xlink:href="pone.0187371.s004.csv">
<caption>
<p>Click here for additional data file.</p>
</caption>
</media>
</supplementary-material>
<supplementary-material content-type="local-data" id="pone.0187371.s005">
<label>S5 Dataset</label>
<caption>
<title>The first dataset selected by GBPSO-SVM.</title>
<p>This dataset was derived from the dataset selected by the TT filter. It contains 124 observations and 48 genes.</p>
<p>(CSV)</p>
</caption>
<media xlink:href="pone.0187371.s005.csv">
<caption>
<p>Click here for additional data file.</p>
</caption>
</media>
</supplementary-material>
<supplementary-material content-type="local-data" id="pone.0187371.s006">
<label>S6 Dataset</label>
<caption>
<title>The second dataset selected by GBPSO-SVM.</title>
<p>This dataset was derived from the dataset selected by the COR filter. It contains 124 observations and 46 genes.</p>
<p>(CSV)</p>
</caption>
<media xlink:href="pone.0187371.s006.csv">
<caption>
<p>Click here for additional data file.</p>
</caption>
</media>
</supplementary-material>
<supplementary-material content-type="local-data" id="pone.0187371.s007">
<label>S7 Dataset</label>
<caption>
<title>The third dataset selected by GBPSO-SVM.</title>
<p>This dataset was derived from the dataset selected by the WRS filter. It contains 124 observations and 37 genes.</p>
<p>(CSV)</p>
</caption>
<media xlink:href="pone.0187371.s007.csv">
<caption>
<p>Click here for additional data file.</p>
</caption>
</media>
</supplementary-material>
<supplementary-material content-type="local-data" id="pone.0187371.s008">
<label>S8 Dataset</label>
<caption>
<title>The merged set of the datasets selected by GBPSO-SVM.</title>
<p>The merged set was generated by fusing the three datasets selected by GBPSO-SVM. It contains 124 observations and 101 genes.</p>
<p>(CSV)</p>
</caption>
<media xlink:href="pone.0187371.s008.csv">
<caption>
<p>Click here for additional data file.</p>
</caption>
</media>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>The authors are grateful to the Department of Computer Science and Software Engineering of the Universiti Teknologi Malaysia for their administrative support. The authors would also like to express their deepest gratitude for the financial support received under the UTM Research University Grant Scheme (Vot number 11H84).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pone.0187371.ref001">
<label>1</label>
<mixed-citation publication-type="journal"><name><surname>Wing</surname><given-names>L</given-names></name>. <article-title>Autistic spectrum disorders</article-title>. <source/>BMJ: British Medical Journal. <year>1996</year>;<volume>312</volume>(<issue>7027</issue>):<fpage>327</fpage>
<pub-id pub-id-type="pmid">8611819</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref002">
<label>2</label>
<mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>IF</given-names></name>, <name><surname>Yamada</surname><given-names>T</given-names></name>, <name><surname>Komine</surname><given-names>Y</given-names></name>, <name><surname>Kato</surname><given-names>N</given-names></name>, <name><surname>Kato</surname><given-names>M</given-names></name>, <name><surname>Kashino</surname><given-names>M</given-names></name>. <article-title>Vocal Identity Recognition in Autism Spectrum Disorder</article-title>. <source/>PLOS ONE. <year>2015</year>;<volume>10</volume>(<issue>6</issue>):<fpage>e0129451</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0129451">10.1371/journal.pone.0129451</ext-link></comment>
<pub-id pub-id-type="pmid">26070199</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref003">
<label>3</label>
<mixed-citation publication-type="journal"><name><surname>De Rubeis</surname><given-names>S</given-names></name>, <name><surname>Buxbaum</surname><given-names>JD</given-names></name>. <article-title>Recent advances in the genetics of autism spectrum disorder</article-title>. <source/>Current neurology and neuroscience reports. <year>2015</year>;<volume>15</volume>(<issue>6</issue>):<fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref004">
<label>4</label>
<mixed-citation publication-type="journal"><name><surname>Thurm</surname><given-names>A</given-names></name>, <name><surname>Swedo</surname><given-names>SE</given-names></name>. <article-title>The importance of autism research</article-title>. <source/>Dialogues on Clinical Neurosciences. <year>2012</year>;<volume>14</volume>(<issue>3</issue>):<fpage>219</fpage>–<lpage>22</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref005">
<label>5</label>
<mixed-citation publication-type="journal"><name><surname>Taniai</surname><given-names>H</given-names></name>, <name><surname>Nishiyama</surname><given-names>T</given-names></name>, <name><surname>Miyachi</surname><given-names>T</given-names></name>, <name><surname>Imaeda</surname><given-names>M</given-names></name>, <name><surname>Sumi</surname><given-names>S</given-names></name>. <article-title>Genetic influences on the broad spectrum of autism: Study of proband‐ascertained twins</article-title>. <source/>American Journal of Medical Genetics Part B: Neuropsychiatric Genetics. <year>2008</year>;<volume>147</volume>(<issue>6</issue>):<fpage>844</fpage>–<lpage>9</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref006">
<label>6</label>
<mixed-citation publication-type="journal"><name><surname>Yoo</surname><given-names>H</given-names></name>. <article-title>Genetics of autism spectrum disorder: current status and possible clinical applications</article-title>. <source/>Experimental neurobiology. <year>2015</year>;<volume>24</volume>(<issue>4</issue>):<fpage>257</fpage>–<lpage>72</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5607/en.2015.24.4.257">10.5607/en.2015.24.4.257</ext-link></comment>
<pub-id pub-id-type="pmid">26713075</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref007">
<label>7</label>
<mixed-citation publication-type="journal"><name><surname>Alarcón</surname><given-names>M</given-names></name>, <name><surname>Abrahams</surname><given-names>BS</given-names></name>, <name><surname>Stone</surname><given-names>JL</given-names></name>, <name><surname>Duvall</surname><given-names>JA</given-names></name>, <name><surname>Perederiy</surname><given-names>JV</given-names></name>, <name><surname>Bomar</surname><given-names>JM</given-names></name>, <etal>et al</etal>
<article-title>Linkage, association, and gene-expression analyses identify CNTNAP2 as an autism-susceptibility gene</article-title>. <source/>The American Journal of Human Genetics. <year>2008</year>;<volume>82</volume>(<issue>1</issue>):<fpage>150</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.ajhg.2007.09.005">10.1016/j.ajhg.2007.09.005</ext-link></comment>
<pub-id pub-id-type="pmid">18179893</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref008">
<label>8</label>
<mixed-citation publication-type="journal"><name><surname>Purcell</surname><given-names>A</given-names></name>, <name><surname>Jeon</surname><given-names>O</given-names></name>, <name><surname>Zimmerman</surname><given-names>A</given-names></name>, <name><surname>Blue</surname><given-names>M</given-names></name>, <name><surname>Pevsner</surname><given-names>J</given-names></name>. <article-title>Postmortem brain abnormalities of the glutamate neurotransmitter system in autism</article-title>. <source/>Neurology. <year>2001</year>;<volume>57</volume>(<issue>9</issue>):<fpage>1618</fpage>–<lpage>28</lpage>. <pub-id pub-id-type="pmid">11706102</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref009">
<label>9</label>
<mixed-citation publication-type="journal"><name><surname>Gregg</surname><given-names>JP</given-names></name>, <name><surname>Lit</surname><given-names>L</given-names></name>, <name><surname>Baron</surname><given-names>CA</given-names></name>, <name><surname>Hertz-Picciotto</surname><given-names>I</given-names></name>, <name><surname>Walker</surname><given-names>W</given-names></name>, <name><surname>Davis</surname><given-names>RA</given-names></name>, <etal>et al</etal>
<article-title>Gene expression changes in children with autism</article-title>. <source/>Genomics. <year>2008</year>;<volume>91</volume>(<issue>1</issue>):<fpage>22</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.ygeno.2007.09.003">10.1016/j.ygeno.2007.09.003</ext-link></comment>
<pub-id pub-id-type="pmid">18006270</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref010">
<label>10</label>
<mixed-citation publication-type="journal"><name><surname>de Menezes</surname><given-names>RX</given-names></name>, <name><surname>Boer</surname><given-names>JM</given-names></name>, <name><surname>van Houwelingen</surname><given-names>HC</given-names></name>. <article-title>Microarray Data Analysis</article-title>. <source/>Applied Bioinformatics. <year>2004</year>;<volume>3</volume>(<issue>4</issue>):<fpage>229</fpage>–<lpage>35</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.2165/00822942-200403040-00004">10.2165/00822942-200403040-00004</ext-link></comment>
<pub-id pub-id-type="pmid">15702953</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref011">
<label>11</label>
<mixed-citation publication-type="journal"><name><surname>Govindarajan</surname><given-names>R</given-names></name>, <name><surname>Duraiyan</surname><given-names>J</given-names></name>, <name><surname>Kaliyappan</surname><given-names>K</given-names></name>, <name><surname>Palanisamy</surname><given-names>M</given-names></name>. <article-title>Microarray and its applications</article-title>. <source/>Journal of Pharmacy &amp; Bioallied Sciences. <year>2012</year>;<volume>4</volume>(<issue>Suppl 2</issue>):<fpage>S310</fpage>–<lpage>S2</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.4103/0975-7406.100283">10.4103/0975-7406.100283</ext-link></comment>
<pub-id pub-id-type="pmid">23066278</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref012">
<label>12</label>
<mixed-citation publication-type="journal"><name><surname>Leung</surname><given-names>MK</given-names></name>, <name><surname>Delong</surname><given-names>A</given-names></name>, <name><surname>Alipanahi</surname><given-names>B</given-names></name>, <name><surname>Frey</surname><given-names>BJ</given-names></name>. <article-title>Machine Learning in Genomic Medicine: A Review of Computational Problems and Data Sets</article-title>. <source/>Proceedings of the IEEE. <year>2016</year>;<volume>104</volume>(<issue>1</issue>):<fpage>176</fpage>–<lpage>97</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref013">
<label>13</label>
<mixed-citation publication-type="journal"><name><surname>Libbrecht</surname><given-names>MW</given-names></name>, <name><surname>Noble</surname><given-names>WS</given-names></name>. <article-title>Machine learning applications in genetics and genomics</article-title>. <source/>Nature Reviews Genetics. <year>2015</year>;<volume>16</volume>(<issue>6</issue>):<fpage>321</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrg3920">10.1038/nrg3920</ext-link></comment>
<pub-id pub-id-type="pmid">25948244</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref014">
<label>14</label>
<mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>B</given-names></name>, <name><surname>Liu</surname><given-names>F</given-names></name>, <name><surname>Fang</surname><given-names>L</given-names></name>, <name><surname>Wang</surname><given-names>X</given-names></name>, <name><surname>Chou</surname><given-names>K-C</given-names></name>. <article-title>repDNA: a Python package to generate various modes of feature vectors for DNA sequences by incorporating user-defined physicochemical properties and sequence-order effects</article-title>. <source/>Bioinformatics. <year>2014</year>;<volume>31</volume>(<issue>8</issue>):<fpage>1307</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btu820">10.1093/bioinformatics/btu820</ext-link></comment>
<pub-id pub-id-type="pmid">25504848</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref015">
<label>15</label>
<mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>B</given-names></name>, <name><surname>Liu</surname><given-names>F</given-names></name>, <name><surname>Fang</surname><given-names>L</given-names></name>, <name><surname>Wang</surname><given-names>X</given-names></name>, <name><surname>Chou</surname><given-names>K-C</given-names></name>. <article-title>repRNA: a web server for generating various feature vectors of RNA sequences</article-title>. <source/>Molecular Genetics and Genomics. <year>2016</year>;<volume>291</volume>(<issue>1</issue>):<fpage>473</fpage>–<lpage>81</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00438-015-1078-7">10.1007/s00438-015-1078-7</ext-link></comment>
<pub-id pub-id-type="pmid">26085220</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref016">
<label>16</label>
<mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>B</given-names></name>, <name><surname>Liu</surname><given-names>F</given-names></name>, <name><surname>Wang</surname><given-names>X</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Fang</surname><given-names>L</given-names></name>, <name><surname>Chou</surname><given-names>K-C</given-names></name>. <article-title>Pse-in-One: a web server for generating various modes of pseudo components of DNA, RNA, and protein sequences</article-title>. <source/>Nucleic acids research. <year>2015</year>;<volume>43</volume>(<issue>W1</issue>):<fpage>W65</fpage>–<lpage>W71</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkv458">10.1093/nar/gkv458</ext-link></comment>
<pub-id pub-id-type="pmid">25958395</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref017">
<label>17</label>
<mixed-citation publication-type="journal"><name><surname>Annavarapu</surname><given-names>Chandra Sekhara Rao</given-names></name>
<name><surname>D</surname><given-names>S</given-names></name>, <name><surname>Banka</surname><given-names>H</given-names></name>. <article-title>Cancer microarray data feature selection using multi-objective binary particle swarm optimization algorithm</article-title>. <source/>EXCLI journal. <year>2016</year>;<volume>15</volume>:<fpage>460</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17179/excli2016-481">10.17179/excli2016-481</ext-link></comment>
<pub-id pub-id-type="pmid">27822174</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref018">
<label>18</label>
<mixed-citation publication-type="other">Rejani Y, Selvi ST. Early detection of breast cancer using SVM classifier technique. arXiv preprint arXiv:09122314. 2009.</mixed-citation>
</ref>
<ref id="pone.0187371.ref019">
<label>19</label>
<mixed-citation publication-type="journal"><name><surname>Guyon</surname><given-names>I</given-names></name>, <name><surname>Weston</surname><given-names>J</given-names></name>, <name><surname>Barnhill</surname><given-names>S</given-names></name>, <name><surname>Vapnik</surname><given-names>V</given-names></name>. <article-title>Gene Selection for Cancer Classification using Support Vector Machines</article-title>. <source/>Machine Learning. <year>2002</year>;<volume>46</volume>(<issue>1</issue>):<fpage>389</fpage>–<lpage>422</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1023/A:1012487302797">10.1023/A:1012487302797</ext-link></comment></mixed-citation>
</ref>
<ref id="pone.0187371.ref020">
<label>20</label>
<mixed-citation publication-type="journal"><name><surname>Hu</surname><given-names>VW</given-names></name>, <name><surname>Sarachana</surname><given-names>T</given-names></name>, <name><surname>Kim</surname><given-names>KS</given-names></name>, <name><surname>Nguyen</surname><given-names>A</given-names></name>, <name><surname>Kulkarni</surname><given-names>S</given-names></name>, <name><surname>Steinberg</surname><given-names>ME</given-names></name>, <etal>et al</etal>
<article-title>Gene expression profiling differentiates autism case–controls and phenotypic variants of autism spectrum disorders: Evidence for circadian rhythm dysfunction in severe autism</article-title>. <source/>Autism research. <year>2009</year>;<volume>2</volume>(<issue>2</issue>):<fpage>78</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/aur.73">10.1002/aur.73</ext-link></comment>
<pub-id pub-id-type="pmid">19418574</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref021">
<label>21</label>
<mixed-citation publication-type="journal"><name><surname>Hira</surname><given-names>ZM</given-names></name>, <name><surname>Gillies</surname><given-names>DF</given-names></name>. <article-title>A review of feature selection and feature extraction methods applied on microarray data</article-title>. <source/>Advances in bioinformatics. <year>2015</year>;<volume>2015</volume>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref022">
<label>22</label>
<mixed-citation publication-type="book"><name><surname>Han</surname><given-names>J</given-names></name>, <name><surname>Pei</surname><given-names>J</given-names></name>, <name><surname>Kamber</surname><given-names>M</given-names></name>. <source/>Data mining: concepts and techniques: <publisher-name>Elsevier</publisher-name>; <year>2011</year>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref023">
<label>23</label>
<mixed-citation publication-type="journal"><name><surname>Zhu</surname><given-names>L</given-names></name>, <name><surname>Zhang</surname><given-names>H</given-names></name>, <name><surname>Huang</surname><given-names>D-S</given-names></name>. <article-title>LMMO: A Large Margin Approach for Refining Regulatory Motifs</article-title>. <source/>IEEE/ACM Transactions on Computational Biology and Bioinformatics. <year>2017</year>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref024">
<label>24</label>
<mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>H</given-names></name>, <name><surname>Zhu</surname><given-names>L</given-names></name>, <name><surname>Huang</surname><given-names>D-S</given-names></name>. <article-title>DiscMLA: an efficient discriminative motif learning algorithm over high-throughput datasets</article-title>. <source/>IEEE/ACM transactions on computational biology and bioinformatics. <year>2016</year>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref025">
<label>25</label>
<mixed-citation publication-type="journal"><name><surname>Singh</surname><given-names>RK</given-names></name>, <name><surname>Sivabalakrishnan</surname><given-names>M</given-names></name>. <article-title>Feature selection of gene expression data for cancer classification: a review</article-title>. <source/>Procedia Computer Science. <year>2015</year>;<volume>50</volume>:<fpage>52</fpage>–<lpage>7</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref026">
<label>26</label>
<mixed-citation publication-type="journal"><name><surname>Saeys</surname><given-names>Y</given-names></name>, <name><surname>Inza</surname><given-names>I</given-names></name>, <name><surname>Larrañaga</surname><given-names>P</given-names></name>. <article-title>A review of feature selection techniques in bioinformatics</article-title>. <source/>bioinformatics. <year>2007</year>;<volume>23</volume>(<issue>19</issue>):<fpage>2507</fpage>–<lpage>17</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btm344">10.1093/bioinformatics/btm344</ext-link></comment>
<pub-id pub-id-type="pmid">17720704</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref027">
<label>27</label>
<mixed-citation publication-type="journal"><name><surname>Bolón-Canedo</surname><given-names>V</given-names></name>, <name><surname>Sánchez-Marono</surname><given-names>N</given-names></name>, <name><surname>Alonso-Betanzos</surname><given-names>A</given-names></name>, <name><surname>Benítez</surname><given-names>JM</given-names></name>, <name><surname>Herrera</surname><given-names>F</given-names></name>. <article-title>A review of microarray datasets and applied feature selection methods</article-title>. <source/>Information Sciences. <year>2014</year>;<volume>282</volume>:<fpage>111</fpage>–<lpage>35</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref028">
<label>28</label>
<mixed-citation publication-type="journal"><name><surname>Gnana</surname><given-names>DAA</given-names></name>, <name><surname>Appavu</surname><given-names>S</given-names></name>, <name><surname>Leavline</surname><given-names>EJ</given-names></name>. <article-title>Literature Review on Feature Selection Methods for High-Dimensional Data</article-title>. <source/>methods. <year>2016</year>;<volume>136</volume>(<issue>1</issue>).</mixed-citation>
</ref>
<ref id="pone.0187371.ref029">
<label>29</label>
<mixed-citation publication-type="other">Das S, editor Filters, wrappers and a boosting-based hybrid for feature selection. ICML; 2001: Citeseer.</mixed-citation>
</ref>
<ref id="pone.0187371.ref030">
<label>30</label>
<mixed-citation publication-type="book"><name><surname>Cateni</surname><given-names>S</given-names></name>, <name><surname>Vannucci</surname><given-names>M</given-names></name>, <name><surname>Vannocci</surname><given-names>M</given-names></name>, <name><surname>Colla</surname><given-names>V</given-names></name>. <chapter-title>Variable Selection and Feature Extraction Through Artificial Intelligence Techniques</chapter-title> In: <name><surname>Freitas</surname><given-names>LVd</given-names></name>, <name><surname>Freitas</surname><given-names>APBRd</given-names></name>, editors. <source/>Multivariate Analysis in Management, Engineering and the Sciences. <publisher-loc>Rijeka</publisher-loc>: <publisher-name>InTech</publisher-name>; <year>2013</year>. p. Ch. 06.</mixed-citation>
</ref>
<ref id="pone.0187371.ref031">
<label>31</label>
<mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>L-F</given-names></name>, <name><surname>Su</surname><given-names>C-T</given-names></name>, <name><surname>Chen</surname><given-names>K-H</given-names></name>, <name><surname>Wang</surname><given-names>P-C</given-names></name>. <article-title>Particle swarm optimization for feature selection with application in obstructive sleep apnea diagnosis</article-title>. <source/>Neural Computing and Applications. <year>2012</year>;<volume>21</volume>(<issue>8</issue>):<fpage>2087</fpage>–<lpage>96</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref032">
<label>32</label>
<mixed-citation publication-type="journal"><name><surname>Latkowski</surname><given-names>T</given-names></name>, <name><surname>Osowski</surname><given-names>S</given-names></name>. <article-title>Data mining for feature selection in gene expression autism data</article-title>. <source/>Expert Systems with Applications. <year>2015</year>;<volume>42</volume>(<issue>2</issue>):<fpage>864</fpage>–<lpage>72</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref033">
<label>33</label>
<mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>Y</given-names></name>, <name><surname>Miao</surname><given-names>D</given-names></name>, <name><surname>Wang</surname><given-names>R</given-names></name>. <article-title>A rough set approach to feature selection based on ant colony optimization</article-title>. <source/>Pattern Recognition Letters. <year>2010</year>;<volume>31</volume>(<issue>3</issue>):<fpage>226</fpage>–<lpage>33</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref034">
<label>34</label>
<mixed-citation publication-type="other">González F, Belanche LA. Feature selection for microarray gene expression data using simulated annealing guided by the multivariate joint entropy. arXiv preprint arXiv:13021733. 2013.</mixed-citation>
</ref>
<ref id="pone.0187371.ref035">
<label>35</label>
<mixed-citation publication-type="other">Tran B, Xue B, Zhang M, editors. Improved PSO for feature selection on high-dimensional datasets. Asia-Pacific Conference on Simulated Evolution and Learning; 2014: Springer.</mixed-citation>
</ref>
<ref id="pone.0187371.ref036">
<label>36</label>
<mixed-citation publication-type="other">Alba E, Garcia-Nieto J, Jourdan L, Talbi E-G, editors. Gene selection in cancer classification using PSO/SVM and GA/SVM hybrid algorithms. Evolutionary Computation, 2007 CEC 2007 IEEE Congress on; 2007: IEEE.</mixed-citation>
</ref>
<ref id="pone.0187371.ref037">
<label>37</label>
<mixed-citation publication-type="other">Kennedy J, Eberhart RC, editors. A discrete binary version of the particle swarm algorithm. Systems, Man, and Cybernetics, 1997 Computational Cybernetics and Simulation, 1997 IEEE International Conference on; 1997: IEEE.</mixed-citation>
</ref>
<ref id="pone.0187371.ref038">
<label>38</label>
<mixed-citation publication-type="other">Cervante L, Xue B, Zhang M, Shang L, editors. Binary particle swarm optimisation for feature selection: A filter based approach. Evolutionary Computation (CEC), 2012 IEEE Congress on; 2012: IEEE.</mixed-citation>
</ref>
<ref id="pone.0187371.ref039">
<label>39</label>
<mixed-citation publication-type="other">He F, Yang H, Wang G, Cui G, editors. A novel method for hepatitis disease diagnosis based on RS and PSO. Proc of International Conference of 4th Electronic System-Integration Technology Conference; 2012.</mixed-citation>
</ref>
<ref id="pone.0187371.ref040">
<label>40</label>
<mixed-citation publication-type="journal"><name><surname>Xue</surname><given-names>B</given-names></name>, <name><surname>Zhang</surname><given-names>M</given-names></name>, <name><surname>Browne</surname><given-names>WN</given-names></name>. <article-title>Particle swarm optimization for feature selection in classification: A multi-objective approach</article-title>. <source/>IEEE transactions on cybernetics. <year>2013</year>;<volume>43</volume>(<issue>6</issue>):<fpage>1656</fpage>–<lpage>71</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TSMCB.2012.2227469">10.1109/TSMCB.2012.2227469</ext-link></comment>
<pub-id pub-id-type="pmid">24273143</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref041">
<label>41</label>
<mixed-citation publication-type="journal"><name><surname>Teng</surname><given-names>X</given-names></name>, <name><surname>Dong</surname><given-names>H</given-names></name>, <name><surname>Zhou</surname><given-names>X</given-names></name>. <article-title>Adaptive feature selection using v-shaped binary particle swarm optimization</article-title>. <source/>PLOS ONE. <year>2017</year>;<volume>12</volume>(<issue>3</issue>):<fpage>e0173907</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0173907">10.1371/journal.pone.0173907</ext-link></comment>
<pub-id pub-id-type="pmid">28358850</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref042">
<label>42</label>
<mixed-citation publication-type="journal"><name><surname>Christobel</surname><given-names>M</given-names></name>, <name><surname>Tamil Selvi</surname><given-names>S</given-names></name>, <name><surname>Benedict</surname><given-names>S</given-names></name>. <article-title>Efficient scheduling of scientific workflows with energy reduction using novel discrete particle swarm optimization and dynamic voltage scaling for computational grids</article-title>. <source/>The Scientific World Journal. <year>2015</year>;<volume>2015</volume>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref043">
<label>43</label>
<mixed-citation publication-type="journal"><name><surname>Moraglio</surname><given-names>A</given-names></name>, <name><surname>Di Chio</surname><given-names>C</given-names></name>, <name><surname>Togelius</surname><given-names>J</given-names></name>, <name><surname>Poli</surname><given-names>R</given-names></name>. <article-title>Geometric particle swarm optimization</article-title>. <source/>Journal of Artificial Evolution and Applications. <year>2008</year>;<volume>2008</volume>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref044">
<label>44</label>
<mixed-citation publication-type="other">Autistic children and their father’s age: peripheral blood lymphocytes [Internet]. <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov">www.ncbi.nlm.nih.gov</ext-link>. 2011. <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/sites/GDSbrowser?acc=GDS4431">http://www.ncbi.nlm.nih.gov/sites/GDSbrowser?acc=GDS4431</ext-link>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref045">
<label>45</label>
<mixed-citation publication-type="journal"><name><surname>Alter</surname><given-names>MD</given-names></name>, <name><surname>Kharkar</surname><given-names>R</given-names></name>, <name><surname>Ramsey</surname><given-names>KE</given-names></name>, <name><surname>Craig</surname><given-names>DW</given-names></name>, <name><surname>Melmed</surname><given-names>RD</given-names></name>, <name><surname>Grebe</surname><given-names>TA</given-names></name>, <etal>et al</etal>
<article-title>Autism and increased paternal age related changes in global levels of gene expression regulation</article-title>. <source/>PloS one. <year>2011</year>;<volume>6</volume>(<issue>2</issue>):<fpage>e16715</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0016715">10.1371/journal.pone.0016715</ext-link></comment>
<pub-id pub-id-type="pmid">21379579</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref046">
<label>46</label>
<mixed-citation publication-type="journal"><name><surname>El-Fishawy</surname><given-names>P</given-names></name>, <name><surname>State</surname><given-names>MW</given-names></name>. <article-title>The genetics of autism: key issues, recent findings, and clinical implications</article-title>. <source/>Psychiatric Clinics of North America. <year>2010</year>;<volume>33</volume>(<issue>1</issue>):<fpage>83</fpage>–<lpage>105</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.psc.2009.12.002">10.1016/j.psc.2009.12.002</ext-link></comment>
<pub-id pub-id-type="pmid">20159341</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref047">
<label>47</label>
<mixed-citation publication-type="book"><name><surname>Fisher</surname><given-names>RA</given-names></name>, editor <chapter-title>Theory of statistical estimation</chapter-title>
<source/>Mathematical Proceedings of the Cambridge Philosophical Society; <year>1925</year>: <publisher-name>Cambridge Univ Press</publisher-name>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref048">
<label>48</label>
<mixed-citation publication-type="journal"><name><surname>Latkowski</surname><given-names>T</given-names></name>, <name><surname>Osowski</surname><given-names>S</given-names></name>. <article-title>Computerized system for recognition of autism on the basis of gene expression microarray data</article-title>. <source/>Computers in biology and medicine. <year>2015</year>;<volume>56</volume>:<fpage>82</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.compbiomed.2014.11.004">10.1016/j.compbiomed.2014.11.004</ext-link></comment>
<pub-id pub-id-type="pmid">25464350</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref049">
<label>49</label>
<mixed-citation publication-type="journal"><name><surname>John Lu</surname><given-names>Z</given-names></name>. <article-title>The elements of statistical learning: data mining, inference, and prediction</article-title>. <source/>Journal of the Royal Statistical Society: Series A (Statistics in Society). <year>2010</year>;<volume>173</volume>(<issue>3</issue>):<fpage>693</fpage>–<lpage>4</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref050">
<label>50</label>
<mixed-citation publication-type="journal"><name><surname>Lai</surname><given-names>C</given-names></name>, <name><surname>Reinders</surname><given-names>MJ</given-names></name>, <name><surname>van't Veer</surname><given-names>LJ</given-names></name>, <name><surname>Wessels</surname><given-names>LF</given-names></name>. <article-title>A comparison of univariate and multivariate gene selection techniques for classification of cancer datasets</article-title>. <source/>BMC bioinformatics. <year>2006</year>;<volume>7</volume>(<issue>1</issue>):<fpage>235</fpage>.<pub-id pub-id-type="pmid">16670007</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref051">
<label>51</label>
<mixed-citation publication-type="other">Huertas C, Juárez-Ramírez R, editors. Filter feature selection performance comparison in high-dimensional data: A theoretical and empirical analysis of most popular algorithms. Information Fusion (FUSION), 2014 17th International Conference on; 2014: IEEE.</mixed-citation>
</ref>
<ref id="pone.0187371.ref052">
<label>52</label>
<mixed-citation publication-type="journal"><name><surname>Haury</surname><given-names>A-C</given-names></name>, <name><surname>Gestraud</surname><given-names>P</given-names></name>, <name><surname>Vert</surname><given-names>J-P</given-names></name>. <article-title>The influence of feature selection methods on accuracy, stability and interpretability of molecular signatures</article-title>. <source/>PloS one. <year>2011</year>;<volume>6</volume>(<issue>12</issue>):<fpage>e28210</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0028210">10.1371/journal.pone.0028210</ext-link></comment>
<pub-id pub-id-type="pmid">22205940</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref053">
<label>53</label>
<mixed-citation publication-type="journal"><name><surname>Lazar</surname><given-names>C</given-names></name>, <name><surname>Taminau</surname><given-names>J</given-names></name>, <name><surname>Meganck</surname><given-names>S</given-names></name>, <name><surname>Steenhoff</surname><given-names>D</given-names></name>, <name><surname>Coletta</surname><given-names>A</given-names></name>, <name><surname>Molter</surname><given-names>C</given-names></name>, <etal>et al</etal>
<article-title>A survey on filter techniques for feature selection in gene expression microarray analysis</article-title>. <source/>IEEE/ACM Transactions on Computational Biology and Bioinformatics. <year>2012</year>;<volume>9</volume>(<issue>4</issue>):<fpage>1106</fpage>–<lpage>19</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TCBB.2012.33">10.1109/TCBB.2012.33</ext-link></comment>
<pub-id pub-id-type="pmid">22350210</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref054">
<label>54</label>
<mixed-citation publication-type="journal"><name><surname>Muszyński</surname><given-names>M</given-names></name>, <name><surname>Osowski</surname><given-names>S</given-names></name>. <article-title>Data mining methods for gene selection on the basis of gene expression arrays</article-title>. <source/>International Journal of Applied Mathematics and Computer Science. <year>2014</year>;<volume>24</volume>(<issue>3</issue>):<fpage>657</fpage>–<lpage>68</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref055">
<label>55</label>
<mixed-citation publication-type="journal"><name><surname>Wiliński</surname><given-names>A</given-names></name>, <name><surname>Osowski</surname><given-names>S</given-names></name>. <article-title>Ensemble of data mining methods for gene ranking. Bulletin of the Polish Academy of Sciences</article-title>: <source/>Technical Sciences. <year>2012</year>;<volume>60</volume>(<issue>3</issue>):<fpage>461</fpage>–<lpage>70</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref056">
<label>56</label>
<mixed-citation publication-type="journal"><name><surname>Wilcoxon</surname><given-names>F</given-names></name>. <article-title>Individual comparisons by ranking methods</article-title>. <source/>Biometrics bulletin. <year>1945</year>;<volume>1</volume>(<issue>6</issue>):<fpage>80</fpage>–<lpage>3</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref057">
<label>57</label>
<mixed-citation publication-type="other">Wild C, Seber G. The Wilcoxon rank-sum test. Chapter; 2011.</mixed-citation>
</ref>
<ref id="pone.0187371.ref058">
<label>58</label>
<mixed-citation publication-type="other">Khoshgoftaar T, Dittman D, Wald R, Fazelpour A, editors. First order statistics based feature selection: A diverse and powerful family of feature seleciton techniques. Machine Learning and Applications (ICMLA), 2012 11th International Conference on; 2012: IEEE.</mixed-citation>
</ref>
<ref id="pone.0187371.ref059">
<label>59</label>
<mixed-citation publication-type="book"><name><surname>Sprent</surname><given-names>P</given-names></name>, <name><surname>Smeeton</surname><given-names>NC</given-names></name>. <source/>Applied nonparametric statistical methods: <publisher-name>CRC Press</publisher-name>; <year>2016</year>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref060">
<label>60</label>
<mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>S</given-names></name>, <name><surname>Wu</surname><given-names>X</given-names></name>, <name><surname>Tan</surname><given-names>M</given-names></name>. <article-title>Gene selection using hybrid particle swarm optimization and genetic algorithm</article-title>. <source/>Soft Computing-A Fusion of Foundations, Methodologies and Applications. <year>2008</year>;<volume>12</volume>(<issue>11</issue>):<fpage>1039</fpage>–<lpage>48</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref061">
<label>61</label>
<mixed-citation publication-type="journal"><name><surname>Saha</surname><given-names>S</given-names></name>, <name><surname>Seal</surname><given-names>DB</given-names></name>, <name><surname>Ghosh</surname><given-names>A</given-names></name>, <name><surname>Dey</surname><given-names>KN</given-names></name>. <article-title>A novel gene ranking method using Wilcoxon rank sum test and genetic algorithm</article-title>. <source/>International Journal of Bioinformatics Research and Applications. <year>2016</year>;<volume>12</volume>(<issue>3</issue>):<fpage>263</fpage>–<lpage>79</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref062">
<label>62</label>
<mixed-citation publication-type="journal"><name><surname>Bridge</surname><given-names>PD</given-names></name>, <name><surname>Sawilowsky</surname><given-names>SS</given-names></name>. <article-title>Increasing physicians’ awareness of the impact of statistics on research outcomes: comparative power of the t-test and Wilcoxon rank-sum test in small samples applied research</article-title>. <source/>Journal of clinical epidemiology. <year>1999</year>;<volume>52</volume>(<issue>3</issue>):<fpage>229</fpage>–<lpage>35</lpage>. <pub-id pub-id-type="pmid">10210240</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref063">
<label>63</label>
<mixed-citation publication-type="other">Ardjani F, Sadouni K, Benyettou M, editors. Optimization of SVM MultiClass by Particle Swarm (PSO-SVM). 2010 2nd International Workshop on Database Technology and Applications; 2010 27–28 Nov. 2010.</mixed-citation>
</ref>
<ref id="pone.0187371.ref064">
<label>64</label>
<mixed-citation publication-type="journal"><name><surname>Cortes</surname><given-names>C</given-names></name>, <name><surname>Vapnik</surname><given-names>V</given-names></name>. <article-title>Support-vector networks</article-title>. <source/>Machine learning. <year>1995</year>;<volume>20</volume>(<issue>3</issue>):<fpage>273</fpage>–<lpage>97</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref065">
<label>65</label>
<mixed-citation publication-type="journal"><name><surname>Jirapech-Umpai</surname><given-names>T</given-names></name>, <name><surname>Aitken</surname><given-names>S</given-names></name>. <article-title>Feature selection and classification for microarray data analysis: Evolutionary methods for identifying predictive genes</article-title>. <source/>BMC bioinformatics. <year>2005</year>;<volume>6</volume>(<issue>1</issue>):<fpage>148</fpage>.<pub-id pub-id-type="pmid">15958165</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref066">
<label>66</label>
<mixed-citation publication-type="journal"><name><surname>Hassanien</surname><given-names>AE</given-names></name>, <name><surname>Al-Shammari</surname><given-names>ET</given-names></name>, <name><surname>Ghali</surname><given-names>NI</given-names></name>. <article-title>Computational intelligence techniques in bioinformatics</article-title>. <source/>Computational biology and chemistry. <year>2013</year>;<volume>47</volume>:<fpage>37</fpage>–<lpage>47</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.compbiolchem.2013.04.007">10.1016/j.compbiolchem.2013.04.007</ext-link></comment>
<pub-id pub-id-type="pmid">23891719</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref067">
<label>67</label>
<mixed-citation publication-type="other">Huerta EB, Duval B, Hao J-K, editors. A hybrid GA/SVM approach for gene selection and classification of microarray data. Workshops on Applications of Evolutionary Computation; 2006: Springer.</mixed-citation>
</ref>
<ref id="pone.0187371.ref068">
<label>68</label>
<mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>B</given-names></name>, <name><surname>Fang</surname><given-names>L</given-names></name>, <name><surname>Liu</surname><given-names>F</given-names></name>, <name><surname>Wang</surname><given-names>X</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Chou</surname><given-names>K-C</given-names></name>. <article-title>Identification of real microRNA precursors with a pseudo structure status composition approach</article-title>. <source/>PloS one. <year>2015</year>;<volume>10</volume>(<issue>3</issue>):<fpage>e0121501</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0121501">10.1371/journal.pone.0121501</ext-link></comment>
<pub-id pub-id-type="pmid">25821974</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref069">
<label>69</label>
<mixed-citation publication-type="journal"><name><surname>Furey</surname><given-names>TS</given-names></name>, <name><surname>Cristianini</surname><given-names>N</given-names></name>, <name><surname>Duffy</surname><given-names>N</given-names></name>, <name><surname>Bednarski</surname><given-names>DW</given-names></name>, <name><surname>Schummer</surname><given-names>M</given-names></name>, <name><surname>Haussler</surname><given-names>D</given-names></name>. <article-title>Support vector machine classification and validation of cancer tissue samples using microarray expression data</article-title>. <source/>Bioinformatics. <year>2000</year>;<volume>16</volume>(<issue>10</issue>):<fpage>906</fpage>–<lpage>14</lpage>. <pub-id pub-id-type="pmid">11120680</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref070">
<label>70</label>
<mixed-citation publication-type="other">Latkowski T, Osowski S, editors. Developing Gene Classifier System for Autism Recognition. International Work-Conference on Artificial Neural Networks; 2015: Springer.</mixed-citation>
</ref>
<ref id="pone.0187371.ref071">
<label>71</label>
<mixed-citation publication-type="journal"><name><surname>García-Nieto</surname><given-names>J</given-names></name>, <name><surname>Alba</surname><given-names>E</given-names></name>, <name><surname>Jourdan</surname><given-names>L</given-names></name>, <name><surname>Talbi</surname><given-names>E</given-names></name>. <article-title>Sensitivity and specificity based multiobjective approach for feature selection: Application to cancer diagnosis</article-title>. <source/>Information Processing Letters. <year>2009</year>;<volume>109</volume>(<issue>16</issue>):<fpage>887</fpage>–<lpage>96</lpage>.</mixed-citation>
</ref>
<ref id="pone.0187371.ref072">
<label>72</label>
<mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>B</given-names></name>, <name><surname>Wu</surname><given-names>H</given-names></name>, <name><surname>Zhang</surname><given-names>D</given-names></name>, <name><surname>Wang</surname><given-names>X</given-names></name>, <name><surname>Chou</surname><given-names>K-C</given-names></name>. <article-title>Pse-Analysis: a python package for DNA/RNA and protein/peptide sequence analysis based on pseudo components and kernel methods</article-title>. <source/>Oncotarget. <year>2017</year>;<volume>8</volume>(<issue>8</issue>):<fpage>13338</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.18632/oncotarget.14524">10.18632/oncotarget.14524</ext-link></comment>
<pub-id pub-id-type="pmid">28076851</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref073">
<label>73</label>
<mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>B</given-names></name>, <name><surname>Xu</surname><given-names>J</given-names></name>, <name><surname>Lan</surname><given-names>X</given-names></name>, <name><surname>Xu</surname><given-names>R</given-names></name>, <name><surname>Zhou</surname><given-names>J</given-names></name>, <name><surname>Wang</surname><given-names>X</given-names></name>, <etal>et al</etal>
<article-title>iDNA-Prot| dis: identifying DNA-binding proteins by incorporating amino acid distance-pairs and reduced alphabet profile into the general pseudo amino acid composition</article-title>. <source/>PloS one. <year>2014</year>;<volume>9</volume>(<issue>9</issue>):<fpage>e106691</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0106691">10.1371/journal.pone.0106691</ext-link></comment>
<pub-id pub-id-type="pmid">25184541</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref074">
<label>74</label>
<mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>B</given-names></name>, <name><surname>Zhang</surname><given-names>D</given-names></name>, <name><surname>Xu</surname><given-names>R</given-names></name>, <name><surname>Xu</surname><given-names>J</given-names></name>, <name><surname>Wang</surname><given-names>X</given-names></name>, <name><surname>Chen</surname><given-names>Q</given-names></name>, <etal>et al</etal>
<article-title>Combining evolutionary information extracted from frequency profiles with sequence-based kernels for protein remote homology detection</article-title>. <source/>Bioinformatics. <year>2013</year>;<volume>30</volume>(<issue>4</issue>):<fpage>472</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btt709">10.1093/bioinformatics/btt709</ext-link></comment>
<pub-id pub-id-type="pmid">24318998</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref075">
<label>75</label>
<mixed-citation publication-type="other">Talbi E-G, Jourdan L, Garcia-Nieto J, Alba E, editors. Comparison of population based metaheuristics for feature selection: Application to microarray data classification. Computer Systems and Applications, 2008 AICCSA 2008 IEEE/ACS International Conference on; 2008: IEEE.</mixed-citation>
</ref>
<ref id="pone.0187371.ref076">
<label>76</label>
<mixed-citation publication-type="journal"><name><surname>Sadakata</surname><given-names>T</given-names></name>, <name><surname>Sekine</surname><given-names>Y</given-names></name>, <name><surname>Oka</surname><given-names>M</given-names></name>, <name><surname>Itakura</surname><given-names>M</given-names></name>, <name><surname>Takahashi</surname><given-names>M</given-names></name>, <name><surname>Furuichi</surname><given-names>T</given-names></name>. <article-title>Calcium-dependent activator protein for secretion 2 interacts with the class II ARF small GTPases and regulates dense-core vesicle trafficking</article-title>. <source/>The FEBS journal. <year>2012</year>;<volume>279</volume>(<issue>3</issue>):<fpage>384</fpage>–<lpage>94</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1742-4658.2011.08431.x">10.1111/j.1742-4658.2011.08431.x</ext-link></comment>
<pub-id pub-id-type="pmid">22111578</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref077">
<label>77</label>
<mixed-citation publication-type="journal"><name><surname>Krey</surname><given-names>JF</given-names></name>, <name><surname>Dolmetsch</surname><given-names>RE</given-names></name>. <article-title>Molecular mechanisms of autism: a possible role for Ca 2+ signaling</article-title>. <source/>Current opinion in neurobiology. <year>2007</year>;<volume>17</volume>(<issue>1</issue>):<fpage>112</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2007.01.010">10.1016/j.conb.2007.01.010</ext-link></comment>
<pub-id pub-id-type="pmid">17275285</pub-id></mixed-citation>
</ref>
<ref id="pone.0187371.ref078">
<label>78</label>
<mixed-citation publication-type="journal"><name><surname>Sadakata</surname><given-names>T</given-names></name>, <name><surname>Shinoda</surname><given-names>Y</given-names></name>, <name><surname>Ishizaki</surname><given-names>Y</given-names></name>, <name><surname>Furuichi</surname><given-names>T</given-names></name>. <article-title>Analysis of gene expression in Ca2+-dependent activator protein for secretion 2 (Cadps2) knockout cerebellum using GeneChip and KEGG pathways</article-title>. <source/>Neuroscience letters. <year>2017</year>;<volume>639</volume>:<fpage>88</fpage>–<lpage>93</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neulet.2016.12.068">10.1016/j.neulet.2016.12.068</ext-link></comment>
<pub-id pub-id-type="pmid">28041965</pub-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
</pmc-articleset>