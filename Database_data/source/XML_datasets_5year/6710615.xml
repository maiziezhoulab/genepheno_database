<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="research-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">SLAS Discov</journal-id>
<journal-id journal-id-type="iso-abbrev">SLAS Discov</journal-id>
<journal-id journal-id-type="publisher-id">JBX</journal-id>
<journal-id journal-id-type="hwp">spjbx</journal-id>
<journal-title-group>
<journal-title>Slas Discovery</journal-title>
</journal-title-group>
<issn pub-type="ppub">2472-5552</issn>
<issn pub-type="epub">2472-5560</issn>
<publisher>
<publisher-name>SAGE Publications</publisher-name>
<publisher-loc>Sage CA: Los Angeles, CA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">31284814</article-id>
<article-id pub-id-type="pmc">6710615</article-id>
<article-id pub-id-type="doi">10.1177/2472555219857715</article-id>
<article-id pub-id-type="publisher-id">10.1177_2472555219857715</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original Research</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Applying Deep Neural Network Analysis to High-Content Image-Based Assays</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id authenticated="false" contrib-id-type="orcid">https://orcid.org/0000-0003-2460-6456</contrib-id>
<name>
<surname>Yang</surname>
<given-names>Samuel J.</given-names>
</name>
<xref ref-type="aff" rid="aff1-2472555219857715">1</xref>
<xref ref-type="author-notes" rid="fn1-2472555219857715">*</xref>
<xref ref-type="corresp" rid="corresp1-2472555219857715"></xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lipnick</surname>
<given-names>Scott L.</given-names>
</name>
<xref ref-type="aff" rid="aff2-2472555219857715">2</xref>
<xref ref-type="aff" rid="aff3-2472555219857715">3</xref>
<xref ref-type="aff" rid="aff4-2472555219857715">4</xref>
<xref ref-type="author-notes" rid="fn1-2472555219857715">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Makhortova</surname>
<given-names>Nina R.</given-names>
</name>
<xref ref-type="aff" rid="aff2-2472555219857715">2</xref>
<xref ref-type="aff" rid="aff5-2472555219857715">5</xref>
<xref ref-type="author-notes" rid="fn1-2472555219857715">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id authenticated="false" contrib-id-type="orcid">https://orcid.org/0000-0003-3729-8456</contrib-id>
<name>
<surname>Venugopalan</surname>
<given-names>Subhashini</given-names>
</name>
<xref ref-type="aff" rid="aff1-2472555219857715">1</xref>
<xref ref-type="author-notes" rid="fn1-2472555219857715">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Fan</surname>
<given-names>Minjie</given-names>
</name>
<xref ref-type="aff" rid="aff1-2472555219857715">1</xref>
<xref ref-type="author-notes" rid="fn1-2472555219857715">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Armstrong</surname>
<given-names>Zan</given-names>
</name>
<xref ref-type="aff" rid="aff1-2472555219857715">1</xref>
<xref ref-type="author-notes" rid="fn2-2472555219857715">**</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schlaeger</surname>
<given-names>Thorsten M.</given-names>
</name>
<xref ref-type="aff" rid="aff5-2472555219857715">5</xref>
<xref ref-type="author-notes" rid="fn2-2472555219857715">**</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Deng</surname>
<given-names>Liyong</given-names>
</name>
<xref ref-type="aff" rid="aff6-2472555219857715">6</xref>
<xref ref-type="author-notes" rid="fn2-2472555219857715">**</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chung</surname>
<given-names>Wendy K.</given-names>
</name>
<xref ref-type="aff" rid="aff6-2472555219857715">6</xref>
<xref ref-type="author-notes" rid="fn2-2472555219857715">**</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>O’Callaghan</surname>
<given-names>Liadan</given-names>
</name>
<xref ref-type="aff" rid="aff1-2472555219857715">1</xref>
<xref ref-type="author-notes" rid="fn2-2472555219857715">**</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Geraschenko</surname>
<given-names>Anton</given-names>
</name>
<xref ref-type="aff" rid="aff1-2472555219857715">1</xref>
<xref ref-type="author-notes" rid="fn2-2472555219857715">**</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Whye</surname>
<given-names>Dosh</given-names>
</name>
<xref ref-type="aff" rid="aff2-2472555219857715">2</xref>
<xref ref-type="author-notes" rid="fn2-2472555219857715">**</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Berndl</surname>
<given-names>Marc</given-names>
</name>
<xref ref-type="aff" rid="aff1-2472555219857715">1</xref>
<xref ref-type="author-notes" rid="fn2-2472555219857715">**</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hazard</surname>
<given-names>Jon</given-names>
</name>
<xref ref-type="aff" rid="aff1-2472555219857715">1</xref>
<xref ref-type="author-notes" rid="fn2-2472555219857715">**</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Williams</surname>
<given-names>Brian</given-names>
</name>
<xref ref-type="aff" rid="aff1-2472555219857715">1</xref>
<xref ref-type="author-notes" rid="fn2-2472555219857715">**</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Narayanaswamy</surname>
<given-names>Arunachalam</given-names>
</name>
<xref ref-type="aff" rid="aff1-2472555219857715">1</xref>
<xref ref-type="author-notes" rid="fn2-2472555219857715">**</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ando</surname>
<given-names>D. Michael</given-names>
</name>
<xref ref-type="aff" rid="aff1-2472555219857715">1</xref>
<xref ref-type="author-notes" rid="fn3-2472555219857715">***</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Nelson</surname>
<given-names>Philip</given-names>
</name>
<xref ref-type="aff" rid="aff1-2472555219857715">1</xref>
<xref ref-type="author-notes" rid="fn3-2472555219857715">***</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Rubin</surname>
<given-names>Lee L.</given-names>
</name>
<xref ref-type="aff" rid="aff2-2472555219857715">2</xref>
<xref ref-type="aff" rid="aff7-2472555219857715">7</xref>
<xref ref-type="author-notes" rid="fn3-2472555219857715">***</xref>
</contrib>
</contrib-group>
<aff id="aff1-2472555219857715"><label>1</label>Google, LLC, Mountain View, CA, USA</aff>
<aff id="aff2-2472555219857715"><label>2</label>Department of Stem Cell and Regenerative Biology, Harvard University, Cambridge, MA, USA</aff>
<aff id="aff3-2472555219857715"><label>3</label>Department of Biomedical Informatics, Harvard Medical School, Boston, MA, USA</aff>
<aff id="aff4-2472555219857715"><label>4</label>Center for Assessment Technology &amp; Continuous Health (CATCH), Massachusetts General Hospital, Boston, MA, USA</aff>
<aff id="aff5-2472555219857715"><label>5</label>Stem Cell Program, Boston Children’s Hospital, Boston, MA, USA</aff>
<aff id="aff6-2472555219857715"><label>6</label>Departments of Pediatrics and Medicine, Columbia University Medical Center, New York, NY, USA</aff>
<aff id="aff7-2472555219857715"><label>7</label>Harvard Stem Cell Institute, Cambridge, MA, USA</aff>
<author-notes>
<corresp id="corresp1-2472555219857715">Samuel J. Yang, Google, LLC, 1600 Amphitheatre Pkwy, Attn: Samuely, Mountain View, CA 94043, USA. Email: <email>samuely@google.com</email></corresp>
<fn fn-type="equal" id="fn1-2472555219857715">
<label>*</label>
<p>These authors contributed equally to this work as lead authors.</p>
</fn>
<fn fn-type="equal" id="fn2-2472555219857715">
<label>**</label>
<p>These authors contributed equally to this work; names are given in random order.</p>
</fn>
<fn fn-type="equal" id="fn3-2472555219857715">
<label>***</label>
<p>These authors contributed equally to this work.</p>
</fn>
</author-notes>
<pub-date pub-type="epub">
<day>08</day>
<month>7</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="ppub">
<month>9</month>
<year>2019</year>
</pub-date>
<volume>24</volume>
<issue>8</issue>
<fpage>829</fpage>
<lpage>841</lpage>
<history>
<date date-type="received">
<day>20</day>
<month>2</month>
<year>2019</year>
</date>
<date date-type="rev-recd">
<day>9</day>
<month>4</month>
<year>2019</year>
</date>
<date date-type="accepted">
<day>26</day>
<month>4</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-statement>© 2019 Society for Laboratory Automation and Screening</copyright-statement>
<copyright-year>2019</copyright-year>
<copyright-holder content-type="society">Society for Laboratory Automation and Screening</copyright-holder>
<license license-type="open-access" xlink:href="http://www.creativecommons.org/licenses/by-nc/4.0/">
<license-p>This article is distributed under the terms of the Creative Commons Attribution-NonCommercial 4.0 License (<ext-link ext-link-type="uri" xlink:href="http://www.creativecommons.org/licenses/by-nc/4.0/">http://www.creativecommons.org/licenses/by-nc/4.0/</ext-link>) which permits non-commercial use, reproduction and distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages (<ext-link ext-link-type="uri" xlink:href="https://us.sagepub.com/en-us/nam/open-access-at-sage">https://us.sagepub.com/en-us/nam/open-access-at-sage</ext-link>).</license-p>
</license>
</permissions>
<abstract>
<p>The etiological underpinnings of many CNS disorders are not well understood. This is likely due to the fact that individual diseases aggregate numerous pathological subtypes, each associated with a complex landscape of genetic risk factors. To overcome these challenges, researchers are integrating novel data types from numerous patients, including imaging studies capturing broadly applicable features from patient-derived materials. These datasets, when combined with machine learning, potentially hold the power to elucidate the subtle patterns that stratify patients by shared pathology. In this study, we interrogated whether high-content imaging of primary skin fibroblasts, using the Cell Painting method, could reveal disease-relevant information among patients. First, we showed that technical features such as batch/plate type, plate, and location within a plate lead to detectable nuisance signals, as revealed by a pre-trained deep neural network and analysis with deep image embeddings. Using a plate design and image acquisition strategy that accounts for these variables, we performed a pilot study with 12 healthy controls and 12 subjects affected by the severe genetic neurological disorder spinal muscular atrophy (SMA), and evaluated whether a convolutional neural network (CNN) generated using a subset of the cells could distinguish disease states on cells from the remaining unseen control–SMA pair. Our results indicate that these two populations could effectively be differentiated from one another and that model selectivity is insensitive to batch/plate type. One caveat is that the samples were also largely separated by source. These findings lay a foundation for how to conduct future studies exploring diseases with more complex genetic contributions and unknown subtypes.</p>
</abstract>
<kwd-group>
<kwd>deep learning</kwd>
<kwd>high-content screening</kwd>
<kwd>disease modeling</kwd>
<kwd>assay development</kwd>
<kwd>spinal muscular atrophy</kwd>
</kwd-group>
<funding-group>
<award-group id="award1-2472555219857715">
<funding-source id="funding1-2472555219857715">
<institution-wrap>
<institution>National Institute of Neurological Disorders and Stroke</institution>
<institution-id institution-id-type="FundRef">https://doi.org/10.13039/100000065</institution-id>
</institution-wrap>
</funding-source>
<award-id rid="funding1-2472555219857715">P01 NS066888</award-id>
</award-group>
<award-group id="award2-2472555219857715">
<funding-source id="funding2-2472555219857715">
<institution-wrap>
<institution>spinal muscular atrophy foundation</institution>
<institution-id institution-id-type="FundRef">https://doi.org/10.13039/100000894</institution-id>
</institution-wrap>
</funding-source>
</award-group>
<award-group id="award3-2472555219857715">
<funding-source id="funding3-2472555219857715">
<institution-wrap>
<institution>Google</institution>
<institution-id institution-id-type="FundRef">https://doi.org/10.13039/100006785</institution-id>
</institution-wrap>
</funding-source>
</award-group>
<award-group id="award4-2472555219857715">
<funding-source id="funding4-2472555219857715">
<institution-wrap>
<institution>Harvard Stem Cell Institute</institution>
<institution-id institution-id-type="FundRef">https://doi.org/10.13039/100008035</institution-id>
</institution-wrap>
</funding-source>
</award-group>
<award-group id="award5-2472555219857715">
<funding-source id="funding5-2472555219857715">
<institution-wrap>
<institution>massachusetts general hospital</institution>
<institution-id institution-id-type="FundRef">https://doi.org/10.13039/100005294</institution-id>
</institution-wrap>
</funding-source>
<award-id rid="funding5-2472555219857715">Center for Assessment Technology and Continuous Health</award-id>
</award-group>
</funding-group>
</article-meta>
</front>
<body>
<sec id="section1-2472555219857715" sec-type="intro">
<title>Introduction</title>
<p>Disorders of the CNS are a leading cause of disability and mortality worldwide;<sup><xref ref-type="bibr" rid="bibr1-2472555219857715">1</xref></sup> yet, despite significant research efforts, little is known about their etiology. A major impediment toward studying and developing drugs for these disorders is the fact that patients with shared end-stage clinical presentations are classified as single groups when their presentations are more likely to result from different underlying processes. The field is looking for robust and scalable methods for dividing patients into similar classes to study these processes more effectively and to match specific therapeutics to likely responders. One promising route for patient stratification related to underlying disease drivers is through identification of shared genetic traits. Large-scale genome-wide association studies (GWAS) have been performed for CNS disorders that resulted in the identification of hundreds of risk variants.<sup><xref ref-type="bibr" rid="bibr2-2472555219857715">2</xref><xref ref-type="bibr" rid="bibr3-2472555219857715"></xref>–<xref ref-type="bibr" rid="bibr4-2472555219857715">4</xref></sup> Unfortunately, for the most part, this complex genetic landscape has not provided a clear picture of patient subtypes, thereby motivating groups to supplement genetic studies with additional clinical and patient-specific data sources as recently described.<sup><xref ref-type="bibr" rid="bibr5-2472555219857715">5</xref></sup> A critical aspect of these approaches is the reliance on patient-derived material to guide patient subtyping.</p>
<p>Given the genetic complexity and likely nonlinear relationships among genetic risk variants in CNS disorders, studies using patient materials will require the use of samples from many patients to achieve statistical power. In support of such studies, large-scale collection of patient materials is underway.<sup><xref ref-type="bibr" rid="bibr6-2472555219857715">6</xref>,<xref ref-type="bibr" rid="bibr7-2472555219857715">7</xref></sup> Accounting for the fact that little is known about the etiology of most CNS disorders, unbiased data such as transcriptomic or imaging studies capturing broadly applicable features, like Cell Painting,<sup><xref ref-type="bibr" rid="bibr8-2472555219857715">8</xref></sup> are likely to be useful starting points for interrogation. These datasets, when combined with novel machine learning approaches, potentially hold the power to elucidate features that stratify patients and yield hypotheses for more precise studies of disease drivers. One technology that has enabled identification of subtle complex patterns in large datasets is deep neural networks (DNNs).<sup><xref ref-type="bibr" rid="bibr9-2472555219857715">9</xref></sup> DNNs are one of the machine learning methods that use a set of model parameters and operations that allow input data to be transformed into useful outputs after a training (fitting) procedure. Compared with previous machine learning approaches, deep learning methods require minimal manual feature engineering and less parameter tuning, and have a remarkable ability to generalize to related data inputs. Leveraging the power of DNNs to explore data generated from numerous patients is of great interest, but it also requires adaptation of the algorithms and establishment of best practices for data collection to ensure that systemic non-disease-associated patterns, namely nuisance signals, do not drive the selectivity of any resulting models. This is particularly important because exploration of what leads to the selectivity of DNNs is still an evolving field.<sup><xref ref-type="bibr" rid="bibr10-2472555219857715">10</xref></sup> As such, identifying features that could be providing selectivity and controlling for them in study design are critical.</p>
<p>The question we aimed to address in the current work is whether high-content imaging of patient-derived cells, namely primary skin fibroblasts, can reveal disease-relevant information among a large number of patients. Fibroblasts represent an accessible source of primary unmodified human cells, which retain the genetic traits of the patients from whom they were obtained, that can provide a patient-specific culture system to study disease. It is also possible that these cells will retain epigenetic features from aging and environmental exposure<sup><xref ref-type="bibr" rid="bibr11-2472555219857715">11</xref></sup> that are also associated with disease onset. While these cells are nonneuronal and not implicated in CNS disorders, they represent an opportunity in the present to functionalize genetic variation among many patients; access to primary human neurons at scale is challenging, and current protocols for generating stem cell–derived neurons vary in consistency when applied to numerous individuals.<sup><xref ref-type="bibr" rid="bibr12-2472555219857715">12</xref>,<xref ref-type="bibr" rid="bibr13-2472555219857715">13</xref></sup> Moreover, studies using fibroblasts from numerous patients with CNS disorders have been shown to represent some broad disease-related features.<sup><xref ref-type="bibr" rid="bibr14-2472555219857715">14</xref><xref ref-type="bibr" rid="bibr15-2472555219857715"></xref><xref ref-type="bibr" rid="bibr16-2472555219857715"></xref><xref ref-type="bibr" rid="bibr17-2472555219857715"></xref><xref ref-type="bibr" rid="bibr18-2472555219857715"></xref>–<xref ref-type="bibr" rid="bibr19-2472555219857715">19</xref></sup></p>
<p>The work presented in this article is: (1) to identify variables that drive nuisance signals<sup><xref ref-type="bibr" rid="bibr20-2472555219857715">20</xref></sup> detectable using machine learning and to develop study designs to minimize their impact, and (2) to predict disease status using high-content imaging of patient and control cell lines. To do this, we used three distinct deep learning approaches. First, we showed in a pilot experiment that image focus can be detected by a pre-trained DNN<sup><xref ref-type="bibr" rid="bibr21-2472555219857715">21</xref></sup> and demonstrated that it can vary significantly as a function of position on a 96-well plate. These data led us to propose an acquisition strategy that accounts for focus variation, and a cell-plating approach, based on previous findings of predictable plate-based variation (Shamir<sup><xref ref-type="bibr" rid="bibr20-2472555219857715">20</xref></sup> and others), that would enable us simultaneously to test the detectability of nuisance signals derived from assay features (including batch/plate type, plate, and location within a plate), and to perform a disease-focused study accounting for these features. To explore the resulting data, we used a second deep learning approach using image embeddings,<sup><xref ref-type="bibr" rid="bibr22-2472555219857715">22</xref></sup> a lower dimensional semantically meaningful representation of images that could be used with conventional machine learning methods such as logistic regression or random forest.<sup><xref ref-type="bibr" rid="bibr23-2472555219857715">23</xref></sup> The embedding method uses the Inception architecture<sup><xref ref-type="bibr" rid="bibr24-2472555219857715">24</xref></sup> pre-trained on the ImageNet object recognition dataset<sup><xref ref-type="bibr" rid="bibr25-2472555219857715">25</xref></sup> containing about 1.2 million images of a thousand categories of objects. The value of embeddings in general for biological studies was later demonstrated in a study that showed they outperform traditional segmented feature-based approaches, using Cell Painting, when tasked with predicting the mechanism of action of various compounds given to cells.<sup><xref ref-type="bibr" rid="bibr26-2472555219857715">26</xref></sup> This paradigm has also been shown true for other fields comparing segmented features and continuous embeddings or raw data.<sup><xref ref-type="bibr" rid="bibr27-2472555219857715">27</xref></sup> Finally, we performed an analysis to distinguish diseased cells, derived from patients with spinal muscular atrophy (SMA), a severe genetically driven neurological disorder, from healthy controls using conventional machine learning methods trained on the image embeddings and a third deep learning method, namely a convolutional neural network (CNN),<sup><xref ref-type="bibr" rid="bibr28-2472555219857715">28</xref></sup> trained directly on raw cellular images. The choice of SMA was made because it is an ideal disorder for evaluating whether a technology can detect disease-relevant signals for the following reasons: The genes associated with SMA, <italic>survival of motor neuron 1</italic> (<italic>SMN1</italic>) and <italic>SMN2</italic>, lead to a penetrant phenotype;<sup><xref ref-type="bibr" rid="bibr29-2472555219857715">29</xref></sup> their copy number correlates with age of onset;<sup><xref ref-type="bibr" rid="bibr30-2472555219857715">30</xref></sup> and they are transcribed in all cell types, including fibroblasts.<sup><xref ref-type="bibr" rid="bibr14-2472555219857715">14</xref>,<xref ref-type="bibr" rid="bibr31-2472555219857715">31</xref></sup> Furthermore, while the exact function of the SMN protein is unknown, evidence exists that it is related to RNA processing in a cell-autonomous manner affecting all cell types, even though some cells (e.g., motor neurons)<sup><xref ref-type="bibr" rid="bibr32-2472555219857715">32</xref>,<xref ref-type="bibr" rid="bibr33-2472555219857715">33</xref></sup> may be more sensitive than others.</p>
</sec>
<sec id="section2-2472555219857715" sec-type="materials|methods">
<title>Materials and Methods</title>
<p>To execute this study, we first performed a pilot experiment using six cell lines to test certain parameters in study implementation and also quality issues. Using knowledge gained from the pilot, we then performed two batches of disease-focused experiments using 27 cell lines. For all experiments, we used the same cell sources and protocols for expansion, plating, and staining.</p>
<sec id="section3-2472555219857715">
<title>Cell Sources</title>
<p>Primary fibroblasts were obtained from skin punch biopsies banked at two source labs, the Coriell Institute for Medical Research (Camden, NJ; denoted lab A; 15 healthy controls and 1 with SMA) and the Pediatric Neuromuscular Research Network’s cell repository at Columbia University Medical Center (New York, NY; denoted lab B; 11 with SMA).<sup><xref ref-type="bibr" rid="bibr34-2472555219857715">34</xref>,<xref ref-type="bibr" rid="bibr35-2472555219857715">35</xref></sup> The latter fibroblasts were collected under institutional review board (IRB) approval at Boston Children’s Hospital, Children’s Hospital of Philadelphia, and Columbia University Medical Center. The Harvard University IRB approved the use of these lines in the described research. To avoid a potential signal from gender differences, only male lines were used in this study. Control lines were obtained from individuals without SMA and selected based on a pairwise matching, to the extent possible, to age at biopsy of the SMA lines. Details including identification (ID), source, gender, age at biopsy, SMN1/2 copy number for SMA subjects, passage number at experiment, and other features are presented in <ext-link ext-link-type="uri" xlink:href="http://journals.sagepub.com/doi/suppl/10.1177/2472555219857715"><bold>Supplementary Table 1</bold></ext-link>.</p>
</sec>
<sec id="section4-2472555219857715">
<title>Cell Expansion Protocol</title>
<p>Cells were obtained at various different early passages. To avoid differences in cellular phenotype due to differences in cell line passage number, we first normalized passage number among all cell lines to passage number 5, the earliest passage at which sufficient number of cells could be banked for experimentation for all cell lines. For fibroblast expansion and culturing, we adapted a protocol used by the Coriell Institute for Medical Research.<sup><xref ref-type="bibr" rid="bibr36-2472555219857715">36</xref></sup> In summary, on thawing, a 15 µL sample was aspirated, stained with trypan blue (cat. no. SV30084.01; GE, Boston, MA), and counted using a hemocytometer (Biorad, Hercules, CA). They were then plated at 100,000 cells per well in a six-well plate (cat. no. 3516; Corning, Corning, NY), expanded, and, on reaching 90% confluency, re-passaged using the same initial plating density. For cell expansion, we used Dulbecco’s modified Eagle medium (DMEM; cat no. 11995-065; Gibco, Carlsbad, CA), supplemented with 10% fetal bovine serum (FBS; cat. no. F2442; Sigma-Aldrich, St. Louis, MO), penicillin–streptomycin (100 U/ml; cat. no. 15140-122; Gibco), and 2 mM L-glutamine (cat. no. 25030-081; Gibco). Cells were grown in a tissue culture incubator at 5% CO<sub>2</sub> and 37 °C. For passaging, we used phosphate-buffered saline (PBS; cat. no. 14190-136; Gibco) and TrypLE (cat. no. 12605-010; Gibco). Cells were frozen at 100,000 cells per cryovial, with growth medium supplemented with 5% DMSO (cat. no. D2650; Sigma-Aldrich).</p>
</sec>
<sec id="section5-2472555219857715">
<title>Pilot Experiment</title>
<p>The aim of our first experiment was to test certain parameters in study implementation, such as the complexity of working with 27 individual lines, and also known quality issues in the screening field, including discrepant cell growth in outer versus inner wells. To accomplish this aim, we ran a mock 27-line experiment using six cell lines separately aliquoted to represent the 27 individual lines. First, each line was thawed, cultured for 10 days, and split once in advance of the experiment to achieve 90% confluency. The resulting passage number for use in the experiment was passage 7. Two wells of a six-well plate were then dissociated for each line. This was done in two rounds to minimize time out of the incubator for live cultures. Each of the rounds was treated identically but performed sequentially. Cells were trypsinized and counted using the protocol described above. Finally, 3000 cells were dispensed into each well of a 96-well plate (ViewPlate, cat. no. 6005182; PerkinElmer, Waltham, MA) using a Matrix multichannel pipette (Thermo Fisher, Waltham, MA). Following distribution of all cell lines, the plates were returned to the incubator. Our decision to use 96-well plates over 384-well plates was largely motivated by a desire to increase the number of imaged cells per well.</p>
<p>After 48 h incubation, we performed the Cell Painting<sup><xref ref-type="bibr" rid="bibr8-2472555219857715">8</xref></sup> assay using six fluorescent stains: Hoechst (cat. no. H3570; Life Technologies, Carlsbad, CA), SYTO 14 (cat. no. S7576; Life Technologies), Concanavalin A 488 (cat. no. C11252; Life Technologies), Wheat Germ Agglutinin (cat. no. W32464; Life Technologies), Phalloidin 568 (cat. no. A12380; Life Technologies), and MitoTracker Deep Red FM (cat. no. M22426; Life Technologies) diluted into Hank’s balanced salt solution (HBSS, cat. no. 14065056; Life Technologies). The pilot experiment was imaged in widefield mode with 20× magnification using the PerkinElmer Opera Phenix running the Harmony software package (Logitech, Lausanne, Switzerland). Thirty-seven sites were collected for each well, which maximized coverage of the entire well.</p>
</sec>
<sec id="section6-2472555219857715">
<title>Image Processing</title>
<p>Prior to cell segmentation, the 16-bit images were flat-field corrected as described in Ando et al.<sup><xref ref-type="bibr" rid="bibr26-2472555219857715">26</xref></sup> Next, cell segmentation was conducted on the DAPI channel image by detecting nuclei centers, then cropping a 256×256 subimage region. Only regions that were completely within the original image boundaries were used for further analysis, yielding approximately 2000 cells per well. To have a balanced sampling of cells from each well, for wells with 2000 or more cells, 2000 cells were randomly sampled without replacement, and for wells with fewer than 2000 cells, additional cells were randomly sampled with replacement to get to 2000 total cells.</p>
</sec>
<sec id="section7-2472555219857715">
<title>Focus Quality Analysis</title>
<p>Quantitative analysis of this experiment included evaluation of focus quality, which was assessed using segmented nuclei in the DAPI channel, using the pre-trained DNN model described in Yang et al.<sup><xref ref-type="bibr" rid="bibr21-2472555219857715">21</xref></sup> For each 84×84 pixel region of a segmented DAPI cell image, the pre-trained DNN model predicts a probability distribution among 11 ordered classes of focus quality, corresponding to image blur ranging from 1 to 31 pixels in diameter. We then calculated the “focus score” of a cell image as the sum of the probability distribution in the three most in-focus classes among regions, yielding a continuous value between 0.0 and 1.0, with 1.0 being the best focus.</p>
</sec>
<sec id="section8-2472555219857715">
<title>Disease-Focused Experiment</title>
<p>The second set of experiments used 27 total cell lines in two batches of 12 96-well plates, according to the plate maps in <xref ref-type="fig" rid="fig1-2472555219857715">
<bold>Figure 1</bold>
</xref>. Using a subset of three of the cell lines in these experiments (labeled C1, C2, and C3 in <xref ref-type="fig" rid="fig1-2472555219857715">
<bold>Fig. 1</bold>
</xref>), we were able to test the detectability of spurious nuisance signals derived from parameters such as well location and plate identity. The intelligent plate map also enabled us to simultaneously run an experiment (minimizing the impact of these features using 12 SMA lines and 12 healthy control lines) to test whether we could effectively predict disease state. This was performed in two batches with different plate types: the first with the Greiner µClear plastic-bottom plate (cat. no. 655090; Sigma-Aldrich), and the second with a Cellvis glass-bottom plate (cat. no. P96-1.5H-N; Cellvis, Mountain View, CA). The use of the different plate types for each batch of experiments enabled us to evaluate our ability to detect signal arising from different experimental conditions and also to see whether disease prediction models for SMA would be insensitive to these different conditions. Our vision was to mimic potential future studies that would integrate data from different groups using different experimental conditions.</p>
<fig id="fig1-2472555219857715" orientation="portrait" position="float">
<label>Figure 1.</label>
<caption>
<p>Plate layout design for a disease-focused experiment with 27 human fibroblast cell lines. Each square represents one well (on a 96-well plate) containing cells from one subject cell line (labeled with a two-digit subject ID). The images of the cells were used in two separate analyses with completely independent sets of subjects. In the first analysis, the gray wells representing three healthy control subjects (C1, C2, and C3) were used to assess the detectability of nuisance factors. The second analysis, for detecting disease state, used the green and magenta wells representing 24 experimental subjects (01, …, 24) consisting of 12 healthy subjects and 12 subjects with spinal muscular atrophy [SMA; five with the <italic>survival of motor neuron 1</italic> (<italic>SMA1</italic>) gene, four with <italic>SMA2</italic>, and three with <italic>SMA3; SMA</italic>* refers to disease type]. Unused wells were filled with media but contained no cells.</p>
</caption>
<graphic xlink:href="10.1177_2472555219857715-fig1"></graphic>
</fig>
<p>Cell plating and staining were performed as described in the pilot experiment. One difference in experimental design was a shift to confocal imaging with multiple z-stacks, which was deemed necessary due to focus issues detected in the pilot that are described in the Results section. Since the Phenix uses four excitation lasers in confocal mode and the Cell Painting assay requires five channels, we shifted to the Yokogawa CV7000 operating with the CellVoyager Measurement System (version R1.17.06; Yokogawa, Tokyo, Japan) software and a robotic arm (BiNEDx; PAA Automation, Farnborough, UK) for handling multiple plates, controlled by the Wako Automation Software Suite (FUJIFILM Wako, Mountain View, CA). Image acquisition was performed with a 0.75 NA 20× objective, producing 2560×2160 resolution images. For Hoechst, laser excitation at 405 nm with the emission filter at 445/45 nm was used; for SYTO 14, 488 nm and 600/37 nm; for A 488, 488 nm and 525/20 nm; for Phalloidin 568, 561 nm and 600/37 nm; and for MitoTracker, 640 nm and 676/29 nm; Hoechst and MitoTracker were acquired simultaneously. Thirty-five nonoverlapping confocal images with five planes at 2 µm steps were acquired from each well for maximal coverage. For each site and channel, these z-stacked images were converted into a maximum-intensity projection image for analysis. Image processing and cell segmentation were performed as described above. To support exploration of various signals using traditional machine learning approaches, we either converted segmented cells into one-dimensional embeddings or used raw images for exploration of disease signals, as represented in the schema in <xref ref-type="fig" rid="fig2-2472555219857715">
<bold>Figure 2</bold>
</xref>.</p>
<fig id="fig2-2472555219857715" orientation="portrait" position="float">
<label>Figure 2.</label>
<caption>
<p>Flow chart of three primary data analysis methods used. (Upper left) For the first two approaches, a pre-trained convolutional neural network (CNN) is used for dimensionality reduction to produce 320-dimensional (320D) cell embeddings (i.e., a numeric vector with length 320) for each segmented five-channel image of a cell. A vector with the median value throughout each dimension is used to produce one embedding (e.g., 320D point) per well, after which either T-distributed stochastic neighbor embedding (t-SNE) is used to further reduce the dimensionality such that each well is represented as a two-dimensional (2D) point for visualization, or a random forest classifier is trained to identify nuisance factors. (Bottom left) The final approach utilized the original cellular images labeled with healthy or disease status from which we trained a CNN to predict disease state.</p>
</caption>
<graphic xlink:href="10.1177_2472555219857715-fig2"></graphic>
</fig>
</sec>
<sec id="section9-2472555219857715">
<title>Image-Embedding Generation</title>
<p>Compared to engineered image feature approaches, image embeddings require less manual parameter tuning, especially if a pretrained model is used, and they have outperformed engineered features in their predictive power.<sup><xref ref-type="bibr" rid="bibr26-2472555219857715">26</xref></sup> To obtain image embeddings, each individual 256×256 channel image of a cell was first converted into an 8-bit RGB (red-green-blue) image. Next, we extracted features and activations from the penultimate, fully connected layer of a CNN.<sup><xref ref-type="bibr" rid="bibr28-2472555219857715">28</xref></sup> In this work, we used Inception architecture<sup><xref ref-type="bibr" rid="bibr24-2472555219857715">24</xref></sup> pre-trained on the ImageNet object recognition dataset<sup><xref ref-type="bibr" rid="bibr25-2472555219857715">25</xref></sup> containing about 1.2 million images of a thousand categories of objects. Each 256×256×3 single-channel RGB image is propagated through the Inception network, and the embeddings from the penultimate layer of the network are projected to a 64-dimensional vector (i.e., 64×1×1).<sup><xref ref-type="bibr" rid="bibr26-2472555219857715">26</xref></sup> Concatenating the five vectors from the five individual fluorescence channels for a particular 256×256 crop yielded a 320-dimensional (320D) vector (i.e., 320×1×1), also known as an embedding.<sup><xref ref-type="bibr" rid="bibr26-2472555219857715">26</xref></sup></p>
</sec>
<sec id="section10-2472555219857715">
<title>Modeling and Data Analysis</title>
<p>We conducted three types of analyses on the data from the disease-focused set of experiments. For the T-distributed stochastic neighbor embedding (t-SNE) dimension reduction<sup><xref ref-type="bibr" rid="bibr37-2472555219857715">37</xref></sup> analysis, an exploratory unsupervised learning approach, the median 320D embedding vector among all cells in each well was taken to represent that particular well (i.e., for each dimension, the median among all cells was computed), and the t-SNE algorithm was run on the collection of well-median embeddings from all 24 experimental subjects using default settings (perplexity = 30.0, early exaggeration = 12.0, learning rate 200, 1000 iterations), to produce a transformation into a two-dimensional space. To unveil dominant variations other than the batch/plate type effect, we also applied the t-SNE algorithm to embeddings in each batch separately.</p>
<p>In the next analysis with the random forest classifier, we sought to quantify the ability to predict certain nuisance signals using a supervised learning analysis. We similarly started with a collection of well-median embeddings, but focused on a subset of wells corresponding to three control subjects. We then selected a subset of well embeddings that enabled us to balance the number of samples representing each nuisance strata. For each nuisance factor (plate, column, or row), the embeddings were randomly divided into three sets (folds), and a random forest estimator (with 100 base estimators) was fit and evaluated using threefold cross-validation, yielding an average prediction accuracy. To estimate a baseline accuracy, we randomly permuted labels<sup><xref ref-type="bibr" rid="bibr38-2472555219857715">38</xref></sup> of each nuisance factor before fitting a random forest estimator. The random permutation is supposed to destroy the dependency between embeddings and the nuisance factor, so that the prediction accuracy can be used as a baseline as if there were no nuisance factor at all. Because we sought to only reveal the existence of nuisance signals rather than maximize prediction accuracy, we used this random forest model rather than a DNN.</p>
<p>Finally, to assess predictions of SMA, we used three types of models. The first two methods, random forest (with 100 base estimators) and logistic regression, were trained using the image embeddings, similarly to the approach used to explore nuisance signals. The third, a CNN, was trained directly on the 256×256 cell images. We decided to test CNNs as an additional method because they have achieved expert-level performance in identifying many disease types, including diabetic retinopathy,<sup><xref ref-type="bibr" rid="bibr39-2472555219857715">39</xref></sup> skin cancer,<sup><xref ref-type="bibr" rid="bibr40-2472555219857715">40</xref></sup> and breast cancer.<sup><xref ref-type="bibr" rid="bibr41-2472555219857715">41</xref></sup> CNNs<sup><xref ref-type="bibr" rid="bibr42-2472555219857715">42</xref></sup> operate directly on raw images and implicitly learn features necessary for the final classification task. In this study, we used a seven-layer CNN architecture with a two-class prediction head containing softmax scores. The model was trained for about 100 epochs, or 900,000 steps, using a batch size of 32. Given that the embeddings were generated using the model pre-trained on consumer data, it is likely that they may capture the information contained in the images differently from the CNN model that was trained on the images directly. For all the models, we conducted 12-fold cross-validation on the 12 age-matched pairs of experimental subjects, with one healthy subject and one with SMA in each pair. The prediction for each well is taken to be the mean of the predicted probabilities among all cell images in that well, and the area under the receiver operating characteristic (ROC) curve (or AUC) was evaluated on well-level predictions for the pair of subjects.</p>
</sec>
</sec>
<sec id="section11-2472555219857715" sec-type="results">
<title>Results</title>
<sec id="section12-2472555219857715">
<title>Focus Quality Analysis</title>
<p>In our pilot experiment, we acquired single z-plane widefield fluorescence images from all wells of the 96-well plates. Thirty-seven nonoverlapping single z-plane widefield sites were imaged in each well. Example images of each channel are presented in <xref ref-type="fig" rid="fig3-2472555219857715">
<bold>Figure 3a</bold>
</xref>. Using the pre-trained DNN model described in Yang et al.,<sup><xref ref-type="bibr" rid="bibr21-2472555219857715">21</xref></sup> we objectively and comprehensively assessed focus quality for every cell in the DAPI channel. The results are presented in <xref ref-type="fig" rid="fig3-2472555219857715">
<bold>Figure 3b</bold>
</xref>. The average focus score throughout all cells in a site image is represented as a colored pixel, with the values for sites within a well displayed row by row, starting at the upper left. The arrangement of the sites within each well, as presented in <xref ref-type="fig" rid="fig3-2472555219857715">
<bold>Figure 3b</bold>
</xref>, is not the same as the physical layout of the sites. We observed degraded focus quality toward the edges of the plates, as can be confirmed with visual inspection of images in <bold><xref ref-type="fig" rid="fig3-2472555219857715">Figure 3c</xref> and <xref ref-type="fig" rid="fig3-2472555219857715">3d</xref></bold>. Although we were unable to attribute it to the particular plate, the microscope, or the interaction of the two, we nevertheless made the decision to carry out the second set of the main experiments with confocal z-stack imaging, using only the inner 60 wells, which resulted in a significant improvement in focus quality, as shown in <xref ref-type="fig" rid="fig3-2472555219857715">
<bold>Figure 3e</bold>
</xref>.</p>
<fig id="fig3-2472555219857715" orientation="portrait" position="float">
<label>Figure 3.</label>
<caption>
<p>Cell Painting example and image focus analyses: (a) images of each stain acquired using Cell Painting; (b) image focus quality analysis as a function of position on six 96-well plates (PerkinElmer ViewPlate) for DAPI stain widefield images; (c) 128×128 crops around randomly sampled cells from well B07; (d) cropped cells from well H01; and (e) image focus quality analysis, similar to (b), but with a different plate type (Cellvis glass) and image acquisition scheme (maximum projections of a confocal z-stack).</p>
</caption>
<graphic xlink:href="10.1177_2472555219857715-fig3"></graphic>
</fig>
</sec>
<sec id="section13-2472555219857715">
<title>Detection of Nuisance Signals</title>
<p>We first took an unsupervised learning approach to see if nuisance signals could be detected. Because it would be computationally difficult to run dimensionality reduction methods on raw image pixels, we used image embeddings from the cell images. <xref ref-type="fig" rid="fig4-2472555219857715">
<bold>Figure 4</bold>
</xref> displays the results of the unsupervised dimensionality reduction conducted using t-SNE. The plots reveal little discernible separation or clustering by subject disease state or by plate number, but significant separation by experimental batch/plate type. These plots suggest that it is important to balance experimental conditions (e.g., subject cell lines) among experimental batches/plate types, and in the extreme case, as in ours, include all experimental conditions on every experimental batch/plate type because any biased distribution may cause partial selectivity due to batch/plate type signal. <ext-link ext-link-type="uri" xlink:href="http://journals.sagepub.com/doi/suppl/10.1177/2472555219857715"><bold>Supplementary Figures 1 and 2</bold></ext-link> display the results of the unsupervised dimensionality reduction conducted using t-SNE for batches/plate types 0 and 1, respectively. The same phenomena were observed as when t-SNE was applied to both batches/plate types.</p>
<fig id="fig4-2472555219857715" orientation="portrait" position="float">
<label>Figure 4.</label>
<caption>
<p>Dimensionality reduction visualization with T-distributed stochastic neighbor embedding (t-SNE) of image embeddings from 24 experimental subjects. Each point represents the median cell image embedding from ~2000 cells in a single well, and the points are colored based on the following: (<bold>a</bold>) column; (<bold>b</bold>) row; (<bold>c</bold>) batch/plate type; (<bold>d</bold>) plate; and (<bold>e</bold>) disease condition.</p>
</caption>
<graphic xlink:href="10.1177_2472555219857715-fig4"></graphic>
</fig>
<p>We next sought to quantify the extent of the nuisance signals present in the data via a supervised learning assessment, as shown in <xref ref-type="fig" rid="fig5-2472555219857715">
<bold>Figure 5</bold>
</xref>. Again, for ease of use, we started with the image embeddings of the cells rather than the raw images, and we used a random forest classifier as a simple baseline test. When using a subset of wells (highlighted in <xref ref-type="fig" rid="fig5-2472555219857715">
<bold>Figure 5a</bold>
</xref>) that have representation balanced among batch/plate type, column, and row, a model can predict (from the image embeddings) columns with 61.9% accuracy compared with 50.1% baseline, and rows with 26.5% accuracy compared with 17.6% baseline, as shown in <bold><xref ref-type="fig" rid="fig5-2472555219857715">Figure 5b</xref> and <xref ref-type="fig" rid="fig5-2472555219857715">5c</xref></bold>. When using the subset of wells highlighted in <xref ref-type="fig" rid="fig5-2472555219857715">
<bold>Figure 5d</bold>
</xref> that are balanced among batch/plate type and plate, a model can predict batch/plate type at 99.2% accuracy versus 50.7% by chance and plate at 39.5% accuracy versus 8.1% by chance, as shown in <bold><xref ref-type="fig" rid="fig5-2472555219857715">Figure 5e</xref> and <xref ref-type="fig" rid="fig5-2472555219857715">5f</xref></bold>. Taken together, these results suggest that these nuisance factors, experimental batch/plate type and position of a well on a plate, can be identified with better-than-chance accuracy and hence likely influence the appearance of cells, motivating the need to be cautious about the distribution of experimental conditions within plates, among plates, and between batches/plate types to ensure that their signals are evenly distributed. These observations confirm that our plate design in <xref ref-type="fig" rid="fig1-2472555219857715">
<bold>Figure 1</bold>
</xref> was warranted, in which we have the experimental conditions (e.g., subject cell lines) distributed among multiple plates and positions on a plate.</p>
<fig id="fig5-2472555219857715" orientation="portrait" position="float">
<label>Figure 5.</label>
<caption>
<p>Supervised learning assessment of nuisance signals. (<bold>a,d</bold>) The subset of wells, highlighted in yellow, corresponding to healthy control subjects (denoted by “C”; “E” denotes experimental subjects) that were selected on all 12 plates from both batches/plate types for analyses. (<bold>b,c,e,f</bold>) Accuracy from a random forest model trained on well-median 320-dimensional embeddings using threefold cross-validation, repeated five times. Error bars denote one standard deviation. Both the unmodified set of embeddings and a “permuted” baseline dataset (the same embeddings but with randomly permuted labels) were evaluated. (<bold>b</bold>) Column and (<bold>c</bold>) row predictions, both using the wells highlighted in (<bold>a</bold>). (<bold>e</bold>) Batch/plate type and (<bold>f</bold>) plate predictions, both using the wells highlighted in (<bold>d</bold>).</p>
</caption>
<graphic xlink:href="10.1177_2472555219857715-fig5"></graphic>
</fig>
</sec>
<sec id="section14-2472555219857715">
<title>Predicting Healthy Subjects versus Subjects with SMA</title>
<p>Finally, we sought to answer the question of whether a model could be trained to identify whether cells from an unseen or unknown subject (e.g., not used to generate the model) were from a healthy or SMA subject. For each instance of each model we evaluated, we trained it on data from 11 pairs of subjects matched by age at biopsy, using the remaining, held-out, 12th pair of subjects to evaluate the prediction accuracy of the model. As before, we started using embeddings with logistic regression and random forest within each batch/plate type, among the batches/plate types, and finally with the combined dataset. The results for logistic regression and random forest are presented in <ext-link ext-link-type="uri" xlink:href="http://journals.sagepub.com/doi/suppl/10.1177/2472555219857715"><bold>Supplementary Figures 3 and 4</bold></ext-link>. Another approach that we took, instead of extracting features and applying a machine learning model to the features, was to evaluate how CNNs, which have become the de facto standard for any image-based classification, would compare. In this work, we evaluate their performance in distinguishing healthy and disease lines. These CNN prediction results are presented in <xref ref-type="fig" rid="fig6-2472555219857715">
<bold>Figure 6</bold>
</xref>. Qualitatively, all attempts at modeling show that disease-relevant features are detectable and yield AUCs generally better than random (0.5 AUC). These results are complicated when compared by formal statistical hypothesis testing, because the reuse of pairs among training datasets makes AUCs as estimators of the model performance correlated to each other. With that caveat in mind, we did attempt to compare among the modeling approaches with summarized boxplots presented in <ext-link ext-link-type="uri" xlink:href="http://journals.sagepub.com/doi/suppl/10.1177/2472555219857715"><bold>Supplementary Figure 5</bold></ext-link>. The mean AUC for the broadest task, in which we trained and tested with batches/plate types 0 and 1, was the highest using the CNN (0.83), followed by random forest (0.77) and logistic regression (0.74). A pattern emerged in the CNN result that was not present in the other methods. In all subject pairs but one, the AUCs are generally significantly better than chance (0.5 AUC); in one subject pair, however, the AUC was generally significantly worse than chance. A closer inspection reveals that this is the only subject pair for which both the healthy and disease cell lines were obtained from the same laboratory source; for all other pairs of subjects, all of the healthy subject cell lines came from one source, and the disease cell lines from the other. As a result, it is possible that the use of raw images combined with the CNN approach revealed that additional information may be detectable from the cell source that is either partially masked by the embeddings or less detectable using the logistic regression or random forest models. For the CNN, it is inconclusive whether our prediction ability in this task is due to true SMA disease signals, because it could be any combination of true SMA disease signals or laboratory source for a particular cell line. A follow-up analysis, shown in <ext-link ext-link-type="uri" xlink:href="http://journals.sagepub.com/doi/suppl/10.1177/2472555219857715"><bold>Supplementary Figure 6</bold></ext-link>, was conducted using the SMA subject line that did not produce positive predictions (subject 14), in which this subject was held out as the test pair with each other healthy individual, totaling an additional 12 trained models. The results show that this subject does not consistently get predicted as either an SMA subject or a healthy control.</p>
<fig id="fig6-2472555219857715" orientation="portrait" position="float">
<label>Figure 6.</label>
<caption>
<p>Convolutional neural network (CNN) performance in predicting disease state <bold>[</bold>i.e., healthy or spinal muscular atrophy (SMA)] of individual cell images from the listed unseen (e.g., not used during model training) subject pairs. The 24 experimental subjects, denoted by a two-digit subject ID, disease state, and lab source (A or B), are grouped into 12 subject pairs. Each bar denotes a CNN trained on images from 11 other pairs of subjects and evaluated on images from an unseen subject pair using the well-level area under the receiver operator characteristic curve (AUC) metric.</p>
</caption>
<graphic xlink:href="10.1177_2472555219857715-fig6"></graphic>
</fig>
</sec>
</sec>
<sec id="section15-2472555219857715" sec-type="discussion">
<title>Discussion</title>
<p>The research described in this article represents a critical step toward the use of machine learning for identification of subtle patterns in data derived from cells from numerous patients. Evidence is provided that inherent properties of cells representing dozens of subjects affected by SMA and matched controls could be identified using solely images of their primary fibroblasts stained to highlight universal cellular features.<sup><xref ref-type="bibr" rid="bibr8-2472555219857715">8</xref></sup> These findings, derived from genetically defined and distinct cohorts, lay a foundation for future studies exploring diseases in which more complex genetic contributions may lead to common cellular phenotypes suggesting similar disease trajectories. It is our hope that our work regarding the establishment of methods and guidelines that minimize the effects of avoidable technical issues associated with these large-scale cell-based assays will empower future studies of other CNS disorders.</p>
<p>In this study, we acquired images from fibroblasts of 27 unique subjects, 12 of which had a genetically confirmed diagnosis of SMA. Their cells were distributed throughout 12 96-well plates in such a way as to permit evaluation of whether subtle signals derived from various sources of study design could be detected by machine learning technologies, while also supporting a study accounting for these features to determine whether prediction of SMA disease state was possible using a trained DNN. Our experiment used the tSNE technique to generate unsupervised clustering of site- (or well-) level aggregated data. The resulting plots clearly showed two clusters. There is a clear separation between batches/plate types, highlighting the necessity for any predictions generated to be insensitive to batch/plate type effects. We note that our median aggregation inevitably may mask valuable information about subpopulations of cells that may exist in each well.</p>
<p>Secondary data analysis leveraged supervised learning techniques to validate the positive prediction of batch/plate type effects and to test whether models could be generated to predict signal derived from plate, row, and column. Our results indicate that it is possible to predict each of these nuisance factors. These findings demonstrate the critical need to distribute cells from each experimental condition (e.g., disease state or subject cell line) uniformly among nuisance factors so that changes in cell appearance associated with said factors do not contribute to the model selectivity for detection of the target (e.g., disease). Based on our findings, we provide a template for distribution of cells lines that we intend to serve as a guide for future studies. Specifically, we suggest the following: even representation of cell lines (or suspected classes) among batch/plate type, plate, location within a plate, cell line source, passage, and subject demographics at sample collection. As the number of subjects increases, transition to higher-number well plate formats will be necessary. That will require additional assay development. Furthermore, we expect that larger studies will require a form of randomization to distribute subject lines among plates. These studies may need a larger number of replicates to ensure that prediction models are not affected by the distribution of subject samples.</p>
<p>Finally, we used our proposed plate design to determine the accuracy of prediction models at predicting disease state when applied to cells from an unseen subject not used to train the model. This was done using 12 pairs of matched SMA subjects and controls. Independent prediction models were generated from data using 11 of those pairs and applied to the remaining. This was done using data within each batch/plate type, from one batch/plate type applied to the other, and with the combined batches/plate types. All three machine learning approaches performed better than random. During visual comparison of the results, a unique pattern emerged with the CNN results. Except for one SMA–control pairing, our prediction models performed well above chance and for many pairings perfectly predicted disease state. An important feature of the pairing that regularly did worse than random in the CNN model is that the SMA line was acquired from the same source as all of the control samples. All other SMA lines were collected as a part of a single study and expanded at the same repository.<sup><xref ref-type="bibr" rid="bibr34-2472555219857715">34</xref>,<xref ref-type="bibr" rid="bibr35-2472555219857715">35</xref></sup> This indicated to us that this cell line either had outlier properties as it related to its SMA status or that selectivity of our CNN model was not solely based on SMA but based on integrated properties of cell source. The logistic regression and random forest models did not show any evidence of cell source having an impact on selectivity. Given the fact that the CNN-based modeling task was the only one to use raw data, it was unsurprising that its selectivity may be derived from different features. The fact that cell source could potentially drive selectivity highlights the need for future studies to ensure sufficient representation from all sources of cells or to use a single source.</p>
<p>In summary, we demonstrated that cell line–specific features could be predicted using images of fibroblasts collected with our study design. That the model was applicable among batches/plate types demonstrated that the detectable differences in batches/plate types driving separation in the unsupervised analyses were independent of what is being selected as SMA, and indicates that this model may be applied with differing resources such as plate or other experimental parameters. This is critical because widespread deployment of a diagnostic prediction model likely will need to accommodate differing resources and expertise at study sites. Future steps will be to explore biologically relevant features that can be studied to reveal the underlying drivers of disease, which could ultimately be targeted with interventions.</p>
<p>We recognize that there are limitations to our study, the most prominent being the lack of uniform distribution of controls and SMA cells from the two different sources. This is something we intend to address in the near future. Even so, we remain confident that while a signal attributable to cell source signal may have affected the SMA selectivity of our model, it reinforces the model’s capability of selecting inherent features of the cells and suggests that the model will be applicable to other comparisons between disease and healthy cells, especially taking into account potential problems we have already highlighted.</p>
<p>In conclusion, our work demonstrates the promise for elucidating subtle patterns representing biologically important cellular features among numerous patient samples. Our findings highlight the importance of designing experiments in such a way so that readily present nuisance signals are not mistaken for real signals. Collectively, because of the exquisite sensitivity of the model to exogenous factors of study design and potentially cell source, we hope to motivate more controlled studies that will demonstrate the ability for machine learning to identify subtle disease-relevant signals in images generated from patient-derived cells. These findings were generated on primary fibroblasts, but we expect the results to apply to more disease-specific cells, such as neurons generated from patient induced pluripotent stem cells (iPSCs).</p>
</sec>
<sec id="section16-2472555219857715" sec-type="supplementary-material" specific-use="figshare">
<title>Supplemental Material</title>
<supplementary-material content-type="local-data" id="suppl1-2472555219857715">
<caption>
<title>Google_Harvard_Fibroblast_SMA_supplementary_6-20-2019 – Supplemental material for Applying Deep Neural Network Analysis to High-Content Image-Based Assays</title>
</caption>
<media xlink:href="Google_Harvard_Fibroblast_SMA_supplementary_6-20-2019.pdf">
<caption>
<p>Click here for additional data file.</p>
</caption>
</media>
<p>Supplemental material, Google_Harvard_Fibroblast_SMA_supplementary_6-20-2019 for Applying Deep Neural Network Analysis to High-Content Image-Based Assays by Samuel J. Yang, Scott L. Lipnick, Nina R. Makhortova, Subhashini Venugopalan, Minjie Fan, Zan Armstrong, Thorsten M. Schlaeger, Liyong Deng, Wendy K. Chung, Liadan O’Callaghan, Anton Geraschenko, Dosh Whye, Marc Berndl, Jon Hazard, Brian Williams, Arunachalam Narayanaswamy, D. Michael Ando, Philip Nelson and Lee L. Rubin in SLAS Discovery</p>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We would like to acknowledge Silvia Piccinotti for her help expanding cells and assistance editing this article. We acknowledge Steve Finkbeiner and Steve Perrin for helpful discussions, and Shan Carter for help with visualization.</p>
</ack>
<fn-group>
<fn fn-type="supplementary-material">
<p>Supplemental material is available online with this article.</p>
</fn>
<fn fn-type="other">
<p><bold>Data Availability:</bold> The image datasets generated and analyzed in this study are not publicly available due to subject privacy.</p>
</fn>
<fn fn-type="con">
<p><bold>Author Contributions:</bold>
<italic>Conceptualization</italic>: S.J.Y., M.B., D.M.A., P.N., S.L.L., L.L.R. <italic>Data curation</italic>: S.J.Y., Z.A., S.L.L. <italic>Formal analysis</italic>: S.J.Y., S.V., M.F., A.N., S.L.L. <italic>Funding acquisition</italic>: J.H., P.N., S.L.L., L.L.R., W.K.C. <italic>Investigation</italic>: S.L.L., N.R.M., D.W., T.M.S., L.D. <italic>Methodology</italic>: S.J.Y., S.V., M.F., A.N., M.B., D.M.A., S.L.L., N.R.M., L.L.R. <italic>Project administration</italic>: S.J.Y., J.H., S.L.L. <italic>Resources</italic>: P.N., N.R.M., D.W., T.M.S., L.D. <italic>Software</italic>: S.J.Y., S.V., M.F., A.N., Z.A., B.W., A.G., L.O. <italic>Supervision</italic>: L.O., D.M.A., P.N., L.L.R., W.K.C. <italic>Validation</italic>: S.J.Y., S.V., S.L.L. <italic>Visualization</italic>: S.J.Y., Z.A., S.L.L. <italic>Writing—original draft preparation</italic>: S.J.Y., S.L.L. <italic>Writing—review and editing</italic>: S.J.Y., M.F., S.L.L.</p>
</fn>
<fn fn-type="COI-statement">
<p><bold>Declaration of Conflicting Interests:</bold> The authors declared the following potential conflicts of interest with respect to the research, authorship, and/or publication of this article: S.J.Y., S.V., M.F., Z.A., L.O., A.G., M.B., J.H., B.W., A.N., D.A.M., and P.N. are employees of Google and own Alphabet stock.</p>
</fn>
<fn fn-type="financial-disclosure">
<p><bold>Funding:</bold> The authors disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: Financial support for this work came from Google and by the SMA Foundation (L.L.R.), National Institute of Neurological Disorders and Stroke grant P01 NS066888 (L.L.R.), the Harvard Stem Cell Institute (L.L.R.), and the MGH Center for Assessment Technology and Continuous Health (S.L.L.).</p>
</fn>
<fn fn-type="other">
<p><bold>ORCID iDs:</bold> Samuel J. Yang <inline-graphic xlink:href="10.1177_2472555219857715-img1.jpg"></inline-graphic>
<ext-link ext-link-type="uri" xlink:href="https://orcid.org/0000-0003-2460-6456">https://orcid.org/0000-0003-2460-6456</ext-link></p>
<p>Subhashini Venugopalan <inline-graphic xlink:href="10.1177_2472555219857715-img1.jpg"></inline-graphic>
<ext-link ext-link-type="uri" xlink:href="https://orcid.org/0000-0003-3729-8456">https://orcid.org/0000-0003-3729-8456</ext-link></p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="bibr1-2472555219857715">
<label>1</label>
<mixed-citation publication-type="journal">
<collab>GBD 2015 Neurological Disorders Collaborator Group</collab>. <article-title>Global, Regional, and National Burden of Neurological Disorders during 1990–2015: A Systematic Analysis for the Global Burden of Disease Study 2015</article-title>. <source/>Lancet Neurol. <year>2017</year>, <volume>16</volume>, <fpage>877</fpage>–<lpage>897</lpage>.<pub-id pub-id-type="pmid">28931491</pub-id></mixed-citation>
</ref>
<ref id="bibr2-2472555219857715">
<label>2</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Nalls</surname><given-names>M. A.</given-names></name><name><surname>Blauwendraat</surname><given-names>C.</given-names></name><name><surname>Vallerga</surname><given-names>C. L.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Parkinson’s Disease Genetics: Identifying Novel Risk Loci, Providing Causal Insights and Improving Estimates of Heritable Risk</article-title>. <source/>bioRxiv. <year>2018</year>
<pub-id pub-id-type="doi">10.1101/388165</pub-id>.</mixed-citation>
</ref>
<ref id="bibr3-2472555219857715">
<label>3</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Pardiñas</surname><given-names>A. F.</given-names></name><name><surname>Holmans</surname><given-names>P.</given-names></name><name><surname>Pocklington</surname><given-names>A. J.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Common Schizophrenia Alleles Are Enriched in Mutation-Intolerant Genes and in Regions under Strong Background Selection</article-title>. <source/>Nat. Genet. <year>2018</year>, <volume>50</volume>, <fpage>381</fpage>–<lpage>389</lpage>.<pub-id pub-id-type="pmid">29483656</pub-id></mixed-citation>
</ref>
<ref id="bibr4-2472555219857715">
<label>4</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Harold</surname><given-names>D.</given-names></name><name><surname>Abraham</surname><given-names>R.</given-names></name><name><surname>Hollingworth</surname><given-names>P.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Genome-Wide Association Study Identifies Variants at CLU and PICALM Associated with Alzheimer’s Disease</article-title>. <source/>Nat. Genet. <year>2009</year>, <volume>41</volume>, <fpage>1088</fpage>–<lpage>1093</lpage>.<pub-id pub-id-type="pmid">19734902</pub-id></mixed-citation>
</ref>
<ref id="bibr5-2472555219857715">
<label>5</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Gibbs</surname><given-names>R. M.</given-names></name><name><surname>Lipnick</surname><given-names>S.</given-names></name><name><surname>Bateman</surname><given-names>J. W.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Toward Precision Medicine for Neurological and Neuropsychiatric Disorders</article-title>. <source/>Cell Stem Cell. <year>2018</year>, <volume>23</volume>, <fpage>21</fpage>–<lpage>24</lpage>.<pub-id pub-id-type="pmid">29887317</pub-id></mixed-citation>
</ref>
<ref id="bibr6-2472555219857715">
<label>6</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Scott</surname><given-names>C. T.</given-names></name><name><surname>Caulfield</surname><given-names>T.</given-names></name><name><surname>Borgelt</surname><given-names>E.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Erratum: Personal Medicine—the New Banking Crisis</article-title>. <source/>Nat. Biotechnol. <year>2012</year>, <volume>30</volume>, <fpage>466</fpage>–<lpage>466</lpage>.</mixed-citation>
</ref>
<ref id="bibr7-2472555219857715">
<label>7</label>
<mixed-citation publication-type="confproc">
<person-group person-group-type="author"><name><surname>Kim</surname><given-names>J.-H.</given-names></name><name><surname>Kurtz</surname><given-names>A.</given-names></name><name><surname>Yuan</surname><given-names>B.-Z.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Report of the International Stem Cell Banking Initiative Workshop Activity: Current Hurdles and Progress in Seed-Stock Banking of Human Pluripotent Stem Cells</article-title>. <conf-name>Stem Cell Trans. Med</conf-name>, <year>2017</year>, <volume>6</volume>, <fpage>1956</fpage>–<lpage>1962</lpage>.</mixed-citation>
</ref>
<ref id="bibr8-2472555219857715">
<label>8</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Bray</surname><given-names>M.-A.</given-names></name><name><surname>Singh</surname><given-names>S.</given-names></name><name><surname>Han</surname><given-names>H.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Cell Painting, a High-Content Image-Based Assay for Morphological Profiling Using Multiplexed Fluorescent Dyes</article-title>. <source/>Nat. Protoc. <year>2016</year>, <volume>11</volume>, <fpage>1757</fpage>–<lpage>1774</lpage>.<pub-id pub-id-type="pmid">27560178</pub-id></mixed-citation>
</ref>
<ref id="bibr9-2472555219857715">
<label>9</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name><name><surname>Hinton</surname><given-names>G.</given-names></name></person-group>
<article-title>Deep Learning</article-title>. <source/>Nature. <year>2015</year>, <volume>521</volume>, <fpage>436</fpage>–<lpage>444</lpage>.<pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
</ref>
<ref id="bibr10-2472555219857715">
<label>10</label>
<mixed-citation publication-type="web">
<person-group person-group-type="author"><name><surname>Selvaraju</surname><given-names>R. R.</given-names></name><name><surname>Cogswell</surname><given-names>M.</given-names></name><name><surname>Das</surname><given-names>A.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization</article-title>. <source/>arXiv. <year>2016</year>
<ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1610.02391">https://arxiv.org/abs/1610.02391</ext-link>.</mixed-citation>
</ref>
<ref id="bibr11-2472555219857715">
<label>11</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Horvath</surname><given-names>S.</given-names></name></person-group>
<article-title>DNA Methylation Age of Human Tissues and Cell Types</article-title>. <source/>Genome Biol. <year>2013</year>, <volume>14</volume>, R115.</mixed-citation>
</ref>
<ref id="bibr12-2472555219857715">
<label>12</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Brennand</surname><given-names>K. J.</given-names></name><name><surname>Marchetto</surname><given-names>M. C.</given-names></name><name><surname>Benvenisty</surname><given-names>N.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Creating Patient-Specific Neural Cells for the In Vitro Study of Brain Disorders</article-title>. <source/>Stem Cell Reports. <year>2015</year>, <volume>5</volume>, <fpage>933</fpage>–<lpage>945</lpage>.<pub-id pub-id-type="pmid">26610635</pub-id></mixed-citation>
</ref>
<ref id="bibr13-2472555219857715">
<label>13</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Panchision</surname><given-names>D. M.</given-names></name></person-group>
<article-title>Concise Review: Progress and Challenges in Using Human Stem Cells for Biological and Therapeutics Discovery: Neuropsychiatric Disorders</article-title>. <source/>Stem Cells. <year>2016</year>, <volume>34</volume>, <fpage>523</fpage>–<lpage>536</lpage>.<pub-id pub-id-type="pmid">26840228</pub-id></mixed-citation>
</ref>
<ref id="bibr14-2472555219857715">
<label>14</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Naryshkin</surname><given-names>N. A.</given-names></name><name><surname>Weetall</surname><given-names>M.</given-names></name><name><surname>Dakka</surname><given-names>A.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Motor Neuron Disease. SMN2 Splicing Modifiers Improve Motor Function and Longevity in Mice with Spinal Muscular Atrophy</article-title>. <source/>Science. <year>2014</year>, <volume>345</volume>, <fpage>688</fpage>–<lpage>693</lpage>.<pub-id pub-id-type="pmid">25104390</pub-id></mixed-citation>
</ref>
<ref id="bibr15-2472555219857715">
<label>15</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Konrad</surname><given-names>C.</given-names></name><name><surname>Kawamata</surname><given-names>H.</given-names></name><name><surname>Bredvik</surname><given-names>K. G.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Fibroblast Bioenergetics to Classify Amyotrophic Lateral Sclerosis Patients</article-title>. <source/>Mol. Neurodegener. <year>2017</year>, <volume>12</volume>, <fpage>76</fpage>.<pub-id pub-id-type="pmid">29065921</pub-id></mixed-citation>
</ref>
<ref id="bibr16-2472555219857715">
<label>16</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Schmunk</surname><given-names>G.</given-names></name><name><surname>Boubion</surname><given-names>B. J.</given-names></name><name><surname>Smith</surname><given-names>I. F.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Shared Functional Defect in IP3R-Mediated Calcium Signaling in Diverse Monogenic Autism Syndromes</article-title>. <source/>Transl. Psychiatry. <year>2015</year>, <volume>5</volume>, <fpage>e643</fpage>–<lpage>e643</lpage>.<pub-id pub-id-type="pmid">26393489</pub-id></mixed-citation>
</ref>
<ref id="bibr17-2472555219857715">
<label>17</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Schmunk</surname><given-names>G.</given-names></name><name><surname>Nguyen</surname><given-names>R. L.</given-names></name><name><surname>Ferguson</surname><given-names>D. L.</given-names></name></person-group>, <etal>et al</etal>
<article-title>High-Throughput Screen Detects Calcium Signaling Dysfunction in Typical Sporadic Autism Spectrum Disorder</article-title>. <source/>Sci. Rep. <year>2017</year>, <volume>7</volume>, <fpage>40740</fpage>.<pub-id pub-id-type="pmid">28145469</pub-id></mixed-citation>
</ref>
<ref id="bibr18-2472555219857715">
<label>18</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Q.</given-names></name><name><surname>Yen</surname><given-names>A.</given-names></name><name><surname>Rymarczyk</surname><given-names>G.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Impairment of PARK14-Dependent Ca2 Signalling Is a Novel Determinant of Parkinson’s Disease</article-title>. <source/>Nat. Commun. <year>2016</year>, <source/>7.</mixed-citation>
</ref>
<ref id="bibr19-2472555219857715">
<label>19</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Teves</surname><given-names>J. M. Y.</given-names></name><name><surname>Bhargava</surname><given-names>V.</given-names></name><name><surname>Kirwan</surname><given-names>K. R.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Parkinson’s Disease Skin Fibroblasts Display Signature Alterations in Growth, Redox Homeostasis, Mitochondrial Function, and Autophagy</article-title>. <source/>Front. Neurosci. <year>2017</year>, <volume>11</volume>, <fpage>737</fpage>.<pub-id pub-id-type="pmid">29379409</pub-id></mixed-citation>
</ref>
<ref id="bibr20-2472555219857715">
<label>20</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Shamir</surname><given-names>L.</given-names></name></person-group>
<article-title>Assessing the Efficacy of Low-Level Image Content Descriptors for Computer-Based Fluorescence Microscopy Image Analysis</article-title>. <source/>J. Microsc. <year>2011</year>, <volume>243</volume>, <fpage>284</fpage>–<lpage>292</lpage>.<pub-id pub-id-type="pmid">21605118</pub-id></mixed-citation>
</ref>
<ref id="bibr21-2472555219857715">
<label>21</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Yang</surname><given-names>S. J.</given-names></name><name><surname>Berndl</surname><given-names>M.</given-names></name><name><surname>Ando</surname><given-names>D. M.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Assessing Microscope Image Focus Quality with Deep Learning</article-title>. <source/>BMC Bioinformatics. <year>2018</year>, <volume>19</volume>, <fpage>77</fpage>.<pub-id pub-id-type="pmid">29540156</pub-id></mixed-citation>
</ref>
<ref id="bibr22-2472555219857715">
<label>22</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Frome</surname><given-names>A.</given-names></name><name><surname>Corrado</surname><given-names>G. S.</given-names></name><name><surname>Shlens</surname><given-names>J.</given-names></name></person-group>, <etal>et al</etal>
<article-title>DeViSE: A Deep Visual-Semantic Embedding Model</article-title>. <source/>Adv. Neural Inf. Process. Syst. <year>2013</year>, <source/>26. <fpage>2121</fpage>–<lpage>2129</lpage>.</mixed-citation>
</ref>
<ref id="bibr23-2472555219857715">
<label>23</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F.</given-names></name><name><surname>Varoquaux</surname><given-names>G.</given-names></name><name><surname>Gramfort</surname><given-names>A.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Scikit-Learn: Machine Learning in Python</article-title>. <source/>J. Mach. Learn. Res. <year>2011</year>, <volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
</ref>
<ref id="bibr24-2472555219857715">
<label>24</label>
<mixed-citation publication-type="confproc">
<person-group person-group-type="author"><name><surname>Szegedy</surname><given-names>C.</given-names></name><name><surname>Vanhoucke</surname><given-names>V.</given-names></name><name><surname>Ioffe</surname><given-names>S.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Rethinking the Inception Architecture for Computer Vision</article-title>. In <conf-name>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</conf-name>, <conf-loc>Las Vegas, NV</conf-loc>, <year>2016</year>.</mixed-citation>
</ref>
<ref id="bibr25-2472555219857715">
<label>25</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Russakovsky</surname><given-names>O.</given-names></name><name><surname>Deng</surname><given-names>J.</given-names></name><name><surname>Su</surname><given-names>H.</given-names></name></person-group>, <etal>et al</etal>
<article-title>ImageNet Large Scale Visual Recognition Challenge</article-title>. <source/>Intl. J. Comp. Vision. <year>2015</year>, <volume>115</volume>, <fpage>211</fpage>–<lpage>252</lpage>.</mixed-citation>
</ref>
<ref id="bibr26-2472555219857715">
<label>26</label>
<mixed-citation publication-type="web">
<person-group person-group-type="author"><name><surname>Ando</surname><given-names>D. M.</given-names></name><name><surname>McLean</surname><given-names>C.</given-names></name><name><surname>Berndl</surname><given-names>M.</given-names></name></person-group>
<article-title>Improving Phenotypic Measurements in High-Content Imaging Screens</article-title>. <source/>bioRxiv. <year>2017</year>
<pub-id pub-id-type="doi">10.1101/161422</pub-id>.</mixed-citation>
</ref>
<ref id="bibr27-2472555219857715">
<label>27</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Rajaraman</surname><given-names>S.</given-names></name><name><surname>Antani</surname><given-names>S. K.</given-names></name><name><surname>Poostchi</surname><given-names>M.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Pre-Trained Convolutional Neural Networks as Feature Extractors toward Improved Malaria Parasite Detection in Thin Blood Smear Images</article-title>. <source/>PeerJ. <year>2018</year>, <volume>6</volume>, e4568.</mixed-citation>
</ref>
<ref id="bibr28-2472555219857715">
<label>28</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Krizhevsky</surname><given-names>A.</given-names></name><name><surname>Sutskever</surname><given-names>I.</given-names></name><name><surname>Hinton</surname><given-names>G. E.</given-names></name></person-group>
<article-title>ImageNet Classification with Deep Convolutional Neural Networks</article-title>. <source/>Commun. ACM. <year>2017</year>, <volume>60</volume>, <fpage>84</fpage>–<lpage>90</lpage>.</mixed-citation>
</ref>
<ref id="bibr29-2472555219857715">
<label>29</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Lefebvre</surname><given-names>S.</given-names></name><name><surname>Bürglen</surname><given-names>L.</given-names></name><name><surname>Reboullet</surname><given-names>S.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Identification and Characterization of a Spinal Muscular Atrophy-Determining Gene</article-title>. <source/>Cell. <year>1995</year>, <volume>80</volume>, <fpage>155</fpage>–<lpage>165</lpage>.<pub-id pub-id-type="pmid">7813012</pub-id></mixed-citation>
</ref>
<ref id="bibr30-2472555219857715">
<label>30</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Swoboda</surname><given-names>K. J.</given-names></name><name><surname>Prior</surname><given-names>T. W.</given-names></name><name><surname>Scott</surname><given-names>C. B.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Natural History of Denervation in SMA: Relation to Age, SMN2 Copy Number, and Function</article-title>. <source/>Ann. Neurol. <year>2005</year>, <volume>57</volume>, <fpage>704</fpage>–<lpage>712</lpage>.<pub-id pub-id-type="pmid">15852397</pub-id></mixed-citation>
</ref>
<ref id="bibr31-2472555219857715">
<label>31</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Makhortova</surname><given-names>N. R.</given-names></name><name><surname>Hayhurst</surname><given-names>M.</given-names></name><name><surname>Cerqueira</surname><given-names>A.</given-names></name></person-group>, <etal>et al</etal>
<article-title>A Screen for Regulators of Survival of Motor Neuron Protein Levels</article-title>. <source/>Nat. Chem. Biol. <year>2011</year>, <volume>7</volume>, <fpage>544</fpage>–<lpage>552</lpage>.<pub-id pub-id-type="pmid">21685895</pub-id></mixed-citation>
</ref>
<ref id="bibr32-2472555219857715">
<label>32</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Hamilton</surname><given-names>G.</given-names></name><name><surname>Gillingwater</surname><given-names>T. H.</given-names></name></person-group>
<article-title>Spinal Muscular Atrophy: Going beyond the Motor Neuron</article-title>. <source/>Trends Mol. Med. <year>2013</year>, <volume>19</volume>, <fpage>40</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">23228902</pub-id></mixed-citation>
</ref>
<ref id="bibr33-2472555219857715">
<label>33</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Ng</surname><given-names>S.-Y.</given-names></name><name><surname>Soh</surname><given-names>B. S.</given-names></name><name><surname>Rodriguez-Muela</surname><given-names>N.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Genome-Wide RNA-Seq of Human Motor Neurons Implicates Selective ER Stress Activation in Spinal Muscular Atrophy</article-title>. <source/>Cell Stem Cell
<year>2015</year>, <volume>17</volume>, <fpage>569</fpage>–<lpage>584</lpage>.<pub-id pub-id-type="pmid">26321202</pub-id></mixed-citation>
</ref>
<ref id="bibr34-2472555219857715">
<label>34</label>
<mixed-citation publication-type="book">
<person-group person-group-type="author"><name><surname>Allen</surname><given-names>T.</given-names></name></person-group>
<source/>Living with Spinal Muscular Atrophy: The True Story of Kassidy Jade Sears. <publisher-loc>iUniverse, Inc.</publisher-loc>: <publisher-name>Bloomington, IN</publisher-name>, <year>2006</year>.</mixed-citation>
</ref>
<ref id="bibr35-2472555219857715">
<label>35</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Kaufmann</surname><given-names>P.</given-names></name><name><surname>McDermott</surname><given-names>M. P.</given-names></name><name><surname>Darras</surname><given-names>B. T.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Prospective Cohort Study of Spinal Muscular Atrophy Types 2 and 3</article-title>. <source/>Neurology. <year>2012</year>, <volume>79</volume>, <fpage>1889</fpage>–<lpage>1897</lpage>.<pub-id pub-id-type="pmid">23077013</pub-id></mixed-citation>
</ref>
<ref id="bibr36-2472555219857715">
<label>36</label>
<mixed-citation publication-type="book">
<collab>Coriell Institute for Medical Research. Fibroblast Culture FAQ. Form 1302-16 Rev H-113017</collab>. <publisher-name>Coriell Institute for Medical Research</publisher-name>: <publisher-loc>Camden, NJ</publisher-loc>, <year>2019</year>.</mixed-citation>
</ref>
<ref id="bibr37-2472555219857715">
<label>37</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Maaten</surname><given-names>L. V. D.</given-names></name><name><surname>Hinton</surname><given-names>G.</given-names></name></person-group>
<article-title>Visualizing Data Using T-SNE</article-title>. <source/>J. Mach. Learn. Res. <volume>2008</volume>, <fpage>2579</fpage>–<lpage>2605</lpage>.</mixed-citation>
</ref>
<ref id="bibr38-2472555219857715">
<label>38</label>
<mixed-citation publication-type="confproc">
<person-group person-group-type="author"><name><surname>Ojala</surname><given-names>M.</given-names></name><name><surname>Garriga</surname><given-names>G. C.</given-names></name></person-group>
<article-title>Permutation Tests for Studying Classifier Performance</article-title>. In <conf-name>2009 Ninth IEEE International Conference on Data Mining</conf-name>, <conf-loc>Miami, FL</conf-loc>, <year>2009</year>.</mixed-citation>
</ref>
<ref id="bibr39-2472555219857715">
<label>39</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Gulshan</surname><given-names>V.</given-names></name><name><surname>Peng</surname><given-names>L.</given-names></name><name><surname>Coram</surname><given-names>M.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs</article-title>. <source/>JAMA. <year>2016</year>, <volume>316</volume>, <fpage>2402</fpage>–<lpage>2410</lpage>.<pub-id pub-id-type="pmid">27898976</pub-id></mixed-citation>
</ref>
<ref id="bibr40-2472555219857715">
<label>40</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Esteva</surname><given-names>A.</given-names></name><name><surname>Kuprel</surname><given-names>B.</given-names></name><name><surname>Novoa</surname><given-names>R. A.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Dermatologist-Level Classification of Skin Cancer with Deep Neural Networks</article-title>. <source/>Nature. <year>2017</year>, <volume>542</volume>, <fpage>115</fpage>–<lpage>118</lpage>.<pub-id pub-id-type="pmid">28117445</pub-id></mixed-citation>
</ref>
<ref id="bibr41-2472555219857715">
<label>41</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Gadepalli</surname><given-names>K.</given-names></name><name><surname>Norouzi</surname><given-names>M.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Detecting Cancer Metastases on Gigapixel Pathology Images</article-title>. <source/>arXiv. <year>2017</year>
<ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/">https://arxiv.org/abs/</ext-link>
<volume>1703</volume>.02442.</mixed-citation>
</ref>
<ref id="bibr42-2472555219857715">
<label>42</label>
<mixed-citation publication-type="journal">
<person-group person-group-type="author"><name><surname>Lecun</surname><given-names>Y.</given-names></name><name><surname>Bottou</surname><given-names>L.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name></person-group>, <etal>et al</etal>
<article-title>Gradient-Based Learning Applied to Document Recognition</article-title>. <source/>Proceedings of the IEEE, <year>1998</year>, <volume>86</volume>, <fpage>2278</fpage>–<lpage>2324</lpage>.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
</pmc-articleset>