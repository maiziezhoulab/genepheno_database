<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="research-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<?properties manuscript?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-journal-id">0410462</journal-id>
<journal-id journal-id-type="pubmed-jr-id">6011</journal-id>
<journal-id journal-id-type="nlm-ta">Nature</journal-id>
<journal-id journal-id-type="iso-abbrev">Nature</journal-id>
<journal-title-group>
<journal-title>Nature</journal-title>
</journal-title-group>
<issn pub-type="ppub">0028-0836</issn>
<issn pub-type="epub">1476-4687</issn>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">28700580</article-id>
<article-id pub-id-type="pmc">5842695</article-id>
<article-id pub-id-type="doi">10.1038/nature22999</article-id>
<article-id pub-id-type="manuscript">NIHMS879771</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Infant viewing of social scenes is under genetic control and atypical in autism</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Constantino</surname>
<given-names>John N.</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
<xref ref-type="aff" rid="A2">2</xref>
<xref ref-type="aff" rid="A3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kennon-McGill</surname>
<given-names>Stefanie</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Weichselbaum</surname>
<given-names>Claire</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Marrus</surname>
<given-names>Natasha</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
<xref ref-type="aff" rid="A3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Haider</surname>
<given-names>Alyzeh</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Glowinski</surname>
<given-names>Anne L.</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gillespie</surname>
<given-names>Scott</given-names>
</name>
<xref ref-type="aff" rid="A4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Klaiman</surname>
<given-names>Cheryl</given-names>
</name>
<xref ref-type="aff" rid="A5">5</xref>
<xref ref-type="aff" rid="A6">6</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Klin</surname>
<given-names>Ami</given-names>
</name>
<xref ref-type="aff" rid="A5">5</xref>
<xref ref-type="aff" rid="A6">6</xref>
<xref ref-type="aff" rid="A7">7</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Jones</surname>
<given-names>Warren</given-names>
</name>
<xref ref-type="aff" rid="A5">5</xref>
<xref ref-type="aff" rid="A6">6</xref>
<xref ref-type="aff" rid="A7">7</xref>
</contrib>
</contrib-group>
<aff id="A1">
<label>1</label>Department of Psychiatry, Washington University, St. Louis, MO</aff>
<aff id="A2">
<label>2</label>Department of Pediatrics, Washington University, St. Louis, MO</aff>
<aff id="A3">
<label>3</label>Intellectual and Developmental Disabilities Research Center, Washington University, St. Louis, MO</aff>
<aff id="A4">
<label>4</label>Pediatric Biostatistics Core, Emory University School of Medicine, Atlanta, GA</aff>
<aff id="A5">
<label>5</label>Marcus Autism Center, Children’s Healthcare of Atlanta, Atlanta, GA</aff>
<aff id="A6">
<label>6</label>Division of Autism &amp; Related Disabilities, Department of Pediatrics, Emory University School of Medicine, Atlanta, GA</aff>
<aff id="A7">
<label>7</label>Center for Translational Social Neuroscience, Emory University, Atlanta, GA</aff>
<author-notes>
<corresp id="FN1">Correspondence and requests for materials should be addressed to W.J. (<email>warren.jones@emory.edu</email>) or J.N.C. (<email>constantino@wustl.edu</email>)</corresp>
</author-notes>
<pub-date pub-type="nihms-submitted">
<day>10</day>
<month>10</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="epub">
<day>12</day>
<month>7</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="ppub">
<day>20</day>
<month>7</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="pmc-release">
<day>08</day>
<month>3</month>
<year>2018</year>
</pub-date>
<volume>547</volume>
<issue>7663</issue>
<fpage>340</fpage>
<lpage>344</lpage>
<!--elocation-id from pubmed: 10.1038/nature22999-->
<permissions>
<license>
<license-p>Users may view, print, copy, and download text and data-mine the content in such documents, for the purposes of academic research, subject always to the full Conditions of use:
<uri xlink:href="http://www.nature.com/authors/editorial_policies/license.html#terms" xlink:type="simple">http://www.nature.com/authors/editorial_policies/license.html#terms</uri></license-p>
</license>
<license license-type="permissions-link">
<license-p>Reprints and permissions information is available at <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/reprints">www.nature.com/reprints</ext-link>.</license-p>
</license>
</permissions>
<abstract>
<p id="P1">Long before infants reach, crawl, or walk, they explore the world by looking: they look to learn and to engage<sup><xref ref-type="bibr" rid="R1">1</xref></sup>, giving preferential attention to social stimuli including faces<sup><xref ref-type="bibr" rid="R2">2</xref></sup>, face-like stimuli<sup><xref ref-type="bibr" rid="R3">3</xref></sup>, and biological motion<sup><xref ref-type="bibr" rid="R4">4</xref></sup>. This capacity—social visual engagement—shapes typical infant development from birth<sup><xref ref-type="bibr" rid="R5">5</xref></sup> and is pathognomonically impaired in children affected by autism<sup><xref ref-type="bibr" rid="R6">6</xref></sup>. Here we show that variation in viewing of social scenes—including levels of preferential attention and the timing, direction, and targeting of individual eye movements—is strongly influenced by genetic factors, with effects directly traceable to the active seeking of social information<sup><xref ref-type="bibr" rid="R7">7</xref></sup>. In a series of eye-tracking experiments conducted with 338 toddlers—including 166 epidemiologically-ascertained twins, 88 non-twins with autism, and 84 singleton controls—we find high monozygotic twin-twin concordance (0.91) and relatively low dizygotic concordance (0.35). Moreover, the measures that are most highly heritable, preferential attention to eye and mouth regions of the face, are also those that are differentially diminished in children with autism (<italic>Χ</italic><sup>2</sup>=64.03, <italic>P</italic>&lt;0.0001). These results—which implicate social visual engagement as a neurodevelopmental endophenotype—not only for autism, but for population-wide variation in social-information-seeking<sup><xref ref-type="bibr" rid="R8">8</xref></sup>—reveal a means of human biological niche construction, with phenotypic differences emerging from the interaction of individual genotypes with early life experience<sup><xref ref-type="bibr" rid="R7">7</xref></sup>.</p>
</abstract>
</article-meta>
</front>
<body>
<p id="P2">Despite evidence that autism is among the most highly heritable of neuropsychiatric conditions<sup><xref ref-type="bibr" rid="R9">9</xref></sup>, with a majority of genetic risk attributable to common (polygenic) factors<sup><xref ref-type="bibr" rid="R10">10</xref>,<xref ref-type="bibr" rid="R11">11</xref></sup>, its neurobiological mechanisms remain unknown<sup><xref ref-type="bibr" rid="R12">12</xref></sup>. Autism is instead defined behaviorally, by atypical trajectories of social development<sup><xref ref-type="bibr" rid="R6">6</xref></sup> that can result in profound impairments in social-communicative function<sup><xref ref-type="bibr" rid="R13">13</xref></sup> and poor inclusion in wider societies that are often less-than-tolerant<sup><xref ref-type="bibr" rid="R14">14</xref></sup>. Atypical social visual engagement is observable within the first 6 months in infants later diagnosed with autism<sup><xref ref-type="bibr" rid="R6">6</xref></sup> and carries forward through later life<sup><xref ref-type="bibr" rid="R15">15</xref>,<xref ref-type="bibr" rid="R16">16</xref></sup>.</p>
<p id="P3">In the present study, as an entry to understanding the genetic structure of factors affecting normative social development—factors that may be influenced by common genetic variation in the population at-large and are disrupted, at the extreme, in autism—we examined patterns of concordance in how children visually engage with (look at) caregivers<sup><xref ref-type="bibr" rid="R6">6</xref></sup> and peers<sup><xref ref-type="bibr" rid="R15">15</xref></sup> in social interaction (<xref ref-type="fig" rid="F5">Extended Data Figure 1a</xref>; Methods). We examined pairwise concordance in social visual engagement as a function of zygosity, collecting eye-tracking data from 82 monozygotic twins (MZ, 41 pairs), 84 dizygotic twins (DZ, 42 pairs), and 84 non-siblings (42 randomized pairs). We established measurement stability over 15 months, and assessed the measures as an endophenotype for social disability, testing 88 toddlers with autism spectrum disorder (ASD) in comparison and replication cohorts (N=43, N=45).</p>
<p id="P4">In experiment 1, we measured macro-level indices of social visual engagement, calculating percentages of time spent looking at eye and mouth regions (<xref ref-type="fig" rid="F5">Extended Data Figure 1b,c</xref>). In experiment 2, we measured micro-level indices, testing for concordance—on timescales of tens of milliseconds—in timing of eye movements, in direction of eye movements, and in the collocation of contemporaneous visual fixations. We also tested whether observed concordance could be partitioned into variation reflecting either stimulus response<sup><xref ref-type="bibr" rid="R17">17</xref></sup> (responding to specific features of the exact stimulus presented) or goal-directed action<sup><xref ref-type="bibr" rid="R18">18</xref></sup> (individual differences in seeking social information).</p>
<p id="P5">Trait heritability was estimated according to the classic twin design, with epidemiologically-ascertained samples of MZ and DZ twins, together with a sample of non-siblings. Non-siblings had no familial biological relationship to one another, lived apart, and were compared with twins in two ways: individually matched on sex and age (mean(SD) age difference: 0.99(0.27) days) and randomly matched in 10,000 re-samplings without replacement<sup><xref ref-type="bibr" rid="R19">19</xref></sup>. We restricted analyses to like-sex twin pairs (inclusion of opposite-sex DZ pairs yielded either no change or accentuation of MZ-DZ differences). For age at time of testing, we selected a dynamic period in typical development, 18–24 months of age (mean(SD)=21.3(4.3) months), coinciding with large shifts in language, cognition, and adaptive behavior<sup><xref ref-type="bibr" rid="R20">20</xref></sup>, and affording wide variation in our trait of interest<sup><xref ref-type="bibr" rid="R6">6</xref></sup> (see Methods).</p>
<p id="P6">We confirmed that groups did not differ significantly in age at time of testing (<italic>F</italic><sub>(2,247)</sub>=2.3, <italic>p</italic>=0.10; MZvs.DZ, <italic>t</italic><sub>164</sub>=1.59, <italic>p</italic>=0.11); participant demographics (<xref ref-type="table" rid="T1">Extended Data Table 1</xref>); calibration accuracy, oculomotor function (<xref ref-type="fig" rid="F6">Extended Data Figure 2</xref>); or percentage of time spent in eye-looking, mouth-looking, or attention to task (<xref ref-type="fig" rid="F5">Extended Data Figure 1d-f</xref>).</p>
<p id="P7">For concordance in eye- and mouth-looking (<xref ref-type="fig" rid="F1">Figure 1d, 1i</xref>), MZ intraclass correlations (ICCs, case 2,1<sup><xref ref-type="bibr" rid="R21">21</xref></sup>) were remarkably high: 0.91 for eyes (95% CI: 0.85–0.95) and 0.86 for mouth (95% CI: 0.76–0.92). This contrasted markedly with DZ correlations: eyes, 0.35(0.07–0.59) and mouth, 0.44(0.16–0.65) (<xref ref-type="fig" rid="F1">Figure 1c, 1h</xref>). In non-siblings, correlations did not differ significantly from zero: either when age- and sex-matched (<xref ref-type="fig" rid="F1">Figure 1b, 1g</xref>) or when randomly-matched (<xref ref-type="fig" rid="F1">Figure 1a, 1f</xref>, <xref ref-type="table" rid="T2">Extended Data Table 2a</xref>). In all groups, within-subject stability (test-retest reliability) was consistently high, indicating ‘trait-like’ stability (<xref ref-type="fig" rid="F7">Extended Data Figure 3</xref>). These results are consistent with broad heritability of 0.86–0.90 for eye- and mouth-looking<sup><xref ref-type="bibr" rid="R22">22</xref></sup>.</p>
<p id="P8">When seen for follow-up 15 months after initial testing, at 36.8(1.7) months (mean(SD)), MZ twins again demonstrated pairwise concordance in eye-looking of 0.93(0.75–0.98), while DZ concordance was 0.25(0.00–0.60) (<xref ref-type="fig" rid="F8">Extended Data Figure 4a-4l</xref> and <xref ref-type="table" rid="T2">Table 2b</xref>, see Methods), indicating strong preservation of genetic influence on social visual engagement over development (<xref ref-type="fig" rid="F8">Extended Data Figure 4m-4n</xref>). Moreover, longitudinal <italic>within-subject stability</italic>—from 21 until 36 months—was high in both groups: equal to ~0.70 (<xref ref-type="fig" rid="F9">Extended Data Figure 5a-5e</xref>).</p>
<p id="P9">To test the specificity of these measures to social engagement, we compared concordance in eye-looking with concordance of two additional indices: time spent looking at non-social content (inanimate objects/background) and time spent attending to task (maintaining stable onscreen fixation<sup><xref ref-type="bibr" rid="R23">23</xref></sup>). In MZ twins, eye-looking was significantly more concordant than non-social object-looking—eyes, 0.91(0.85–0.95) vs. object, 0.66(0.46–0.80)—and more concordant than time spent attending to task, 0.46(0.19–0.67) (<xref ref-type="fig" rid="F1">Figure 1n</xref>). In contrast, in DZ twins, eye-looking (0.35(0.07–0.59)) was not more concordant than either object-looking, 0.09(0.0–0.38), or attention to task, 0.34(0.05–0.58) (<xref ref-type="fig" rid="F1">Figure 1c,h,m</xref>). Similarly, in age- and sex-matched non-siblings, all ICC estimates overlapped (<xref ref-type="fig" rid="F1">Figure 1b,g,l</xref>). While heritable effects of domain general visual attention are likely observable in other contexts, these analyses indicate effects that are differentially social (<xref ref-type="fig" rid="F1">Figure 1e,j,o</xref>).</p>
<p id="P10">In the next experiment, we measured moment-by-moment, micro-level concordance (<xref ref-type="fig" rid="F2">Figures 2a,b</xref>). Macro-level concordance observed in the first experiment does not guarantee micro-level concordance; similarly, micro-level concordance could be present but present too weakly to yield global similarities. Comparison of the two creates an opportunity to test how genetic variation might influence social visual engagement across varying phenomenological timescales.</p>
<p id="P11">We first analyzed concordance in timing of eye movements (<xref ref-type="fig" rid="F2">Figure 2c</xref>). <xref ref-type="supplementary-material" rid="SD5">Data in Supplementary Videos</xref> provide an immediately-appreciable sense of moment-to-moment MZ concordance—weakened substantially in DZ twins—when viewing social scenes. Number and rate of eye movements did not differ significantly by group (~1944 fixations/child: mean(SD) rates of 1.66(0.59) fixations/sec DZ and 1.66(0.49) fixations/sec MZ; all <italic>t</italic>&lt;0.65, <italic>p</italic>&gt;0.20). However, MZ twins demonstrated greater probability of moving their eyes at the same times: for each movement by twin 1, within 350 milliseconds, there was an 18.6% increase in twin 2’s probability of <italic>also</italic> making an eye movement (<xref ref-type="fig" rid="F2">Figure 2d,e</xref>). More surprisingly, when analyses were restricted to moments of motor <italic>initiation</italic> of a saccade (<xref ref-type="fig" rid="F2">Figure 2f</xref>), we observed a 21.1% increase in probability of time-locked eye movements: within +/−16.7 msec, MZ twins, but not DZ twins, initiated saccades at the same moments (<xref ref-type="fig" rid="F2">Figure 2g,h</xref>). These results suggest that MZ toddlers, freely viewing naturalistic social stimuli, may synchronize not only the timing of overt eye movements, but also the activity of neuronal ensembles commonly associated with those movements: activity connecting areas of cortex to brainstem and cranial nerves<sup><xref ref-type="bibr" rid="R23">23</xref>,<xref ref-type="bibr" rid="R24">24</xref></sup>, ultimately resulting in time-locked shifts of gaze<sup><xref ref-type="bibr" rid="R24">24</xref></sup>.</p>
<p id="P12">We next tested for concordance in <italic>direction</italic> of eye movements (<xref ref-type="fig" rid="F2">Figure 2i</xref>). We mined the eye movement data to identify contemporaneous collocated fixations: instances when both twins fixated on the same approximate locations at the same moments. In such cases, twins not only share an approximate fixation location, they share an approximate pattern of retinal irradiance (stimulation of retinal photoreceptors). By identifying these instances, we could then test the probability—given initially shared retinal stimulation—of twins subsequently moving their eyes in the same or different directions. We varied the criteria for collocation from within 1° (<italic>i.e.,</italic> shared stimulation of the rod-free, capillary-free foveola of the retina); to 1.7° (shared stimulation of rod-free fovea); to 5.2° (shared stimulation of whole fovea); to 10° (shared quadrant of visual information); to finally within 15° (‘collocated’ in only the broadest sense of looking at the same hemi-field of the presentation monitor). Across all comparisons (<xref ref-type="fig" rid="F2">Figures 2l</xref>), MZ twins were more likely than DZ twins to shift saccades in more similar subsequent directions (see Methods).</p>
<p id="P13">Next, we compared twins’ probability of fixating on the same social content at the same moments (<xref ref-type="fig" rid="F2">Figure 2m</xref>). If twin 1 and twin 2 both looked at the eyes (or mouth) at the same time, this counted as a ‘hit’ for shared fixation; if twin 1 looked at the eyes when twin 2 looked at the mouth (or vice versa), this counted as a ‘miss’. While both groups show more co-occurring, collocated fixations than chance (<xref ref-type="fig" rid="F2">Figures 2n,o</xref>), MZ twins exhibited greater concordance than DZ (<italic>F</italic><sub>1,81</sub>=4.89, <italic>p</italic>=0.030; <xref ref-type="fig" rid="F2">Figure 2p</xref>).</p>
<p id="P14">In summary, MZ twins exhibit strikingly high concordance in levels of eye-looking; greater probability of shifting their eyes at the same moments in time; greater probability of shifting their eyes in the same subsequent directions; and greater probability of contemporaneously fixating the same semantic content. These high levels of MZ concordance, observed at both macro- and micro-levels, indicate strong biological basis for variation in social visual engagement<sup><xref ref-type="bibr" rid="R7">7</xref></sup>, with a substantial portion of that variation attributable to additive genetic influence. While concordance in micro-level measures was more modest than macro, even modest micro-level concordance marks repeatable shifts in probability: repetition of these shifts—recurring as frequently as every 400–500msec—suggests a striking means by which small probabilistic differences might amount, developmentally, to large eventual effects.</p>
<p id="P15">To further explore potential underlying biological mechanisms, we tested whether observed concordance could be partitioned into variation reflecting either stimulus response<sup><xref ref-type="bibr" rid="R17">17</xref></sup> or goal-directed action<sup><xref ref-type="bibr" rid="R18">18</xref></sup>. This distinction is intriguing because it relates to what aspects of social behavior may be more or less phylogenetically-conserved: have evolutionary pressures favored biological systems that rely on specific responses to particular features of external stimuli (in the manner of feature detectors<sup><xref ref-type="bibr" rid="R25">25</xref></sup>), or have evolutionary pressures favored systems that specialize in particular modes of seeking, internally driven with less direct dependence on the exact stimulus <italic>per se</italic><sup><xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R27">27</xref></sup>? The related question in autism, when social development is disrupted, is whether to focus research on biological determinants related to processing particular social cues (afferent sensory systems) or to the seeking and adaptive usage of such cues (systems subserving social engagement and reciprocity, and the valuation of social stimuli).</p>
<p id="P16">To test this question, we conducted <italic>post-hoc</italic> comparisons capitalizing on two elements of the experimental protocol: because presentation order of video stimuli was randomized (with total duration longer than some toddlers’ willingness to sit), each twin saw a separate set of videos, the majority of which were the same (M(SD)=86.4(19.3)%) but some of which were different (13.6(19.3)%), seen by only one among the pair. Moreover, each twin saw two different categories of video, one emphasizing dyadic mutual gaze (<xref ref-type="fig" rid="F5">Extended Data Fig 1</xref>) and the other triadic peer interaction (<xref ref-type="fig" rid="F10">Extended Data Fig 6</xref>).</p>
<p id="P17">We conducted three tests. For the first, analyses were restricted to measures made only when both twins watched the <italic>same</italic> videos; the null hypothesis held that concordance would be equal (ICC<sub>sameVideos</sub>=ICC<sub>allVideos</sub>), the alternative stated that concordance would be greater (ICC<sub>sameVideos</sub>&gt;ICC<sub>allVideos</sub>). Greater concordance when watching the same videos would evidence stimulus response (more concordant responding given the exact same stimulus). For the second and third tests, analyses were restricted to measures made only when each twin watched <italic>different</italic> videos or <italic>different content categories</italic> of video; the null hypothesis held that concordance would be zero (ICC<sub>differentVideos</sub>=0 and ICC<sub>differentContent</sub>=0), the alternative stated that concordance would be greater than zero (ICC<sub>differentVideos</sub>&gt;0 and ICC<sub>differentContent</sub>&gt;0). Greater-than-zero concordance when each twin watched different videos or different content categories would evidence goal-directed action, less dependent on the exact stimulus (flexibly seeking social information as a form of active niche-picking<sup><xref ref-type="bibr" rid="R7">7</xref></sup>). For each test, we measured levels of eye-looking and quantified physical image properties of all eyes stimuli<sup><xref ref-type="bibr" rid="R28">28</xref></sup> (<xref ref-type="fig" rid="F11">Extended Data Figure 7</xref>).</p>
<p id="P18">In the first test, we were unable to reject the null: concordance when watching the same videos was no greater than concordance when watching all videos (<xref ref-type="fig" rid="F3">Figure 3b,g,l</xref>). In the second test, however, when each twin watched different videos, MZ and DZ concordance was significantly greater than zero (<xref ref-type="fig" rid="F3">Figure 3c,h,m</xref>). And in the third test, when each twin watched different content categories, MZ concordance was significantly greater than zero but DZ concordance was not (<xref ref-type="fig" rid="F3">Figure 3d,i,n</xref>). These results suggest that the relevant biological mechanisms more likely relate to systems subserving goal-directed seeking and valuation of social information.</p>
<p id="P19">Finally, to directly assess the functional significance of these measures, we compared the above results with data from two independent cohorts of toddlers with ASD (<xref ref-type="fig" rid="F4">Figure 4</xref>): one primary comparison sample, N=43, and a second replication sample, N=45 (all consecutive referrals for diagnostic evaluation). In toddlers with ASD, the same measures of social visual engagement that were most highly heritable—eye- and mouth-looking—are markedly reduced (<xref ref-type="fig" rid="F4">Figure 4a-c</xref>), providing a robust index of diagnostic membership (<xref ref-type="fig" rid="F4">Figure 4d-f</xref>, AUCs=0.88(0.84–0.92) and 0.86(0.82–0.91)).</p>
<p id="P20">Taken as a whole, these findings lend insight into the means by which phenotypic differences emerge from the interaction between individual genotypes and individually-experienced environments, theorized decades ago as the means by which children 'make their own environments'<sup><xref ref-type="bibr" rid="R7">7</xref></sup> via developmental successions of reliable and repeated couplings between organism and environment<sup><xref ref-type="bibr" rid="R29">29</xref></sup>. Similar notions have been advanced in phenotypic studies contrasting the experiential development of children with autism and their typically-developing peers<sup><xref ref-type="bibr" rid="R30">30</xref></sup>, yet never heretofore demonstrated as having directly traceable genetic influence. Inherent to the classic twin design is the fact that interactions between genetic and unmeasured environmental factors will be subsumed under the category of additive genetic influence. Although the twins' individual experiences of dynamic social stimuli were markedly influenced by genetic factors—reflecting a form of gene-environment <italic>correlation</italic> influencing their assimilation of standardized social scenes presented in the laboratory—it is likely that earlier life events already interacted with genetic variation, in development of both typical social visual engagement and autism susceptibility. Elucidating mechanisms by which genes interact with experienced (measured) environments is critical for future identification of preventive-intervention targets. The current findings underscore the notion that social visual engagement constitutes a neurodevelopmental endophenotype, not only for autism but for population-wide variation in goal-directed seeking and valuation of social information.</p>
<sec id="S1" sec-type="methods">
<title>METHODS</title>
<p id="P21">This research was based in the Intellectual and Developmental Disabilities Research Center at Washington University and at the Marcus Autism Center, Children’s Healthcare of Atlanta and Emory University School of Medicine. Study protocol was approved by the Washington University School of Medicine Human Research Protection Office (IRB), HRPO #201208010, and by the Emory University Institutional Review Board, IRB00048146. Parents of all participants gave informed consent prior to assessment. Children were shown video scenes of naturalistic caregiver and peer interaction. We measured percentage of visual fixation time to eyes, mouth, body, and object regions (Experiment 1 – macro-level measures of social visual engagement) as well as moment-by-moment variation in timing, direction, and location of eye movements (Experiment 2 – micro-level measures of social visual engagement). Visual scanning was measured with eye-tracking equipment (ISCAN, Inc., Woburn, MA). Analysis of eye movements and coding of fixation data were performed with software written in MATLAB. Data acquisition and processing were performed by experimenters blind to clinical assessment data (zygosity status, diagnosis etc.). Details of participants, experimental procedures, data acquisition, and analysis are provided below.</p>
<sec id="S2" sec-type="subjects">
<title>Participants</title>
<p id="P22">This study protocol was approved by the Washington University School of Medicine (WUSM) Human Research Protection Office (IRB), HRPO #201208010, and by the Emory University Institutional Review Board, IRB00048146. The parents of all participants gave informed consent prior to each assessment. A total of 414 children participated (242 twins, 84 non-sibling comparison children, and 88 children diagnosed with autism spectrum disorder (ASD)).</p>
<p id="P23">The twin sample was epidemiologically ascertained through the Missouri Family Register (MFR), a birth records registry maintained by the WUSM Department of Psychiatry in collaboration with the State of Missouri as described in detail in Marrus et al.<sup><xref ref-type="bibr" rid="R1">1</xref></sup>. Age- and sex-matched non-sibling comparison children (N=84 children, N=42 randomly-assigned pairs, age- and sex-matched within each pair) were recruited from the general population via flyers, direct mailings, and advertisement. Children with ASD were consecutive referrals to a diagnostic clinic (Marcus Autism Center), with experimental procedures collected at the time of each child’s initial diagnosis (N=88 total from two independent cohorts of 43 and 45). The consenting family member was required to be the legal guardian and primary caregiver and to speak fluent English (given both the English language component of the video stimuli and as English is the sole spoken language in 93.9% of Missouri and 86.7% of Georgia households (<ext-link ext-link-type="uri" xlink:href="http://quickfacts.census.gov/qfd/states/29000.html">quickfacts.census.gov/qfd/states/29000.html</ext-link>)).</p>
<p id="P24">Based upon Missouri Family Register data, we were able to contact 330 eligible families of Missouri twins in the specified age range during the calendar years 2011–2013. Of these, 180 enrolled in the Early Reciprocal Social Behavior study (the larger study, described in <sup><xref ref-type="bibr" rid="R31">31</xref></sup>, of which the present experiments were a subcomponent). Of the 180, 121 (242 children) resided in close enough proximity to the St. Louis metropolitan area to be feasibly enrolled in the in-lab eye-tracking component of the study. For these 121 twin pairs, 242 individual eye-tracking data collection sessions were conducted. Sample demographics of the entire epidemiologically-ascertained sample (N=330) are given in <xref ref-type="table" rid="T1">Extended Data Table 1</xref>. The subset of twins participating in eye-tracking (121 pairs) was well-matched to the entire epidemiologically-ascertained twin group (the total 180 pairs enrolled). There were no group differences in sex, zygosity, race, or ethnicity. There was a difference in level of income, with the eye-tracking subset having slightly higher proportion than the general population of families in the highest wage-earning bracket (<italic>Χ</italic><sup>2</sup>=1.55, <italic>p</italic>=0.21).</p>
<p id="P25">Due to the paired nature of planned eye-tracking analyses (requiring complete sets of eye-tracking data from both twins), and due to the restriction of analyses to like-sex DZ twin pairs, the eye-tracking twin sample comprised 166 children (83 twin pairs, 41 MZ and 42 like-sex DZ). Demographics data for these children are given in <xref ref-type="table" rid="T1">Extended Data Table 1</xref>. Descriptions of eye-tracking data quality control and pairing procedures are given below in sections, ‘Data Acquisition &amp; Processing: Quality Control’ and ‘Data Acquisition &amp; Processing: Pairing Procedures’. Mean age at time of testing in these 166 twins and in the non-sibling control samples (N=84) was 21.3 months (SD=4.26 months). By group, ages and sexes were as follows: non-sibling controls, mean(SD)=20.87(2.77) months, 52.4% male; DZ twins, 22.13(4.89) months, 52.4% male; and MZ twins, 20.94(4.74) months, 58.5% male.</p>
<p id="P26">For children with ASD, all eye-tracking data were collected at the time of initial diagnosis. Personnel blind to the diagnostic status of the children performed all aspects of eye-tracking data collection and analysis. Trained clinicians blind to results of all eye-tracking procedures administered all diagnostic measures. Children in each of the two ASD groups met the following inclusionary criteria: (1) they met criteria for Autistic Disorder or ASD on the <italic>Autism Diagnostic Observation Schedule</italic><sup><xref ref-type="bibr" rid="R32">32</xref></sup>, Module 1; and (2) they received a diagnosis of either Autistic Disorder (32 of 43 children in cohort 1), Pervasive Developmental Disorder-Not Otherwise Specified (11 of 43 children in cohort 1), or Autism Spectrum Disorder (45 of 45 children in Cohort 2) by two experienced clinicians upon independent review of all available clinical data, including standardized testing and video of the diagnostic examination. At time of testing of ASD cohort 1 (2011–2013, as in the twin sample), diagnostic guidelines followed DSM-IV-TR criteria<sup><xref ref-type="bibr" rid="R33">33</xref></sup>; all children would also meet criteria for ASD per current, DSM-5 criteria<sup><xref ref-type="bibr" rid="R13">13</xref></sup>. At time of testing of ASD cohort 2 (2015–2016), diagnostic guidelines followed DSM-5 criteria. Mean age at time of testing was 22.8(4.0) for ASD cohort 1 and 25.8(3.4) for cohort 2. Because the ASD cohorts were consecutive clinical referrals, age at time of testing depended on the age of referral. ASD cohorts were older than the epidemiologically-ascertained sample (<italic>t</italic><sub>291</sub>=2.78, <italic>P</italic>&lt;0.001 and <italic>t</italic><sub>293</sub>=7.36, <italic>P</italic>&lt;0.001 for cohorts 1 and 2, respectively). However, age was not significantly correlated with eye- or mouth-looking in either ASD cohort (<italic>r</italic><sub>eyes</sub>=0.01, <italic>p</italic>=0.95, <italic>r</italic><sub>mouth</sub>=-0.08, <italic>p</italic>=0.61 for cohort 1; <italic>r</italic><sub>eyes</sub>=-0.01, <italic>p</italic>=0.92, <italic>r</italic><sub>mouth</sub>=-0.12, <italic>p</italic>=0.41 for cohort 2), and constraining analyses to ASD subsamples age-matched to the twin and non-sibling typically-developing samples did not significantly change the area under the ROC curves in <xref ref-type="fig" rid="F4">Figure 4</xref> (ASD1<sub>age-matched</sub> AUC = 0.87(0.83–0.92) and ASD2<sub>age-matched</sub> AUC = 0.85(0.80–0.90)).</p>
</sec>
<sec id="S3">
<title>Zygosity Confirmation</title>
<p id="P27">Zygosity was determined by the Goldsmith Child Zygosity Questionnaire, which corresponds to DNA marker/blood type determinations of zygosity in 94.8% of cases<sup><xref ref-type="bibr" rid="R34">34</xref></sup>. The questionnaire was administered during a phone interview with the twins‘ biological mother or father. Correspondence between the questionnaire-based zygosity determination and genotypic assignment, using DNA acquired by buccal swab, was tested for a randomly selected subset of families (n=24 twin pairs) and in all cases positively confirmed the questionnaire results. In 6 twin pairs, zygosity could not be determined by questionnaire; data from those twins were excluded from the present analyses.</p>
<p id="P28">Data acquisition and data processing were performed by experimenters blind to the zygosity status of each twin pair. Measures of eye movement were made directly by videooculography for each child, collected in semi-automated fashion (by an experimenter using automated data collection software), and analyzed in fully automated fashion; aside from final group assignment, there were no components of data collection or analysis adjusted on the basis of zygosity. As a result, eye-tracking-based measures of social visual engagement benefit from the relative absence of rater/observational biases that have elsewhere been cited as a potential confound in twin studies (<italic>e.g.</italic>, <sup><xref ref-type="bibr" rid="R35">35</xref></sup>).</p>
</sec>
<sec id="S4">
<title>Experimental Procedures</title>
<p id="P29">Twins and non-sibling control participants were tested individually and accompanied at all times by a parent or primary caregiver. Eye-tracking data collection procedures matched those reported in <sup><xref ref-type="bibr" rid="R6">6</xref></sup> and <sup><xref ref-type="bibr" rid="R36">36</xref></sup>. Eye-tracking was accomplished by a video-based, dark pupil/corneal reflection technique with hardware and software created by ISCAN, Inc. (Woburn, MA, USA). The system was remotely-mounted within a wall panel beneath the stimuli presentation monitor, concealed from the child’s view by an infrared filter.</p>
<p id="P30">Children were led into the testing room one at a time while an age-appropriate children’s video was playing on the stimuli presentation monitor. Each twin was tested separately while the other was engaged in other assessments. Experimenters remained out of view behind a curtain, while the parent buckled the child into a car seat. The car seat was mounted on a pneumatic lift so that viewing height (aligned vertically to fall within the lower 1/3<sup>rd</sup> of the stimuli presentation monitor) and distance from the monitor (approximately 28–30 inches; 71–76 cm) were standardized for all participants. The stimuli presentation monitor was a 20-in (50.8-cm) computer monitor with refresh rate of 60 Hz. Lights in the room were dimmed in order to direct attention toward the stimuli presentation monitor. Audio was played through a set of concealed speakers. The experimenter was able to observe the child at all times using a live video feed.</p>
<p id="P31">A five-point calibration method was used, presenting spinning and/or flashing points of light as well as cartoon animations, ranging in size from 1° to 1.5° of visual angle, on an otherwise blank screen, all with accompanying sounds. The calibration routine was followed by verification of calibration in which more calibration targets were presented at any of nine on-screen locations. Throughout the remainder of the testing session, calibration targets were shown between experimental videos to measure possible drift in accuracy. After calibration checks, the system was re-calibrated if excessive drift (&gt;3° of visual angle) in calibration accuracy occurred. Please see <italic>Quality Control</italic> section below for measures of calibration accuracy and concordance thereof.</p>
</sec>
<sec id="S5">
<title>Stimuli</title>
<p id="P32">Following calibration and verification, 27 videos in randomized presentation order were shown to each child. Each video lasted an average of 44.2 sec, for a total viewing time of 19 min 54 sec. Videos comprised two content categories designed to recapitulate naturalistic social experience (as also described in <sup><xref ref-type="bibr" rid="R6">6</xref></sup> and <sup><xref ref-type="bibr" rid="R15">15</xref></sup>). The first category of video displayed an adult female actor who spoke directly to the viewer/camera, as shown in <xref ref-type="fig" rid="F5">Extended Data Figure 1a</xref>, <xref ref-type="fig" rid="F11">Extended Data Figure 7a</xref>, and <xref ref-type="supplementary-material" rid="SD1">Supplementary Videos 1</xref> and <xref ref-type="supplementary-material" rid="SD2">2</xref>, representing what would be experienced in dyadic interaction with a caregiver (‘Dyadic Mutual Gaze’, 15 videos in total). The actors were filmed in naturalistic settings that emulated the real-world environment of a child’s room, with pictures and toys. The other category of videos consisted of children interacting in a daycare setting (‘Triadic Peer Interaction’, 12 videos total, shown in <xref ref-type="fig" rid="F11">Extended Data Figure 7i</xref> and <xref ref-type="supplementary-material" rid="SD3">Supplementary Videos 3</xref> and <xref ref-type="supplementary-material" rid="SD4">4</xref>). The adult actors or the parent or legal guardian of the child actors provided written informed consent for filming and for publication of images (in <xref ref-type="fig" rid="F5">Extended Data Figures 1</xref>, <xref ref-type="fig" rid="F10">6</xref>, and <xref ref-type="fig" rid="F11">7</xref>, and in <xref ref-type="supplementary-material" rid="SD1">Supplementary Videos 1</xref>–<xref ref-type="supplementary-material" rid="SD4">4</xref>). The two content categories were randomly interleaved during presentation.</p>
<p id="P33">Levels of eye- and mouth-looking differ between content categories (see <xref ref-type="fig" rid="F5">Extended Data Figure 1d-e</xref> for ‘Dyadic Mutual Gaze’ and <xref ref-type="fig" rid="F11">Extended Data Figure 7d-e</xref> for ‘Triadic Peer Interaction’). Where cross-category comparisons are made (<xref ref-type="fig" rid="F3">Figure 3</xref>), normalization is required (described below in Data Analysis &amp; Statistics: Macro-Level Indices of Social Visual Engagement). In all other analyses where levels of eye- and mouth-looking constitute the primary comparison, a single video stimuli content category was used (<xref ref-type="fig" rid="F1">Figures 1</xref>, <xref ref-type="fig" rid="F3">3</xref>, <xref ref-type="fig" rid="F5">Extended Data Figures 1</xref>, <xref ref-type="fig" rid="F7">3</xref>, <xref ref-type="fig" rid="F8">4</xref>, &amp; <xref ref-type="fig" rid="F9">5</xref>, dyadic; <xref ref-type="fig" rid="F4">Figure 4</xref>, <xref ref-type="fig" rid="F10">Extended Data Figures 6</xref> &amp; <xref ref-type="fig" rid="F11">7</xref>, triadic). Other analyses (micro-level measures in <xref ref-type="fig" rid="F2">Figure 2</xref>, controls in <xref ref-type="fig" rid="F6">Extended Data Figure 2</xref>) require no normalization and summarize results for all stimuli.</p>
<p id="P34">Videos were presented as full-screen audiovisual stimuli; in 32-bit color; at 640 × 480 pixels in resolution; at 30 frames per sec; with mono-channel audio sampled at 44.1 kHz. Stimuli were sound and luminosity equalized, and were piloted in an independent sample of children before the start of study in order to optimize engagement for typical infant and toddler viewers.</p>
</sec>
<sec id="S6">
<title>Data Acquisition and Processing</title>
<p id="P35">Analysis of eye movements and coding of fixation data were performed with software written in MATLAB (MathWorks). The first phase of analysis was an automated identification of non-fixation data, comprising blinks, saccades and fixations directed away from the presentation screen. Saccades were identified by eye velocity using a threshold of 30° per sec<sup><xref ref-type="bibr" rid="R23">23</xref></sup>. We tested the velocity threshold with the 60-Hz eye-tracking system described above and, separately, with an eye-tracking system collecting data at 500Hz (SensoMotoric Instruments GmbH). In both cases saccades were identified with equivalent reliability as compared with both hand coding of the raw eye-position data and with high-speed video of the child’s eyes. Blinks were identified as described in <sup><xref ref-type="bibr" rid="R15">15</xref></sup>. Off-screen fixations (when a participant looked away from the video) were identified by gaze vectors directed to locations beyond the stimuli presentation monitor.</p>
<p id="P36">Eye movements identified as fixations were coded into four regions of interest that were defined within each frame of all video stimuli: eyes, mouth, body (neck, shoulders and contours around eyes and mouth, such as hair) and objects (surrounding inanimate stimuli) (<xref ref-type="fig" rid="F5">Extended Data Figure 1b,c</xref> and <xref ref-type="fig" rid="F10">Extended Data Figure 6b,c</xref>). The regions of interest were hand traced for all frames of the video and stored as binary bitmaps. Automated coding of fixation time to each region of interest then consisted of a numerical comparison of each child’s coordinate fixation location data with the bitmapped regions of interest. <xref ref-type="table" rid="T3">Extended Data Tables 3c and 3d</xref> give the percentage of time spent fixating on each region of interest as well as the corresponding time (in minutes) spent fixating. Average total duration of included video trials per child was M = 18.2 min (SD = 3.1min) for MZ twins and M=17.9 min (SD = 3.4 min) for DZ twins.</p>
<sec id="S7">
<title>Quality Control</title>
<p id="P37">In 10 of the 242 twin data collection sessions (4.13%), data could not be collected due to the following: child fussiness, child sleep, and/or temporary equipment failure. In 16 of 242 twin data collection sessions (6.61%), data were collected but checks of calibration accuracy either could not be performed or, when performed, indicated sufficiently low quality data (<italic>i.e.</italic>, calibration accuracy in excess of +/−3°) that the data should not be used for analyses. Determination of quality was performed at time of data collection, independently from further analyses, and by separate staff from those who conducted primary analyses (in addition, to ensure that exclusion of these data did not introduce bias, analyses were repeated with the 16 sessions of low quality data <italic>included</italic>; although the inclusion introduced additional measurement error, there was no statistically significant change in overall results). In the remaining 216 of 242 sessions (89.26%), data were successfully collected. The 26 sessions with missing values (10 by failure-to-collect and 16 by low-quality-collection) spanned 24 cases with values missing for one twin and 2 cases (1 twin pair) with values missing for both twins.</p>
<p id="P38">Average calibration accuracy for all groups was less than 1° of visual angle. <xref ref-type="fig" rid="F6">Extended Data Figure 2a-c</xref> shows total variance in calibration accuracy, and <xref ref-type="fig" rid="F6">Extended Data Figure 2d-f</xref> shows average calibration accuracy. Pairwise concordance in calibration accuracy was measured as both fixation position and distance to address the possibility that systematic saccadic overshoots or undershoots to particular locations might be more concordant in MZ versus DZ twins. Position was measured as horizontal and vertical fixation location relative to the center of the calibration accuracy validation target (in degrees of visual angle) while distance was measured from fixation location to center of the calibration accuracy validation target (also in degrees of visual angle). Concordance in calibration accuracy fixation position was not statistically different from 0 in either MZ, DZ, or non-sibling controls for fixation position (<xref ref-type="fig" rid="F6">Extended Data Figure 2g-j</xref>). Concordance in calibration accuracy fixation position also did not differ significantly between groups, calculated by intraclass correlation coefficient<sup><xref ref-type="bibr" rid="R21">21</xref>,<xref ref-type="bibr" rid="R37">37</xref></sup> (ICC, case (2,1)): ICC<sub>MZ</sub>=0.07(0.00–0.29), ICC<sub>DZ</sub>=0.00(0.00–0.20), ICC<sub>non-sib</sub>=0.01(0.00–0.24). Results were also non-significant for distance: ICC<sub>DZdist</sub>=0.00(0.00–0.22), ICC<sub>MZdist</sub>=0.15(0.00,0.45), ICC<sub>non-sib_dist</sub>=0.00(0.00–0.26).</p>
<p id="P39">It is theoretically possible that eye movement accuracy could be more concordant in MZ vs. DZ twins (<italic>i.e.</italic>, ballistic muscle movements of the eyes might be incrementally more similar in MZ than DZ). MZ group results, although not approaching statistical significance, exhibit a slight numerical increase in ICC value. However, given the size of this effect in the current experimental testing framework, power analyses indicate that approximately 1600 pairs of MZ twins would be required to reject or confirm its existence (80% power, α=0.05). More importantly, the magnitude of such an effect in the present context, if it existed, would be substantially smaller in size than that of the semantic content regions in our stimuli: stated differently, the relative increase or decrease in concordance in accuracy would, based on current measures, operate in a range of tenths of degrees of visual angle, whereas the size of our semantic target regions is 40–80-fold greater in size (summary of size of regions of interest in the stimuli is given in <xref ref-type="table" rid="T3">Extended Data Table 3a</xref>). Such an effect could not, in and of itself, account for the large differences in MZ vs. DZ concordance in looking to semantic content regions.</p>
<p id="P40">To ensure best practices for consistent data collection, each eye-tracking session was also qualitatively rated at time of collection by in-lab staff on a scale from 0–5, using a scoring system in which staff were trained and checked for reliability. The score was based on quality of the eye image throughout the session, amount of measurement error during each calibration check, and perceived degree of overall child engagement during testing. The ratings were used to ensure best practices for consistent data collection. Sessions in which data could not be collected (the 10 of 242 mentioned above) were given scores of 0; poor quality sessions (the 16 of 242 noted above) were given scores of 1. As noted, analyses were repeated with and without the 16 sessions of low quality data included, to no change in results.</p>
<p id="P41">For each experimental trial (each video stimulus), we used a minimum-valid-data criterion of fixation time greater than or equal to 20% of total trial duration. The criterion was established on the basis of prior analyses of an independent sample of eye-tracking data (207 children, aged 16.5–30 months; with threshold identified in that sample by analyzing the full set of fixation percentages as two separable components of a finite mixture model).</p>
<p id="P42">In the present data set for MZ and DZ twins, 4,232 video trials were presented; application of the exclusion criterion excluded 4.44% of collected trials (188 videos), leaving 4,044 included video trials. For number of video trials included, excluded, or presented, there were no significant differences between MZ and DZ twins (<italic>t</italic><sub>164</sub> = 1.25, <italic>p</italic>=0.21; <italic>t</italic><sub>164</sub> = 0.17, <italic>p</italic>=0.87; <italic>t</italic><sub>164</sub> = 1.31, <italic>p</italic>=0.19, for included, excluded, and presented, respectively; data were tested with both a two-sample <italic>t</italic> test as well as a Wilcoxon signed rank test / Mann-Whitney U test with comparable results [no significant differences in any analysis]). We set no threshold for minimum number of trials sufficient for inclusion of a child’s data in final analyses; if usable data were collected, with trials fixated at a level greater than or equal to the minimum-valid criterion described above, the child’s data were included.</p>
<p id="P43">Of 27 possible video trials, the mean number of included trials for MZ twins was 24.8 (3.7) and for DZ twins was 24.0 (4.7) (data given as mean(SD)). The mode number of included trials per child for both MZ and DZ groups was 27; likewise, the median number of included video trials for children in both groups was 26, while the minimum number of included trials collected for any single participant was 8 for one MZ twin and 4 for one DZ twin.</p>
</sec>
<sec id="S8">
<title>Pairing of Participant Data</title>
<p id="P44">Due to the paired nature of planned analyses, only twin pairs having complete eye-tracking data sets from <italic>both</italic> twins could be analyzed. Of the 121 total twin pairs enrolled in the eye-tracking study, 96 pairs (192 children) had complete data sets. Twenty-five twin pairs had missing data (24 pairs missing one twin’s data, 1 pair missing both). In 10 of the 25 twin pairs with incomplete data, an additional eye-tracking session was scheduled and conducted, re-testing both twins; we repeated all analyses with and without these data (<italic>i.e.</italic>, either constraining analyses to the first attempted testing session [constrained to the 96 twin pairs succeeding in collection on first visit] or including results from the next data collection session in which data were successfully collected for both twins); in either case, twin pair data were always collected on the same day for each twin. With and without these data included, there was no statistically significant change in overall results. Of the 15 twin pairs with insufficient data, the proportion of twins included/excluded did not differ between MZ and DZ twins: 5/15 (33.3%) were MZ (2f:3m) and 5/15 (33.3%) were like-sex DZ (1f:4m); the remaining 5/15 were opposite-sex DZ and, like all opposite-sex DZ, were not a part of the analyses.</p>
<p id="P45">For analyses of pairwise concordance in eye-tracking measures, the final set of children with successfully collected, paired data consisted of N=41 MZ twin pairs (82 children), N=42 DZ like-sex twin pairs (84 children), and N=42 age- and sex-matched non-sibling comparison children (84 children). Analyses were also conducted for the DZ opposite sex twin pairs (N=17 pair, 34 children); inclusion of these children <italic>increased</italic> the MZ – DZ differences in all cases (<italic>i.e.</italic>, DZ concordance was reduced by inclusion of opposite sex pairs); in light of those results, consistent with other published studies, and in order to be conservative in our estimates of concordance and heritability, we constrained present analyses to DZ like-sex twins.</p>
<p id="P46">For age- and sex-matched non-sibling comparison, paired children had no biological relationship to one another; were matched on sex; and were matched to within 1 day of mean chronological age (average difference in age: mean(SD) = 0.99 (0.27) days; average absolute difference in age: mean(SD) = 4.8 (0.22) days). Our rationale for including this age- and sex-matched, non-sibling control group was specifically to include an overt comparison for effects of age and sex on measures of social visual engagement. Our previous work using this same experimental paradigm<sup><xref ref-type="bibr" rid="R6">6</xref></sup> shows evidence that these behaviors, as with many others that emerge in early development (<italic>e.g.</italic>, walking and talking), undergo progressive changes that are very sensitive to a child’s developmental stage and may be sensitive to sex effects (<italic>e.g.</italic>, precociousness in female verbal abilities<sup><xref ref-type="bibr" rid="R38">38</xref></sup>). Because it is therefore possible that genetically unrelated individuals could show a degree of concordance based on similarities in developmental stage or sex, we included this comparison sample.</p>
<p id="P47">Finally, we also included a comparison with fully randomized pairings of the non-sibling controls: these analyses were conducted irrespective of age and sex, across 10,000 randomized pairings without replacement, to calculate concordance estimates and confidence intervals across all permutations<sup><xref ref-type="bibr" rid="R19">19</xref></sup>. The weak—but non-zero—ICC values in age- and sex-matched non-sibling controls (main text, <xref ref-type="fig" rid="F1">Figure 1b, 1g, 1l</xref>) do appear to indicate that a portion of concordance may be due to developmental effects independent of direct biological familial relationship. We are under-powered to confirm or reject such an effect; however, the graded pattern of results across all 4 groups—from fully randomized pairings (<xref ref-type="fig" rid="F1">Figure 1a, 1f, 1k</xref>), to age- and sex-matched non-sib controls, to DZ twins, to MZ twins—suggests that such an effect may exist.</p>
</sec>
</sec>
<sec id="S9">
<title>Data Analysis and Statistics</title>
<p id="P48">As noted above in the Data Acquisition and Processing section, eye movements identified as fixations were coded into four regions of interest defined within each frame of all video stimuli: eyes, mouth, body (neck, shoulders and contours around eyes and mouth, such as hair) and objects (surrounding inanimate stimuli) (<xref ref-type="fig" rid="F5">Extended Data Figure 1b,c</xref>). <xref ref-type="supplementary-material" rid="SD1">Supplementary Videos 1</xref>–<xref ref-type="supplementary-material" rid="SD4">4</xref> show examples of coded data.</p>
<sec id="S10">
<title>Code Availability</title>
<p id="P49">Analysis of eye movements and coding of fixation data were performed with software written in MATLAB (MathWorks) either via the commandline or in scripts, available upon request.</p>
</sec>
<sec id="S11">
<title>Macro-Level Indices of Social Visual Engagement</title>
<p id="P50">In Experiment 1, we measured macro-level indices of social visual engagement, calculating proportion of time spent looking at eyes, mouth, and body regions. Percentage of total time spent attending to video stimuli (<xref ref-type="fig" rid="F5">Extended Data Figure 1f</xref>), as well as time spent fixating specifically on eyes (<xref ref-type="fig" rid="F5">Extended Data Figure 1d</xref>), mouth (<xref ref-type="fig" rid="F5">Extended Data Figure 1e</xref>), body, and nonsocial object regions was calculated. The twin-twin and paired non-sibling concordance plots for proportion of time looking at each region were constructed (main text <xref ref-type="fig" rid="F1">Figure 1</xref>), and intraclass coefficients calculated. Because negative values of the intraclass correlation coefficient (ICC) only arise when estimates of the variance components are negative or zero—which is mathematically possible but not theoretically meaningful<sup><xref ref-type="bibr" rid="R39">39</xref>,<xref ref-type="bibr" rid="R40">40</xref></sup>—all reported ICC values fall within the range [0,1].</p>
<p id="P51">As observed in previous work<sup><xref ref-type="bibr" rid="R6">6</xref></sup>, the 18–24-month developmental period in which testing was conducted corresponds with large changes in typical infant eye- and mouth-looking, with amount of mouth-looking in typical infants rising to a peak value at approximately 18 months of age (when single word vocabulary is also rapidly increasing). Given floor and ceiling effects noted in the distributions of eye- and mouth-looking, respectively, analyses of concordance were also repeated with non-parametric measures, with no appreciable difference in results: we compared correlations for MZ and DZ twin pairs using both Spearman’s rank correlation and intraclass correlation coefficient (ICC). Non-parametric results were as follows: 1) eyes: MZ, ρ = 0.843 (<italic>P</italic>&lt;0.001) and DZ, ρ = 0.333 (<italic>p</italic>=0.031); and mouth: MZ, ρ = 0.822 (<italic>P</italic>&lt;0.001) and DZ, ρ = 0.405 (<italic>p</italic>=0.008).</p>
<p id="P52">Likewise, macro-level measures of eye- and mouth-looking differ, as expected, by video content category (<xref ref-type="fig" rid="F5">Extended Data Figure 1d-f</xref> and <xref ref-type="fig" rid="F10">Extended Data Figure 6d-f</xref>). For this reason, analysis of concordance in levels of looking across different content categories, as undertaken in <xref ref-type="fig" rid="F3">Figure 3, parts d, i, and n</xref>, requires normalization (measures of Pearson correlation would, of course, by unaffected by such differences, but measures of agreement and consistency, as is the case for the intraclass correlation coefficients, are affected by differences in scale). To analyze measures of concordance on a common scale, data were normalized by linear transformation as follows: for each set of measured levels of eye-looking in dyadic mutual gaze stimuli and triadic peer interaction stimuli (the X and Y axes of <xref ref-type="fig" rid="F3">Figure 3 parts d,i,n</xref>), the minimum value was identified and the range was calculated; the minimum value was subtracted from each individual value and then each value was multiplied by the range, resulting in values scaled from 0 to 100 (comparable results were found by using a <italic>Z</italic> score transformation, but because the data were not normally distributed, we used this non-parametric alternative).</p>
<p id="P53">In addition, as described in the main text, to test the specificity of the measures to <italic>social</italic> engagement, we compared concordance in eye- and mouth-looking with concordance of time spent looking at nonsocial content (inanimate object and background regions), and time spent attending to task (maintaining stable onscreen fixation with less than 5°/sec of eye movement<sup><xref ref-type="bibr" rid="R23">23</xref></sup>). Interestingly, in MZ twins, eye-looking (ICC: 0.91, 95% CI: 0.85–0.95) was significantly more concordant than nonsocial object-looking (ICC: 0.66, 95% CI: 0.46–0.80) and more concordant than time spent maintaining steady fixation (0.46 (0.19–0.67)); mouth-looking, by contrast, (mouth ICC: 0.86, 95% CI: (0.76–0.92) was more concordant in MZ twins than time spent maintaining steady fixation but was <italic>not</italic> more concordant than time spent looking at nonsocial content. This difference is consistent with other studies emphasizing the distinct evolutionary and functional role of the eyes in social interaction<sup><xref ref-type="bibr" rid="R41">41</xref></sup>.</p>
</sec>
<sec id="S12">
<title>Measures of Trait-like Stability</title>
<p id="P54">To measure the extent of trait-like stability of these behaviors, we measured within-subject stability / test-retest reliability across both short and long timescales. For short timescales, results are plotted in <xref ref-type="fig" rid="F7">Extended Data Figure 3</xref>. Within-subject stability is strong, irrespective of group membership, and within-subject stability results present a striking contrast to the twin-twin concordance results which vary by degree of genetic relatedness (plotted below each respective panel for comparison). These measures reflect trait-like stability for any given individual during <italic>single-day</italic> testing sessions, quantified by intraclass correlation coefficients with a 2-way random effects model, ICC(2,1)). Another related measure, not plotted, is that of <italic>inter</italic>-individual variation—the reliability of measured differences between any individuals A and B (<italic>i.e.</italic>, the stability with which the measured trait is higher/lower in individual A than individual B, individual C, etc., given a series of repeated measures). In that case, the observed ICC values are on the order of 0.9 for each group, quantified in that case by a fixed rather than random effects model, ICC(3,k). Both measures are strong evidence that the levels of looking across individuals are highly reliable.</p>
<p id="P55">Regarding the question of stability over longer timescales, we invited back as many participants as possible for follow-up at the age of 36 months. We were able to collect and analyze data for N=22 MZ twins (11 pairs, age at Time 1, mean(SD) = 21.1(2.6) months, age at Time 2, 36.9(2.6) months) and for N=44 DZ twins (22 pairs, age at Time 1, mean(SD) = 22.1(2.5) months, age at Time 2, 36.8(1.0) months; ages for combined groups, Time 1 = 21.7(2.6), Time 2 = 36.8(1.7).</p>
<p id="P56">We analyzed these data in three ways: (1) twin-twin concordance of measures at Time 2 alone (<xref ref-type="fig" rid="F8">Extended Data Figure 4a-l</xref>); (2) within-subject stability from Time 1 until Time 2 (<xref ref-type="fig" rid="F9">Extended Data Figure 5a-e</xref>); and (3) twin-twin concordance from Time 1 until Time 2 (<xref ref-type="fig" rid="F9">Extended Data Figure 5f-j</xref>).</p>
<p id="P57">For the first comparison (twin-twin concordance of measures at Time 2 alone), results show robust MZ twin-twin concordance at Time 2 alone relative to diminished DZ twin-twin concordance (similar to results observed at Time 1 alone). Results are plotted in <xref ref-type="fig" rid="F8">Extended Data Figure 4a-l</xref> and given in <xref ref-type="table" rid="T2">Extended Data Table 2b</xref>.</p>
<p id="P58">For the second comparison (within-subject stability <italic>from</italic> Time 1 <italic>until</italic> Time 2), results show comparable within-subject stability over time for both groups, irrespective of zygosity. Results are plotted in the top row of <xref ref-type="fig" rid="F9">Extended Data Figure 5</xref>, parts a-e. These results indicate that within-subject stability of eye-looking from 21 until 36 months is very high in both groups: 0.72 for MZ twins (95% CI: 0.44–0.87) and 0.69 for DZ twins (95% CI: 0.50–0.82). Also, as expected for within-subject stability, the two groups (with 95% confidence intervals that fully overlap mean estimates for both groups) do not differ significantly in this regard.</p>
<p id="P59">Finally, for the third comparison (<italic>twin-twin concordance</italic> from Time 1 until Time 2, bottom row of <xref ref-type="fig" rid="F9">Extended Data Figure 5, parts f-j</xref> and <xref ref-type="table" rid="T2">Extended Data Table 2c</xref>), the results differ starkly as a function of zygosity: concordance of twin 1’s eye-looking at 21 months with Twin 2’s eye-looking at 36 months for MZ twins is 0.70 (0.40–0.86), whereas for DZ twins the twin-twin concordance is 0.22 (0.00–0.49); for mouth looking, the difference is 0.73 (0.45–0.88) for MZ and 0.07 (0.00–0.36) for DZ.</p>
<p id="P60">Taken as a whole, these analyses of within-subject stability and twin-twin concordance strongly support the notion that social visual engagement exhibits heritable trait-like characteristics during this period of early childhood: there is substantial within-subject stability across all participant groups in marked contrast to differences in twin-twin concordance varying by zygosity; MZ twin-twin concordance is preserved over 15 months of time and substantially contrasts with DZ twin-twin correlations at both 21 months and 36 months; and within-subject stability is extremely strong when examined on both short and long timescales.</p>
</sec>
<sec id="S13">
<title>Physical Image Properties of Eye Regions</title>
<p id="P61">To address the question of whether observed concordance could be partitioned into variation reflecting stimulus response<sup><xref ref-type="bibr" rid="R17">17</xref></sup> (responding to specific features of the exact stimulus presented) or goal-directed action<sup><xref ref-type="bibr" rid="R18">18</xref>,<xref ref-type="bibr" rid="R26">26</xref></sup> (individual differences in the seeking of social information, able to be dissociated from an exact stimulus), we measured concordance in eye-looking across varying conditions in which twins watched either the same or different stimuli (as described in the main text and presented in <xref ref-type="fig" rid="F3">Figure 3</xref>).</p>
<p id="P62">To quantify differences in the physical image properties of stimuli seen by each twin, we analyzed image property profiles of regions demarcated as eyes across all frames of all videos presented. Specifically, we analyzed the lightness and color (color opponency in red-green and blue-yellow following the CIE 1976 model <sup><xref ref-type="bibr" rid="R42">42</xref></sup>), contrast (RMS, root-mean-squared contrast), orientation gradients (sum of local maxima of image intensity gradient), and amount of motion (sum of change in image intensity) present within all eye regions in all videos<sup><xref ref-type="bibr" rid="R28">28</xref>,<xref ref-type="bibr" rid="R43">43</xref></sup>. Image property profiles for representative videos are plotted in <xref ref-type="fig" rid="F11">Extended Data Figure 7</xref>. Variation in stimulus image properties can be seen in the histograms themselves (parts c-h and m-r) as well as in the statistical comparisons of video image property profiles (parts i-j and s-t, compared by two-sample Kolmogorov-Smirnov tests). These data underscore the notion that “eyes” are a semantic content category rather than a singular stimulus image property<sup><xref ref-type="bibr" rid="R28">28</xref></sup>, a notion consistent with research distinguishing stimulus-driven or “bottom-up”<sup><xref ref-type="bibr" rid="R43">43</xref>–<xref ref-type="bibr" rid="R47">47</xref></sup> processes in visual saliency from those that are goal-directed or “top-down”<sup><xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R48">48</xref>–<xref ref-type="bibr" rid="R51">51</xref></sup>.</p>
<p id="P63">Analyses in <xref ref-type="fig" rid="F3">Figure 3</xref> and <xref ref-type="fig" rid="F11">Extended Data Figure 7</xref> show that concordance in eye-looking is strongly preserved in MZ twins despite watching different stimuli: in MZ twins, the extent to which twin 1 looks at the eyes in Dyadic Mutual Gaze videos (examples can be found in <xref ref-type="supplementary-material" rid="SD1">Supplementary Videos 1</xref> and <xref ref-type="supplementary-material" rid="SD2">2</xref>) is highly concordant with the extent to which twin 2 looks at the eyes in scenes of unscripted peer interaction (Triadic Peer Interaction videos; examples can be found in <xref ref-type="supplementary-material" rid="SD3">Supplementary Videos 3</xref> and <xref ref-type="supplementary-material" rid="SD4">4</xref>): ICC = 0.81 (95% CI: 0.67–0.89). This effect persists despite the fact that eyes found in the triadic peer interaction videos differ substantially in lightness, color, contrast, orientation gradients, and motion. These eyes are ½ to ¼ the size of eyes found in the dyadic mutual gaze videos (see <xref ref-type="table" rid="T3">Extended Data Table 3</xref>); they do not engage the viewer in mutual gaze, and they are instead frequently encountered in partial occlusion or profile and frequently present multiple onscreen targets (for each of multiple onscreen characters) rather than a single eye region. Notably, when DZ twins are presented with these different content categories, concordance in their levels of eye-looking no longer differ significantly from 0: ICC = 0.12 (95% CI: 0.00–0.41). These analyses are not meant to suggest that concordance in social visual engagement is stimulus-<italic>independent</italic>; necessarily, there are consistencies across the stimuli presented in the current study and there are limits to the extent of reasonable differences in stimuli that comparisons of the current type would allow (<italic>e.g.</italic>, there would be no expectation that measures of social visual engagement should remain consistent across entirely non-social stimuli). Instead, we take the present analyses as indication that what is heritable does not appear to be a response to a particular physical feature <italic>per se</italic> (<italic>i.e.</italic>, response to a single feature found within a highly uncertain visual world); rather, the evidence indicates that what is conserved is an adaptive action: behavioral seeking (in goal-directed fashion) to engage with relevant social stimuli in the environment<sup><xref ref-type="bibr" rid="R26">26</xref>,<xref ref-type="bibr" rid="R27">27</xref>,<xref ref-type="bibr" rid="R52">52</xref></sup> (seeking to engage with stimuli that can exist in a variety of different forms and features). This notion is consistent with basic evolutionary theory (aligning with survival impulses that drive adaptive action), particularly for primate species seeking to survive in highly social environments<sup><xref ref-type="bibr" rid="R53">53</xref></sup>.</p>
</sec>
<sec id="S14">
<title>Micro-Level Indices</title>
<p id="P64">In MZ and DZ twins, we collected 322,672 fixational eye movements (DZ: 161,963; MZ: 160,709; ~1944 fixations per child), occurring at a rate of 1.66 fixations per second (DZ mean(SD) = 1.66(0.59) fixation/sec; MZ mean(SD) = 1.66(0.49) fixation/sec), each lasting an average of 514 milliseconds (DZ = 523(188) msec; MZ = 505(245) msec). As a function of zygosity, there were no significant between-group differences in fixation count, frequency, or duration (tested by 2-sample <italic>t</italic> test, all <italic>p</italic> &gt; 0.594, all <italic>t</italic><sub>(164)</sub> &lt; 0.534). Saccadic amplitude data are given in <xref ref-type="fig" rid="F6">Extended Data Figure 2k-m</xref>. Summary statistics regarding saccadic eye movements are limited to instances in which saccades begin and end with within-range, measurable fixations. (In cases in which saccadic eye movements either originate from or result in offscreen/out-of-range fixation locations, or cases in which saccades co-occur with blinks, accurate measurements of saccade amplitude, duration, and velocity are not available and were thus excluded.) We analyzed 133,582 saccadic eye movements (DZ: 68,262; MZ: 65,320; ~804 saccades analyzed per child), with no significant between-group difference in quantity as a function of zygosity: <italic>t</italic><sub>(164)</sub> = 0.649, <italic>p</italic> = 0.517.</p>
</sec>
<sec id="S15">
<title>Timing of Eye Movements</title>
<p id="P65">In Experiment 2, we measured concordance in the timing of individual eye movements, testing whether probability of making a saccade was significantly modulated as a function of zygosity. Specifically, we analyzed the time series eye movement data in terms of timing of saccades and timing of saccade initiation using peristimulus (or “peri-event”) time histograms (PSTHs, <sup><xref ref-type="bibr" rid="R54">54</xref></sup>).</p>
<p id="P66">Following methods detailed in <sup><xref ref-type="bibr" rid="R15">15</xref></sup>, PSTHs were constructed by aligning each twin pair’s individual time series eye movement data to the start of each video stimulus, and by then computing counts of co-occurring saccades in 33.3 msec bins in a surrounding 1333.3 msec window. Bin counts were computed for each twin pair and then averaged across all pairs to obtain group means (plotted in main test <xref ref-type="fig" rid="F2">Figures 2d,e and 2g,h</xref>).</p>
<p id="P67">To test whether observed changes in saccade probability differed from those expected by chance, we used permutation testing<sup><xref ref-type="bibr" rid="R19">19</xref>,<xref ref-type="bibr" rid="R55">55</xref></sup>. In each of 1000 iterations, the binary time-series saccade data for each twin (0 = not saccading, 1 = saccading) were permuted by circular shifting<sup><xref ref-type="bibr" rid="R56">56</xref></sup>, following the equation: 
<disp-formula id="FD1"><mml:math display="block" id="M1" overflow="scroll"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mtext>modulo</mml:mtext><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> written as 
<disp-formula id="FD2"><mml:math display="block" id="M2" overflow="scroll"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">〈</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">〉</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:math></disp-formula> which, for <italic>r<sub>j</sub></italic> &gt;= 0, equals 
<disp-formula id="FD3"><mml:math display="block" id="M3" overflow="scroll"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="true">{</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:mi>T</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>t</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <italic>s<sub>j</sub></italic> is the measured saccade time-series data for each participant, <italic>j</italic>; <italic>s<sub>j,c</sub></italic> is the circular-shifted saccade time-series data for the same participant, <italic>j</italic>; <italic>t</italic> is a time point in the time series defined over the interval 0 ≤ t ≤ T; <italic>T</italic> is the total duration of the stimulus (in the present case, the duration of a video shown to participants); and <italic>r<sub>j</sub></italic> is the size of the random circular shift, in the same units of time as <italic>t,</italic> for each participant, <italic>j</italic>. Size of the random circular shift for each participant was drawn independently from a random number generator with uniform distribution with possible values ranging from <italic>–T</italic> to <italic>T</italic>.</p>
<p id="P68">PSTHs were then computed on each of those permuted data sets. By this method, durations of saccades and inter-saccade intervals were preserved for each individual, but the timing of each saccade was made random in relation to the actual timing of the other twin’s saccades. The mean instantaneous probability of making a saccade, during each bin, across all 1000 PSTHs from permuted data, quantified the results one would observe if saccade probability were random between twins. If, on the other hand, the timing of one twin’s saccades was synchronized with his or her twin sibling, and not random (<italic>i.e.</italic>, if when twin 1 made a saccade, twin 2 exhibited a greater probability of making a saccade), one would expect to see significant deviations from the permuted data distribution. The 2.5<sup>th</sup> and 97.5<sup>th</sup> percentiles of instantaneous saccade probability across all PSTHs from permuted data served as a <italic>p</italic> = 0.05 confidence level against which to compare saccade rates in the actual data (two-tailed comparison).</p>
<p id="P69">Taken as a whole, this approach enabled the comparison of actual patterns of saccading to randomized, chance patterns, and also allowed us to test the null hypothesis that DZ or MZ twins demonstrated no greater than chance levels of time-locking of eye movements. Results in main text <xref ref-type="fig" rid="F2">Figures 2c-h</xref> show significant time-locking in MZ twins, to within +/−16.67 milliseconds of saccade initiation. This level of concordance suggests an impressive set of related biological implications. Specifically, this degree of time-locking of eye movements would not be possible without time-locked contractions of rectus and oblique extraocular muscles<sup><xref ref-type="bibr" rid="R23">23</xref></sup>. Cranial nerves III, IV, and VI supply these muscles<sup><xref ref-type="bibr" rid="R23">23</xref></sup>, whose afferent connections are in turn supplied by the reticular formation in brainstem<sup><xref ref-type="bibr" rid="R57">57</xref>,<xref ref-type="bibr" rid="R58">58</xref></sup>. Synapsing directly upon the reticular formation are projections from the frontal eye fields<sup><xref ref-type="bibr" rid="R59">59</xref></sup>. With so few synapses separating frontal eye fields from the extraocular muscles<sup><xref ref-type="bibr" rid="R24">24</xref></sup>, spontaneous time-locking of eye movements suggests the likely presence of some, even modest, degree of time-locked neural activity in stages prior to motor movement initiation. Given the present behavioral results, it is intriguing to speculate on the extent of possible concordance in activity of neural systems that play a role in saccadic eye movements<sup><xref ref-type="bibr" rid="R24">24</xref></sup> (frontal eye fields, supplementary eye fields, parietal eye fields, Area 22, DLPFC).</p>
</sec>
<sec id="S16">
<title>Direction of Eye Movements</title>
<p id="P70">In Experiment 2, we measured twin-twin concordance in direction of eye movements. Saccade direction was computed as an angle (θ), in degrees. Difference in saccade direction was measured as the difference, in degrees, between the angles of twin 1 and twin 2’s saccades: θ<sub>twin1</sub> - θ<sub>twin2</sub>. Polar histograms of twin-twin differences are plotted in main text <xref ref-type="fig" rid="F2">Figures 2j,k</xref>. As noted in the main text, the analysis began by identifying instances of data in which both twins fixated on the same approximate locations at the same moments in time. Necessarily, these analyses involved selection of thresholds (<italic>i.e.</italic>, analytic definitions of what would constitute the “same” approximate location as well as the “same” moment in time). To assure that any observed differences were not merely the result of selecting one threshold versus another, we conducted analyses across varying thresholds of contemporaneous timing (temporal windows of 66.7msec, 133msec, 250msec, 500msec) and degree of collocation (retinal eccentricities of 1°, 1.7°, 5.2°, 10°, 15°). Main text <xref ref-type="fig" rid="F2">Figures 2j &amp; k</xref> plot results for saccades starting from fixations collocated within 5.2° (at least partially overlapping foveas) and co-occurring within 500msec or less. Main text <xref ref-type="fig" rid="F2">Figure 2l</xref> plots results across varying degrees of collocation, also co-occurring within 500msec or less. Across all comparisons of varying retinal eccentricities and temporal windows, MZ twins were more likely than DZ twins to shift saccades in more similar subsequent directions.</p>
<p id="P71">As in the preceding analyses of timing of eye movements, we compared observed differences in twin-twin saccade direction to results expected by chance by means of permutation testing. For permuted analyses, within each twin pair, twin-twin pairings of saccades starting at common locations were randomly shuffled in 1000 iterations, computing the angular difference across all randomly paired saccades in all iterations. The polar histogram data plotted as gray bars in <xref ref-type="fig" rid="F2">Figures 2j &amp; k</xref> shows the upper 95<sup>th</sup> percentile of differences expected by chance alone across all 1000 permutations (with the upper 95<sup>th</sup> percentile serving as a <italic>p</italic> = 0.05 confidence level against which to compare the actual observed differences). By comparison, the 50<sup>th</sup> percentile of permuted data would have less skew. The 95<sup>th</sup> percentile established the upper limit of similarity in saccade direction expected by chance. Skew seen in the chance distribution (with the histogram shifted towards more versus less similar saccade directions), is likely due to the nature of the video content and the effect of that content on probable saccade direction (<italic>i.e.</italic>, video stimuli presented content that was, in general, centrally-framed; as a result, saccades are more probably made in specific directions towards or away from that content). While both MZ and DZ twins show an increase in the probability of moving their eyes in a shared direction, also summarized in <xref ref-type="fig" rid="F2">Figure 2l</xref>, MZ twins exhibit greater probability of shifting saccades in more similar subsequent directions.</p>
</sec>
<sec id="S17">
<title>Collocation of Contemporaneous Fixations</title>
<p id="P72">Finally, we measured concordance in the collocation of contemporaneous visual fixations with respect to semantic content regions (eyes and mouth). We compared the twins’ probability of fixating on each of these regions at the same moments by creating 2x2 contingency tables of co-occurring fixations (main text <xref ref-type="fig" rid="F2">Figure 2m</xref>). When twin 1 and twin 2 looked at the eyes (or mouth) at the same moments, this counted as a ‘hit’ for shared fixation; if twin 1 looked at the eyes when twin 2 looked at the mouth (or vice versa), this counted as a ‘miss’. The counts of collocated fixations to eyes or mouth thus depend on the exact timing of when these fixations occurred; to compare the observed counts to those expected by chance, we again used permutation testing (permuting the observed sequences of fixations by circular shifting in each of 1000 iterations). Observed counts were normalized relative to the mean and standard deviation of permuted data (yielding counts of collocated fixations as <italic>Z</italic> scores). As noted in the main text, both groups show more co-occurring, collocated fixations on eye and mouth than expected by chance (main text <xref ref-type="fig" rid="F2">Figures 2n,o</xref>), but MZ twins exhibit greater concordance than DZ twins (<italic>F</italic><sub>1,81</sub> = 4.89, <italic>p</italic>=0.030; main text <xref ref-type="fig" rid="F2">Figure 2p</xref>). In addition, the relative difference between hits and misses (difference in <italic>Z</italic> scores for eyes-eyes or mouth-mouth versus eyes-mouth or mouth-eyes, seen in the relative heights of plots in main text <xref ref-type="fig" rid="F2">Figures 2n,o</xref>) is greater for MZ than DZ twins: MZ twins are both <italic>more</italic> likely to look at the eyes or mouth at the same moments in time, as well as relatively <italic>less</italic> likely to split their looking between different regions.</p>
</sec>
<sec id="S18">
<title>Power Calculations</title>
<p id="P73">For determining sample size in the present study, power calculations were based on assumptions from the existing literature on the longitudinal course and genetic structure of reciprocal social behavior<sup><xref ref-type="bibr" rid="R60">60</xref>–<xref ref-type="bibr" rid="R63">63</xref></sup>. Analyses indicated that twin pairs samples of 40 or greater would provide 80% power to detect correlations of approximately <italic>r</italic>=0.38 (approximately half the magnitude of MZ correlations observed in <sup><xref ref-type="bibr" rid="R31">31</xref></sup>). Actual statistical power to detect concordance between two measurements depends not only on the true genetic correlation (<italic>r</italic>) between them, but on their marginal heritabilities (H<sup>2</sup>): When H<sup>2</sup> =50%, power is above 80% when <italic>r</italic> &gt;= 0.27; and when H<sup>2</sup> =20% (lower than anticipated from the existing literature), power is above 80% when <italic>r</italic> &gt;= 0.55 (alpha = 0.001). Given the size of the observed MZ and DZ concordance effects, measurement estimates of our achieved power (1-β error probability) for MZ eye-looking was ~1; in DZ twins, achieved power for eye-looking was 0.77. Future work will follow-up in larger samples.</p>
<p id="P74">Additionally, in our final experiment, we tested two further hypotheses (described in the main text). For the first, the null hypothesis stated that concordance when watching the same videos would be equal to the value observed for watching all videos (H<sub>0</sub>: ICC<sub>same</sub>=ICC<sub>all</sub>); the alternative stated that concordance would be greater (H<sub>1</sub>: ICC<sub>same</sub>&gt;ICC<sub>all</sub>). Given the extremely high intraclass correlation coefficients already observed for MZ twins (eyes, 0.91), we were aware that we would not be sufficiently powered to detect a significant increase in concordance greater than this value for the MZ sample; however, we were adequately powered to detect significant increases, should they be observed, in the DZ and non-sibling samples. Likewise, in the second and third tests—comparing concordance when each twin watched <italic>different</italic> videos and when each twin watched different content categories of videos—the null stated that concordance would be zero (H<sub>0</sub>: ICC<sub>different</sub>=0), the alternative stated that concordance would be greater than zero (H<sub>1</sub>: ICC<sub>different</sub>&gt;0). Here, as in the main set of analyses, we had &gt;80% power to detect correlations of &gt;=0.38.</p>
</sec>
</sec>
</sec>
<sec id="S19">
<title>Extended Data</title>
<fig id="F5" orientation="portrait" position="anchor">
<label>Extended Data Figure 1</label>
<caption>
<title>Measuring genetic structure of social visual engagement in 250 paired toddlers: dizygotic twins (N=84, 42 pair), monozygotic twins (N=82, 41 pair), and non-sibling comparison children (N=84, randomized to 42 pairs)</title>
<p id="P75"><bold>a,</bold> Example still images from dyadic mutual gaze video stimuli. <bold>b,</bold> Data from two typically-developing 18-month-old dizygotic (DZ) twins. <bold>c,</bold> Data from two typically-developing 18-month-old monozygotic (MZ) twins. (b) and (c) plot two seconds of eye-tracking data, corresponding to each image in (a) (the image onscreen at midpoint of two-second data sample). Data are overlaid on each image’s corresponding regions of interest, shaded to indicate eyes, mouth, body, and object regions. Saccades are plotted as thin white lines with white dots; fixation data are plotted as larger colored dots. <bold>d-f,</bold> Fixation time summaries for each comparison group for percentage of total fixation time on eyes region (d), percentage of total fixation time on mouth region (e), and percentage of total time spent fixating (f). Boxplots span full range of data collected, with vertical lines extending from minimum to maximum values, boxes spanning the 25th to 75th percentiles, and horizontal black lines marking medians.</p>
</caption>
<graphic xlink:href="nihms879771f5"></graphic>
</fig>
<fig id="F6" orientation="portrait" position="anchor">
<label>Extended Data Figure 2</label>
<caption>
<title>Between-group controls for calibration accuracy and oculomotor function</title>
<p id="P76">To test for group-wise differences unrelated to subsequent paired comparisons in the main study experiments we measured calibration accuracy and oculomotor function. <bold>a-c,</bold> Total variance in calibration accuracy for age- and sex-matched non-sibling controls (a), DZ twins (b), and MZ twins (c). Plots show kernel density estimates of the distribution of measured fixation locations relative to calibration accuracy verification targets. <bold>d-f,</bold> Average calibration accuracy for non-sibling controls (d), DZ twins (e), and MZ twins (f). Crosses mark the location of mean calibration accuracy, while annuli mark 95% confidence intervals (CI). <bold>g-i,</bold> Concordance in calibration accuracy measures for non-sibling controls (g), DZ twins (h), and MZ twins (i). Measures in (g-i) are average accuracy per child across all accuracy verification trials. <bold>j,</bold> Intraclass correlation coefficients (ICC, plotted with 95% confidence intervals). <bold>k-m,</bold> Oculomotor relationship between maximum saccade velocity (Vmax) and amplitude for non-sibling controls (k), DZ twins (l), and MZ twins (m).</p>
</caption>
<graphic xlink:href="nihms879771f6"></graphic>
</fig>
<fig id="F7" orientation="portrait" position="anchor">
<label>Extended Data Figure 3</label>
<caption>
<title>Within-subject stability versus between-subject concordance</title>
<p id="P77">For heritable traits, one expects to observe substantial within-subject stability contrasting with marked differences, varying by zygosity, in between-subject (twin-twin) concordance. <bold>a-d,</bold> Within-subject stability of observed levels of eye-looking for non-siblings (a, b), DZ twins (c), and MZ twins (d). (Scatter plots in (a) and (b) are repeated for comparison with plots (f) and (g).) <bold>e,</bold> Group-wise summary of within-subject stability (test-retest reliability) of measures of eye-looking quantified by intraclass correlation coefficient (ICC) with 2-way random effects model (ICC(2,1)). Error bars are 95% confidence intervals. Note that estimates assuming fixed rather than random effects of testing (ICC(3,k), not plotted) yield ICC values greater than 0.9 for each group, evidence that the measures of inter-individual variation—the difference between individuals—are also highly reliable. <bold>f-i,</bold> Plots<bold></bold> repeated from main text <xref ref-type="fig" rid="F1">Figure 1a-e</xref>, showing paired measures of eye-looking in randomly-paired non-siblings (f), in age- and sex-matched non-siblings (g), in DZ twins (h), and in MZ twins (i). <bold>j,</bold> Intraclass correlation coefficients and 95% confidence intervals for twin-twin concordance in eye-looking.</p>
</caption>
<graphic xlink:href="nihms879771f7"></graphic>
</fig>
<fig id="F8" orientation="portrait" position="anchor">
<label>Extended Data Figure 4</label>
<caption>
<title>Monozygotic (MZ) twins maintain high twin-twin concordance, significantly greater than that observed in dizygotic (DZ) twins, when tested again at 36 months</title>
<p id="P78"><bold>a-c,</bold> Paired measures of eye-looking in randomly-assigned pairs (a), in DZ twins (b), and in MZ twins (c). <bold>d,</bold> Intraclass correlation coefficients and 95% confidence intervals across groups for eye-looking. <bold>e-h,</bold> Paired measures of concordance in mouth-looking. <bold>i-l,</bold> Paired measures of concordance in percentage of time spent attending to task (maintaining stable onscreen fixation). In all plots, randomly-matched controls in white, DZ twins in orange, and MZ twins in blue. Error estimates are 95% confidence intervals. <bold>m-n,</bold> Summary of MZ (m) and DZ (n) results at initial time of testing (21 months, summary data from <xref ref-type="fig" rid="F1">Figure 1</xref> in main text) relative to results at time of longitudinal follow-up (36 months, summary from d, h, &amp; l above). MZ twins exhibit marginally, though not significantly, increased concordance values when tested again at 36 months; in contrast, DZ twins exhibit marginally, though not significantly, decreased concordance values. Plotted data in (a), (e), and (i) are a representative case of random pairing, selected to match the mean ICC value of all 10,000 re-samplings.</p>
</caption>
<graphic xlink:href="nihms879771f8"></graphic>
</fig>
<fig id="F9" orientation="portrait" position="anchor">
<label>Extended Data Figure 5</label>
<caption>
<title>Longitudinal within-subject stability versus longitudinal twin-twin concordance, from 21 until 36 months</title>
<p id="P79">DZ and MZ twins both show high levels of longitudinal within-subject stability when tested again 15 months after initial data were collected, but only MZ twins show high levels of longitudinal twin-twin concordance, with twin 1’s results at 21 months being highly concordant with twin 2’s at 36 months. <bold>a-d,</bold> Within-subject stability of observed levels of eye-looking (a) and mouth-looking (b) for DZ twins, and within-subject stability of eye-looking (c) and mouth-looking (d) for MZ twins. <bold>e,</bold> Summary of longitudinal within-subject stability quantified by intraclass correlation coefficient (ICC) with 2-way random effects model. Error bars are 95% confidence intervals. <bold>f-i,</bold> Longitudinal twin-twin concordance (twin 1 at 21 months paired with twin 2 at 36 months) for eye-looking (f) and mouth-looking (g) in DZ twins, and for eye- (h) and mouth-looking (i) in MZ twins. <bold>j,</bold> Intraclass correlation coefficients and 95% confidence intervals.</p>
</caption>
<graphic xlink:href="nihms879771f9"></graphic>
</fig>
<fig id="F10" orientation="portrait" position="anchor">
<label>Extended Data Figure 6</label>
<caption>
<title>Social visual engagement when watching Triadic Peer Interaction stimuli in 250 paired toddlers: dizygotic twins (N=84, 42 pairs), monozygotic twins (N=82, 41 pairs), and non-sibling comparison children (N=84, randomized to 42 pairs)</title>
<p id="P80"><bold>a,</bold> Example still images from triadic peer interaction stimuli. <bold>b,</bold> Data from two typically-developing 18-month-old dizygotic (DZ) twins. <bold>c,</bold> Data from two typically-developing 18-month-old monozygotic (MZ) twins. In (b) and (c), two seconds of eye-tracking data are plotted, corresponding to each image in (a) (the image onscreen at midpoint of the two-second data sample). Data are overlaid on each image’s corresponding regions of interest, shaded to indicate eyes, mouth, body, and object regions. Saccades are plotted as thin white lines with white dots; fixation data are plotted as larger colored dots. <bold>d-f,</bold> Fixation time summaries for each comparison group for percentage of total fixation time on eyes region (d), percentage of total fixation time on mouth region (e), and percentage of total time spent fixating (f). Boxplots span full range of data collected, with vertical lines extending from minimum to maximum values, boxes spanning the 25<sup>th</sup> to 75<sup>th</sup> percentiles, and horizontal black lines marking medians.</p>
</caption>
<graphic xlink:href="nihms879771f10"></graphic>
</fig>
<fig id="F11" orientation="portrait" position="anchor">
<label>Extended Data Figure 7</label>
<caption>
<title>Physical image properties that constitute eyes vary significantly from video stimulus to video stimulus in lightness, color, contrast, orientation gradients, and motion</title>
<p id="P81"><bold>a,</bold> Still images sampled from videos depicting dyadic mutual gaze stimuli (an entreating caregiver, engaging the child in mutual gaze and play routines). Still images from 5 of 15 videos are shown (all 15 dyadic mutual gaze videos included in actual analyses). <bold>b,</bold> Eye region demarcated from each still image in (a). Across all demarcated eye regions, across all frames of videos presented, physical image property profiles were analyzed. In the row to the right of each representative still image and corresponding eye region, physical image property profiles, analyzed across all video frames, are given as histograms. <bold>c,</bold> Lightness. <bold>d,</bold> Red-green color opponency. <bold>e,</bold> Yellow-blue color opponency. <bold>f,</bold> Contrast. <bold>g,</bold> Orientation gradients. <bold>h,</bold> Motion. <bold>i,</bold> For each physical image property analyzed in columns (a-h), row (i) gives corresponding comparison plots across the 5 histograms located in the column directly above. <bold>j,</bold> Statistical comparisons of the measured image property distributions by 2-sample Kolmogorov- Smirnov test. <italic>P</italic> values are corrected for multiple comparisons by the Bonferroni method. For each of the physical image properties analyzed in columns (a-h), row (j) presents the corresponding matrix of statistical comparisons (<italic>i.e.</italic>, the 1<sup>st</sup> row of colored circles presents comparisons for video 1 vs. 2, video 1 vs. 3, etc.; while the 2<sup>nd</sup> row presents comparisons for video 2 vs. 3, 2 vs. 4, etc.). <bold>k,</bold> Still images sampled from videos depicting triadic peer interaction stimuli (scenes of children interacting in a daycare setting). Still images from 5 of 12 videos are shown (all 12 triadic peer interaction videos included in actual analyses). <bold>l,</bold> Eye regions demarcated from each still image in (k). <bold>m-t,</bold> All parts of (m-t) are as in (c-j).</p>
</caption>
<graphic xlink:href="nihms879771f11"></graphic>
</fig>
<table-wrap id="T1" orientation="portrait" position="anchor">
<label>Extended Data Table 1</label>
<caption>
<title>Participant Demographics</title>
</caption>
<table frame="hsides" rules="none">
<thead>
<tr>
<th align="left" colspan="1" rowspan="1"></th>
<th align="center" colspan="2" rowspan="1">Total Epidemiologically-<break></break>Ascertained Twins</th>
<th align="center" colspan="2" rowspan="1">Eye-Tracking Participants<break></break>(Twins)</th>
<th align="center" colspan="2" rowspan="1">Eye-Tracking Participants<break></break>(Non-Siblings)</th>
</tr>
<tr>
<th align="left" colspan="7" rowspan="1" valign="bottom">
<hr/></th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1"></th>
<th align="center" colspan="1" rowspan="1">%</th>
<th align="center" colspan="1" rowspan="1">N</th>
<th align="center" colspan="1" rowspan="1">%</th>
<th align="center" colspan="1" rowspan="1">N</th>
<th align="center" colspan="1" rowspan="1">%</th>
<th align="center" colspan="1" rowspan="1">N</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Sex</bold>
</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  Male</td>
<td align="center" colspan="1" rowspan="1">47.8</td>
<td align="center" colspan="1" rowspan="1">172</td>
<td align="center" colspan="1" rowspan="1">55.4</td>
<td align="center" colspan="1" rowspan="1">92</td>
<td align="center" colspan="1" rowspan="1">52.4</td>
<td align="center" colspan="1" rowspan="1">44</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  Female</td>
<td align="center" colspan="1" rowspan="1">52.2</td>
<td align="center" colspan="1" rowspan="1">188</td>
<td align="center" colspan="1" rowspan="1">44.6</td>
<td align="center" colspan="1" rowspan="1">74</td>
<td align="center" colspan="1" rowspan="1">47.6</td>
<td align="center" colspan="1" rowspan="1">40</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Zygosity</bold>
</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  Monozygotic</td>
<td align="center" colspan="1" rowspan="1">35</td>
<td align="center" colspan="1" rowspan="1">126</td>
<td align="center" colspan="1" rowspan="1">49.4</td>
<td align="center" colspan="1" rowspan="1">82</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  Dizygotic</td>
<td align="center" colspan="1" rowspan="1">58.3</td>
<td align="center" colspan="1" rowspan="1">210</td>
<td align="center" colspan="1" rowspan="1">50.6</td>
<td align="center" colspan="1" rowspan="1">84</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<italic>    same sex</italic>
</td>
<td align="center" colspan="1" rowspan="1">36.1</td>
<td align="center" colspan="1" rowspan="1">130</td>
<td align="center" colspan="1" rowspan="1">50.6</td>
<td align="center" colspan="1" rowspan="1">84</td>
<td align="center" colspan="1" rowspan="1">N/A</td>
<td align="center" colspan="1" rowspan="1">N/A</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<italic>    opposite sex</italic>
</td>
<td align="center" colspan="1" rowspan="1">22.2</td>
<td align="center" colspan="1" rowspan="1">80</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  Undetermined</td>
<td align="center" colspan="1" rowspan="1">6.7</td>
<td align="center" colspan="1" rowspan="1">24</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Income</bold>
</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  ≤ $29,999</td>
<td align="center" colspan="1" rowspan="1">19.4</td>
<td align="center" colspan="1" rowspan="1">70</td>
<td align="center" colspan="1" rowspan="1">15.7</td>
<td align="center" colspan="1" rowspan="1">26</td>
<td align="center" colspan="1" rowspan="1">6.1</td>
<td align="center" colspan="1" rowspan="1">5</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  $30,000–$59,999</td>
<td align="center" colspan="1" rowspan="1">24.4</td>
<td align="center" colspan="1" rowspan="1">88</td>
<td align="center" colspan="1" rowspan="1">24.1</td>
<td align="center" colspan="1" rowspan="1">40</td>
<td align="center" colspan="1" rowspan="1">10.6</td>
<td align="center" colspan="1" rowspan="1">9</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  $60,000–$89,999</td>
<td align="center" colspan="1" rowspan="1">21.7</td>
<td align="center" colspan="1" rowspan="1">78</td>
<td align="center" colspan="1" rowspan="1">22.9</td>
<td align="center" colspan="1" rowspan="1">38</td>
<td align="center" colspan="1" rowspan="1">18.6</td>
<td align="center" colspan="1" rowspan="1">16</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  ≥ $90,000</td>
<td align="center" colspan="1" rowspan="1">30.6</td>
<td align="center" colspan="1" rowspan="1">110</td>
<td align="center" colspan="1" rowspan="1">37.3</td>
<td align="center" colspan="1" rowspan="1">62</td>
<td align="center" colspan="1" rowspan="1">56.6</td>
<td align="center" colspan="1" rowspan="1">46</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  N/A</td>
<td align="center" colspan="1" rowspan="1">3.9</td>
<td align="center" colspan="1" rowspan="1">14</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">8.1</td>
<td align="center" colspan="1" rowspan="1">7</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Race</bold>
</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  Asian</td>
<td align="center" colspan="1" rowspan="1">1.1</td>
<td align="center" colspan="1" rowspan="1">4</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">4.8</td>
<td align="center" colspan="1" rowspan="1">4</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  Black/African-American</td>
<td align="center" colspan="1" rowspan="1">21.1</td>
<td align="center" colspan="1" rowspan="1">76</td>
<td align="center" colspan="1" rowspan="1">14.5</td>
<td align="center" colspan="1" rowspan="1">24</td>
<td align="center" colspan="1" rowspan="1">4.8</td>
<td align="center" colspan="1" rowspan="1">4</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  Caucasian</td>
<td align="center" colspan="1" rowspan="1">77.8</td>
<td align="center" colspan="1" rowspan="1">280</td>
<td align="center" colspan="1" rowspan="1">85.5</td>
<td align="center" colspan="1" rowspan="1">142</td>
<td align="center" colspan="1" rowspan="1">78.5</td>
<td align="center" colspan="1" rowspan="1">66</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  More than one race</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">7.1</td>
<td align="center" colspan="1" rowspan="1">6</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  Unknown / Not reported</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">4.8</td>
<td align="center" colspan="1" rowspan="1">4</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Ethnicity</bold>
</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  Hispanic</td>
<td align="center" colspan="1" rowspan="1">7.8</td>
<td align="center" colspan="1" rowspan="1">28</td>
<td align="center" colspan="1" rowspan="1">8.4</td>
<td align="center" colspan="1" rowspan="1">14</td>
<td align="center" colspan="1" rowspan="1">7.3</td>
<td align="center" colspan="1" rowspan="1">6</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  Non-Hispanic</td>
<td align="center" colspan="1" rowspan="1">92.2</td>
<td align="center" colspan="1" rowspan="1">332</td>
<td align="center" colspan="1" rowspan="1">91.6</td>
<td align="center" colspan="1" rowspan="1">152</td>
<td align="center" colspan="1" rowspan="1">74.4</td>
<td align="center" colspan="1" rowspan="1">63</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">  Unknown / Not reported</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">0</td>
<td align="center" colspan="1" rowspan="1">18.3</td>
<td align="center" colspan="1" rowspan="1">15</td>
</tr>
</tbody>
</table>
</table-wrap>
<table-wrap id="T2" orientation="portrait" position="anchor">
<label>Extended Data Table 2</label>
<caption>
<title>Concordance in social visual engagement at 21 months, at 36 months, and from 21 until 36 months</title>
<p id="P82"><bold>a,</bold> Concordance in social visual engagement at 21 months. <bold>b,</bold> Concordance in social visual engagement in subset seen for repeated testing at 36 months (see Methods). <bold>c,</bold> Cross-twin concordance in social visual engagement from 21 (time 1, twin 1) until 36 months (time 2, twin 2). In all cases, results are given as intraclass correlation coefficient (ICC) with 95% confidence intervals in parentheses.</p>
</caption>
<table frame="below" rules="groups">
<thead>
<tr>
<th align="left" colspan="6" rowspan="1">a</th>
</tr>
<tr>
<th align="left" colspan="6" rowspan="1" valign="bottom">
<hr/></th>
</tr>
<tr>
<th align="center" colspan="1" rowspan="1"></th>
<th align="center" colspan="1" rowspan="1">Eyes</th>
<th align="center" colspan="1" rowspan="1">Mouth</th>
<th align="center" colspan="1" rowspan="1">Body</th>
<th align="center" colspan="1" rowspan="1">Object</th>
<th align="center" colspan="1" rowspan="1">Time Spent<break></break>Attending to Task</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>MZ Twins</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.91 (0.85 – 0.95)<xref ref-type="table-fn" rid="TFN2">**</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.86 (0.76 – 0.92)<xref ref-type="table-fn" rid="TFN2">**</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.71 (0.52 – 0.83)<xref ref-type="table-fn" rid="TFN2">**</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.66 (0.46 – 0.80)<xref ref-type="table-fn" rid="TFN2">**</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.46 (0.19 – 0.67)<xref ref-type="table-fn" rid="TFN1">*</xref></td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 41 pairs)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>DZ Twins</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.35 (0.07 – 0.59)<xref ref-type="table-fn" rid="TFN1">*</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.44 (0.16 – 0.65)<xref ref-type="table-fn" rid="TFN1">*</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.33 (0.04 – 0.57)<xref ref-type="table-fn" rid="TFN1">*</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.09 (0.00 – 0.38)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.34 (0.05 – 0.58)<xref ref-type="table-fn" rid="TFN1">*</xref></td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 42 pairs)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>Age-, Sex-Matched Non-Siblings</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.16 (0.00 – 0.44)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.13 (0.00 – 0.42)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.29 (0.00 – 0.55)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.14 (0.00 – 0.42)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.14 (0.00 – 0.43)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 42 pairs)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>Randomly-Matched Non-Siblings</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.00 (0.00 – 0.29)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.00 (0.00 – 0.29)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.00 (0.00 – 0.29)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.00 (0.00 – 0.30)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.00 (0.00 – 0.30)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 42 pairs; 10,000 resamplings)</td>
</tr>
</tbody>
</table>
<table frame="below" rules="groups">
<thead>
<tr>
<th align="left" colspan="6" rowspan="1">b</th>
</tr>
<tr>
<th align="left" colspan="6" rowspan="1" valign="bottom">
<hr/></th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1"></th>
<th align="center" colspan="1" rowspan="1">Eyes</th>
<th align="center" colspan="1" rowspan="1">Mouth</th>
<th align="center" colspan="1" rowspan="1">Body</th>
<th align="center" colspan="1" rowspan="1">Object</th>
<th align="center" colspan="1" rowspan="1">Time Spent<break></break>Attending to Task</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>MZ Twins</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.93 (0.75 – 0.98)<xref ref-type="table-fn" rid="TFN2">**</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.93 (0.77 – 0.98)<xref ref-type="table-fn" rid="TFN2">**</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.63 (0.08 – 0.88)<xref ref-type="table-fn" rid="TFN1">*</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.95 (0.81 – 0.99)<xref ref-type="table-fn" rid="TFN2">**</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.80 (0.19 – 0.94)<xref ref-type="table-fn" rid="TFN2">**</xref></td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 11 pairs)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>DZ Twins</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.25 (0.00 – 0.60)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.14 (0.00 – 0.52)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.21 (0.00 – 0.58)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.00 (0.00 – 0.41)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.23 (0.00 – 0.59)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 22 pairs)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>Randomly-Matched Pairs</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.00 (0.00 – 0.33)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.00 (0.00 – 0.33)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.00 (0.00 – 0.33)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.00 (0.00 – 0.33)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.00 (0.00 – 0.33)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 33 pairs)</td>
</tr>
</tbody>
</table>
<table frame="below" rules="groups">
<thead>
<tr>
<th align="left" colspan="6" rowspan="1">c</th>
</tr>
<tr>
<th align="left" colspan="6" rowspan="1" valign="bottom">
<hr/></th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1"></th>
<th align="center" colspan="1" rowspan="1">Eyes</th>
<th align="center" colspan="1" rowspan="1">Mouth</th>
<th align="center" colspan="1" rowspan="1">Body</th>
<th align="center" colspan="1" rowspan="1">Object</th>
<th align="center" colspan="1" rowspan="1">Time Spent<break></break>Attending to Task</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>MZ Twins</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.70 (0.40 – 0.86)<xref ref-type="table-fn" rid="TFN2">**</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.73 (0.45 – 0.88)<xref ref-type="table-fn" rid="TFN2">**</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.21 (0.00 – 0.58)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.74 (0.47 – 0.88)<xref ref-type="table-fn" rid="TFN2">**</xref></td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.09 (0.00 – 0.49)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 11 pairs)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>DZ Twins</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.22 (0.00 – 0.49)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.07 (0.00 – 0.36)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.02 (0.00 – 0.31)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.07 (0.00 – 0.35)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.00 (0.00 – 0.30)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 22 pairs)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<fn id="TFN1">
<p id="P83">Single asterisk (*) signifies <italic>P</italic> &lt; 0.05 significance value, one-sided comparison relative to 0.</p>
</fn>
<fn id="TFN2">
<p id="P84">Double asterisk (**) signifies <italic>P</italic> &lt; 0.01 significance value, one-sided comparison relative to 0.</p>
</fn>
</table-wrap-foot>
</table-wrap>
<table-wrap id="T3" orientation="portrait" position="anchor">
<label>Extended Data Table 3</label>
<caption>
<title>Size of experimental stimuli and viewing time summaries</title>
<p id="P85"><bold>a,</bold> Size of Regions-of-Interest, Dyadic Mutual Gaze Stimuli. Data are given as mean (SD) in degrees of visual angle. Object ROIs generally spanned the full horizontal and vertical extent of the background in all video images, excepting cases of some body and hand gestures, as shown in <xref ref-type="fig" rid="F5">Extended Data Figure 1</xref>. The average minimum visual area subtended by any portion of the object ROI is equal to the difference between object and body ROIs. <bold>b,</bold> Size of Regions-of-Interest, Triadic Peer Interaction Stimuli. Data are given as mean (SD) in degrees of visual angle. Eyes and Mouth ROI sizes reflect the average size of a single face within the stimuli. Body ROIs are frequently contiguous between individuals in the stimuli (see <xref ref-type="fig" rid="F10">Extended Data Figure 6k</xref>); measures reflect total body region size. <bold>c,</bold> Total Viewing Time and Time Spent in Fixation, Saccade, Offscreen/Missing, Blink; mean (SD) in minutes. All measures summarized across both Dyadic Mutual Gaze Stimuli and Triadic Peer Interaction Stimuli. Non-sibling controls watched foreshortened subset of video stimuli. <bold>c,</bold> Time Fixating Per Onscreen Region-of-Interest, mean (SD) in minutes. All measures summarized across both Dyadic Mutual Gaze Stimuli and Triadic Peer Interaction Stimuli. Non-sibling controls watched foreshortened subset of video stimuli.</p>
</caption>
<table frame="below" rules="groups">
<thead>
<tr>
<th align="left" colspan="5" rowspan="1">a</th>
</tr>
<tr>
<th align="left" colspan="5" rowspan="1" valign="bottom">
<hr/></th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1"></th>
<th align="center" colspan="1" rowspan="1">Eyes</th>
<th align="center" colspan="1" rowspan="1">Mouth</th>
<th align="center" colspan="1" rowspan="1">Body</th>
<th align="center" colspan="1" rowspan="1">Object</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Horizontal</bold>
</td>
<td align="center" colspan="1" rowspan="1">8.04° (0.46)</td>
<td align="center" colspan="1" rowspan="1">7.71° (0.49)</td>
<td align="center" colspan="1" rowspan="1">25.11° (2.70)</td>
<td align="center" colspan="1" rowspan="1">31.99° (0.05)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Vertical</bold>
</td>
<td align="center" colspan="1" rowspan="1">6.91° (0.44)</td>
<td align="center" colspan="1" rowspan="1">5.72° (0.59)</td>
<td align="center" colspan="1" rowspan="1">21.71° (0.73)</td>
<td align="center" colspan="1" rowspan="1">23.94° (0.49)</td>
</tr>
</tbody>
</table>
<table frame="below" rules="groups">
<thead>
<tr>
<th align="left" colspan="5" rowspan="1">b</th>
</tr>
<tr>
<th align="left" colspan="5" rowspan="1" valign="bottom">
<hr/></th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1"></th>
<th align="center" colspan="1" rowspan="1">Eyes</th>
<th align="center" colspan="1" rowspan="1">Mouth</th>
<th align="center" colspan="1" rowspan="1">Body</th>
<th align="center" colspan="1" rowspan="1">Object</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Horizontal</bold>
</td>
<td align="center" colspan="1" rowspan="1">4.64° (2.75)</td>
<td align="center" colspan="1" rowspan="1">4.24° (2.54)</td>
<td align="center" colspan="1" rowspan="1">20.64° (7.66)</td>
<td align="center" colspan="1" rowspan="1">28.00° (6.81)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Vertical</bold>
</td>
<td align="center" colspan="1" rowspan="1">4.06° (2.19)</td>
<td align="center" colspan="1" rowspan="1">3.16° (1.54)</td>
<td align="center" colspan="1" rowspan="1">20.83° (4.09)</td>
<td align="center" colspan="1" rowspan="1">23.62° (1.74)</td>
</tr>
</tbody>
</table>
<table frame="below" rules="groups">
<thead>
<tr>
<th align="left" colspan="6" rowspan="1">c</th>
</tr>
<tr>
<th align="left" colspan="6" rowspan="1" valign="bottom">
<hr/></th>
</tr>
<tr>
<th align="center" colspan="1" rowspan="1"></th>
<th align="center" colspan="1" rowspan="1">Fixation</th>
<th align="center" colspan="1" rowspan="1">Saccade</th>
<th align="center" colspan="1" rowspan="1">Offscreen/Missing</th>
<th align="center" colspan="1" rowspan="1">Blink</th>
<th align="center" colspan="1" rowspan="1">Total Viewing Time</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>MZ Twins</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">11.43 (2.86)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">3.28 (1.07)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">3.12 (1.68)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.36 (0.23)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">18.20 (3.12)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 42 pairs)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>DZ Twins</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">11.54 (3.24)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">3.24 (1.05)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">2.82 (1.47)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.30 (0.19)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">17.90 (3.40)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 42 pairs)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>Non-Sibling Controls</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">6.93 (3.01)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">1.55 (0.71)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">1.30 (0.93)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.25 (0.30)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">10.03 (3.81)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 42 pairs)</td>
</tr>
</tbody>
</table>
<table frame="below" rules="groups">
<thead>
<tr>
<th align="left" colspan="5" rowspan="1">d</th>
</tr>
<tr>
<th align="left" colspan="5" rowspan="1" valign="bottom">
<hr/></th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1"></th>
<th align="center" colspan="1" rowspan="1">Eyes</th>
<th align="center" colspan="1" rowspan="1">Mouth</th>
<th align="center" colspan="1" rowspan="1">Body</th>
<th align="center" colspan="1" rowspan="1">Object</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>MZ Twins</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">2.09 (1.57)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">3.71 (1.67)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">3.27 (0.83)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">2.37 (0.71)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 41 pairs)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>DZ Twins</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">2.02 (1.48)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">3.85 (1.87)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">3.34 (1.00)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">2.33 (0.74)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 42 pairs)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">
<bold>Non-Sibling Controls</bold>
</td>
<td align="center" colspan="1" rowspan="2" valign="middle">1.92 (1.48)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">2.84 (1.87)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">1.30 (0.56)</td>
<td align="center" colspan="1" rowspan="2" valign="middle">0.87 (0.42)</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">(N = 42 pairs)</td>
</tr>
</tbody>
</table>
</table-wrap>
</sec>
<sec id="SM" sec-type="supplementary-material">
<title>Supplementary Material</title>
<supplementary-material content-type="local-data" id="SD1">
<label>Movie 1</label>
<media id="d36e2978" mimetype="video" orientation="portrait" position="anchor" xlink:href="NIHMS879771-supplement-Movie_1.mov" xlink:type="simple"></media>
</supplementary-material>
<supplementary-material content-type="local-data" id="SD2">
<label>Movie 2</label>
<media id="d36e2982" mimetype="video" orientation="portrait" position="anchor" xlink:href="NIHMS879771-supplement-Movie_2.mov" xlink:type="simple"></media>
</supplementary-material>
<supplementary-material content-type="local-data" id="SD3">
<label>Movie 3</label>
<media id="d36e2986" mimetype="video" orientation="portrait" position="anchor" xlink:href="NIHMS879771-supplement-Movie_3.mov" xlink:type="simple"></media>
</supplementary-material>
<supplementary-material content-type="local-data" id="SD4">
<label>Movie 4</label>
<media id="d36e2990" mimetype="video" orientation="portrait" position="anchor" xlink:href="NIHMS879771-supplement-Movie_4.mov" xlink:type="simple"></media>
</supplementary-material>
<supplementary-material content-type="local-data" id="SD5">
<label>Supp 1</label>
<media id="d36e2994" orientation="portrait" position="anchor" xlink:href="NIHMS879771-supplement-Supp_1.docx" xlink:type="simple"></media>
</supplementary-material>
</sec>
</body>
<back>
<fn-group>
<fn id="FN2">
<p id="P86"><bold>Data Availability</bold>. The data that support the findings of this study are available from the corresponding author upon reasonable request.</p>
</fn>
<fn id="FN3">
<p id="P87"><xref ref-type="supplementary-material" rid="SD5">Supplementary Information</xref> is available in the online version of the paper.</p>
</fn>
<fn fn-type="con" id="FN4">
<p id="P88"><bold>Author Contributions</bold> J.N.C., A.L.G., A.K., and W.J. developed the initial idea and study design. J.N.C. and W.J. had full access to all data and take responsibility for data integrity and accuracy of analyses. J.N.C. supervised participant characterization. W.J. supervised technology development, data acquisition, and analysis. S.K-M., C.W., N.M., and A.H. collected data, ensured quality control at Washington University, conducted sub-analyses, and participated in manuscript writing and revision. S.G., C.K., and W.J. performed data processing at Emory, ensured quality control across sites, and participated in manuscript revision. W.J., A.K. and J.N.C. interpreted data and wrote the manuscript.</p>
</fn>
<fn id="FN5">
<p id="P89">The authors declare no competing financial interests.</p>
</fn>
</fn-group>
<ack id="S20">
<p id="P90">We thank the families and children for their participation. Research was supported by grants from the National Institute of Child Health &amp; Human Development, HD068479 (JNC) and U54 HD087011 (Intellectual and Developmental Disabilities Research Center at Washington University, JNC PI); and by the National Institute of Mental Health, MH100019 (NM) and MH100029 (AK, WJ). Additional support provided by the Marcus Foundation, the Whitehead Foundation, and the Georgia Research Alliance. Epidemiologic ascertainment of twins was made possible by the Missouri Family Register, a joint program of Washington University and the Missouri Department of Health and Senior Services; authorization to access was approved by the MO DHSS Institutional Review Board (Sharon Ayers, Chair) under auspices of the project entitled, <italic>Early Quantitative Characterization of Reciprocal Social Behavior.</italic> We thank Erika Mortenson, Sayli Sant, Teddi Gray, Yi Zhang, Laura Campbell, Leena Malik, Alyna Khan and Elizabeth McGarry for data collection and analysis; Andrew C. Heath and Arpana Agrawal for discussions of data analysis and statistics; Caroline Drain and Deborah Hopper for project coordination and data collection; Dejan Jovanovic and Rade Todorovic for contributions to twin family ascertainment; Megan Panther for administrative support; and Steve Kovar, Jose Paredes, and Maria Ly for designing and building the eye-tracking laboratory.</p>
</ack>
<ref-list>
<ref id="R1">
<label>1</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gibson</surname>
<given-names>EJ</given-names>
</name>
</person-group>
<article-title>Exploratory behavior in the development of perceiving, acting, and the acquiring of knowledge</article-title>
<source/>Annu. Rev. Psychol
          <volume>39</volume>
<fpage>1</fpage>
<lpage>41</lpage>
<year>1988</year>
</element-citation>
</ref>
<ref id="R2">
<label>2</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Valenza</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Simion</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Cassia</surname>
<given-names>VM</given-names>
</name>
<name>
<surname>Umiltà</surname>
<given-names>C</given-names>
</name>
</person-group>
<article-title>Face preference at birth</article-title>
<source/>J. Exp. Psychol. Hum. Percept. Perform
          <volume>22</volume>
<fpage>892</fpage>
<year>1996</year>
<pub-id pub-id-type="pmid">8756957</pub-id>
</element-citation>
</ref>
<ref id="R3">
<label>3</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Goren</surname>
<given-names>CC</given-names>
</name>
<name>
<surname>Sarty</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Wu</surname>
<given-names>PYK</given-names>
</name>
</person-group>
<article-title>Visual Following and Pattern Discrimination of Face-like Stimuli by Newborn Infants</article-title>
<source/>Pediatrics
          <volume>56</volume>
<fpage>544</fpage>
<lpage>549</lpage>
<year>1975</year>
<pub-id pub-id-type="pmid">1165958</pub-id>
</element-citation>
</ref>
<ref id="R4">
<label>4</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Simion</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Regolin</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Bulf</surname>
<given-names>H</given-names>
</name>
</person-group>
<article-title>A predisposition for biological motion in the newborn baby</article-title>
<source/>Proc. Natl. Acad. Sci
          <volume>105</volume>
<fpage>809</fpage>
<lpage>813</lpage>
<year>2008</year>
<pub-id pub-id-type="pmid">18174333</pub-id>
</element-citation>
</ref>
<ref id="R5">
<label>5</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Simion</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Leo</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Turati</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Valenza</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Dalla Barba</surname>
<given-names>B</given-names>
</name>
</person-group>
<article-title>How face specialization emerges in the first months of life</article-title>
<source/>Progress in Brain Research
          <volume>164</volume>
<fpage>169</fpage>
<lpage>185</lpage>
<year>2007</year>
<pub-id pub-id-type="pmid">17920431</pub-id>
</element-citation>
</ref>
<ref id="R6">
<label>6</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jones</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Klin</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Attention to eyes is present but in decline in 2–6-month-old infants later diagnosed with autism</article-title>
<source/>Nature
          <volume>504</volume>
<fpage>427</fpage>
<lpage>31</lpage>
<year>2013</year>
<pub-id pub-id-type="pmid">24196715</pub-id>
</element-citation>
</ref>
<ref id="R7">
<label>7</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Scarr</surname>
<given-names>S</given-names>
</name>
<name>
<surname>McCartney</surname>
<given-names>K</given-names>
</name>
</person-group>
<article-title>How People Make Their Own Environments: A Theory of Genotype -&gt;Environment Effects</article-title>
<source/>Child Dev
          <volume>54</volume>
<fpage>424</fpage>
<lpage>435</lpage>
<year>1983</year>
<pub-id pub-id-type="pmid">6683622</pub-id>
</element-citation>
</ref>
<ref id="R8">
<label>8</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Constantino</surname>
<given-names>JN</given-names>
</name>
<name>
<surname>Charman</surname>
<given-names>T</given-names>
</name>
</person-group>
<article-title>Diagnosis of autism spectrum disorder: Reconciling the syndrome, its diverse origins, and variation in expression</article-title>
<source/>Lancet Neurol
          <volume>15</volume>
<fpage>279</fpage>
<lpage>291</lpage>
<year>2015</year>
<pub-id pub-id-type="pmid">26497771</pub-id>
</element-citation>
</ref>
<ref id="R9">
<label>9</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Constantino</surname>
<given-names>JN</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Autism recurrence in half siblings: strong support for genetic mechanisms of transmission in ASD</article-title>
<source/>Mol. Psychiatry
          <volume>18</volume>
<fpage>137</fpage>
<lpage>8</lpage>
<year>2013</year>
<pub-id pub-id-type="pmid">22371046</pub-id>
</element-citation>
</ref>
<ref id="R10">
<label>10</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gaugler</surname>
<given-names>T</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Most genetic risk for autism resides with common variation</article-title>
<source/>Nat. Genet
          <volume>46</volume>
<fpage>881</fpage>
<lpage>5</lpage>
<year>2014</year>
<pub-id pub-id-type="pmid">25038753</pub-id>
</element-citation>
</ref>
<ref id="R11">
<label>11</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Robinson</surname>
<given-names>EB</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Evidence that autistic traits show the same etiology in the general population and at the quantitative extremes (5%, 2.5%, and 1%)</article-title>
<source/>Arch. Gen. Psychiatry
          <volume>68</volume>
<fpage>1113</fpage>
<lpage>21</lpage>
<year>2011</year>
<pub-id pub-id-type="pmid">22065527</pub-id>
</element-citation>
</ref>
<ref id="R12">
<label>12</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Geschwind</surname>
<given-names>DH</given-names>
</name>
<name>
<surname>State</surname>
<given-names>MW</given-names>
</name>
</person-group>
<article-title>Gene hunting in autism spectrum disorder: On the path to precision medicine</article-title>
<source/>The Lancet Neurology
          <volume>14</volume>
<fpage>1109</fpage>
<lpage>1120</lpage>
<year>2015</year>
<pub-id pub-id-type="pmid">25891009</pub-id>
</element-citation>
</ref>
<ref id="R13">
<label>13</label>
<element-citation publication-type="book">
<collab>American Psychiatric Association</collab>
<source/>Diagnostic and Statistical Manual of Mental Disorders, fifth edition: DSM-5
          <publisher-name>American Psychiatric Pub</publisher-name>
<year>2013</year>
<pub-id pub-id-type="doi">10.1176/appi.books.9780890425596.744053</pub-id>
</element-citation>
</ref>
<ref id="R14">
<label>14</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Magiati</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Tay</surname>
<given-names>XW</given-names>
</name>
<name>
<surname>Howlin</surname>
<given-names>P</given-names>
</name>
</person-group>
<article-title>Cognitive, language, social and behavioural outcomes in adults with autism spectrum disorders: A systematic review of longitudinal follow-up studies in adulthood</article-title>
<source/>Clin. Psychol. Rev
          <volume>34</volume>
<fpage>73</fpage>
<lpage>86</lpage>
<year>2014</year>
<pub-id pub-id-type="pmid">24424351</pub-id>
</element-citation>
</ref>
<ref id="R15">
<label>15</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Shultz</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Klin</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Jones</surname>
<given-names>W</given-names>
</name>
</person-group>
<article-title>Inhibition of eye blinking reveals subjective perceptions of stimulus salience</article-title>
<source/>Proc. Natl. Acad. Sci. U. S. A
          <volume>108</volume>
<fpage>21270</fpage>
<lpage>5</lpage>
<year>2011</year>
<pub-id pub-id-type="pmid">22160686</pub-id>
</element-citation>
</ref>
<ref id="R16">
<label>16</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Klin</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Jones</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Schultz</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Volkmar</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Cohen</surname>
<given-names>D</given-names>
</name>
</person-group>
<article-title>Visual fixation patterns during viewing of naturalistic social situations as predictors of social competence in individuals with autism</article-title>
<source/>Arch. Gen. Psychiatry
          <volume>59</volume>
<fpage>809</fpage>
<lpage>816</lpage>
<year>2002</year>
<pub-id pub-id-type="pmid">12215080</pub-id>
</element-citation>
</ref>
<ref id="R17">
<label>17</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Pearce</surname>
<given-names>JM</given-names>
</name>
<name>
<surname>Bouton</surname>
<given-names>ME</given-names>
</name>
</person-group>
<article-title>Theories of associative learning in animals</article-title>
<source/>Annu. Rev. Psychol
          <volume>52</volume>
<fpage>111</fpage>
<lpage>139</lpage>
<year>2001</year>
<pub-id pub-id-type="pmid">11148301</pub-id>
</element-citation>
</ref>
<ref id="R18">
<label>18</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dickinson</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Actions and Habits: The Development of Behavioural Autonomy</article-title>
<source/>Philos. Trans. R. Soc. Lond. B. Biol. Sci
          <volume>308</volume>
<fpage>67</fpage>
<lpage>78</lpage>
<year>1985</year>
</element-citation>
</ref>
<ref id="R19">
<label>19</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Good</surname>
<given-names>P</given-names>
</name>
</person-group>
<source/>Permutation, parametric, and bootstrap tests of hypotheses
          <publisher-name>Springer</publisher-name>
<year>2000</year>
</element-citation>
</ref>
<ref id="R20">
<label>20</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Liben</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Müller</surname>
<given-names>U</given-names>
</name>
<name>
<surname>Lerner</surname>
<given-names>R</given-names>
</name>
</person-group>
<source/>Handbook of child psychology and developmental science. Volume 2. Cognitive Processes (Seventh ed.)
          <publisher-name>John Wiley &amp; Sons</publisher-name>
<year>2015</year>
</element-citation>
</ref>
<ref id="R21">
<label>21</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>McGraw</surname>
<given-names>KO</given-names>
</name>
<name>
<surname>Wong</surname>
<given-names>SP</given-names>
</name>
</person-group>
<article-title>Forming inferences about some intraclass correlations coefficients</article-title>
<source/>Psychol. Methods
          <volume>1</volume>
<fpage>30</fpage>
<lpage>46</lpage>
<year>1996</year>
</element-citation>
</ref>
<ref id="R22">
<label>22</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jacquard</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Heritability: One Word, Three Concepts</article-title>
<source/>Biometrics
          <volume>39</volume>
<fpage>465</fpage>
<lpage>477</lpage>
<year>1983</year>
<pub-id pub-id-type="pmid">6626665</pub-id>
</element-citation>
</ref>
<ref id="R23">
<label>23</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Leigh</surname>
<given-names>RJ</given-names>
</name>
<name>
<surname>Zee</surname>
<given-names>DS</given-names>
</name>
</person-group>
<source/>The Neurology of Eye Movements
          <publisher-name>Oxford University Press</publisher-name>
<publisher-loc>USA</publisher-loc>
<year>2006</year>
</element-citation>
</ref>
<ref id="R24">
<label>24</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Schall</surname>
<given-names>JD</given-names>
</name>
<name>
<surname>Thompson</surname>
<given-names>KG</given-names>
</name>
</person-group>
<article-title>Neural Selection and Control of Visually Guided Eye Movements</article-title>
<source/>Annu. Rev. Neurosci
          <volume>22</volume>
<fpage>241</fpage>
<lpage>259</lpage>
<year>1999</year>
<pub-id pub-id-type="pmid">10202539</pub-id>
</element-citation>
</ref>
<ref id="R25">
<label>25</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Marr</surname>
<given-names>D</given-names>
</name>
</person-group>
<article-title>Vision: A Computational Investigation into the Human Representation and Processing of Visual Information</article-title>
<source/>New York
          <volume>397</volume>
<year>1982</year>
<pub-id pub-id-type="doi">10.2307/2185011</pub-id>
</element-citation>
</ref>
<ref id="R26">
<label>26</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Treue</surname>
<given-names>S</given-names>
</name>
</person-group>
<article-title>Visual attention: The where, what, how and why of saliency</article-title>
<source/>Current Opinion in Neurobiology
          <volume>13</volume>
<fpage>428</fpage>
<lpage>432</lpage>
<year>2003</year>
<pub-id pub-id-type="pmid">12965289</pub-id>
</element-citation>
</ref>
<ref id="R27">
<label>27</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hopfinger</surname>
<given-names>JB</given-names>
</name>
<name>
<surname>Buonocore</surname>
<given-names>MH</given-names>
</name>
<name>
<surname>Mangun</surname>
<given-names>GR</given-names>
</name>
</person-group>
<article-title>The neural mechanisms of top-down attentional control</article-title>
<source/>Nat. Neurosci
          <volume>3</volume>
<fpage>284</fpage>
<lpage>291</lpage>
<year>2000</year>
<pub-id pub-id-type="pmid">10700262</pub-id>
</element-citation>
</ref>
<ref id="R28">
<label>28</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wang</surname>
<given-names>S</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Atypical Visual Saliency in Autism Spectrum Disorder Quantified through Model-Based Eye Tracking</article-title>
<source/>Neuron
          <volume>88</volume>
<fpage>604</fpage>
<lpage>616</lpage>
<year>2015</year>
<pub-id pub-id-type="pmid">26593094</pub-id>
</element-citation>
</ref>
<ref id="R29">
<label>29</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Oyama</surname>
<given-names>S</given-names>
</name>
</person-group>
<source/>Evolution’s eye: A systems view of the biology-culture divide
          <publisher-name>Duke University Press</publisher-name>
<year>2000</year>
</element-citation>
</ref>
<ref id="R30">
<label>30</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Klin</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Jones</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Schultz</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Volkmar</surname>
<given-names>F</given-names>
</name>
</person-group>
<article-title>The enactive mind, or from actions to cognition: lessons from autism</article-title>
<source/>Philos. Trans. R. Soc. Lond. B. Biol. Sci
          <volume>358</volume>
<fpage>345</fpage>
<lpage>60</lpage>
<year>2003</year>
<pub-id pub-id-type="pmid">12639332</pub-id>
</element-citation>
</ref>
<ref id="R31">
<label>31</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Marrus</surname>
<given-names>N</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Rapid video-referenced ratings of reciprocal social behavior in toddlers: a twin study</article-title>
<source/>J. Child Psychol. Psychiatry
          <volume>56</volume>
<fpage>1338</fpage>
<lpage>46</lpage>
<year>2015</year>
<pub-id pub-id-type="pmid">25677414</pub-id>
</element-citation>
</ref>
<ref id="R32">
<label>32</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Lord</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Rutter</surname>
<given-names>M</given-names>
</name>
<name>
<surname>DiLavore</surname>
<given-names>PC</given-names>
</name>
<name>
<surname>Risi</surname>
<given-names>S</given-names>
</name>
</person-group>
<source/>Autism Diagnostic Observation Schedule
          <publisher-name>Western Psychological Services</publisher-name>
<year>2002</year>
</element-citation>
</ref>
<ref id="R33">
<label>33</label>
<element-citation publication-type="book">
<collab>American Psychiatric Association</collab>
<source/>Diagnostic and Statistical Manual of Mental Disorders, fourth edition, text revision: DSM-IV-TR
          <publisher-name>American Psychiatric Association</publisher-name>
<year>2004</year>
</element-citation>
</ref>
<ref id="R34">
<label>34</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Price</surname>
<given-names>TS</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Infant zygosity can be assigned by parental report questionnaire data</article-title>
<source/>Twin Res
          <volume>3</volume>
<fpage>129</fpage>
<lpage>33</lpage>
<year>2000</year>
<pub-id pub-id-type="pmid">11035484</pub-id>
</element-citation>
</ref>
<ref id="R35">
<label>35</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Neale</surname>
<given-names>MC</given-names>
</name>
<name>
<surname>Stevenson</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>Rater bias in the EASI temperament scales: a twin study</article-title>
<source/>J. Pers. Soc. Psychol
          <volume>56</volume>
<fpage>446</fpage>
<lpage>55</lpage>
<year>1989</year>
<pub-id pub-id-type="pmid">2926639</pub-id>
</element-citation>
</ref>
<ref id="R36">
<label>36</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jones</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Carr</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Klin</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Absence of preferential looking to the eyes of approaching adults predicts level of social disability in 2-year-old toddlers with autism spectrum disorder</article-title>
<source/>Arch. Gen. Psychiatry
          <volume>65</volume>
<fpage>946</fpage>
<lpage>54</lpage>
<year>2008</year>
<pub-id pub-id-type="pmid">18678799</pub-id>
</element-citation>
</ref>
<ref id="R37">
<label>37</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Shrout</surname>
<given-names>PE</given-names>
</name>
<name>
<surname>Fleiss</surname>
<given-names>JL</given-names>
</name>
</person-group>
<article-title>Intraclass correlations: Uses in assessing rater reliability</article-title>
<source/>Psychol. Bull
          <volume>86</volume>
<fpage>420</fpage>
<lpage>428</lpage>
<year>1979</year>
<pub-id pub-id-type="pmid">18839484</pub-id>
</element-citation>
</ref>
<ref id="R38">
<label>38</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Locke</surname>
<given-names>JL</given-names>
</name>
</person-group>
<source/>The child’s path to spoken language
          <publisher-name>Harvard University Press</publisher-name>
<year>1993</year>
</element-citation>
</ref>
<ref id="R39">
<label>39</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fleiss</surname>
<given-names>JL</given-names>
</name>
<name>
<surname>Shrout</surname>
<given-names>PE</given-names>
</name>
</person-group>
<article-title>Approximate interval estimation for a certain intraclass correlation coefficient</article-title>
<source/>Psychometrika
          <volume>43</volume>
<fpage>259</fpage>
<lpage>262</lpage>
<year>1978</year>
</element-citation>
</ref>
<ref id="R40">
<label>40</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Giraudeau</surname>
<given-names>B</given-names>
</name>
</person-group>
<article-title>Negative values of the intraclass correlation coefficient are not theoretically possible</article-title>
<source/>J. Clin. Epidemiol
          <volume>49</volume>
<fpage>1205</fpage>
<lpage>1206</lpage>
<year>1996</year>
<pub-id pub-id-type="pmid">8827004</pub-id>
</element-citation>
</ref>
<ref id="R41">
<label>41</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Emery</surname>
<given-names>NJ</given-names>
</name>
</person-group>
<article-title>The eyes have it: The neuroethology, function and evolution of social gaze</article-title>
<source/>Neuroscience and Biobehavioral Reviews
          <volume>24</volume>
<fpage>581</fpage>
<lpage>604</lpage>
<year>2000</year>
<pub-id pub-id-type="pmid">10940436</pub-id>
</element-citation>
</ref>
<ref id="R42">
<label>42</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Fairchild</surname>
<given-names>MD</given-names>
</name>
</person-group>
<source/>Color Appearance Models
          <publisher-name>John Wiley &amp; Sons Ltd</publisher-name>
<year>2005</year>
<pub-id pub-id-type="doi">10.1002/9781118653128</pub-id>
</element-citation>
</ref>
<ref id="R43">
<label>43</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Itti</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Koch</surname>
<given-names>C</given-names>
</name>
</person-group>
<article-title>A saliency-based search mechanism for overt and covert shifts of visual attention</article-title>
<source/>Vision Research
          <volume>40</volume>
<fpage>1489</fpage>
<lpage>1506</lpage>
<year>2000</year>
<pub-id pub-id-type="pmid">10788654</pub-id>
</element-citation>
</ref>
<ref id="R44">
<label>44</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Koch</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Ullman</surname>
<given-names>S</given-names>
</name>
</person-group>
<article-title>Shifts in selective visual attention: towards the underlying neural circuitry</article-title>
<source/>Hum. Neurobiol
          <volume>4</volume>
<fpage>219</fpage>
<lpage>27</lpage>
<year>1985</year>
<pub-id pub-id-type="pmid">3836989</pub-id>
</element-citation>
</ref>
<ref id="R45">
<label>45</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Itti</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Itti</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Koch</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Koch</surname>
<given-names>C</given-names>
</name>
</person-group>
<article-title>Computational modelling of visual attention</article-title>
<source/>Nat. Rev. Neurosci
          <volume>2</volume>
<fpage>194</fpage>
<lpage>203</lpage>
<year>2001</year>
<pub-id pub-id-type="pmid">11256080</pub-id>
</element-citation>
</ref>
<ref id="R46">
<label>46</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Parkhurst</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Law</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Niebur</surname>
<given-names>E</given-names>
</name>
</person-group>
<article-title>Modeling the role of salience in the allocation of overt visual attention</article-title>
<source/>Vision Res
          <volume>42</volume>
<fpage>107</fpage>
<lpage>123</lpage>
<year>2002</year>
<pub-id pub-id-type="pmid">11804636</pub-id>
</element-citation>
</ref>
<ref id="R47">
<label>47</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wolfe</surname>
<given-names>JM</given-names>
</name>
<name>
<surname>Horowitz</surname>
<given-names>TS</given-names>
</name>
</person-group>
<article-title>What attributes guide the deployment of visual attention and how do they do it?</article-title>
<source/>Nat. Rev. Neurosci
          <volume>5</volume>
<fpage>495</fpage>
<lpage>501</lpage>
<year>2004</year>
<pub-id pub-id-type="pmid">15152199</pub-id>
</element-citation>
</ref>
<ref id="R48">
<label>48</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Tsotsos</surname>
<given-names>JK</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Modeling visual attention via selective tuning</article-title>
<source/>Artif. Intell
          <volume>78</volume>
<fpage>507</fpage>
<lpage>545</lpage>
<year>1995</year>
</element-citation>
</ref>
<ref id="R49">
<label>49</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Yantis</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Egeth</surname>
<given-names>HE</given-names>
</name>
</person-group>
<article-title>On the distinction between visual salience and stimulus-driven attentional capture</article-title>
<source/>J. Exp. Psychol. Hum. Percept. Perform
          <volume>25</volume>
<fpage>661</fpage>
<lpage>676</lpage>
<year>1999</year>
<pub-id pub-id-type="pmid">10385983</pub-id>
</element-citation>
</ref>
<ref id="R50">
<label>50</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mazer</surname>
<given-names>JA</given-names>
</name>
<name>
<surname>Gallant</surname>
<given-names>JL</given-names>
</name>
</person-group>
<article-title>Goal-related activity in V4 during free viewing visual search: Evidence for a ventral stream visual salience map</article-title>
<source/>Neuron
          <volume>40</volume>
<fpage>1241</fpage>
<lpage>1250</lpage>
<year>2003</year>
<pub-id pub-id-type="pmid">14687556</pub-id>
</element-citation>
</ref>
<ref id="R51">
<label>51</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Henderson</surname>
<given-names>JM</given-names>
</name>
<name>
<surname>Brockmole</surname>
<given-names>JR</given-names>
</name>
<name>
<surname>Castelhano</surname>
<given-names>MS</given-names>
</name>
<name>
<surname>Mack</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>Visual saliency does not account for eye movements during visual search in real world scenes</article-title>
<source/>Eye Movements A Wind. Mind Brain
          <fpage>537</fpage>
<lpage>562</lpage>
<year>2007</year>
<pub-id pub-id-type="doi">10.1167/9.3.6</pub-id>
</element-citation>
</ref>
<ref id="R52">
<label>52</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lettvin</surname>
<given-names>JY</given-names>
</name>
<name>
<surname>Maturana</surname>
<given-names>HR</given-names>
</name>
<name>
<surname>McCulloch</surname>
<given-names>WS</given-names>
</name>
<name>
<surname>Pitts</surname>
<given-names>WH</given-names>
</name>
</person-group>
<article-title>What the Frog’s Eye Tells the Frogs’s Brain</article-title>
<source/>Proc. tha IRE
          <volume>3</volume>
<fpage>1940</fpage>
<lpage>1951</lpage>
<year>1959</year>
</element-citation>
</ref>
<ref id="R53">
<label>53</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Ghazanfar</surname>
<given-names>Aa</given-names>
</name>
<name>
<surname>Santos</surname>
<given-names>LR</given-names>
</name>
</person-group>
<article-title>Primate brains in the wild: the sensory bases for social interactions</article-title>
<source/>Nat. Rev. Neurosci
          <volume>5</volume>
<fpage>603</fpage>
<lpage>616</lpage>
<year>2004</year>
<pub-id pub-id-type="pmid">15263891</pub-id>
</element-citation>
</ref>
<ref id="R54">
<label>54</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Moore</surname>
<given-names>GP</given-names>
</name>
<name>
<surname>Perkel</surname>
<given-names>DH</given-names>
</name>
<name>
<surname>Segundo</surname>
<given-names>JP</given-names>
</name>
</person-group>
<article-title>Statistical analysis and functional interpretation of neuronal spike data</article-title>
<source/>Annu. Rev. Physiol
          <volume>28</volume>
<fpage>493</fpage>
<lpage>522</lpage>
<year>1966</year>
<pub-id pub-id-type="pmid">5323104</pub-id>
</element-citation>
</ref>
<ref id="R55">
<label>55</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Manly</surname>
<given-names>B</given-names>
</name>
</person-group>
<source/>Randomization, Bootstrap, and Monte Carlo Methods in Biology
          <publisher-name>Chapman &amp; Hall</publisher-name>
<year>2006</year>
</element-citation>
</ref>
<ref id="R56">
<label>56</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Oppenheim</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Schafer</surname>
<given-names>R</given-names>
</name>
</person-group>
<source/>Digital Signal Processing
          <publisher-name>Prentice-Hall</publisher-name>
<year>1975</year>
</element-citation>
</ref>
<ref id="R57">
<label>57</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Schnyder</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Reisine</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Hepp</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Henn</surname>
<given-names>V</given-names>
</name>
</person-group>
<article-title>Frontal eye field projection to the paramedian pontine reticular formation traced with wheat germ agglutinin in the monkey</article-title>
<source/>Brain Res
          <volume>329</volume>
<fpage>151</fpage>
<lpage>60</lpage>
<year>1985</year>
<pub-id pub-id-type="pmid">3978438</pub-id>
</element-citation>
</ref>
<ref id="R58">
<label>58</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hanes</surname>
<given-names>DP</given-names>
</name>
<name>
<surname>Wurtz</surname>
<given-names>RH</given-names>
</name>
</person-group>
<article-title>Interaction of the frontal eye field and superior colliculus for saccade generation</article-title>
<source/>J. Neurophysiol
          <volume>85</volume>
<fpage>804</fpage>
<lpage>15</lpage>
<year>2001</year>
<pub-id pub-id-type="pmid">11160514</pub-id>
</element-citation>
</ref>
<ref id="R59">
<label>59</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bruce</surname>
<given-names>CJ</given-names>
</name>
<name>
<surname>Goldberg</surname>
<given-names>ME</given-names>
</name>
</person-group>
<article-title>Physiology of the frontal eye fields</article-title>
<source/>Trends Neurosci
          <volume>7</volume>
<fpage>436</fpage>
<lpage>441</lpage>
<year>1984</year>
</element-citation>
</ref>
<ref id="R60">
<label>60</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Constantino</surname>
<given-names>JN</given-names>
</name>
<name>
<surname>Todd</surname>
<given-names>RD</given-names>
</name>
</person-group>
<article-title>Genetic structure of reciprocal social behavior</article-title>
<source/>Am. J. Psychiatry
          <volume>157</volume>
<fpage>2043</fpage>
<lpage>2045</lpage>
<year>2000</year>
<pub-id pub-id-type="pmid">11097975</pub-id>
</element-citation>
</ref>
<ref id="R61">
<label>61</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Constantino</surname>
<given-names>JN</given-names>
</name>
<name>
<surname>Todd</surname>
<given-names>RD</given-names>
</name>
</person-group>
<article-title>Autistic traits in the general population: a twin study</article-title>
<source/>Arch. Gen. Psychiatry
          <volume>60</volume>
<fpage>524</fpage>
<lpage>530</lpage>
<year>2003</year>
<pub-id pub-id-type="pmid">12742874</pub-id>
</element-citation>
</ref>
<ref id="R62">
<label>62</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Constantino</surname>
<given-names>JN</given-names>
</name>
<name>
<surname>Todd</surname>
<given-names>RD</given-names>
</name>
</person-group>
<article-title>Intergenerational transmission of subthreshold autistic traits in the general population</article-title>
<source/>Biol. Psychiatry
          <volume>57</volume>
<fpage>655</fpage>
<lpage>660</lpage>
<year>2005</year>
<pub-id pub-id-type="pmid">15780853</pub-id>
</element-citation>
</ref>
<ref id="R63">
<label>63</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Constantino</surname>
<given-names>JN</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Developmental course of autistic social impairment in males</article-title>
<source/>Dev. Psychopathol
          <volume>21</volume>
<fpage>127</fpage>
<lpage>38</lpage>
<year>2009</year>
<pub-id pub-id-type="pmid">19144226</pub-id>
</element-citation>
</ref>
</ref-list>
</back>
<floats-group>
<fig id="F1" orientation="portrait" position="float">
<label>Figure 1</label>
<caption>
<title>Monozygotic (MZ) twins exhibit high twin-twin concordance for eye- and mouth-looking, significantly greater than dizygotic (DZ) twins or age- and sex-matched non-siblings</title>
<p id="P91">Paired measures of eye-looking in, <bold>a,</bold> non-siblings paired randomly in 10,000 re-samplings without replacement; <bold>b,</bold> age- and sex-matched non-siblings; <bold>c,</bold> DZ twins; and <bold>d,</bold> MZ twins. <bold>e,</bold> Intraclass correlation coefficients (ICC) and 95% confidence intervals for eye-looking. <bold>f-j,</bold> Concordance in mouth-looking. <bold>k-o,</bold> Concordance in time spent attending to task (maintaining stable onscreen fixation). Plotted data in (a), (f), (k) are representative, selected to match mean ICC of all 10,000 re-samplings.</p>
</caption>
<graphic xlink:href="nihms879771f1"></graphic>
</fig>
<fig id="F2" orientation="portrait" position="float">
<label>Figure 2</label>
<caption>
<title>When viewing scenes of social interaction, monozygotic (MZ) twins exhibit greater probability of shifting their eyes at the same moments; greater probability of shifting their eyes in the same subsequent directions; and greater probability of fixating the same semantic content at the same moments</title>
<p id="P92"><bold>a-b,</bold> Example eye position data for MZ and DZ twins. Gaps in plots reflect blinks or off-screen fixations. <bold>c,</bold> Schematic peristimulus time histograms (PSTHs) showing probability of co-occurring saccades. At left, if saccades co-occur, twin 2’s saccade probability increases with twin 1’s saccades; at right, if saccades do not co-occur, probability remains unchanged. Dotted lines in (d-e) and (g-h) show 95% confidence intervals for change expected by chance (<italic>i.e.</italic>, no time-locking), measured by permutation testing. <bold>d-e,</bold> Small<bold></bold> DZ vs. large MZ increase in probability of time-locked saccades. <bold>f,</bold> Schematic PSTHs showing probability of time-locked saccade initiation (as opposed to c-e, measuring co-occurrence of entire saccades). <bold>g-h,</bold> No significant DZ change, but significant MZ time-locking of saccade initiation. <bold>i,</bold> Schematics showing probability of saccades shifting in the same or different direction (angular difference, twin1-twin2). <bold>j-k,</bold> Polar histograms measuring the distribution of differences in saccade directions for DZ and MZ twins, in relation to upper bound (95% CI) of results expected by chance, measured by permutation testing. <bold>l,</bold> Across all comparisons, MZ twins shift saccades in more similar subsequent directions than DZ twins. <bold>m,</bold> Schematics showing probability of fixating on the same semantic content at the same moments. Left: collocated, co-occurring eye and mouth fixations; right: non-collocated, non-co-occurring. <bold>n-o,</bold> Collocated, co-occurring fixations for DZ and MZ twins, plotted as <italic>Z</italic> scores relative to results expected by chance, measured by permutation testing. <bold>p,</bold> Collocated, co-occurring fixations (diagonals from (n) and (o)); error estimates (s.e.m.) from individual variation.</p>
</caption>
<graphic xlink:href="nihms879771f2"></graphic>
</fig>
<fig id="F3" orientation="portrait" position="float">
<label>Figure 3</label>
<caption>
<title>Monozygotic (MZ) twins exhibit high twin-twin concordance in eye-looking, whether watching the same or different video stimuli, evidence of active niche-picking in the goal-directed seeking of social information</title>
<p id="P93"><bold>a-d,</bold> Paired measures of eye-looking in MZ twins for (a) all video stimuli presenting dyadic interaction, (b) measures collected when both twins watched the same dyadic interaction videos, (c) measures collected when each twin watched different dyadic interaction videos, or (d) measures collected when each twin watched different content categories, showing either dyadic caregiver interaction (twin 1) or triadic peer interaction (twin 2). See <xref ref-type="fig" rid="F10">Extended Data Figure 6</xref> for stimuli examples. <bold>e,</bold> Intraclass correlation coefficients and 95% confidence intervals for a-d. <bold>f-j,</bold> Measures in DZ twins for the same comparisons in a-e. <bold>k-o,</bold> Measures in age- and sex-matched non-siblings for the same comparisons in a-e.</p>
</caption>
<graphic xlink:href="nihms879771f3"></graphic>
</fig>
<fig id="F4" orientation="portrait" position="float">
<label>Figure 4</label>
<caption>
<title>Comparison of social visual engagement in epidemiologically-ascertained toddlers from the general population relative to two cohorts of toddlers diagnosed with autism spectrum disorder (ASD)</title>
<p id="P94"><bold>a,</bold> Raw data marking individual levels of eye- and mouth-looking in 250 epidemiologically-ascertained toddlers watching video scenes of peer interaction. <bold>b,</bold> Population density contours for the data in (a). <bold>c,</bold> Comparison with data from 43 toddlers diagnosed with ASD. Black line marks classification boundary from linear discriminant analysis. <bold>d,</bold> Classification based on individual levels of social visual engagement. Threshold for the receiver operating characteristic (ROC) curve varied by extent of eye- and mouth-looking. <bold>e,</bold> Data from replication cohort of 45 toddlers with ASD. Classification boundary from (c). <bold>f,</bold> Classification based on individual levels of social visual engagement. As in (e), threshold for the ROC curve varied by extent of eye- and mouth-looking. Black diamond on red empirical ROC marks true positive and false positive rates observed in replication cohort using the optimal threshold identified in (c) and (d).</p>
</caption>
<graphic xlink:href="nihms879771f4"></graphic>
</fig>
</floats-group>
</article>
</pmc-articleset>