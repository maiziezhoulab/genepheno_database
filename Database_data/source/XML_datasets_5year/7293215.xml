<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="review-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">Transl Psychiatry</journal-id>
<journal-id journal-id-type="iso-abbrev">Transl Psychiatry</journal-id>
<journal-title-group>
<journal-title>Translational Psychiatry</journal-title>
</journal-title-group>
<issn pub-type="epub">2158-3188</issn>
<publisher>
<publisher-name>Nature Publishing Group UK</publisher-name>
<publisher-loc>London</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">32532967</article-id>
<article-id pub-id-type="pmc">7293215</article-id>
<article-id pub-id-type="publisher-id">780</article-id>
<article-id pub-id-type="doi">10.1038/s41398-020-0780-3</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Review Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Deep learning in mental health outcome research: a scoping review</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Su</surname>
<given-names>Chang</given-names>
</name>
<xref ref-type="aff" rid="Aff1"></xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Xu</surname>
<given-names>Zhenxing</given-names>
</name>
<xref ref-type="aff" rid="Aff1"></xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Pathak</surname>
<given-names>Jyotishman</given-names>
</name>
<xref ref-type="aff" rid="Aff1"></xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Wang</surname>
<given-names>Fei</given-names>
</name>
<address>
<email>few2001@med.cornell.edu</email>
</address>
<xref ref-type="aff" rid="Aff1"></xref>
</contrib>
<aff id="Aff1"><institution-wrap><institution-id institution-id-type="ISNI">000000041936877X</institution-id><institution-id institution-id-type="GRID">grid.5386.8</institution-id><institution>Department of Healthcare Policy and Research, </institution><institution>Weill Cornell Medicine, </institution></institution-wrap>New York, NY USA </aff>
</contrib-group>
<pub-date pub-type="epub">
<day>22</day>
<month>4</month>
<year>2020</year>
</pub-date>
<pub-date pub-type="pmc-release">
<day>22</day>
<month>4</month>
<year>2020</year>
</pub-date>
<pub-date pub-type="collection">
<year>2020</year>
</pub-date>
<volume>10</volume>
<elocation-id>116</elocation-id>
<history>
<date date-type="received">
<day>31</day>
<month>8</month>
<year>2019</year>
</date>
<date date-type="rev-recd">
<day>17</day>
<month>2</month>
<year>2020</year>
</date>
<date date-type="accepted">
<day>26</day>
<month>2</month>
<year>2020</year>
</date>
</history>
<permissions>
<copyright-statement>© The Author(s) 2020</copyright-statement>
<license license-type="OpenAccess">
<license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
</license>
</permissions>
<abstract id="Abs1">
<p id="Par1">Mental illnesses, such as depression, are highly prevalent and have been shown to impact an individual’s physical health. Recently, artificial intelligence (AI) methods have been introduced to assist mental health providers, including psychiatrists and psychologists, for decision-making based on patients’ historical data (e.g., medical records, behavioral data, social media usage, etc.). Deep learning (DL), as one of the most recent generation of AI technologies, has demonstrated superior performance in many real-world applications ranging from computer vision to healthcare. The goal of this study is to review existing research on applications of DL algorithms in mental health outcome research. Specifically, we first briefly overview the state-of-the-art DL techniques. Then we review the literature relevant to DL applications in mental health outcomes. According to the application scenarios, we categorize these relevant articles into four groups: diagnosis and prognosis based on clinical data, analysis of genetics and genomics data for understanding mental health conditions, vocal and visual expression data analysis for disease detection, and estimation of risk of mental illness using social media data. Finally, we discuss challenges in using DL algorithms to improve our understanding of mental health conditions and suggest several promising directions for their applications in improving mental health diagnosis and treatment.</p>
</abstract>
<kwd-group kwd-group-type="npg-subject">
<title>Subject terms</title>
<kwd>Psychiatric disorders</kwd>
<kwd>Biomarkers</kwd>
</kwd-group>
<funding-group>
<award-group>
<funding-source>
<institution>National Science Foundation</institution>
</funding-source>
</award-group>
</funding-group>
<funding-group>
<award-group>
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">https://doi.org/10.13039/100000025</institution-id>
<institution>U.S. Department of Health &amp; Human Services | NIH | National Institute of Mental Health (NIMH)</institution>
</institution-wrap>
</funding-source>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta>
<meta-name>issue-copyright-statement</meta-name>
<meta-value>© The Author(s) 2020</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="Sec1" sec-type="introduction">
<title>Introduction</title>
<p id="Par2">Mental illness is a type of health condition that changes a person’s mind, emotions, or behavior (or all three), and has been shown to impact an individual’s physical health<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR2">2</xref></sup>. Mental health issues including depression, schizophrenia, attention-deficit hyperactivity disorder (ADHD), and autism spectrum disorder (ASD), etc., are highly prevalent today and it is estimated that around 450 million people worldwide suffer from such problems<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. In addition to adults, children and adolescents under the age of 18 years also face the risk of mental health disorders. Moreover, mental health illnesses have also been one of the most serious and prevalent public health problems. For example, depression is a leading cause of disability and can lead to an increased risk for suicidal ideation and suicide attempts<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>.</p>
<p id="Par3">To better understand the mental health conditions and provide better patient care, early detection of mental health problems is an essential step. Different from the diagnosis of other chronic conditions that rely on laboratory tests and measurements, mental illnesses are typically diagnosed based on an individual’s self-report to specific questionnaires designed for the detection of specific patterns of feelings or social interactions<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. Due to the increasing availability of data pertaining to an individual’s mental health status, artificial intelligence (AI) and machine learning (ML) technologies are being applied to improve our understanding of mental health conditions and have been engaged to assist mental health providers for improved clinical decision-making<sup><xref ref-type="bibr" rid="CR4">4</xref>–<xref ref-type="bibr" rid="CR6">6</xref></sup>. As one of the latest advances in AI and ML, deep learning (DL), which transforms the data through layers of nonlinear computational processing units, provides a new paradigm to effectively gain knowledge from complex data<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. In recent years, DL algorithms have demonstrated superior performance in many data-rich application scenarios, including healthcare<sup><xref ref-type="bibr" rid="CR8">8</xref>–<xref ref-type="bibr" rid="CR10">10</xref></sup>.</p>
<p id="Par4">In a previous study, Shatte et al.<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> explored the application of ML techniques in mental health. They reviewed literature by grouping them into four main application domains: diagnosis, prognosis, and treatment, public health, as well as research and clinical administration. In another study, Durstewitz et al.<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> explored the emerging area of application of DL techniques in psychiatry. They focused on DL in the studies of brain dynamics and subjects’ behaviors, and presented the insights of embedding the interpretable computational models into statistical context. In contrast, this study aims to provide a scoping review of the existing research applying DL methodologies on the analysis of different types of data related to mental health conditions. The reviewed articles are organized into four main groups according to the type of the data analyzed, including the following: (1) clinical data, (2) genetic and genomics data, (3) vocal and visual expression data, and (4) social media data. Finally, the challenges the current studies faced with, as well as future research directions towards bridging the gap between the application of DL algorithms and patient care, are discussed.</p>
</sec>
<sec id="Sec2">
<title>Deep learning overview</title>
<p id="Par5">ML aims at developing computational algorithms or statistical models that can automatically infer hidden patterns from data<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup>. Recent years have witnessed an increasing number of ML models being developed to analyze healthcare data<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>. However, conventional ML approaches require a significant amount of feature engineering for optimal performance—a step that is necessary for most application scenarios to obtain good performance, which is usually resource- and time-consuming.</p>
<p id="Par6">As the newest wave of ML and AI technologies, DL approaches aim at the development of an end-to-end mechanism that maps the input raw features directly into the outputs through a multi-layer network structure that is able to capture the hidden patterns within the data. In this section, we will review several popular DL model architectures, including deep feedforward neural network (DFNN), recurrent neural network (RNN)<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, convolutional neural network (CNN)<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, and autoencoder<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. Figure <xref ref-type="fig" rid="Fig1">1</xref> provides an overview of these architectures.<fig id="Fig1"><label>Fig. 1</label><caption><title>Examples of deep neural networks.</title><p><bold>a</bold> Deep feedforward neural network (DFNN). It is the basic design of DL models. Commonly, a DFNN contains multiple hidden layers. <bold>b</bold> A recurrent neural network (RNN) is presented to process sequence data. To encode history information, each recurrent neuron receives the input element and the state vector of the predecessor neuron, and yields a hidden state fed to the successor neuron. For example, not only the individual information but also the dependence of the elements of the sequence x<sub>1</sub> → x<sub>2</sub> → x<sub>3</sub> → x<sub>4</sub> → x<sub>5</sub> is encoded by the RNN architecture. <bold>c</bold> Convolutional neural network (CNN). Between input layer (e.g., input neuroimage) and output layer, a CNN commonly contains three types of layers: the convolutional layer that is to generate feature maps by sliding convolutional kernels in the previous layer; the pooling layer is used to reduce dimensionality of previous convolutional layer; and the fully connected layer is to make prediction. For the illustrative purpose, this example only has one layer of each type; yet, a real-world CNN would have multiple convolutional and pooling layers (usually in an interpolated manner) and one fully connected layer. <bold>d</bold> Autoencoder consists of two components: the encoder, which learns to compress the input data into a latent representation layer by layer, whereas the decoder, inverse to the encoder, learns to reconstruct the data at the output layer. The learned compressed representations can be fed to the downstream predictive model.</p></caption><graphic id="d30e368" xlink:href="41398_2020_780_Fig1_HTML"></graphic></fig></p>
<sec id="Sec3">
<title>Deep feedforward neural network</title>
<p id="Par7">Artificial neural network (ANN) is proposed with the intention of mimicking how human brain works, where the basic element is an artificial neuron depicted in Fig. <xref ref-type="fig" rid="Fig2">2a</xref>. Mathematically, an artificial neuron is a nonlinear transformation unit, which takes the weighted summation of all inputs and feeds the result to an activation function, such as sigmoid, rectifier (i.e., rectified linear unit [ReLU]), or hyperbolic tangent (Fig. <xref ref-type="fig" rid="Fig2">2b</xref>). An ANN is composed of multiple artificial neurons with different connection architectures. The simplest ANN architecture is the feedforward neural network (FNN), which stacks the neurons layer by layer in a feedforward manner (Fig. <xref ref-type="fig" rid="Fig1">1a</xref>), where the neurons across adjacent layers are fully connected to each other. The first layer of the FNN is the input layer that each unit receives one dimension of the data vector. The last layer is the output layer that outputs the probabilities that a subject belonging to different classes (in classification). The layers between the input and output layers are the hidden layers. A DFNN usually contains multiple hidden layers. As shown in Fig. <xref ref-type="fig" rid="Fig2">2a</xref>, there is a weight parameter associated with each edge in the DFNN, which needs to be optimized by minimizing some training loss measured on a specific training dataset (usually through backpropagation<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>). After the optimal set of parameters are learned, the DFNN can be used to predict the target value (e.g., class) of any testing data vectors. Therefore, a DFNN can be viewed as an end-to-end process that transforms a specific raw data vector to its target layer by layer. Compared with the traditional ML models, DFNN has shown superior performance in many data mining tasks and have been introduced to the analysis of clinical data and genetic data to predict mental health conditions. We will discuss the applications of these methods further in the Results section.<fig id="Fig2"><label>Fig. 2</label><caption><title>Technical details of neural networks.</title><p><bold>a</bold> An illustration of basic unit of neural networks, i.e., artificial neuron. Each input <italic>x</italic><sub><italic>i</italic></sub> is associated with a weight <italic>w</italic><sub><italic>i</italic></sub>. The weighted sum of all inputs Σ<italic>w</italic><sub><italic>i</italic></sub><italic>x</italic><sub><italic>i</italic></sub> is fed to a nonlinear activation function <italic>f</italic> to generate the output <italic>y</italic><sub><italic>j</italic></sub> of the <italic>j</italic>-th neuron, i.e., <italic>y</italic><sub><italic>j</italic></sub> = <italic>f</italic>(Σ<italic>w</italic><sub><italic>i</italic></sub><italic>x</italic><sub><italic>i</italic></sub>). <bold>b</bold> Illustrations of the widely used nonlinear activation function.</p></caption><graphic id="d30e463" xlink:href="41398_2020_780_Fig2_HTML"></graphic></fig></p>
<sec id="Sec4">
<title>Recurrent neural network</title>
<p id="Par8">RNNs were designed to analyze sequential data such as natural language, speech, and video. Given an input sequence, the RNN processes one element of the sequence at a time by feeding to a recurrent neuron. To encode the historical information along the sequence, each recurrent neuron receives the input element at the corresponding time point and the output of the neuron at previous time stamp, and the output will also be provided to the neuron at next time stamp (this is also where the term “recurrent” comes from). An example RNN architecture is shown in Fig. <xref ref-type="fig" rid="Fig1">1b</xref> where the input is a sequence of words (a sentence). The recurrence link (i.e., the edge linking different neurons) enables RNN to capture the latent semantic dependencies among words and the syntax of the sentence. In recent years, different variants of RNN, such as long short-term memory (LSTM)<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> and gated recurrent unit<sup><xref ref-type="bibr" rid="CR19">19</xref></sup> have been proposed, and the main difference among these models is how the input is mapped to the output for the recurrent neuron. RNN models have demonstrated state-of-the-art performance in various applications, especially natural language processing (NLP; e.g., machine translation and text-based classification); hence, they hold great premise in processing clinical notes and social media posts to detect mental health conditions as discussed below.</p>
</sec>
<sec id="Sec5">
<title>Convolutional neural network</title>
<p id="Par9">CNN is a specific type of deep neural network originally designed for image analysis<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, where each pixel corresponds to a specific input dimension describing the image. Similar to a DFNN, CNN also maps these input image pixels to the corresponding target (e.g., image class) through layers of nonlinear transformations. Different from DFNN, where only fully connected layers are considered, there are typically three types of layers in a CNN: a convolution–activation layer, a pooling layer, and a fully connected layer (Fig. <xref ref-type="fig" rid="Fig1">1c</xref>). The convolution–activation layer first convolves the entire feature map obtained from previous layer with small two-dimensional convolution filters. The results from each convolution filter are activated through a nonlinear activation function in the same way as a DFNN. A pooling layer reduces the size of the feature map through sub-sampling. The fully connected layer is analogous to the hidden layer in a DFNN, where each neuron is connected to all neurons of the previous layer. The convolution–activation layer extracts locally invariant patterns from the feature maps. The pooling layer effectively reduces the feature dimensionality to avoid model overfitting. The fully connected layer explores the global feature interactions as in DFNNs. Different combinations of these three types of layers constitute different CNN architectures. Because of the various characteristics of images such as local self-similarity, compositionality, and translational and deformation invariance, CNN has demonstrated state-of-the-art performance in many computer vision tasks<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. Hence, the CNN models are promising in processing clinical images and expression data (e.g., facial expression images) to detect mental health conditions. We will discuss the application of these methods in the Results section.</p>
</sec>
<sec id="Sec6">
<title>Autoencoder</title>
<p id="Par10">Autoencoder is a special variant of the DFNN aimed at learning new (usually more compact) data representations that can optimally reconstruct the original data vectors<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>. An autoencoder typically consists of two components (Fig. <xref ref-type="fig" rid="Fig1">1d</xref>) as follows: (1) the encoder, which learns new representations (usually with reduced dimensionality) from the input data through a multi-layer FNN; and (2) the decoder, which is exactly the reverse of the encoder, reconstructs the data in their original space from the representations derived from the encoder. The parameters in the autoencoder are learned through minimizing the reconstruction loss. Autoencoder has demonstrated the capacity of extracting meaningful features from raw data without any supervision information. In the studies of mental health outcomes, the use of autoencoder has resulted in desirable improvement in analyzing clinical and expression image data, which will be detailed in the Results section.</p>
</sec>
</sec>
</sec>
<sec id="Sec7">
<title>Methods</title>
<p id="Par11">The processing and reporting of the results of this review were guided by the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>. To thoroughly review the literature, a two-step method was used to retrieve all the studies on relevant topics. First, we conducted a search of the computerized bibliographic databases including PubMed and Web of Science. The search strategy is detailed in Supplementary Appendix <xref ref-type="media" rid="MOESM1">1</xref>. The literature search comprised articles published until April 2019. Next, a snowball technique was applied to identify additional studies. Furthermore, we manually searched other resources, including Google Scholar, and Institute of Electrical and Electronics Engineers (IEEE Xplore), to find additional relevant articles.</p>
<p id="Par12">Figure <xref ref-type="fig" rid="Fig3">3</xref> presents the study selection process. All articles were evaluated carefully and studies were excluded if: (1) the main outcome is not a mental health condition; (2) the model involved is not a DL algorithm; (3) full-text of the article is not accessible; and (4) the article is written not in English.<fig id="Fig3"><label>Fig. 3</label><caption><title>PRISMA flow diagram: deep learning in mental health outcome research.</title><p>In total, 57 studies, in terms of clinical data analysis, genetic data analysis, vocal and visual expression data analysis, and social media data analysis, which met our eligibility criteria, were included in this review.</p></caption><graphic id="d30e538" xlink:href="41398_2020_780_Fig3_HTML"></graphic></fig></p>
</sec>
<sec id="Sec8" sec-type="results">
<title>Results</title>
<p id="Par13">A total of 57 articles met our eligibility criteria. Most of the reviewed articles were published between 2014 and 2019. To clearly summarize these articles, we grouped them into four categories according to the types of data analyzed, including (1) clinical data, (2) genetic and genomics data, (3) vocal and visual expression data, and (4) social media data. Table <xref ref-type="table" rid="Tab1">1</xref> summarizes the characteristics of these selected studies.<table-wrap id="Tab1"><label>Table 1</label><caption><p>A summary of the selected studies in this review.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Authors, year</th><th>Used deep model</th><th>Data</th><th>Study cohort</th><th>Outcome assessment</th><th>Aims</th><th>Performance</th><th>Findings</th></tr></thead><tbody><tr><td colspan="8">Clinical data</td></tr><tr><td colspan="8">Neuroimage data</td></tr><tr><td>Kuang and He., 2014<sup><xref ref-type="bibr" rid="CR25">25</xref></sup></td><td>DBN</td><td>fMRI</td><td>449 Subjects (ADHD-200<sup>a</sup>)</td><td>Human annotation</td><td>Prediction of ADHD status and subtype</td><td>ACC = 0.407–0.809</td><td>The model is the first time that the DL method has been used for the discrimination of ADHD with fMRI data.</td></tr><tr><td>Kuang et al., 2014<sup><xref ref-type="bibr" rid="CR26">26</xref></sup></td><td>DBN</td><td>fMRI</td><td>492 Subjects (ADHD-200<sup>a</sup>)</td><td>Human annotation</td><td>Prediction of ADHD status and subtype</td><td>ACC = 0.344–0.718</td><td>The study verified that there is difference between ADHD and control in the prefrontal cortex and cingulated cortex.</td></tr><tr><td>Ulloa et al., 2015<sup><xref ref-type="bibr" rid="CR35">35</xref></sup></td><td>DFNN</td><td>sMRI</td><td>198 Schizophrenia subjects, 191 HCs</td><td>Human annotation</td><td>Prediction of schizophrenia</td><td>ACC = 0.75; Baseline ACC = 0.70</td><td>The model classified neuroimaging data in an online fashion using purely synthetic data.</td></tr><tr><td>Pinaya et al., 2016<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> (source code available<sup>k</sup>)</td><td>DBN</td><td>sMRI</td><td>143 Schizophrenia subjects, 32 first-episode psychosis, 191 HCs</td><td>Human annotation based on SCID-I</td><td>Prediction of schizophrenia</td><td>ACC = 0.736; Baseline ACC = 0.681</td><td>The DBN highlighted differences between classes, especially in the frontal, temporal, parietal, and insular cortices, and in some subcortical regions, including the corpus callosum, putamen, and cerebellum.</td></tr><tr><td>Farzi et al., 2017<sup><xref ref-type="bibr" rid="CR27">27</xref></sup></td><td>DBN</td><td>fMRI</td><td>336 Subjects (ADHD-200<sup>a</sup>)</td><td>Human annotation</td><td>Prediction of ADHD</td><td>ACC = 0.637–0.698; Baseline ACC = 0.352–0.642</td><td>The deep model captured relationships from multiple features, including FMRI features, diagnosis status, ADHD measures, secondary symptoms, age, gender, etc.</td></tr><tr><td>Zou et al., 2017<sup><xref ref-type="bibr" rid="CR28">28</xref></sup></td><td>3D CNN</td><td>fMRI</td><td>239 ADHDs, 429 TDCs</td><td>Human annotation</td><td>Prediction of ADHD</td><td>ACC = 0.657; Baseline ACC = 0.615</td><td>The 3D CNN architecture can detect physiologically meaningful 3D local patterns from fMRI data.</td></tr><tr><td>Geng and Xu, 2017<sup><xref ref-type="bibr" rid="CR37">37</xref></sup></td><td>Autoencoder and CNN</td><td>fMRI</td><td>24 MDDs, 24 HCs</td><td>Not specified</td><td>Prediction of depression</td><td>ACC = 0.95; Baseline ACC = 0.71</td><td>The model automatically learned meaningful features from the origin time series of the fMRI.</td></tr><tr><td>Zou et al., 2017<sup><xref ref-type="bibr" rid="CR30">30</xref></sup></td><td>3D CNN</td><td>fMRI and sMRI</td><td>239 ADHDs, 429 TDCs</td><td>Human annotation</td><td>Prediction of ADHD</td><td>ACC = 0.692; Baseline ACC = 0.615</td><td>The study found that brain functional and structural information are complementary. The low-level features and high-level features from fMRI and sMRI are useful for the detection of ADHD.</td></tr><tr><td>Sen et al., 2018<sup><xref ref-type="bibr" rid="CR31">31</xref></sup></td><td>Autoencoder</td><td>fMRI and sMRI</td><td>279 ADHDs, 491 HCs (ADHD-200<sup>a</sup>); 538 ASDs and 573 HCs (ABIDE<sup>b</sup>)</td><td>Human annotation</td><td>Prediction of ADHD and ASD</td><td>ACC = 0.643–0.673; Baseline ACC = 0.500–0.516</td><td>Combining multimodal features can yield good classification accuracy for diagnosis of ADHD and autism.</td></tr><tr><td>Aghdam et al., 2018<sup><xref ref-type="bibr" rid="CR38">38</xref></sup></td><td>DBN</td><td>fMRI and sMRI</td><td>116 ASDs, 69 TDCs (ABIDE <sup>b</sup>)</td><td>Human annotation</td><td>Prediction of ASD</td><td>ACC = 0.656</td><td>(1) There were significant relationships between rs-fMRI and sMRI; (2) Increasing the depth of DBN can help improve diagnostic classification.</td></tr><tr><td>Matsubara et al., 2019<sup><xref ref-type="bibr" rid="CR36">36</xref></sup></td><td>DFNN</td><td>fMRI</td><td>50 Schizophrenia subjects, 49 BDs, and 122 HCs<sup>c</sup></td><td></td><td>Diagnosis of psychiatric disorder</td><td>ACC = 0.766; Baseline ACC = 0.720</td><td>The study modeled joint distribution of rs-fMRI data, class labels, and remaining frame-wise variabilities.</td></tr><tr><td>Pinaya et al., 2019<sup><xref ref-type="bibr" rid="CR34">34</xref></sup></td><td>Autoencoder</td><td>sMRI</td><td>35 Schizophrenia subjects, 40 HCs (NUSDAST<sup>d</sup>); 83 ASDs, 105 HCs (ABIDE<sup>b</sup>)</td><td>Human annotation</td><td>Identification of abnormal brain structural patterns in neuropsychiatric disorders (schizophrenia and ASD)</td><td>ACC = 0.639 to 0.707; Baseline ACC = 0.569 to 0.637</td><td>There are distinct patterns of neuroanatomical deviations for the two diseases (schizophrenia and ASD).</td></tr><tr><td colspan="8">Electroencephalogram data</td></tr><tr><td>Mohan et al., 2017<sup><xref ref-type="bibr" rid="CR44">44</xref></sup></td><td>DFNN</td><td>6.25-sec EEG</td><td>116 University students</td><td>PHQ-9 score and DASS-21</td><td>Prediction of depression</td><td>19 Out of 20 testers were detected correctly</td><td>The profound outcome of this study showed the signals collected from central (C3 and C4) region are marginally higher compared other brain regions.</td></tr><tr><td>Acharya et al., 2018<sup><xref ref-type="bibr" rid="CR43">43</xref></sup></td><td>CNN</td><td>5-min EEG</td><td>15 Depressed subjects, 15 HCs</td><td>Human annotation based on specific questions and physical examination</td><td>Prediction of depression</td><td>ACC = 0.935 (left hemisphere) and 0.960 (right hemisphere)</td><td>The study found that the EEG signals from the right hemisphere are more distinctive in depression than those from the left hemisphere.</td></tr><tr><td>Zhang et al., 2018<sup><xref ref-type="bibr" rid="CR45">45</xref></sup></td><td>CNN</td><td>1000 Hz EEG</td><td>20 subjects</td><td>Cross-task mental workload assessment</td><td>Cross-task mental workload assessment</td><td>ACC = 0.889</td><td>(1) Spectral changes of EEG hemispheric asymmetry provide effective information to distinguish different mental workload tasks. (2) Different time periods can provide different hemispheric EEG activities, and selection of an appropriate time window is essential for extracting hemispheric asymmetry information.</td></tr><tr><td>Li et al., 2019<sup><xref ref-type="bibr" rid="CR46">46</xref></sup></td><td>CNN</td><td>1-sec EEG</td><td>24 Mild depression, 24 HCs</td><td>BDI-II</td><td>Prediction of mild depression</td><td>ACC = 0.856</td><td>They found that the spectral information of EEG played a major role and the temporal information of EEG provided a statistically significant improvement to accuracy.</td></tr><tr><td colspan="8">Electronic health records</td></tr><tr><td>Pham et al., 2017<sup><xref ref-type="bibr" rid="CR51">51</xref></sup> (source code available <sup>l</sup>)</td><td>DeepCare (LSTM based model)</td><td>Longitudinal EMRs</td><td>11,000 Patients</td><td>ICD-10 diagnosis code</td><td>Prediction of the future mental outcomes</td><td>F-score = 0.754; Baseline F-score = 0.679</td><td>The LSTM architecture appropriately captured disease progression by modeling the illness history but also the medical interventions.</td></tr><tr><td>Geraci et al., 2017<sup><xref ref-type="bibr" rid="CR53">53</xref></sup></td><td>DFNN</td><td>Clinical notes</td><td>366 Patients</td><td>Human annotation</td><td>Prediction of youth depression</td><td>Sensitivity = 0.935, Specificity = 0.68, Positive predictive value = 0.77</td><td>The model identified individuals who meet the inclusion–exclusion criteria for depression research.</td></tr><tr><td>Rios and Kavuluru, 2017<sup><xref ref-type="bibr" rid="CR56">56</xref></sup></td><td>CNN</td><td>Clinical notes</td><td>1000 Neuropsychiatric notes<sup>e</sup></td><td>Human annotation</td><td>Prediction of psychiatric symptom severity</td><td>NMMAE = 0.856</td><td>The CNN scheme showed superiority in extract text features and the predictive performance is better than many traditional text classification methods.</td></tr><tr><td>Tran and Kavuluru, 2017<sup><xref ref-type="bibr" rid="CR58">58</xref></sup></td><td>CNN and attention-based RNN</td><td>Clinical notes</td><td>1000 Neuropsychiatric notes<sup>e</sup></td><td>Human annotation</td><td>Prediction of 11 mental health conditions (e.g., ADHD, anxiety, bipolar, dementia, depression, etc.)</td><td>F-score = 0.631; Baseline F-score = 0.598</td><td>Both the CNN and RNN architectures achieved desirable prediction performances.</td></tr><tr><td>Choi et al., 2018<sup><xref ref-type="bibr" rid="CR50">50</xref></sup></td><td>DFNN</td><td>Structured EHRs</td><td>SD: 2546, HC: 817,405</td><td>ICD-10 diagnosis code</td><td>Prediction of suicide death</td><td>AUC = 0.683; Baseline AUC = 0.688</td><td>The model is able to address the imbalance classification problem.</td></tr><tr><td>Lin et al., 2018<sup><xref ref-type="bibr" rid="CR52">52</xref></sup></td><td>DFNN</td><td>Clinical biomarkers and genetic biomarkers (SNPs)</td><td>257 MDD treatment responders, 164 MDD treatment non-responders</td><td>HRSD</td><td>Prediction of antidepressant response and remission</td><td>AUC = 0.823; Baseline AUC = 0.816</td><td>The model achieved better performance than the logistic regression classifier.</td></tr><tr><td>Dai and Jonnagaddala, 2018<sup><xref ref-type="bibr" rid="CR57">57</xref></sup></td><td>CNN</td><td>Clinical notes</td><td>Clinical notes of psychiatric disorder subjects: Absent: 92, Mild: 252, Moderate: 156, Severe: 149<sup>e</sup></td><td>Human annotation</td><td>Prediction of positive valence symptom severity</td><td>MAE = 0.539; Baseline MAE = 0.583</td><td>The CNN models provided comparable solutions without sophisticated preprocessing on the text data.</td></tr><tr><td colspan="8">Genetic data</td></tr><tr><td>Laksshman et al., 2017<sup><xref ref-type="bibr" rid="CR71">71</xref></sup></td><td>CNN</td><td>Whole exome sequencing data</td><td>1000 Subjects<sup>f</sup></td><td>Not specified</td><td>Differentiating bipolar disorder patients with healthy controls</td><td>AUC = 0.65; Baseline AUC = 0.62</td><td>The 1D convolution captured correlation of neighboring loci. The model achieved a winning predictive performance of 0.65 AUC, compared with traditional methods ranging from 0.5 to 0.55. This revealed that the model might be picking up complex patterns across the samples.</td></tr><tr><td>Khan and Wang, 2017<sup><xref ref-type="bibr" rid="CR67">67</xref></sup> (source code available<sup>m</sup>)</td><td>ncDeepBrain (DFNN based)</td><td>Genome sequencing data</td><td>-</td><td>Not specified</td><td>Identification of non-coding variants associated with mental disorders</td><td>ACC = 0.82; Baseline ACC = 0.71</td><td>The model was trained for scoring the non-coding variants for prioritization.</td></tr><tr><td>Khan et al., 2018<sup><xref ref-type="bibr" rid="CR68">68</xref></sup> (source code available<sup>m</sup>)</td><td>iMEGES (DFNN based)</td><td>Genome sequencing data</td><td>-</td><td>Not specified</td><td>Prioritization of susceptibility genes for mental disorders</td><td>AUC = 0.57 (schizophrenia) and 0.58 (ASD)</td><td>The model integrated the ncDeepBrain score, general gene scores, and disease-specific scores to prioritize susceptibility genes for mental disorders.</td></tr><tr><td>Wang et al., 2018<sup><xref ref-type="bibr" rid="CR69">69</xref></sup></td><td>Deep structured phenotype network (DSPN)</td><td>Regulatory network</td><td>PsychENCODE Consortium dataset <sup>g</sup></td><td>Not specified</td><td>Prediction of psychiatric phenotypes from genotype and expression</td><td>ACC = 0.729; Baseline ACC = 0.681</td><td>The model provided insights about intermediate phenotypes and their connections to high-level phenotypes (disease traits).</td></tr><tr><td colspan="8">Vocal and visual expression data</td></tr><tr><td>Chao et al., 2015<sup><xref ref-type="bibr" rid="CR84">84</xref></sup></td><td>CNN and LSTM</td><td>Voice and visual data</td><td>84 Subjects (AVEC dataset)</td><td>Human annotation</td><td>Prediction of depression severity</td><td>MAE = 8.7</td><td>Face appearance features were extracted by CNN. The deep-learned appearance features, combined with audio and face shape features, were fed to a LSTM to capture long-term sequence features.</td></tr><tr><td>Yang et al., 2016<sup><xref ref-type="bibr" rid="CR85">85</xref></sup></td><td>LSTM and autoencoder</td><td>Elicited speech voice data</td><td>13 BDs, 13 UDs, and 13 HCs (Chi-Mei mood dataset)</td><td>Human annotation</td><td>Prediction of mood disorder</td><td>ACC = 0.769; Baseline ACC = 0.498</td><td>The denoising autoencoder adopted emotion domain data to the speech data space to generate emotion profiles (EPs). The LSTM characterized the temporal evolution of the EP sequence with respect to eliciting emotional videos.</td></tr><tr><td>Ma et al., 2016<sup><xref ref-type="bibr" rid="CR76">76</xref></sup></td><td>CNN and LSTM</td><td>Voice data</td><td>(AVEC dataset)</td><td>PHQ-8 score</td><td>Prediction of depression</td><td>F-score = 0.52</td><td>The model incorporated short-term temporal and spectral correlations by a 1D CNN, captured middle-term correlations by 1D max-pooling, and extracted long-term correlations with LSTM.</td></tr><tr><td>Huang et al., 2017<sup><xref ref-type="bibr" rid="CR86">86</xref></sup></td><td>LSTM and autoencoder</td><td>Elicited speech voice data</td><td>15 BDs, 15 UDs, and 15 HCs (Chi-Mei mood dataset)</td><td>Human annotation</td><td>Prediction of mood disorder</td><td>ACC = 0.733</td><td>The denoising autoencoder adopted emotion domain data to the speech data space to generate emotion profiles (EPs). The LSTM characterized the temporal evolution of the EP sequence with respect to eliciting emotional videos.</td></tr><tr><td>Su et al., 2017<sup><xref ref-type="bibr" rid="CR90">90</xref></sup></td><td>LSTM and autoencoder</td><td>Elicited video data</td><td>12 BDs, 12 MDDs, and 12 HCs (Chi-Mei mood dataset)</td><td>Human annotation</td><td>Classification of mood disorders</td><td>ACC = 0.677; Baseline ACC = 0.556</td><td>The study modeled the long-term variation among different mood disorders types by LSTM.</td></tr><tr><td>Jaiswal et al., 2017<sup><xref ref-type="bibr" rid="CR92">92</xref></sup></td><td>CNN</td><td>Facial expression RGBD data (A RGB-D image is simply a combination of a color image and its corresponding depth image.)</td><td>4 ADHDs, 22 ASDs, 11 ADHD + ASDs, and 18 HCs</td><td>Not specified</td><td>Prediction of ADHD and ASD</td><td>ACC = 0.96 (condition vs. HC) and 0.93 (ADHD + ASD vs. ASD only)</td><td>The study established the relationship between facial expression/gestures and neurodevelopmental conditions such as ADHD and ASD.</td></tr><tr><td>Cho et al., 2017<sup><xref ref-type="bibr" rid="CR93">93</xref></sup> (source code available<sup>n</sup>)</td><td>CNN</td><td>Thermal images</td><td>8 Healthy adults<sup>h</sup></td><td>Human annotation</td><td>Recognition of psychological stress level (mental overload)</td><td>ACC = 0.846 (no stress vs. stress) and 0.565 (no stress vs. low-level stress vs. high-level stress)</td><td>The model identified psychological stress level by using a low-cost thermal camera, which tracks the person’s breathing patterns.</td></tr><tr><td>Yang et al., 2017<sup><xref ref-type="bibr" rid="CR79">79</xref></sup></td><td>CNN and DFNN</td><td>Voice and visual data</td><td>189 Segments of clinical interview (AVEC dataset)</td><td>PHQ-8 score</td><td>Prediction of depression</td><td>MAE = 5.4</td><td>The study proposed a multimodal approach: two CNNs were introduced to encode audio and video data, respectively. Then a fully connected DNN was used to combine the two channel feature maps to predict PHQ-8 scores.</td></tr><tr><td>Gupta et al., 2017<sup><xref ref-type="bibr" rid="CR94">94</xref></sup></td><td>DFNN</td><td>Voice and visual data</td><td>300 Video samples (AVEC dataset)</td><td>Valence, arousal, and dominance ratings by human annotation</td><td>Affective prediction</td><td>Correlation coefficient <italic>ρ</italic> between the true and predicted ratings: 0.21–0.51</td><td>The DFNN incorporated depression severity as the parameter, linking the effects of depression on subjects’ affective expressions.</td></tr><tr><td>He and Cao, 2018<sup><xref ref-type="bibr" rid="CR77">77</xref></sup></td><td>CNN</td><td>Voice data</td><td>300 Video samples (AVEC dataset)</td><td>BDI-II</td><td>Prediction of depression</td><td>MAE = 8.2; Baseline MAE = 10.4</td><td>The model consists of four CNNs, one for extracting audio features from raw waveform, one for extracting texture features from spectrogram images, and two for modeling handcraft features.</td></tr><tr><td>Dawood et al., 2018<sup><xref ref-type="bibr" rid="CR81">81</xref></sup></td><td>CNN and LSTM</td><td>Video collected by webcam</td><td>862 Videos of AS, 545 videos of TDC</td><td>Not specified</td><td>Prediction of depression</td><td>ACC = 0.901</td><td>The model takes the power of CNN to learn facial expression features from images (frame’s response map) and LSTM to learn from series of temporal data (sequence of response maps).</td></tr><tr><td>Song et al., 2018<sup><xref ref-type="bibr" rid="CR82">82</xref></sup></td><td>CNN</td><td>Video data</td><td>30 Depressed subjects, 77 non-depressed subjects, and 35 subjects for development (AVEC dataset)</td><td>PHQ-8 score</td><td>Prediction of depression and depression severity</td><td>MAE = 5.01; Baseline = 4.4</td><td>The model transformed behavior signals to spectrum maps to capture long-term series information. Then CNN was used to extract spectral features.</td></tr><tr><td>Zhu et al., 2018<sup><xref ref-type="bibr" rid="CR83">83</xref></sup></td><td>CNN</td><td>Video data</td><td>340 Videos from 292 subjects (AVEC dataset)</td><td>BDI-II</td><td>Prediction of depression</td><td>MAE = 7.6; Baseline MAE = 8.2</td><td>The model introduced two CNNs, one pre-trained for modeling the static facial appearance and the other modeling the optical flow images extracted from different frames.</td></tr><tr><td>Prasetio et al., 2018<sup><xref ref-type="bibr" rid="CR91">91</xref></sup></td><td>CNN</td><td>Facial image</td><td>Female: 87 high stress, 129 low stress, and 175 neutral; Male: 134 high stress, 212 low stress, and 237 neutral</td><td>Human annotation</td><td>Stress recognition</td><td>ACC = 0.959; Baseline ACC = 0.890</td><td>The features were from facial images and fed to a CNN to identify stress.</td></tr><tr><td>Jan et al. 2018<sup><xref ref-type="bibr" rid="CR87">87</xref></sup></td><td>CNN (only for image</td><td>Voice and visual data</td><td>300 Videos (AVEC dataset)</td><td>BDI-II</td><td>Prediction of depression severity</td><td>MAE = 6.7 (Unimodal) and 6.1 (Bimodal); Baseline MAE = 8.0 (Unimodal) and 6.4 (Bimodal)</td><td>The deep-learnt features showed significant improvement on prediction.</td></tr><tr><td>Harati et al. 2018<sup><xref ref-type="bibr" rid="CR89">89</xref></sup></td><td>LSTM</td><td>Audio of interview during Deep Brain Stimulation treatment</td><td>13 Subjects</td><td>HRMD score</td><td>Prediction of depression severity</td><td>AUC = 0.80</td><td>The model extracted emotion features from patients’ clinical audio utterances.</td></tr><tr><td>Huang et al. 2019<sup><xref ref-type="bibr" rid="CR80">80</xref></sup></td><td>CNN and LSTM</td><td>Elicited speech voice data</td><td>15 BDs, 15 UDs, and 15 HCs (Chi-Mei mood dataset)</td><td>Human annotation</td><td>Short-term detection of mood disorders</td><td>ACC = 0.756; Baseline ACC = 0.622</td><td>The CNN was used to generate an emotion profile (EP) of each elicited speech response. The LSTM was used to characterize temporal evolution of EPs of patients</td></tr><tr><td>Su et al., 2019<sup><xref ref-type="bibr" rid="CR88">88</xref></sup></td><td>Autoencoder and LSTM</td><td>Voice and visual data</td><td>13 BDs, 13 UDs, and 13 HCs (Chi-Mei mood dataset)</td><td>Human annotation</td><td>Prediction of mood disorder</td><td>ACC = 0.692; Baseline ACC = 0.498</td><td>Autoencoder generated bottleneck features of the facial expression and speech response. LSTM modeled the temporal information of all elicited responses. The model is able to overcome misdiagnosis of bipolar disorder as unipolar disorder.</td></tr><tr><td colspan="8">Social media data</td></tr><tr><td>Lin et al., 2014<sup><xref ref-type="bibr" rid="CR98">98</xref></sup></td><td>CNN and DFNN</td><td>Sina Weibo posts</td><td>11,074 Subjects of stress, 12,230 subjects of no stress</td><td>Pattern matching in tweets</td><td>Stress detection</td><td>ACC = 0.756–0.844</td><td>There are relationships between users’ stress and their tweeting content, social engagement, and behavior patterns.</td></tr><tr><td>Lin et al., 2014<sup><xref ref-type="bibr" rid="CR99">99</xref></sup></td><td>Denoising autoencoder</td><td>Hashtag-labeled tweets</td><td>3634 Tweets of affection stress, 3966 tweets of work stress, 5747 tweets with social stress, 13,973 tweets of physiological stress, 14,543 tweets of other stress, and 14,931 tweets of no stress</td><td>User-labeled hashtag</td><td>Stress detection</td><td>ACC = 0.823; Baseline ACC = 59.7</td><td>Detection results were improved by using deep neural network models.</td></tr><tr><td>Gkotsis et al., 2017<sup><xref ref-type="bibr" rid="CR106">106</xref></sup></td><td>CNN and DFNN</td><td>Reddit posts</td><td>538,245 Posts related to 11 mental themes, 476,388 non-mental health posts<sup>i</sup></td><td>Human annotation</td><td>Identification of posts related to mental illness</td><td>ACC = 0.911 (binary classification) and 0.714 (multiclass classification); Baseline ACC = 0.908 (binary classification) and 0.708 (multiclass classification)</td><td>(1) The most common misclassification is depression; (2) Some of the themes are highly inter-related and not always distinguishable as separate and exclusive classes.</td></tr><tr><td>Li et al., 2017<sup><xref ref-type="bibr" rid="CR100">100</xref></sup></td><td>RNN</td><td>Tencent Weibo posts</td><td>29,232 Posts of 124 students, containing 122 study-related stressor events</td><td>Human annotation</td><td>Prediction of adolescent stress</td><td>MSE = 0.19; Baseline MSE = 0.25</td><td>The model incorporated relationships of stressor events and improved the prediction of stress in adolescent.</td></tr><tr><td>Lin et al., 2017<sup><xref ref-type="bibr" rid="CR101">101</xref></sup></td><td>CNN</td><td>Sina Weibo posts, Tencent Weibo posts, and Twitter posts; social interactions</td><td>11,074 Subjects of stress, 12,230 subjects of no stress</td><td>Pattern matching in tweets</td><td>Stress detection</td><td>ACC = 0.916</td><td>Users stress state is closely related to that of his/her friends in social media.</td></tr><tr><td>Sadeque et al., 2017<sup><xref ref-type="bibr" rid="CR104">104</xref></sup></td><td>GRU</td><td>Reddit posts</td><td>136 Depressed subjects, 752 HCs</td><td>Self-declaration of depression in posts</td><td>Prediction of early depression</td><td>F-score = 0.64; Baseline F-score = 0.40</td><td>The RNN captured sequential information from texts with sequential property.</td></tr><tr><td>Cong et al., 2018<sup><xref ref-type="bibr" rid="CR102">102</xref></sup></td><td>LSTM</td><td>The Reddit Self-reported Depression Diagnosis (RSDD) dataset</td><td>9000 Depressed subjects, 107,000 HCs</td><td>Self-declaration of depression in posts</td><td>Prediction of depression</td><td>F-score = 0.60; Baseline F-score = 0.44</td><td>The model reduced data imbalance and enhanced classification capacity.</td></tr><tr><td>Coppersmith et al., 2018<sup><xref ref-type="bibr" rid="CR107">107</xref></sup></td><td>LSTM</td><td>Social media posts</td><td>418 Users with suicide attempts; number of HC not specified</td><td>Self-declaration of depression in posts</td><td>Prediction of suicidal risk</td><td>AUC = 0.94</td><td>The LSTM captured contextual information between words and better obtained nuances of language related to mental health.</td></tr><tr><td>Du et al, 2018<sup><xref ref-type="bibr" rid="CR108">108</xref></sup></td><td>CNN and RNN</td><td>Twitter posts</td><td>1,962,766 Tweets</td><td>Suicide-related keywords matching</td><td>Identification of suicide-related psychiatric stressors</td><td>ACC = 0.74 (CNN) and 0.72 (RNN); Baseline ACC = 0.703</td><td>CNN- and RNN-based model obtained better performance at identifying suicide-related tweets and psychiatric stressors, respectively.</td></tr><tr><td>Ive et al., 2018<sup><xref ref-type="bibr" rid="CR103">103</xref></sup></td><td>GRU</td><td>Social media posts</td><td>538,245 Posts related to 11 mental themes, 476,388 non-mental health posts</td><td>Human annotation</td><td>Classification of media text related to mental health</td><td>ACC = 0.76</td><td>RNN has the intrinsic ability of considering input in its sequence and the hierarchical structure is beneficial for the analysis of health-related online text.</td></tr><tr><td>Fraga et al., 2018<sup><xref ref-type="bibr" rid="CR105">105</xref></sup></td><td>RNN</td><td>Reddit posts</td><td>261,511 Posts and 1,256,669 comments from 105,878 users related to depression, 44,541 users related to SuicideWatch, 43,321 users related to anxiety, 13,939 users related to BD<sup>j</sup></td><td>Keywords matching</td><td>Analysis of four subreddits (anxiety, bipolar, depression, and suicide) related to mental health disorders</td><td>–</td><td>(1) Interaction patterns are very similar across the subreddits and interactions are centered around content rather than users; (2) the four subreddits share a common language.</td></tr><tr><td>Alambo et al., 2019<sup><xref ref-type="bibr" rid="CR109">109</xref></sup></td><td>RNN</td><td>Reddit posts</td><td>4992 Posts of 500 users</td><td>Human annotation</td><td>Prediction of suicidal risk</td><td>–</td><td>This study generated a gold standard dataset of suicide posts with their risk levels and formed a basis for the next step of constructing conversational agents that elicited suicide-related natural conversation on basis of questions.</td></tr></tbody></table><table-wrap-foot><p><italic>ACC</italic> accuracy, <italic>ADHD</italic> attention-deficit hyperactivity disorder, <italic>ASD</italic> autism spectrum disorder, <italic>AUC</italic> area under the receiver operating characteristic curve, <italic>AVEC</italic> Audio-Visual Emotion recognition Challenge, <italic>BD</italic> bipolar disorder, <italic>BDI-II</italic> Beck Depression Inventory II, <italic>CNN</italic> convolutional neural network, <italic>DASS-21</italic> Depression Anxiety stress scale, <italic>DBN</italic> deep belief network, <italic>DFNN</italic> deep feedforward neural network, <italic>GRU</italic> gated recurrent unit network, <italic>HC</italic> healthy control, <italic>HRSD</italic> Hamilton Rating Scale for Depression, <italic>LSTM</italic> long short-term memory network, <italic>MAE</italic> mean absolute error, <italic>MSE</italic> mean squared error, <italic>NMMAE</italic> normalized macro mean absolute error, <italic>PHQ-8</italic> Patient Health Questionnaire eighth version, <italic>PHQ-9</italic> Patient Health Questionnaire ninth version, <italic>RNN</italic> recurrent neural network, <italic>SCID-I</italic> Structured Clinical Interview for DSM-IV, <italic>SNP</italic> single-nucleotide polymorphism, <italic>TDC</italic> typical developing control, <italic>UD</italic> unipolar depression</p><p><sup>a</sup>ADHD-200 dataset, http://fcon_1000.projects.nitrc.org/indi/adhd200/</p><p><sup>b</sup>ABIDE dataset, http://fcon_1000.projects.nitrc.org/indi/abide/</p><p><sup>c</sup><ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds000030">https://openneuro.org/datasets/ds000030</ext-link></p><p><sup>d</sup>NUSDAST dataset, <ext-link ext-link-type="uri" xlink:href="http://schizconnect.org">http://schizconnect.org</ext-link></p><p><sup>e</sup><ext-link ext-link-type="uri" xlink:href="https://www.i2b2.org/NLP/RDoCforPsychiatry/">https://www.i2b2.org/NLP/RDoCforPsychiatry/</ext-link></p><p><sup>f</sup><ext-link ext-link-type="uri" xlink:href="https://genomeinterpretation.org/content/4-bipolar-exomes">https://genomeinterpretation.org/content/4-bipolar-exomes</ext-link></p><p><sup>g</sup>PsychENCODE Consortium dataset, <ext-link ext-link-type="uri" xlink:href="https://www.nimhgenetics.org/resources/psychencode">https://www.nimhgenetics.org/resources/psychencode</ext-link></p><p><sup>h</sup><ext-link ext-link-type="uri" xlink:href="http://youngjuncho.com/datasets/">http://youngjuncho.com/datasets/</ext-link></p><p><sup>i</sup><ext-link ext-link-type="uri" xlink:href="https://www.reddit.com/comments/3mg812">https://www.reddit.com/comments/3mg812</ext-link></p><p><sup>j</sup><ext-link ext-link-type="uri" xlink:href="http://files.pushshift.io/reddit/">http://files.pushshift.io/reddit/</ext-link></p><p><sup>k</sup><ext-link ext-link-type="uri" xlink:href="https://github.com/mihaelacr/pydeeplearn">https://github.com/mihaelacr/pydeeplearn</ext-link></p><p><sup>l</sup><ext-link ext-link-type="uri" xlink:href="https://github.com/trangptm/DeepCare">https://github.com/trangptm/DeepCare</ext-link></p><p><sup>m</sup><ext-link ext-link-type="uri" xlink:href="https://github.com/WGLab/iMEGES">https://github.com/WGLab/iMEGES</ext-link></p><p><sup>n</sup><ext-link ext-link-type="uri" xlink:href="http://youngjuncho.com/2017/acii2017-open-sources/">http://youngjuncho.com/2017/acii2017-open-sources/</ext-link></p></table-wrap-foot></table-wrap></p>
<sec id="Sec9">
<title>Clinical data</title>
<sec id="Sec10">
<title>Neuroimages</title>
<p id="Par14">Previous studies have shown that neuroimages can record evidence of neuropsychiatric disorders<sup><xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR23">23</xref></sup>. Two common types of neuroimage data analyzed in mental health studies are functional magnetic resonance imaging (fMRI) and structural MRI (sMRI) data. In fMRI data, the brain activity is measured by identification of the changes associated with blood flow, based on the fact that cerebral blood flow and neuronal activation are coupled<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. In sMRI data, the neurological aspect of a brain is described based on the structural textures, which show some information in terms of the spatial arrangements of voxel intensities in 3D. Recently, DL technologies have been demonstrated in analyzing both fMRI and sMRI data.</p>
<p id="Par15">One application of DL in fMRI and sMRI data is the identification of ADHD<sup><xref ref-type="bibr" rid="CR25">25</xref>–<xref ref-type="bibr" rid="CR31">31</xref></sup>. To learn meaningful information from the neuroimages, CNN and deep belief network (DBN) models were used. In particular, the CNN models were mainly used to identify local spatial patterns and DBN models were to obtain a deep hierarchical representation of the neuroimages. Different patterns were discovered between ADHDs and controls in the prefrontal cortex and cingulated cortex. Also, several studies analyzed sMRIs to investigate schizophrenia<sup><xref ref-type="bibr" rid="CR32">32</xref>–<xref ref-type="bibr" rid="CR36">36</xref></sup>, where DFNN, DBN, and autoencoder were utilized. These studies reported abnormal patterns of cortical regions and cortical–striatal–cerebellar circuit in the brain of schizophrenia patients, especially in the frontal, temporal, parietal, and insular cortices, and in some subcortical regions, including the corpus callosum, putamen, and cerebellum. Moreover, the use of DL in neuroimages also targeted at addressing other mental health disorders. Geng et al.<sup><xref ref-type="bibr" rid="CR37">37</xref></sup> proposed to use CNN and autoencoder to acquire meaningful features from the original time series of fMRI data for predicting depression. Two studies<sup><xref ref-type="bibr" rid="CR31">31</xref>,<xref ref-type="bibr" rid="CR38">38</xref></sup> integrated the fMRI and sMRI data modalities to develop predictive models for ASDs. Significant relationships between fMRI and sMRI data were observed with regard to ASD prediction.</p>
<sec id="FPar1">
<title>Challenges and opportunities</title>
<p id="Par16">The aforementioned studies have demonstrated that the use of DL techniques in analyzing neuroimages can provide evidence in terms of mental health problems, which can be translated into clinical practice and facilitate the diagnosis of mental health illness. However, multiple challenges need to be addressed to achieve this objective. First, DL architectures generally require large data samples to train the models, which may pose a difficulty in neuroimaging analysis because of the lack of such data<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. Second, typically the imaging data lie in a high-dimensional space, e.g., even a 64 × 64 2D neuroimage can result in 4096 features. This leads to the risk of overfitting by the DL models. To address this, most existing studies reported to utilize MRI data preprocessing tools such as Statistical Parametric Mapping (<ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm/">https://www.fil.ion.ucl.ac.uk/spm/</ext-link>), Data Processing Assistant for Resting-State fMRI<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>, and fMRI Preprocessing Pipeline<sup><xref ref-type="bibr" rid="CR41">41</xref></sup> to extract useful features before feeding to the DL models. Even though an intuitive attribute of DL is the capacity to learn meaningful features from raw data, feature engineering tools are needed especially in the case of small sample size and high-dimensionality, e.g., the neuroimage analysis. The use of such tools mitigates the overfitting risk of DL models. As reported in some selected studies<sup><xref ref-type="bibr" rid="CR28">28</xref>,<xref ref-type="bibr" rid="CR31">31</xref>,<xref ref-type="bibr" rid="CR35">35</xref>,<xref ref-type="bibr" rid="CR37">37</xref></sup>, the DL models can benefit from feature engineering techniques and have been shown to outperform the traditional ML models in the prediction of multiple conditions such as depression, schizophrenia, and ADHD. However, such tools extract features relying on prior knowledge; hence may omit some information that is meaningful for mental outcome research but unknown yet. An alternative way is to use CNN to automatically extract information from the raw data. As reported in the previous study<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>, CNNs perform well in processing raw neuroimage data. Among the studies reviewed in this study, three<sup><xref ref-type="bibr" rid="CR29">29</xref>,<xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR37">37</xref></sup> reported to involve CNN layers and achieved desirable performances.</p>
</sec>
</sec>
<sec id="Sec11">
<title>Electroencephalogram data</title>
<p id="Par17">As a low-cost, small-size, and high temporal resolution signal containing up to several hundred channels, analysis of electroencephalogram (EEG) data has gained significant attention to study brain disorders<sup><xref ref-type="bibr" rid="CR42">42</xref></sup>. As the EEG signal is one kind of streaming data that presents a high density and continuous characteristics, it challenges traditional feature engineering-based methods to obtain sufficient information from the raw EEG data to make accurate predictions. To address this, recently the DL models have been employed to analyze raw EEG signal data.</p>
<p id="Par18">Four articles reviewed proposed to use DL in understanding mental health conditions based on the analysis of EEG signals. Acharya et al.<sup><xref ref-type="bibr" rid="CR43">43</xref></sup> used CNN to extract features from the input EEG signals. They found that the EEG signals from the right hemisphere of the human brain are more distinctive in terms of the detection of depression than those from the left hemisphere. The findings provided shreds of evidence that depression is associated with a hyperactive right hemisphere. Mohan et al.<sup><xref ref-type="bibr" rid="CR44">44</xref></sup> modeled the raw EEG signals by DFNN to obtain information about the human brain waves. They found that the signals collected from the central (C3 and C4) regions are marginally higher compared with other brain regions, which can be used to distinguish the depressed and normal subjects from the brain wave signals. Zhang et al.<sup><xref ref-type="bibr" rid="CR45">45</xref></sup> proposed a concatenated structure of deep recurrent and 3D CNN to obtain EEG features across different tasks. They reported that the DL model can capture the spectral changes of EEG hemispheric asymmetry to distinguish different mental workload effectively. Li et al.<sup><xref ref-type="bibr" rid="CR46">46</xref></sup> presented a computer-aided detection system by extracting multiple types of information (e.g., spectral, spatial, and temporal information) to recognize mild depression based on CNN architecture. The authors found that both spectral and temporal information of EEG are crucial for prediction of depression.</p>
<sec id="FPar2">
<title>Challenges and opportunities</title>
<p id="Par19">EEG data are usually classified as streaming data that are continuous and are of high density. Despite the initial success in applying DL algorithms to analyze EEG data for studying multiple mental health conditions, there exist several challenges. One major challenge is that raw EEG data gathered from sensors have a certain degree of erroneous, noisy, and redundant information caused by discharged batteries, failures in sensor readings, and intermittent communication loss in wireless sensor networks<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>. This may challenge the model in extracting meaningful information from noise. Multiple preprocessing steps (e.g., data denoising, data interpolation, data transformation, and data segmentation) are necessary for dealing with the raw EEG signal before feeding to the DL models. Besides, due to the dense characteristics in the raw EEG data, analysis of the streaming data is computationally more expensive, which poses a challenge for the model architecture selection. A proper model should be designed relatively with less training parameters. This is one reason why the reviewed studies are mainly based on the CNN architecture.</p>
</sec>
</sec>
<sec id="Sec12">
<title>Electronic health records</title>
<p id="Par20">Electronic health records (EHRs) are systematic collections of longitudinal, patient-centered records. Patients’ EHRs consist of both structured and unstructured data: the structured data include information about a patient’s diagnosis, medications, and laboratory test results, and the unstructured data include information in clinical notes. Recently, DL models have been applied to analyze EHR data to study mental health disorders<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>.</p>
<p id="Par21">The first and foremost issue for analyzing the structured EHR data is how to appropriately handle the longitudinal records. Traditional ML models address this by collapsing patients’ records within a certain time window into vectors, which comprised the summary of statistics of the features in different dimensions<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>. For instance, to estimate the probability of suicide deaths, Choi et al.<sup><xref ref-type="bibr" rid="CR50">50</xref></sup> leveraged a DFNN to model the baseline characteristics. One major limitation of these studies is the omittance of temporality among the clinical events within EHRs. To overcome this issue, RNNs are more commonly used for EHR data analysis as an RNN intuitively handles time-series data. DeepCare<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>, a long short-term memory network (LSTM)-based DL model, encodes patient’s long-term health state trajectories to predict the future outcomes of depressive episodes. As the LSTM architecture appropriately captures disease progression by modeling the illness history and the medical interventions, DeepCare achieved over 15% improvement in prediction, compared with the conventional ML methods. In addition, Lin et al.<sup><xref ref-type="bibr" rid="CR52">52</xref></sup> designed two DFNN models for the prediction of antidepressant treatment response and remission. The authors reported that the proposed DFNN can achieve an area under the receiver operating characteristic curve (AUC) of 0.823 in predicting antidepressant response.</p>
<p id="Par22">Analyzing the unstructured clinical notes in EHRs refers to the long-standing topic of NLP. To extract meaningful knowledge from the text, conventional NLP approaches mostly define rules or regular expressions before the analysis. However, it is challenging to enumerate all possible rules or regular expressions. Due to the recent advance of DL in NLP tasks, DL models have been developed to mine clinical text data from EHRs to study mental health conditions. Geraci et al.<sup><xref ref-type="bibr" rid="CR53">53</xref></sup> utilized term frequency-inverse document frequency to represent the clinical documents by words and developed a DFNN model to identify individuals with depression. One major limitation of such an approach is that the semantics and syntax of sentences are lost. In this context, CNN<sup><xref ref-type="bibr" rid="CR54">54</xref></sup> and RNN<sup><xref ref-type="bibr" rid="CR55">55</xref></sup> have shown superiority in modeling syntax for text-based prediction. In particular, CNN has been used to mine the neuropsychiatric notes for predicting psychiatric symptom severity<sup><xref ref-type="bibr" rid="CR56">56</xref>,<xref ref-type="bibr" rid="CR57">57</xref></sup>. Tran and Kavuluru<sup><xref ref-type="bibr" rid="CR58">58</xref></sup> used an RNN to analyze the history of present illness in neuropsychiatric notes for predicting mental health conditions. The model engaged an attention mechanism<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>, which can specify the importance of the words in prediction, making the model more interpretable than their previous CNN model<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>.</p>
<sec id="FPar3">
<title>Challenges and opportunities</title>
<p id="Par23">Although DL has achieved promising results in EHR analysis, several challenges remain unsolved. On one hand, different from diagnosing physical health condition such as diabetes, the diagnosis of mental health conditions lacks direct quantitative tests, such as a blood chemistry test, a buccal swab, or urinalysis. Instead, the clinicians evaluate signs and symptoms through patient interviews and questionnaires during which they gather information based on patient’s self-report. Collection and deriving inferences from such data deeply relies on the experience and subjectivity of the clinician. This may account for signals buried in noise and affect the robustness of the DL model. To address this challenge, a potential way is to comprehensively integrate multimodal clinical information, including structured and unstructured EHR information, as well as neuroimaging and EEG data. Another way is to incorporate existing medical knowledge, which can guide model being trained in the right direction. For instance, the biomedical knowledge bases contain massive verified interactions between biomedical entities, e.g., diseases, genes, and drugs <sup><xref ref-type="bibr" rid="CR59">59</xref></sup>. Incorporating such information brings in meaningful medical constraints and may help to reduce the effects of noise on model training process. On the other hand, implementing a DL model trained from one EHR system into another system is challenging, because EHR data collection and representation is rarely standardized across hospitals and clinics. To address this issue, national/international collaborative efforts such as Observational Health Data Sciences and Informatics (<ext-link ext-link-type="uri" xlink:href="https://ohdsi.org">https://ohdsi.org</ext-link>) have developed common data models, such as OMOP, to standardize EHR data representation for conducting observational data analysis<sup><xref ref-type="bibr" rid="CR60">60</xref></sup>.</p>
</sec>
</sec>
<sec id="Sec13">
<title>Genetic data</title>
<p id="Par24">Multiple studies have found that mental disorders, e.g., depression, can be associated with genetic factors<sup><xref ref-type="bibr" rid="CR61">61</xref>,<xref ref-type="bibr" rid="CR62">62</xref></sup>. Conventional statistical studies in genetics and genomics, such as genome-wide association studies, have identified many common and rare genetic variants, such as single-nucleotide polymorphisms (SNPs), associated with mental health disorders<sup><xref ref-type="bibr" rid="CR63">63</xref>,<xref ref-type="bibr" rid="CR64">64</xref></sup>. Yet, the effect of the genetic factors is small and many more have not been discovered. With the recent developments in next-generation sequencing techniques, a massive volume of high-throughput genome or exome sequencing data are being generated, enabling researchers to study patients with mental health disorders by examining all types of genetic variations across an individual’s genome. In recent years, DL<sup><xref ref-type="bibr" rid="CR65">65</xref>,<xref ref-type="bibr" rid="CR66">66</xref></sup> has been applied to identify genetic risk factors associated with mental illness, by borrowing the capacity of DL in identifying highly complex patterns in large datasets. Khan and Wang<sup><xref ref-type="bibr" rid="CR67">67</xref></sup> integrated genetic annotations, known brain expression quantitative trait locus, and enhancer/promoter peaks to generate feature vectors of variants, and developed a DFNN, named ncDeepBrain, to prioritized non-coding variants associated with mental disorders. To further prioritize susceptibility genes, they designed another deep model, iMEGES<sup><xref ref-type="bibr" rid="CR68">68</xref></sup>, which integrates the ncDeepBrain score, general gene scores, and disease-specific scores for estimating gene risk. Wang et al.<sup><xref ref-type="bibr" rid="CR69">69</xref></sup> developed a novel deep architecture that combines deep Boltzmann machine architecture<sup><xref ref-type="bibr" rid="CR70">70</xref></sup> with conditional and lateral connections derived from the gene regulatory network. The model provided insights about intermediate phenotypes and their connections to high-level phenotypes (disease traits). Laksshman et al.<sup><xref ref-type="bibr" rid="CR71">71</xref></sup> used exome sequencing data to predict bipolar disorder outcomes of patients. They developed a CNN and used the convolution mechanism to capture correlations of the neighboring loci within the chromosome.</p>
<sec id="FPar4">
<title>Challenges and opportunities</title>
<p id="Par25">Although the use of genetic data in DL in studying mental health conditions shows promise, multiple challenges need to be addressed. For DL-based risk c/gene prioritization efforts, one major challenge is the limitation of labeled data. On one hand, the positive samples are limited, as known risk SNPs or genes associated with mental health conditions are limited. For example, there are about 108 risk loci that were genome-wide significant in ASD. On the other hand, the negative samples (i.e., SNPs, variants, or genes) may not be the “true” negative, as it is unclear whether they are associated with the mental illness yet. Moreover, it is also challenging to develop DL models for analyzing patient’s sequencing data for mental illness prediction, as the sequencing data are extremely high-dimensional (over five million SNPs in the human genome). More prior domain knowledge is needed to guide the DL model extracting patterns from the high-dimensional genomic space.</p>
</sec>
</sec>
<sec id="Sec14">
<title>Vocal and visual expression data</title>
<p id="Par26">The use of vocal (voice or speech) and visual (video or image of facial or body behaviors) expression data has gained the attention of many studies in mental health disorders. Modeling the evolution of people’s emotional states from these modalities has been used to identify mental health status. In essence, the voice data are continuous and dense signals, whereas the video data are sequences of frames, i.e., images. Conventional ML models for analyzing such types of data suffer from the sophisticated feature extraction process. Due to the recent success of applying DL in computer vision and sequence data modeling, such models have been introduced to analyze the vocal and/or visual expression data. In this work, most articles reviewed are to predict mental health disorders based on two public datasets: (i) the Chi-Mei corpus, collected by using six emotional videos to elicit facial expressions and speech responses of the subjects of bipolar disorder, unipolar depression, and healthy controls;<sup><xref ref-type="bibr" rid="CR72">72</xref></sup> and (ii) the International Audio/Visual Emotion Recognition Challenges (AVEC) depression dataset<sup><xref ref-type="bibr" rid="CR73">73</xref>–<xref ref-type="bibr" rid="CR75">75</xref></sup>, collected within human–computer interaction scenario. The proposed models include CNNs, RNNs, autoencoders, as well as hybrid models based on the above ones. In particular, CNNs were leveraged to encode the temporal and spectral features from the voice signals<sup><xref ref-type="bibr" rid="CR76">76</xref>–<xref ref-type="bibr" rid="CR80">80</xref></sup> and static facial or physical expression features from the video frames<sup><xref ref-type="bibr" rid="CR79">79</xref>,<xref ref-type="bibr" rid="CR81">81</xref>–<xref ref-type="bibr" rid="CR84">84</xref></sup>. Autoencoders were used to learn low-dimensional representations for people’s vocal<sup><xref ref-type="bibr" rid="CR85">85</xref>,<xref ref-type="bibr" rid="CR86">86</xref></sup> and visual expression<sup><xref ref-type="bibr" rid="CR87">87</xref>,<xref ref-type="bibr" rid="CR88">88</xref></sup>, and RNNs were engaged to characterize the temporal evolution of emotion based on the CNN-learned features and/or other handcraft features<sup><xref ref-type="bibr" rid="CR76">76</xref>,<xref ref-type="bibr" rid="CR81">81</xref>,<xref ref-type="bibr" rid="CR84">84</xref>–<xref ref-type="bibr" rid="CR90">90</xref></sup>. Few studies focused on analyzing static images using a CNN architecture to predict mental health status. Prasetio et al.<sup><xref ref-type="bibr" rid="CR91">91</xref></sup> identified the stress types (e.g., neutral, low stress, and high stress) from facial frontal images. Their proposed CNN model outperforms the conventional ML models by 7% in terms of prediction accuracy. Jaiswal et al.<sup><xref ref-type="bibr" rid="CR92">92</xref></sup> investigated the relationship between facial expression/gestures and neurodevelopmental conditions. They reported accuracy over 0.93 in the diagnostic prediction of ADHD and ASD by using the CNN architecture. In addition, thermal images that track persons’ breathing patterns were also fed to a deep model to estimate psychological stress level (mental overload)<sup><xref ref-type="bibr" rid="CR93">93</xref></sup>.</p>
<sec id="FPar5">
<title>Challenges and opportunities</title>
<p id="Par27">From the above summary, we can observe that analyzing vocal and visual expression data can capture the pattern of subjects’ emotion evolution to predict mental health conditions. Despite the promising initial results, there remain challenges for developing DL models in this field. One major challenge is to link vocal and visual expression data with the clinical data of patients, given the difficulties involved in collecting such expression data during clinical practice. Current studies analyzed vocal and visual expression over individual datasets. Without clinical guidance, the developed prediction models have limited clinical meanings. Linking patients’ expression information with clinical variables may help to improve both the interpretability and robustness of the model. For example, Gupta et al.<sup><xref ref-type="bibr" rid="CR94">94</xref></sup> designed a DFNN for affective prediction from audio and video modalities. The model incorporated depression severity as the parameter, linking the effects of depression on subjects’ affective expressions. Another challenge is the limitation of the samples. For example, the Chi-Mei dataset contains vocal–visual data from only 45 individuals (15 with bipolar disorder, 15 with unipolar disorder, and 15 healthy controls). Also, there is a lack of “emotion labels” for people’s vocal and visual expression. Apart from improving the datasets, an alternative way to solve this challenge is to use transfer learning, which transfers knowledge gained with one dataset (usually more general) to the target dataset. For example, some studies trained autoencoder in public emotion database such as eNTERFACE<sup><xref ref-type="bibr" rid="CR95">95</xref></sup> to generate emotion profiles (EPs). Other studies<sup><xref ref-type="bibr" rid="CR83">83</xref>,<xref ref-type="bibr" rid="CR84">84</xref></sup> pre-trained CNN over general facial expression datasets<sup><xref ref-type="bibr" rid="CR96">96</xref>,<xref ref-type="bibr" rid="CR97">97</xref></sup> for extracting face appearance features.</p>
</sec>
</sec>
<sec id="Sec15">
<title>Social media data</title>
<p id="Par28">With the widespread proliferation of social media platforms, such as Twitter and Reddit, individuals are increasingly and publicly sharing information about their mood, behavior, and any ailments one might be suffering. Such social media data have been used to identify users’ mental health state (e.g., psychological stress and suicidal ideation)<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>.</p>
<p id="Par29">In this study, the articles that used DL to analyze social media data mainly focused on stress detection<sup><xref ref-type="bibr" rid="CR98">98</xref>–<xref ref-type="bibr" rid="CR101">101</xref></sup>, depression identification<sup><xref ref-type="bibr" rid="CR102">102</xref>–<xref ref-type="bibr" rid="CR106">106</xref></sup>, and estimation of suicide risk<sup><xref ref-type="bibr" rid="CR103">103</xref>,<xref ref-type="bibr" rid="CR105">105</xref>,<xref ref-type="bibr" rid="CR107">107</xref>–<xref ref-type="bibr" rid="CR109">109</xref></sup>. In general, the core concept across these work is to mine the textual, and where applicable graphical, content of users’ social media posts to discover cues for mental health disorders. In this context, the RNN and CNN were largely used by the researchers. Especially, RNN usually introduces an attention mechanism to specify the importance of the input elements in the classification process<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>. This provides some interpretability for the predictive results. For example, Ive et al.<sup><xref ref-type="bibr" rid="CR103">103</xref></sup> proposed a hierarchical RNN architecture with an attention mechanism to predict the classes of the posts (including depression, autism, suicidewatch, anxiety, etc.). The authors observed that, benefitting from the attention mechanism, the model can predict risk text efficiently and extract text elements crucial for making decisions. Coppersmith et al.<sup><xref ref-type="bibr" rid="CR107">107</xref></sup> used LSTM to discover quantifiable signals about suicide attempts based on social media posts. The proposed model can capture contextual information between words and obtain nuances of language related to suicide.</p>
<p id="Par30">Apart from text, users also post images on social media. The properties of the images (e.g., color theme, saturation, and brightness) provide some cues reflecting users’ mental health status. In addition, millions of interactions and relationships among users can reflect the social environment of individuals that is also a kind of risk factors for mental illness. An increasing number of studies attempted to combine these two types of information with text content for predictive modeling. For example, Lin et al.<sup><xref ref-type="bibr" rid="CR99">99</xref></sup> leveraged the autoencoder to extract low-level and middle-level representations from texts, images, and comments based on psychological and art theories. They further extended their work with a hybrid model based on CNN by integrating post content and social interactions<sup><xref ref-type="bibr" rid="CR101">101</xref></sup>. The results provided an implication that the social structure of the stressed users’ friends tended to be less connected than that of the users without stress.</p>
<sec id="FPar6">
<title>Challenges and opportunities</title>
<p id="Par31">The aforementioned studies have demonstrated that using social media data has the potential to detect users with mental health problems. However, there are multiple challenges towards the analysis of social media data. First, given that social media data are typically de-identified, there is no straightforward way to confirm the “true positives” and “true negatives” for a given mental health condition. Enabling the linkage of user’s social media data with their EHR data—with appropriate consent and privacy protection—is challenging to scale, but has been done in a few settings<sup><xref ref-type="bibr" rid="CR110">110</xref></sup>. In addition, most of the previous studies mainly analyzed textual and image data from social media platforms, and did not consider analyzing the social network of users. In one study, Rosenquist et al.<sup><xref ref-type="bibr" rid="CR111">111</xref></sup> reported that the symptoms of depression are highly correlated inside the circle of friends, indicating that social network analysis is likely to be a potential way to study the prevalence of mental health problems. However, comprehensively modeling text information and network structure remains challenging. In this context, graph convolutional networks<sup><xref ref-type="bibr" rid="CR112">112</xref></sup> have been developed to address networked data mining. Moreover, although it is possible to discover online users with mental illness by social media analysis, translation of this innovation into practical applications and offer aid to users, such as providing real-time interventions, are largely needed<sup><xref ref-type="bibr" rid="CR113">113</xref></sup>.</p>
</sec>
</sec>
</sec>
</sec>
<sec id="Sec16">
<title>Discussion: findings, open issues, and future directions</title>
<sec id="Sec17">
<title>Principle findings</title>
<p id="Par32">The purpose of this study is to investigate the current state of applications of DL techniques in studying mental health outcomes. Out of 2261 articles identified based on our search terms, 57 studies met our inclusion criteria and were reviewed. Some studies that involved DL models but did not highlight the DL algorithms’ features on analysis were excluded. From the above results, we observed that there are a growing number of studies using DL models for studying mental health outcomes. Particularly, multiple studies have developed disease risk prediction models using both clinical and non-clinical data, and have achieved promising initial results.</p>
</sec>
<sec id="Sec18">
<title>Data bias</title>
<p id="Par33">DL models “think to learn” like a human brain relying on their multiple layers of interconnected computing neurons. Therefore, to train a deep neural network, there are multiple parameters (i.e., weights associated links between neurons within the network) being required to learn. This is one reason why DL has achieved great success in the fields where a massive volume of data can be easily collected, such as computer vision and text mining. Yet, in the health domain, the availability of large-scale data is very limited. For most selected studies in this review, the sample sizes are under a scale of 10<sup>4</sup>. Data availability is even more scarce in the fields of neuroimaging, EEG, and gene expression data, as such data reside in a very high-dimensional space. This then leads to the problem of “curse of dimensionality”<sup><xref ref-type="bibr" rid="CR114">114</xref></sup>, which challenges the optimization of the model parameters.</p>
<p id="Par34">One potential way to address this challenge is to reduce the dimensionality of the data by feature engineering before feeding information to the DL models. On one hand, feature extraction approaches can be used to obtain different types of features from the raw data. For example, several studies reported in this review have attempted to use preprocessing tools to extract features from neuroimaging data. On the other hand, feature selection that is commonly used in conventional ML models is also an option to reduce data dimensionality. However, the feature selection approaches are not often used in the DL application scenario, as one of the intuitive attributes of DL is the capacity to learn meaningful features from “all” available data. The alternative way to address the issue of data bias is to use transfer learning where the objective is to improve learning a new task through the transfer of knowledge from a related task that has already been learned<sup><xref ref-type="bibr" rid="CR115">115</xref></sup>. The basic idea is that data representations learned in the earlier layers are more general, whereas those learned in the latter layers are more specific to the prediction task<sup><xref ref-type="bibr" rid="CR116">116</xref></sup>. In particular, one can first pre-train a deep neural network in a large-scale “source” dataset, then stack fully connected layers on the top of the network and fine-tune it in the small “target” dataset in a standard backpropagation manner. Usually, samples in the “source” dataset are more general (e.g., general image data), whereas those in the “target” dataset are specific to the task (e.g., medical image data). A popular example of the success of transfer learning in the health domain is the dermatologist-level classification of skin cancer<sup><xref ref-type="bibr" rid="CR117">117</xref></sup>. The authors introduced Google’s Inception v3 CNN architecture pre-trained over 1.28 million general images and fine-tuned in the clinical image dataset. The model achieved very high-performance results of skin cancer classification in epidermal (AUC = 0.96), melanocytic (AUC = 0.96), and melanocytic–dermoscopic images (AUC = 0.94). In facial expression-based depression prediction, Zhu et al.<sup><xref ref-type="bibr" rid="CR83">83</xref></sup> pre-trained CNN on the public face recognition dataset to model the static facial appearance, which overcomes the issue that there is no facial expression label information. Chao et al.<sup><xref ref-type="bibr" rid="CR84">84</xref></sup> also pre-trained CNN to encode facial expression information. The transfer scheme of both of the two studies has been demonstrated to be able to improve the prediction performance.</p>
</sec>
<sec id="Sec19">
<title>Diagnosis and prediction issues</title>
<p id="Par35">Unlike the diagnosis of physical conditions that can be based on lab tests, diagnoses of the mental illness typically rely on mental health professionals’ judgment and patient self-report data. As a result, such a diagnostic system may not accurately capture the psychological deficits and symptom progression to provide appropriate therapeutic interventions<sup><xref ref-type="bibr" rid="CR118">118</xref>,<xref ref-type="bibr" rid="CR119">119</xref></sup>. This issue accordingly accounts for the limitation of the prediction models to assist clinicians to make decisions. Except for several studies using the unsupervised autoencoder for learning low-dimensional representations, most studies reviewed in this study reported using supervised DL models, which need the training set containing “true” (i.e., expert provided) labels to optimize the model parameters before the model being used to predict labels of new subjects. Inevitably, the quality of the expert-provided diagnostic labels used for training sets the upper-bound for the prediction performance of the model.</p>
<p id="Par36">One intuitive route to address this issue is to use an unsupervised learning scheme that, instead of learning to predict clinical outcomes, aims at learning compacted yet informative representations of the raw data. A typical example is the autoencoder (as shown in Fig. <xref ref-type="fig" rid="Fig1">1d</xref>), which encodes the raw data into a low-dimensional space, from which the raw data can be reconstructed. Some studies reviewed have proposed to leverage autoencoder to improve our understanding of mental health outcomes. A constraint of the autoencoder is that the input data should be preprocessed to vectors, which may lead to information loss for image and sequence data. To address this, recently convolutional-autoencoder<sup><xref ref-type="bibr" rid="CR120">120</xref></sup> and LSTM-autoencoder<sup><xref ref-type="bibr" rid="CR121">121</xref></sup> have been developed, which integrate the convolution layers and recurrent layers with the autoencoder architecture and enable us to learn informative low-dimensional representations from the raw image data and sequence data, respectively. For instance, Baytas et al.<sup><xref ref-type="bibr" rid="CR122">122</xref></sup> developed a variation of LSTM-autoencoder on patient EHRs and grouped Parkinson’s disease patients into meaningful subtypes. Another potential way is to predict other clinical outcomes instead of the diagnostic labels. For example, several selected studies proposed to predict symptom severity scores<sup><xref ref-type="bibr" rid="CR56">56</xref>,<xref ref-type="bibr" rid="CR57">57</xref>,<xref ref-type="bibr" rid="CR77">77</xref>,<xref ref-type="bibr" rid="CR82">82</xref>,<xref ref-type="bibr" rid="CR84">84</xref>,<xref ref-type="bibr" rid="CR87">87</xref>,<xref ref-type="bibr" rid="CR89">89</xref></sup>. In addition, Du et al.<sup><xref ref-type="bibr" rid="CR108">108</xref></sup> attempted to identify suicide-related psychiatric stressors from users’ posts on Twitter, which plays an important role in the early prevention of suicidal behaviors. Furthermore, training model to predict future outcomes such as treatment response, emotion assessments, and relapse time is also a promising future direction.</p>
</sec>
<sec id="Sec20">
<title>Multimodal modeling</title>
<p id="Par37">The field of mental health is heterogeneous. On one hand, mental illness refers to a variety of disorders that affect people’s emotions and behaviors. On the other hand, though the exact causes of most mental illnesses are unknown to date, it is becoming increasingly clear that the risk factors for these diseases are multifactorial as multiple genetic, environmental, and social factors interact to influence an individual’s mental health<sup><xref ref-type="bibr" rid="CR123">123</xref>,<xref ref-type="bibr" rid="CR124">124</xref></sup>. As a result of domain heterogeneity, researchers have the chance to study the mental health problems from different perspectives, from molecular, genomic, clinical, medical imaging, physiological signal to facial, and body expressive and online behavioral. Integrative modeling of such multimodal data means comprehensively considering different aspects of the disease, thus likely obtaining deep insight into mental health. In this context, DL models have been developed for multimodal modeling. As shown in Fig. <xref ref-type="fig" rid="Fig4">4</xref>, the hierarchical structure of DL makes it easily compatible with multimodal integration. In particular, one can model each modality with a specific network and combine them by the final fully connected layers, such that parameters can be jointly learned by a typical backpropagation manner. In this review, we found an increasing number of studies have attempted to use multimodal modeling. For example, Zou et al.<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> developed a multimodal model composed of two CNNs for modeling fMRI and sMRI modalities, respectively. The model achieved 69.15% accuracy in predicting ADHD, which outperformed the unimodal models (66.04% for fMRI modal-based and 65.86% for sMRI modal-based). Yang et al.<sup><xref ref-type="bibr" rid="CR79">79</xref></sup> proposed a multimodal model to combine vocal and visual expression for depression cognition. The model results in 39% lower prediction error than the unimodal models.<fig id="Fig4"><label>Fig. 4</label><caption><title>An illustration of the multimodal deep neural network.</title><p>One can model each modality with a specific network and combine them using the final fully-connected layers. In this way, parameters of the entire neural network can be jointly learned in a typical backpropagation manner.</p></caption><graphic id="d30e3035" xlink:href="41398_2020_780_Fig4_HTML"></graphic></fig></p>
</sec>
<sec id="Sec21">
<title>Model interpretability</title>
<p id="Par38">Due to the end-to-end design, the DL models usually appear to be “black boxes”: they take raw data (e.g., MRI images, free-text of clinical notes, and EEG signals) as input, and yield output to reach a conclusion (e.g., the risk of a mental health disorder) without clear explanations of their inner working. Although this might not be an issue in other application domains such as identifying animals from images, in health not only the model’s prediction performance but also the clues for making the decision are important. For example in the neuroimage-based depression identification, despite estimation of the probability that a patient suffers from mental health deficits, the clinicians would focus more on recognizing abnormal regions or patterns of the brain associated with the disease. This is really important for convincing the clinical experts about the actions recommended from the predictive model, as well as for guiding appropriate interventions. In addition, as discussed above, the introduction of multimodal modeling leads to an increased challenge in making the models more interpretable. Attempts have been made to open the “black box” of DL<sup><xref ref-type="bibr" rid="CR59">59</xref>,<xref ref-type="bibr" rid="CR125">125</xref>–<xref ref-type="bibr" rid="CR127">127</xref></sup>. Currently, there are two general directions for interpretable modeling: one is to involve the systematic modification of the input and the measure of any resulting changes in the output, as well as in the activation of the artificial neurons in the hidden layers. Such a strategy is usually used in CNN in identifying specific regions of an image being captured by a convolutional layer<sup><xref ref-type="bibr" rid="CR128">128</xref></sup>. Another way is to derive tools to determine the contribution of one or more features of the input data to the output. In this case, the widely used tools include Shapley Additive Explanation<sup><xref ref-type="bibr" rid="CR129">129</xref></sup>, LIME<sup><xref ref-type="bibr" rid="CR127">127</xref></sup>, DeepLIFT<sup><xref ref-type="bibr" rid="CR130">130</xref></sup>, etc., which are able to assign each feature an importance score for the specific prediction task.</p>
</sec>
<sec id="Sec22">
<title>Connection to therapeutic interventions</title>
<p id="Par39">According to the studies reviewed, it is now possible to detect patients with mental illness based on different types of data. Compared with the traditional ML techniques, most of the reviewed DL models reported higher prediction accuracy. The findings suggested that the DL models are likely to assist clinicians in improved diagnosis of mental health conditions. However, to associate diagnosis of a condition with evidence-based interventions and treatment, including identification of appropriate medication<sup><xref ref-type="bibr" rid="CR131">131</xref></sup>, prediction of treatment response<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>, and estimation of relapse risk<sup><xref ref-type="bibr" rid="CR132">132</xref></sup> still remains a challenge. Among the reviewed studies, only one<sup><xref ref-type="bibr" rid="CR52">52</xref></sup> proposed to target at addressing these issues. Thus, further efforts are needed to link the DL techniques with the therapeutic intervention of mental illness.</p>
</sec>
<sec id="Sec23">
<title>Domain knowledge</title>
<p id="Par40">Another important direction is to incorporate domain knowledge. The existing biomedical knowledge bases are invaluable sources for solving healthcare problems<sup><xref ref-type="bibr" rid="CR133">133</xref>,<xref ref-type="bibr" rid="CR134">134</xref></sup>. Incorporating domain knowledge could address the limitation of data volume, problems of data quality, as well as model generalizability. For example, the unified medical language system<sup><xref ref-type="bibr" rid="CR135">135</xref></sup> can help to identify medical entities from the text and gene–gene interaction databases<sup><xref ref-type="bibr" rid="CR136">136</xref></sup> could help to identify meaningful patterns from genomic profiles.</p>
</sec>
</sec>
<sec id="Sec24" sec-type="conclusion">
<title>Conclusion</title>
<p id="Par41">Recent years have witnessed the increasing use of DL algorithms in healthcare and medicine. In this study, we reviewed existing studies on DL applications to study mental health outcomes. All the results available in the literature reviewed in this work illustrate the applicability and promise of DL in improving the diagnosis and treatment of patients with mental health conditions. Also, this review highlights multiple existing challenges in making DL algorithms clinically actionable for routine care, as well as promising future directions in this field.</p>
</sec>
<sec sec-type="supplementary-material">
<title>Supplementary information</title>
<sec id="Sec25">
<p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41398_2020_780_MOESM1_ESM.docx"><caption><p>Supplemental Material</p></caption></media></supplementary-material>
</p>
</sec>
</sec>
</body>
<back>
<fn-group>
<fn>
<p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</fn>
</fn-group>
<sec>
<title>Supplementary information</title>
<p><bold>Supplementary Information</bold> accompanies this paper at (10.1038/s41398-020-0780-3).</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>The work is supported by NSF 1750326, R01 MH112148, R01 MH105384, R01 MH119177, R01 MH121922, and P50 MH113838.</p>
</ack>
<notes notes-type="author-contribution">
<title>Author contributions</title>
<p>C.S., Z.X. and F.W. planned and structured the whole paper. C.S. and Z.X. conducted the literature review and drafted the manuscript. J.P. and F.W. reviewed and edited the manuscript.</p>
</notes>
<notes id="FPar7" notes-type="COI-statement">
<title>Competing interests</title>
<p id="Par42">The authors declare no competing interests.</p>
</notes>
<ref-list id="Bib1">
<title>References</title>
<ref id="CR1">
<label>1.</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<collab>World Health Organization.</collab>
</person-group>
<source/>The World Health Report 2001: Mental Health: New Understanding, New Hope
          <year>2001</year>
<publisher-loc>Switzerland</publisher-loc>
<publisher-name>World Health Organization</publisher-name>
</element-citation>
</ref>
<ref id="CR2">
<label>2.</label>
<mixed-citation publication-type="other">Marcus, M., Yasamy, M. T., van Ommeren, M., Chisholm, D. &amp; Saxena, S. <italic>Depression: A Global Public Health Concern</italic> (World Federation of Mental Health, World Health Organisation, Perth, 2012).</mixed-citation>
</ref>
<ref id="CR3">
<label>3.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hamilton</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>Development of a rating scale for primary depressive illness</article-title>
<source/>Br. J. Soc. Clin. Psychol.
          <year>1967</year>
<volume>6</volume>
<fpage>278</fpage>
<lpage>296</lpage>
<pub-id pub-id-type="pmid">6080235</pub-id>
</element-citation>
</ref>
<ref id="CR4">
<label>4.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dwyer</surname>
<given-names>DB</given-names>
</name>
<name>
<surname>Falkai</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Koutsouleris</surname>
<given-names>N</given-names>
</name>
</person-group>
<article-title>Machine learning approaches for clinical psychology and psychiatry</article-title>
<source/>Annu. Rev. Clin. Psychol.
          <year>2018</year>
<volume>14</volume>
<fpage>91</fpage>
<lpage>118</lpage>
<pub-id pub-id-type="pmid">29401044</pub-id>
</element-citation>
</ref>
<ref id="CR5">
<label>5.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lovejoy</surname>
<given-names>CA</given-names>
</name>
<name>
<surname>Buch</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Maruthappu</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>Technology and mental health: the role of artificial intelligence</article-title>
<source/>Eur. Psychiatry
          <year>2019</year>
<volume>55</volume>
<fpage>1</fpage>
<lpage>3</lpage>
<pub-id pub-id-type="pmid">30384105</pub-id>
</element-citation>
</ref>
<ref id="CR6">
<label>6.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wongkoblap</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Vadillo</surname>
<given-names>MA</given-names>
</name>
<name>
<surname>Curcin</surname>
<given-names>V</given-names>
</name>
</person-group>
<article-title>Researching mental health disorders in the era of social media: systematic review</article-title>
<source/>J. Med. Internet Res.
          <year>2017</year>
<volume>19</volume>
<fpage>e228</fpage>
<pub-id pub-id-type="pmid">28663166</pub-id>
</element-citation>
</ref>
<ref id="CR7">
<label>7.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>LeCun</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Bengio</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Hinton</surname>
<given-names>G</given-names>
</name>
</person-group>
<article-title>Deep learning</article-title>
<source/>Nature
          <year>2015</year>
<volume>521</volume>
<fpage>436</fpage>
<pub-id pub-id-type="pmid">26017442</pub-id>
</element-citation>
</ref>
<ref id="CR8">
<label>8.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Miotto</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Jiang</surname>
<given-names>X</given-names>
</name>
<name>
<surname>Dudley</surname>
<given-names>JT</given-names>
</name>
</person-group>
<article-title>Deep learning for healthcare: review, opportunities and challenges</article-title>
<source/>Brief. Bioinformatics
          <year>2017</year>
<volume>19</volume>
<fpage>1236</fpage>
<lpage>1246</lpage>
</element-citation>
</ref>
<ref id="CR9">
<label>9.</label>
<mixed-citation publication-type="other">Durstewitz, D., Koppe, G. &amp; Meyer-Lindenberg, A. Deep neural networks in psychiatry. <italic>Mol. Psychiatry</italic><bold>24</bold>, 1583–1598 (2019).</mixed-citation>
</ref>
<ref id="CR10">
<label>10.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Vieira</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Pinaya</surname>
<given-names>WH</given-names>
</name>
<name>
<surname>Mechelli</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Using deep learning to investigate the neuroimaging correlates of psychiatric and neurological disorders: methods and applications</article-title>
<source/>Neurosci. Biobehav. Rev.
          <year>2017</year>
<volume>74</volume>
<fpage>58</fpage>
<lpage>75</lpage>
<pub-id pub-id-type="pmid">28087243</pub-id>
</element-citation>
</ref>
<ref id="CR11">
<label>11.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Shatte</surname>
<given-names>AB</given-names>
</name>
<name>
<surname>Hutchinson</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Teague</surname>
<given-names>SJ</given-names>
</name>
</person-group>
<article-title>Machine learning in mental health: a scoping review of methods and applications</article-title>
<source/>Psychol. Med.
          <year>2019</year>
<volume>49</volume>
<fpage>1426</fpage>
<lpage>1448</lpage>
<pub-id pub-id-type="pmid">30744717</pub-id>
</element-citation>
</ref>
<ref id="CR12">
<label>12.</label>
<mixed-citation publication-type="other">Murphy, K. P. <italic>Machine Learning: A Probabilistic Perspective</italic> (MIT Press, Cambridge, 2012).</mixed-citation>
</ref>
<ref id="CR13">
<label>13.</label>
<mixed-citation publication-type="other">Biship, C. M. <italic>Pattern Recognition and Machine Learning (Information Science and Statistics)</italic> (Springer-Verlag, Berlin, 2007).</mixed-citation>
</ref>
<ref id="CR14">
<label>14.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bengio</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Simard</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Frasconi</surname>
<given-names>P</given-names>
</name>
</person-group>
<article-title>Learning long-term dependencies with gradient descent is difficult</article-title>
<source/>IEEE Trans. Neural Netw. Learn. Syst.
          <year>1994</year>
<volume>5</volume>
<fpage>157</fpage>
<lpage>166</lpage>
</element-citation>
</ref>
<ref id="CR15">
<label>15.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>LeCun</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Bottou</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Bengio</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Haffner</surname>
<given-names>P</given-names>
</name>
</person-group>
<article-title>Gradient-based learning applied to document recognition</article-title>
<source/>Proc. IEEE
          <year>1998</year>
<volume>86</volume>
<fpage>2278</fpage>
<lpage>2324</lpage>
</element-citation>
</ref>
<ref id="CR16">
<label>16.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Vincent</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Larochelle</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Lajoie</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Bengio</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Manzagol</surname>
<given-names>PA</given-names>
</name>
</person-group>
<article-title>Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion</article-title>
<source/>J. Mach. Learn. Res.
          <year>2010</year>
<volume>11</volume>
<fpage>3371</fpage>
<lpage>3408</lpage>
</element-citation>
</ref>
<ref id="CR17">
<label>17.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rumelhart</surname>
<given-names>DE</given-names>
</name>
<name>
<surname>Hinton</surname>
<given-names>GE</given-names>
</name>
<name>
<surname>Williams</surname>
<given-names>RJ</given-names>
</name>
</person-group>
<article-title>Learning representations by back-propagating errors</article-title>
<source/>Cogn. modeling.
          <year>1988</year>
<volume>5</volume>
<fpage>1</fpage>
</element-citation>
</ref>
<ref id="CR18">
<label>18.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hochreiter</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Schmidhuber</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>Long short-term memory</article-title>
<source/>Neural Comput.
          <year>1997</year>
<volume>9</volume>
<fpage>1735</fpage>
<lpage>1780</lpage>
<pub-id pub-id-type="pmid">9377276</pub-id>
</element-citation>
</ref>
<ref id="CR19">
<label>19.</label>
<mixed-citation publication-type="other">Cho, K., Van Merriënboer, B., Bahdanau, D. &amp; Bengio, Y. On the properties of neural machine translation: encoder-decoder approaches. In <italic>Proc</italic>. <italic>SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation</italic> 103–111 (Doha, Qatar, 2014).</mixed-citation>
</ref>
<ref id="CR20">
<label>20.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Liou</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Cheng</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Liou</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Liou</surname>
<given-names>D</given-names>
</name>
</person-group>
<article-title>Autoencoder for words</article-title>
<source/>Neurocomputing
          <year>2014</year>
<volume>139</volume>
<fpage>84</fpage>
<lpage>96</lpage>
</element-citation>
</ref>
<ref id="CR21">
<label>21.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Moher</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Liberati</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Tetzlaff</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Altman</surname>
<given-names>DG</given-names>
</name>
</person-group>
<article-title>Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement</article-title>
<source/>Ann. Intern. Med.
          <year>2009</year>
<volume>151</volume>
<fpage>264</fpage>
<lpage>269</lpage>
<pub-id pub-id-type="pmid">19622511</pub-id>
</element-citation>
</ref>
<ref id="CR22">
<label>22.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Schnack</surname>
<given-names>HG</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Can structural MRI aid in clinical classification? A machine learning study in two independent samples of patients with schizophrenia, bipolar disorder and healthy subjects</article-title>
<source/>Neuroimage
          <year>2014</year>
<volume>84</volume>
<fpage>299</fpage>
<lpage>306</lpage>
<pub-id pub-id-type="pmid">24004694</pub-id>
</element-citation>
</ref>
<ref id="CR23">
<label>23.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>O’Toole</surname>
<given-names>AJ</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Theoretical, statistical, and practical perspectives on pattern-based classification approaches to the analysis of functional neuroimaging data</article-title>
<source/>J. Cogn. Neurosci.
          <year>2007</year>
<volume>19</volume>
<fpage>1735</fpage>
<lpage>1752</lpage>
<pub-id pub-id-type="pmid">17958478</pub-id>
</element-citation>
</ref>
<ref id="CR24">
<label>24.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Logothetis</surname>
<given-names>NK</given-names>
</name>
<name>
<surname>Pauls</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Augath</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Trinath</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Oeltermann</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Neurophysiological investigation of the basis of the fMRI signal</article-title>
<source/>Nature
          <year>2001</year>
<volume>412</volume>
<fpage>150</fpage>
<pub-id pub-id-type="pmid">11449264</pub-id>
</element-citation>
</ref>
<ref id="CR25">
<label>25.</label>
<mixed-citation publication-type="other">Kuang, D. &amp; He, L. Classification on ADHD with deep learning. In <italic>Proc</italic>. <italic>Int. Conference on Cloud Computing and Big Data</italic> 27–32 (Wuhan, China, 2014).</mixed-citation>
</ref>
<ref id="CR26">
<label>26.</label>
<mixed-citation publication-type="other">Kuang, D., Guo, X., An, X., Zhao, Y. &amp; He, L. Discrimination of ADHD based on fMRI data with deep belief network. In <italic>Proc</italic>. <italic>Int. Conference on Intelligent Computing</italic> 225–232 (Taiyuan, China, 2014).</mixed-citation>
</ref>
<ref id="CR27">
<label>27.</label>
<mixed-citation publication-type="other">Farzi, S., Kianian, S. &amp; Rastkhadive, I. Diagnosis of attention deficit hyperactivity disorder using deep belief network based on greedy approach. In <italic>Proc</italic>. <italic>5th Int. Symposium on Computational and Business Intelligence</italic> 96–99 (Dubai, United Arab Emirates, 2017).</mixed-citation>
</ref>
<ref id="CR28">
<label>28.</label>
<mixed-citation publication-type="other">Zou, L., Zheng, J. &amp; McKeown, M. J. Deep learning based automatic diagnoses of attention deficit hyperactive disorder. In <italic>Proc</italic>. <italic>2017 IEEE Global Conference on Signal and Information Processing (GlobalSIP)</italic> 962–966 (Montreal, Canada, 2017).</mixed-citation>
</ref>
<ref id="CR29">
<label>29.</label>
<mixed-citation publication-type="other">Riaz A. et al. Deep fMRI: an end-to-end deep network for classification of fMRI data. In <italic>Proc</italic>. <italic>2018 IEEE 15th Int. Symposium on Biomedical Imaging</italic>. 1419–1422 (Washington, DC, USA, 2018).</mixed-citation>
</ref>
<ref id="CR30">
<label>30.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zou</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Zheng</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Miao</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Mckeown</surname>
<given-names>MJ</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>ZJ</given-names>
</name>
</person-group>
<article-title>3D CNN based automatic diagnosis of attention deficit hyperactivity disorder using functional and structural MRI</article-title>
<source/>IEEE Access.
          <year>2017</year>
<volume>5</volume>
<fpage>23626</fpage>
<lpage>23636</lpage>
</element-citation>
</ref>
<ref id="CR31">
<label>31.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Sen</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Borle</surname>
<given-names>NC</given-names>
</name>
<name>
<surname>Greiner</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Brown</surname>
<given-names>MR</given-names>
</name>
</person-group>
<article-title>A general prediction model for the detection of ADHD and Autism using structural and functional MRI</article-title>
<source/>PLoS ONE
          <year>2018</year>
<volume>13</volume>
<fpage>e0194856</fpage>
<pub-id pub-id-type="pmid">29664902</pub-id>
</element-citation>
</ref>
<ref id="CR32">
<label>32.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zeng</surname>
<given-names>L</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Multi-site diagnostic classification of schizophrenia using discriminant deep learning with functional connectivity MRI</article-title>
<source/>EBioMedicine
          <year>2018</year>
<volume>30</volume>
<fpage>74</fpage>
<lpage>85</lpage>
<pub-id pub-id-type="pmid">29622496</pub-id>
</element-citation>
</ref>
<ref id="CR33">
<label>33.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Pinaya</surname>
<given-names>WH</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Using deep belief network modelling to characterize differences in brain morphometry in schizophrenia</article-title>
<source/>Sci. Rep.
          <year>2016</year>
<volume>6</volume>
<fpage>38897</fpage>
<pub-id pub-id-type="pmid">27941946</pub-id>
</element-citation>
</ref>
<ref id="CR34">
<label>34.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Pinaya</surname>
<given-names>WH</given-names>
</name>
<name>
<surname>Mechelli</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Sato</surname>
<given-names>JR</given-names>
</name>
</person-group>
<article-title>Using deep autoencoders to identify abnormal brain structural patterns in neuropsychiatric disorders: a large-scale multi-sample study</article-title>
<source/>Hum. Brain Mapp.
          <year>2019</year>
<volume>40</volume>
<fpage>944</fpage>
<lpage>954</lpage>
<pub-id pub-id-type="pmid">30311316</pub-id>
</element-citation>
</ref>
<ref id="CR35">
<label>35.</label>
<mixed-citation publication-type="other">Ulloa, A., Plis, S., Erhardt, E. &amp; Calhoun, V. Synthetic structural magnetic resonance image generator improves deep learning prediction of schizophrenia. In <italic>Proc</italic>. <italic>25th IEEE Int. Workshop on Machine Learning for Signal Processing (MLSP)</italic> 1–6 (Boston, MA, USA, 2015).</mixed-citation>
</ref>
<ref id="CR36">
<label>36.</label>
<mixed-citation publication-type="other">Matsubara, T., Tashiro, T. &amp; Uehara, K. Deep neural generative model of functional MRI images for psychiatric disorder diagnosis. <italic>IEEE Trans. Biomed. Eng</italic>. 99 (2019).</mixed-citation>
</ref>
<ref id="CR37">
<label>37.</label>
<mixed-citation publication-type="other">Geng, X. &amp; Xu, J. Application of autoencoder in depression diagnosis. In <italic>2017</italic><italic>3rd</italic><italic>Int. Conference on Computer Science and Mechanical Automation</italic> (Wuhan, China, 2017).</mixed-citation>
</ref>
<ref id="CR38">
<label>38.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Aghdam</surname>
<given-names>MA</given-names>
</name>
<name>
<surname>Sharifi</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Pedram</surname>
<given-names>MM</given-names>
</name>
</person-group>
<article-title>Combination of rs-fMRI and sMRI data to discriminate autism spectrum disorders in young children using deep belief network</article-title>
<source/>J. Digit. Imaging
          <year>2018</year>
<volume>31</volume>
<fpage>895</fpage>
<lpage>903</lpage>
<pub-id pub-id-type="pmid">29736781</pub-id>
</element-citation>
</ref>
<ref id="CR39">
<label>39.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Shen</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Wu</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Suk</surname>
<given-names>H-I</given-names>
</name>
</person-group>
<article-title>Deep learning in medical image analysis</article-title>
<source/>Annu. Rev. Biomed. Eng.
          <year>2017</year>
<volume>19</volume>
<fpage>221</fpage>
<lpage>248</lpage>
<pub-id pub-id-type="pmid">28301734</pub-id>
</element-citation>
</ref>
<ref id="CR40">
<label>40.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Yan</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Zang</surname>
<given-names>Y</given-names>
</name>
</person-group>
<article-title>DPARSF: a MATLAB toolbox for “pipeline” data analysis of resting-state fMRI</article-title>
<source/>Front. Syst. Neurosci.
          <year>2010</year>
<volume>4</volume>
<fpage>13</fpage>
<pub-id pub-id-type="pmid">20577591</pub-id>
</element-citation>
</ref>
<ref id="CR41">
<label>41.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Esteban</surname>
<given-names>O</given-names>
</name>
<etal></etal>
</person-group>
<article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>
<source/>Nat. Methods
          <year>2019</year>
<volume>16</volume>
<fpage>111</fpage>
<lpage>116</lpage>
<pub-id pub-id-type="pmid">30532080</pub-id>
</element-citation>
</ref>
<ref id="CR42">
<label>42.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Herrmann</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Demiralp</surname>
<given-names>T</given-names>
</name>
</person-group>
<article-title>Human EEG gamma oscillations in neuropsychiatric disorders</article-title>
<source/>Clin. Neurophysiol.
          <year>2005</year>
<volume>116</volume>
<fpage>2719</fpage>
<lpage>2733</lpage>
<pub-id pub-id-type="pmid">16253555</pub-id>
</element-citation>
</ref>
<ref id="CR43">
<label>43.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Acharya</surname>
<given-names>UR</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Automated EEG-based screening of depression using deep convolutional neural network</article-title>
<source/>Comput. Meth. Prog. Biol.
          <year>2018</year>
<volume>161</volume>
<fpage>103</fpage>
<lpage>113</lpage>
</element-citation>
</ref>
<ref id="CR44">
<label>44.</label>
<mixed-citation publication-type="other">Mohan, Y., Chee, S. S., Xin, D. K. P. &amp; Foong, L. P. Artificial neural network for classification of depressive and normal. In <italic>EEG</italic><italic>Proc</italic>. <italic>2016 IEEE EMBS Conference on Biomedical Engineering and Sciences</italic> 286–290 (Kuala Lumpur, Malaysia, 2016).</mixed-citation>
</ref>
<ref id="CR45">
<label>45.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhang</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>X</given-names>
</name>
<name>
<surname>Zhang</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>Learning spatial–spectral–temporal EEG features with recurrent 3D convolutional neural networks for cross-task mental workload assessment</article-title>
<source/>IEEE Trans. Neural Syst. Rehabil. Eng.
          <year>2018</year>
<volume>27</volume>
<fpage>31</fpage>
<lpage>42</lpage>
<pub-id pub-id-type="pmid">30507536</pub-id>
</element-citation>
</ref>
<ref id="CR46">
<label>46.</label>
<mixed-citation publication-type="other">Li, X. et al. EEG-based mild depression recognition using convolutional neural network. <italic>Med. Biol. Eng. Comput</italic>. <bold>47</bold>, 1341–1352 (2019).</mixed-citation>
</ref>
<ref id="CR47">
<label>47.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Patel</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Park</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Bonato</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Chan</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Rodgers</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>A review of wearable sensors and systems with application in rehabilitation</article-title>
<source/>J. Neuroeng. Rehabil.
          <year>2012</year>
<volume>9</volume>
<fpage>21</fpage>
<pub-id pub-id-type="pmid">22520559</pub-id>
</element-citation>
</ref>
<ref id="CR48">
<label>48.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Smoller</surname>
<given-names>JW</given-names>
</name>
</person-group>
<article-title>The use of electronic health records for psychiatric phenotyping and genomics</article-title>
<source/>Am. J. Med. Genet. B Neuropsychiatr. Genet.
          <year>2018</year>
<volume>177</volume>
<fpage>601</fpage>
<lpage>612</lpage>
<pub-id pub-id-type="pmid">28557243</pub-id>
</element-citation>
</ref>
<ref id="CR49">
<label>49.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wu</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Roy</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Stewart</surname>
<given-names>WF</given-names>
</name>
</person-group>
<article-title>Prediction modeling using EHR data: challenges, strategies, and a comparison of machine learning approaches</article-title>
<source/>Med. Care.
          <year>2010</year>
<volume>48</volume>
<fpage>S106</fpage>
<lpage>S113</lpage>
<pub-id pub-id-type="pmid">20473190</pub-id>
</element-citation>
</ref>
<ref id="CR50">
<label>50.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Choi</surname>
<given-names>SB</given-names>
</name>
<name>
<surname>Lee</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Yoon</surname>
<given-names>JH</given-names>
</name>
<name>
<surname>Won</surname>
<given-names>JU</given-names>
</name>
<name>
<surname>Kim</surname>
<given-names>DW</given-names>
</name>
</person-group>
<article-title>Ten-year prediction of suicide death using Cox regression and machine learning in a nationwide retrospective cohort study in South Korea</article-title>
<source/>J. Affect. Disord.
          <year>2018</year>
<volume>231</volume>
<fpage>8</fpage>
<lpage>14</lpage>
<pub-id pub-id-type="pmid">29408160</pub-id>
</element-citation>
</ref>
<ref id="CR51">
<label>51.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Pham</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Tran</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Phung</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Venkatesh</surname>
<given-names>S</given-names>
</name>
</person-group>
<article-title>Predicting healthcare trajectories from medical records: a deep learning approach</article-title>
<source/>J. Biomed. Inform.
          <year>2017</year>
<volume>69</volume>
<fpage>218</fpage>
<lpage>229</lpage>
<pub-id pub-id-type="pmid">28410981</pub-id>
</element-citation>
</ref>
<ref id="CR52">
<label>52.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lin</surname>
<given-names>E</given-names>
</name>
<etal></etal>
</person-group>
<article-title>A deep learning approach for predicting antidepressant response in major depression using clinical and genetic biomarkers</article-title>
<source/>Front. Psychiatry
          <year>2018</year>
<volume>9</volume>
<fpage>290</fpage>
<pub-id pub-id-type="pmid">30034349</pub-id>
</element-citation>
</ref>
<ref id="CR53">
<label>53.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Geraci</surname>
<given-names>J</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Applying deep neural networks to unstructured text notes in electronic medical records for phenotyping youth depression</article-title>
<source/>Evid. Based Ment. Health
          <year>2017</year>
<volume>20</volume>
<fpage>83</fpage>
<lpage>87</lpage>
<pub-id pub-id-type="pmid">28739578</pub-id>
</element-citation>
</ref>
<ref id="CR54">
<label>54.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kim</surname>
<given-names>Y</given-names>
</name>
</person-group>
<article-title>Convolutional neural networks for sentence classification</article-title>
<source/>arXiv Prepr. arXiv
          <year>2014</year>
<volume>1408</volume>
<fpage>5882</fpage>
</element-citation>
</ref>
<ref id="CR55">
<label>55.</label>
<mixed-citation publication-type="other">Yang, Z. et al. Hierarchical attention networks for document classification. In <italic>Proc</italic>. 2016 <italic>Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</italic> 1480–1489 (San Diego, California, USA, 2016).</mixed-citation>
</ref>
<ref id="CR56">
<label>56.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rios</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Kavuluru</surname>
<given-names>R</given-names>
</name>
</person-group>
<article-title>Ordinal convolutional neural networks for predicting RDoC positive valence psychiatric symptom severity scores</article-title>
<source/>J. Biomed. Inform.
          <year>2017</year>
<volume>75</volume>
<fpage>S85</fpage>
<lpage>S93</lpage>
</element-citation>
</ref>
<ref id="CR57">
<label>57.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dai</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Jonnagaddala</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>Assessing the severity of positive valence symptoms in initial psychiatric evaluation records: Should we use convolutional neural networks?</article-title>
<source/>PLoS ONE
          <year>2018</year>
<volume>13</volume>
<fpage>e0204493</fpage>
<pub-id pub-id-type="pmid">30325934</pub-id>
</element-citation>
</ref>
<ref id="CR58">
<label>58.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Tran</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Kavuluru</surname>
<given-names>R</given-names>
</name>
</person-group>
<article-title>Predicting mental conditions based on “history of present illness” in psychiatric notes with deep neural networks</article-title>
<source/>J. Biomed. Inform.
          <year>2017</year>
<volume>75</volume>
<fpage>S138</fpage>
<lpage>S148</lpage>
</element-citation>
</ref>
<ref id="CR59">
<label>59.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Samek</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Binder</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Montavon</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Lapuschkin</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Müller</surname>
<given-names>K-R</given-names>
</name>
</person-group>
<article-title>Evaluating the visualization of what a deep neural network has learned</article-title>
<source/>IEEE Trans. Neural Netw. Learn. Syst.
          <year>2016</year>
<volume>28</volume>
<fpage>2660</fpage>
<lpage>2673</lpage>
</element-citation>
</ref>
<ref id="CR60">
<label>60.</label>
<mixed-citation publication-type="other">Hripcsak, G. et al. Characterizing treatment pathways at scale using the OHDSI network. <italic>Proc. Natl. Acad. Sci</italic>. <italic>USA</italic><bold>113</bold>, 7329–7336 (2016).</mixed-citation>
</ref>
<ref id="CR61">
<label>61.</label>
<mixed-citation publication-type="other">McGuffin, P., Owen, M. J. &amp; Gottesman, I. I. <italic>Psychiatric Genetics and Genomics</italic> (Oxford Univ. Press, New York, 2004).</mixed-citation>
</ref>
<ref id="CR62">
<label>62.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Levinson</surname>
<given-names>DF</given-names>
</name>
</person-group>
<article-title>The genetics of depression: a review</article-title>
<source/>Biol. Psychiatry
          <year>2006</year>
<volume>60</volume>
<fpage>84</fpage>
<lpage>92</lpage>
<pub-id pub-id-type="pmid">16300747</pub-id>
</element-citation>
</ref>
<ref id="CR63">
<label>63.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wray</surname>
<given-names>NR</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Genome-wide association analyses identify 44 risk variants and refine the genetic architecture of major depression</article-title>
<source/>Nat. Genet.
          <year>2018</year>
<volume>50</volume>
<fpage>668</fpage>
<pub-id pub-id-type="pmid">29700475</pub-id>
</element-citation>
</ref>
<ref id="CR64">
<label>64.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mullins</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Lewis</surname>
<given-names>CM</given-names>
</name>
</person-group>
<article-title>Genetics of depression: progress at last</article-title>
<source/>Curr. Psychiatry Rep.
          <year>2017</year>
<volume>19</volume>
<fpage>43</fpage>
<pub-id pub-id-type="pmid">28608123</pub-id>
</element-citation>
</ref>
<ref id="CR65">
<label>65.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zou</surname>
<given-names>J</given-names>
</name>
<etal></etal>
</person-group>
<article-title>A primer on deep learning in genomics</article-title>
<source/>Nat. Genet.
          <year>2019</year>
<volume>51</volume>
<fpage>12</fpage>
<lpage>18</lpage>
<pub-id pub-id-type="pmid">30478442</pub-id>
</element-citation>
</ref>
<ref id="CR66">
<label>66.</label>
<mixed-citation publication-type="other">Yue, T. &amp; Wang, H. Deep learning for genomics: a concise overview. Preprint at arXiv:1802.00810 (2018).</mixed-citation>
</ref>
<ref id="CR67">
<label>67.</label>
<mixed-citation publication-type="other">Khan, A. &amp; Wang, K. A deep learning based scoring system for prioritizing susceptibility variants for mental disorders. In <italic>Proc</italic>. <italic>2017 IEEE Int. Conference on Bioinformatics and Biomedicine (BIBM)</italic> 1698–1705 (Kansas City, USA, 2017).</mixed-citation>
</ref>
<ref id="CR68">
<label>68.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Khan</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>Q</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>K</given-names>
</name>
</person-group>
<article-title>iMEGES: integrated mental-disorder genome score by deep neural network for prioritizing the susceptibility genes for mental disorders in personal genomes</article-title>
<source/>BMC Bioinformatics
          <year>2018</year>
<volume>19</volume>
<fpage>501</fpage>
<pub-id pub-id-type="pmid">30591030</pub-id>
</element-citation>
</ref>
<ref id="CR69">
<label>69.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wang</surname>
<given-names>D</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Comprehensive functional genomic resource and integrative model for the human brain</article-title>
<source/>Science
          <year>2018</year>
<volume>362</volume>
<fpage>eaat8464</fpage>
<pub-id pub-id-type="pmid">30545857</pub-id>
</element-citation>
</ref>
<ref id="CR70">
<label>70.</label>
<mixed-citation publication-type="other">Salakhutdinov, R. &amp; Hinton, G. Deep Boltzmann machines. In <italic>Proc</italic>. <italic>12th Int. Conference on Artificial Intelligence and Statistics</italic> 448–455 (Clearwater, Florida, USA, 2009).</mixed-citation>
</ref>
<ref id="CR71">
<label>71.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Laksshman</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Bhat</surname>
<given-names>RR</given-names>
</name>
<name>
<surname>Viswanath</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Li</surname>
<given-names>X</given-names>
</name>
</person-group>
<article-title>DeepBipolar: Identifying genomic mutations for bipolar disorder via deep learning</article-title>
<source/>Hum. Mutat.
          <year>2017</year>
<volume>38</volume>
<fpage>1217</fpage>
<lpage>1224</lpage>
<pub-id pub-id-type="pmid">28600868</pub-id>
</element-citation>
</ref>
<ref id="CR72">
<label>72.</label>
<mixed-citation publication-type="other">Huang, K.-Y. et al. Data collection of elicited facial expressions and speech responses for mood disorder detection. In <italic>Proc</italic>. <italic>2015 Int. Conference on Orange Technologies (ICOT)</italic> 42–45 (Hong Kong, China, 2015).</mixed-citation>
</ref>
<ref id="CR73">
<label>73.</label>
<mixed-citation publication-type="other">Valstar, M. et al. AVEC 2013: the continuous audio/visual emotion and depression recognition challenge. In <italic>Proc</italic>. <italic>3rd ACM Int. Workshop on Audio/Visual Emotion Challenge</italic> 3–10 (Barcelona, Spain, 2013).</mixed-citation>
</ref>
<ref id="CR74">
<label>74.</label>
<mixed-citation publication-type="other">Valstar, M. et al. Avec 2014: 3d dimensional affect and depression recognition challenge. In <italic>Proc</italic>. <italic>4th Int. Workshop on Audio/Visual Emotion Challenge</italic> 3–10 (Orlando, Florida, USA, 2014).</mixed-citation>
</ref>
<ref id="CR75">
<label>75.</label>
<mixed-citation publication-type="other">Valstar, M. et al. Avec 2016: depression, mood, and emotion recognition workshop and challenge. In <italic>Proc</italic>. <italic>6th Int. Workshop on Audio/Visual Emotion Challenge</italic> 3–10 (Amsterdam, The Netherlands, 2016).</mixed-citation>
</ref>
<ref id="CR76">
<label>76.</label>
<mixed-citation publication-type="other">Ma, X., Yang, H., Chen, Q., Huang, D. &amp; Wang, Y. Depaudionet: an efficient deep model for audio based depression classification. In <italic>Proc</italic>. <italic>6th Int. Workshop on Audio/Visual Emotion Challenge</italic> 35–42 (Amsterdam, The Netherlands, 2016).</mixed-citation>
</ref>
<ref id="CR77">
<label>77.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>He</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Cao</surname>
<given-names>C</given-names>
</name>
</person-group>
<article-title>Automated depression analysis using convolutional neural networks from speech</article-title>
<source/>J. Biomed. Inform.
          <year>2018</year>
<volume>83</volume>
<fpage>103</fpage>
<lpage>111</lpage>
<pub-id pub-id-type="pmid">29852317</pub-id>
</element-citation>
</ref>
<ref id="CR78">
<label>78.</label>
<mixed-citation publication-type="other">Li, J., Fu, X., Shao, Z. &amp; Shang, Y. Improvement on speech depression recognition based on deep networks. In <italic>Proc</italic>. <italic>2018 Chinese Automation Congress (CAC)</italic> 2705–2709 (Xi’an, China, 2018).</mixed-citation>
</ref>
<ref id="CR79">
<label>79.</label>
<mixed-citation publication-type="other">Yang, L., Jiang, D., Han, W. &amp; Sahli, H. DCNN and DNN based multi-modal depression recognition. In <italic>Proc</italic>. <italic>2017 7th Int. Conference on Affective Computing and Intelligent Interaction</italic> 484–489 (San Antonio, Texas, USA, 2017).</mixed-citation>
</ref>
<ref id="CR80">
<label>80.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Huang</surname>
<given-names>KY</given-names>
</name>
<name>
<surname>Wu</surname>
<given-names>CH</given-names>
</name>
<name>
<surname>Su</surname>
<given-names>MH</given-names>
</name>
</person-group>
<article-title>Attention-based convolutional neural network and long short-term memory for short-term detection of mood disorders based on elicited speech responses</article-title>
<source/>Pattern Recogn.
          <year>2019</year>
<volume>88</volume>
<fpage>668</fpage>
<lpage>678</lpage>
</element-citation>
</ref>
<ref id="CR81">
<label>81.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Dawood</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Turner</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Perepa</surname>
<given-names>P</given-names>
</name>
</person-group>
<article-title>Affective computational model to extract natural affective states of students with Asperger syndrome (AS) in computer-based learning environment</article-title>
<source/>IEEE Access.
          <year>2018</year>
<volume>6</volume>
<fpage>67026</fpage>
<lpage>67034</lpage>
</element-citation>
</ref>
<ref id="CR82">
<label>82.</label>
<mixed-citation publication-type="other">Song, S., Shen, L. &amp; Valstar, M. Human behaviour-based automatic depression analysis using hand-crafted statistics and deep learned spectral features. In <italic>Proc</italic>. <italic>13th IEEE Int. Conference on Automatic Face &amp; Gesture Recognition</italic> 158–165 (Xi’an, China, 2018).</mixed-citation>
</ref>
<ref id="CR83">
<label>83.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhu</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Shang</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Shao</surname>
<given-names>Z</given-names>
</name>
<name>
<surname>Guo</surname>
<given-names>G</given-names>
</name>
</person-group>
<article-title>Automated depression diagnosis based on deep networks to encode facial appearance and dynamics</article-title>
<source/>IEEE Trans. Affect. Comput.
          <year>2018</year>
<volume>9</volume>
<fpage>578</fpage>
<lpage>584</lpage>
</element-citation>
</ref>
<ref id="CR84">
<label>84.</label>
<mixed-citation publication-type="other">Chao, L., Tao, J., Yang, M. &amp; Li, Y. Multi task sequence learning for depression scale prediction from video. In <italic>Proc</italic>. <italic>2015 Int. Conference on Affective Computing and Intelligent Interaction (ACII)</italic> 526–531 (Xi’an, China, 2015).</mixed-citation>
</ref>
<ref id="CR85">
<label>85.</label>
<mixed-citation publication-type="other">Yang, T. H., Wu, C. H., Huang, K. Y. &amp; Su, M. H. Detection of mood disorder using speech emotion profiles and LSTM. In <italic>Proc</italic>. <italic>10th Int. Symposium on Chinese Spoken Language Processing (ISCSLP)</italic> 1–5 (Tianjin, China, 2016).</mixed-citation>
</ref>
<ref id="CR86">
<label>86.</label>
<mixed-citation publication-type="other">Huang, K. Y., Wu, C. H., Su, M. H. &amp; Chou, C. H. Mood disorder identification using deep bottleneck features of elicited speech. In <italic>Proc</italic>. <italic>2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)</italic> 1648–1652 (Kuala Lumpur, Malaysia, 2017).</mixed-citation>
</ref>
<ref id="CR87">
<label>87.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jan</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Meng</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Gaus</surname>
<given-names>YFBA</given-names>
</name>
<name>
<surname>Zhang</surname>
<given-names>F</given-names>
</name>
</person-group>
<article-title>Artificial intelligent system for automatic depression level analysis through visual and vocal expressions</article-title>
<source/>IEEE Trans. Cogn. Dev. Syst.
          <year>2017</year>
<volume>10</volume>
<fpage>668</fpage>
<lpage>680</lpage>
</element-citation>
</ref>
<ref id="CR88">
<label>88.</label>
<mixed-citation publication-type="other">Su, M. H., Wu, C. H., Huang, K. Y. &amp; Yang, T. H. Cell-coupled long short-term memory with l-skip fusion mechanism for mood disorder detection through elicited audiovisual features. <italic>IEEE Trans. Neural Netw. Learn. Syst</italic>. <bold>31</bold> (2019).</mixed-citation>
</ref>
<ref id="CR89">
<label>89.</label>
<mixed-citation publication-type="other">Harati, S., Crowell, A., Mayberg, H. &amp; Nemati, S. Depression severity classification from speech emotion. In <italic>Proc</italic>. <italic>40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</italic> 5763–5766 (Honolulu, HI, USA, 2018).</mixed-citation>
</ref>
<ref id="CR90">
<label>90.</label>
<mixed-citation publication-type="other">Su, M. H., Wu, C. H., Huang, K. Y., Hong, Q. B. &amp; Wang, H. M. Exploring microscopic fluctuation of facial expression for mood disorder classification. In <italic>Proc</italic>. <italic>2017 Int. Conference on Orange Technologies (ICOT)</italic> 65–69 (Singapore, 2017).</mixed-citation>
</ref>
<ref id="CR91">
<label>91.</label>
<mixed-citation publication-type="other">Prasetio, B. H., Tamura, H. &amp; Tanno, K. The facial stress recognition based on multi-histogram features and convolutional neural network. In <italic>Proc</italic>. <italic>2018 IEEE Int. Conference on Systems, Man, and Cybernetics (SMC)</italic> 881–887 (Miyazaki, Japan, 2018).</mixed-citation>
</ref>
<ref id="CR92">
<label>92.</label>
<mixed-citation publication-type="other">Jaiswal, S., Valstar, M. F., Gillott, A. &amp; Daley, D. Automatic detection of ADHD and ASD from expressive behaviour in RGBD data. In <italic>Proc</italic>. <italic>12th IEEE Int. Conference on Automatic Face &amp; Gesture Recognition</italic> 762–769 (Washington, DC, USA, 2017).</mixed-citation>
</ref>
<ref id="CR93">
<label>93.</label>
<mixed-citation publication-type="other">Cho, Y., Bianchi-Berthouze, N. &amp; Julier, S. J. DeepBreath: deep learning of breathing patterns for automatic stress recognition using low-cost thermal imaging in unconstrained settings. In <italic>Proc</italic>. <italic>2017 7th Int. Conference on Affective Computing and Intelligent Interaction (ACII)</italic> 456–463 (San Antonio, Texas, USA, 2017).</mixed-citation>
</ref>
<ref id="CR94">
<label>94.</label>
<mixed-citation publication-type="other">Gupta, R., Sahu, S., Espy-Wilson, C. Y. &amp; Narayanan, S. S. An affect prediction approach through depression severity parameter incorporation in neural networks. In <italic>Proc</italic>. <italic>2017 Int. Conference on INTERSPEECH</italic> 3122–3126 (Stockholm, Sweden, 2017).</mixed-citation>
</ref>
<ref id="CR95">
<label>95.</label>
<mixed-citation publication-type="other">Martin, O., Kotsia, I., Macq, B. &amp; Pitas, I. The eNTERFACE'05 audio-visual emotion database. In <italic>Proc</italic>. <italic>22nd Int. Conference on Data Engineering Workshops</italic> 8–8 (Atlanta, GA, USA, 2006).</mixed-citation>
</ref>
<ref id="CR96">
<label>96.</label>
<mixed-citation publication-type="other">Goodfellow, I. J. et al. Challenges in representation learning: A report on three machine learning contests. In <italic>Proc</italic>. <italic>Int. Conference on Neural Information Processing</italic> 117–124 (Daegu, Korea, 2013).</mixed-citation>
</ref>
<ref id="CR97">
<label>97.</label>
<mixed-citation publication-type="other">Yi, D., Lei, Z., Liao, S. &amp; Li, S. Z.. Learning face representation from scratch. Preprint at arXiv 1411.7923 (2014).</mixed-citation>
</ref>
<ref id="CR98">
<label>98.</label>
<mixed-citation publication-type="other">Lin, H. et al. User-level psychological stress detection from social media using deep neural network. In <italic>Proc</italic>. <italic>22nd ACM Int. Conference on Multimedia</italic> 507–516 (Orlando, Florida, USA, 2014).</mixed-citation>
</ref>
<ref id="CR99">
<label>99.</label>
<mixed-citation publication-type="other">Lin, H. et al. Psychological stress detection from cross-media microblog data using deep sparse neural network. In <italic>Proc</italic>. <italic>2014 IEEE Int. Conference on Multimedia and Expo</italic> 1–6 (Chengdu, China, 2014).</mixed-citation>
</ref>
<ref id="CR100">
<label>100.</label>
<mixed-citation publication-type="other">Li, Q. et al. Correlating stressor events for social network based adolescent stress prediction. In <italic>Proc</italic>. <italic>Int. Conference on Database Systems for Advanced Applications</italic> 642–658 (Suzhou, China, 2017).</mixed-citation>
</ref>
<ref id="CR101">
<label>101.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lin</surname>
<given-names>H</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Detecting stress based on social interactions in social networks</article-title>
<source/>IEEE Trans. Knowl. Data En.
          <year>2017</year>
<volume>29</volume>
<fpage>1820</fpage>
<lpage>1833</lpage>
</element-citation>
</ref>
<ref id="CR102">
<label>102.</label>
<mixed-citation publication-type="other">Cong, Q. et al. X-A-BiLSTM: a deep learning approach for depression detection in imbalanced data. In <italic>Proc</italic>. <italic>2018 IEEE Int. Conference on Bioinformatics and Biomedicine (BIBM)</italic> 1624–1627 (Madrid, Spain, 2018).</mixed-citation>
</ref>
<ref id="CR103">
<label>103.</label>
<mixed-citation publication-type="other">Ive, J., Gkotsis, G., Dutta, R., Stewart, R. &amp; Velupillai, S. Hierarchical neural model with attention mechanisms for the classification of social media text related to mental health. In <italic>Proc</italic>. <italic>Fifth Workshop on Computational Linguistics and Clinical Psychology: From Keyboard to Clinic</italic> 69–77 (New Orleans, Los Angeles, USA, 2018).</mixed-citation>
</ref>
<ref id="CR104">
<label>104.</label>
<mixed-citation publication-type="other">Sadeque, F., Xu, D. &amp; Bethard, S. UArizona at the CLEF eRisk 2017 pilot task: linear and recurrent models for early depression detection. <italic>CEUR Workshop Proc</italic>. <bold>1866</bold> (2017).</mixed-citation>
</ref>
<ref id="CR105">
<label>105.</label>
<mixed-citation publication-type="other">Fraga, B. S., da Silva, A. P. C. &amp; Murai, F. Online social networks in health care: a study of mental disorders on Reddit. In <italic>Proc</italic>. <italic>2018 IEEE/WIC/ACM Int. Conference on Web Intelligence (WI)</italic> 568–573 (Santiago, Chile, 2018).</mixed-citation>
</ref>
<ref id="CR106">
<label>106.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gkotsis</surname>
<given-names>G</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Characterisation of mental health conditions in social media using Informed Deep Learning</article-title>
<source/>Sci. Rep.
          <year>2017</year>
<volume>7</volume>
<fpage>45141</fpage>
<pub-id pub-id-type="pmid">28327593</pub-id>
</element-citation>
</ref>
<ref id="CR107">
<label>107.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Coppersmith</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Leary</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Crutchley</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Fine</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Natural language processing of social media as screening for suicide risk</article-title>
<source/>Biomed. Inform. Insights
          <year>2018</year>
<volume>10</volume>
<fpage>1178222618792860</fpage>
<pub-id pub-id-type="pmid">30158822</pub-id>
</element-citation>
</ref>
<ref id="CR108">
<label>108.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Du</surname>
<given-names>J</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Extracting psychiatric stressors for suicide from social media using deep learning</article-title>
<source/>BMC Med. Inform. Decis. Mak.
          <year>2018</year>
<volume>18</volume>
<fpage>43</fpage>
<pub-id pub-id-type="pmid">30066665</pub-id>
</element-citation>
</ref>
<ref id="CR109">
<label>109.</label>
<mixed-citation publication-type="other">Alambo, A. et al. Question answering for suicide risk assessment using Reddit. In <italic>Proc</italic>. <italic>IEEE 13th Int. Conference on Semantic Computing</italic> 468–473 (Newport Beach, California, USA, 2019).</mixed-citation>
</ref>
<ref id="CR110">
<label>110.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Eichstaedt</surname>
<given-names>JC</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Facebook language predicts depression in medical records</article-title>
<source/>Proc. Natl Acad. Sci. USA
          <year>2018</year>
<volume>115</volume>
<fpage>11203</fpage>
<lpage>11208</lpage>
<pub-id pub-id-type="pmid">30322910</pub-id>
</element-citation>
</ref>
<ref id="CR111">
<label>111.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rosenquist</surname>
<given-names>JN</given-names>
</name>
<name>
<surname>Fowler</surname>
<given-names>JH</given-names>
</name>
<name>
<surname>Christakis</surname>
<given-names>NA</given-names>
</name>
</person-group>
<article-title>Social network determinants of depression</article-title>
<source/>Mol. Psychiatry
          <year>2011</year>
<volume>16</volume>
<fpage>273</fpage>
<pub-id pub-id-type="pmid">20231839</pub-id>
</element-citation>
</ref>
<ref id="CR112">
<label>112.</label>
<mixed-citation publication-type="other">Kipf, T. N. &amp; Welling, M. Semi-supervised classification with graph convolutional networks. In <italic>Proc. 2017 Int. Conference on Learning Representations</italic> (Toulon, France, 2017).</mixed-citation>
</ref>
<ref id="CR113">
<label>113.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rice</surname>
<given-names>SM</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Online and social networking interventions for the treatment of depression in young people: a systematic review</article-title>
<source/>J. Med. Internet Res.
          <year>2014</year>
<volume>16</volume>
<fpage>e206</fpage>
<pub-id pub-id-type="pmid">25226790</pub-id>
</element-citation>
</ref>
<ref id="CR114">
<label>114.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hastie</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Tibshirani</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Friedman</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>The elements of statistical learning: data mining, inference, and prediction. Springer Series in Statistics</article-title>
<source/>Math. Intell.
          <year>2009</year>
<volume>27</volume>
<fpage>83</fpage>
<lpage>85</lpage>
</element-citation>
</ref>
<ref id="CR115">
<label>115.</label>
<mixed-citation publication-type="other">Torrey, L. &amp; Shavlik, J. in <italic>Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques</italic> 242–264 (IGI Global, 2010).</mixed-citation>
</ref>
<ref id="CR116">
<label>116.</label>
<mixed-citation publication-type="other">Yosinski, J., Clune, J., Bengio, Y. &amp; Lipson, H. How transferable are features in deep neural networks? In <italic>Proc</italic>. <italic>Advances in Neural Information Processing Systems</italic> 3320–3328 (Montreal, Canada, 2014).</mixed-citation>
</ref>
<ref id="CR117">
<label>117.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Esteva</surname>
<given-names>A</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Dermatologist-level classification of skin cancer with deep neural networks</article-title>
<source/>Nature
          <year>2017</year>
<volume>542</volume>
<fpage>115</fpage>
<pub-id pub-id-type="pmid">28117445</pub-id>
</element-citation>
</ref>
<ref id="CR118">
<label>118.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Insel</surname>
<given-names>T</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Research domain criteria (RDoC): toward a new classification framework for research on mental disorders</article-title>
<source/>Am. Psychiatr. Assoc.
          <year>2010</year>
<volume>167</volume>
<fpage>748</fpage>
<lpage>751</lpage>
</element-citation>
</ref>
<ref id="CR119">
<label>119.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Nelson</surname>
<given-names>B</given-names>
</name>
<name>
<surname>McGorry</surname>
<given-names>PD</given-names>
</name>
<name>
<surname>Wichers</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Wigman</surname>
<given-names>JT</given-names>
</name>
<name>
<surname>Hartmann</surname>
<given-names>JA</given-names>
</name>
</person-group>
<article-title>Moving from static to dynamic models of the onset of mental disorder: a review</article-title>
<source/>JAMA Psychiatry
          <year>2017</year>
<volume>74</volume>
<fpage>528</fpage>
<lpage>534</lpage>
<pub-id pub-id-type="pmid">28355471</pub-id>
</element-citation>
</ref>
<ref id="CR120">
<label>120.</label>
<mixed-citation publication-type="other">Guo, X., Liu, X., Zhu, E. &amp; Yin, J. Deep clustering with convolutional autoencoders. In <italic>Proc</italic>. <italic>Int. Conference on Neural Information Processing</italic> 373–382 (Guangzhou, China, 2017).</mixed-citation>
</ref>
<ref id="CR121">
<label>121.</label>
<mixed-citation publication-type="other">Srivastava, N., Mansimov, E. &amp; Salakhudinov, R. Unsupervised learning of video representations using LSTMs. In <italic>Proc</italic>. <italic>Int. Conference on Machine Learning</italic> 843–852 (Lille, France, 2015).</mixed-citation>
</ref>
<ref id="CR122">
<label>122.</label>
<mixed-citation publication-type="other">Baytas, I. M. et al. Patient subtyping via time-aware LSTM networks. In <italic>Proc</italic>. <italic>23rd ACM SIGKDD Int. Conference on Knowledge Discovery and Data Mining</italic> 65–74 (Halifax, Canada, 2017).</mixed-citation>
</ref>
<ref id="CR123">
<label>123.</label>
<mixed-citation publication-type="other">American Psychiatric Association. <italic>Diagnostic and Statistical Manual of Mental Disorders (DSM-5®)</italic> (American Psychiatric Pub, Washington, DC, 2013).</mixed-citation>
</ref>
<ref id="CR124">
<label>124.</label>
<mixed-citation publication-type="other">Biological Sciences Curriculum Study. In: <italic>NIH Curriculum Supplement Series</italic> (Internet) (National Institutes of Health, USA, 2007).</mixed-citation>
</ref>
<ref id="CR125">
<label>125.</label>
<mixed-citation publication-type="other">Noh, H., Hong, S. &amp; Han, B. Learning deconvolution network for semantic segmentation. In <italic>Proc</italic>. <italic>IEEE Int. Conference on Computer Vision</italic> 1520–1528 (Santiago, Chile, 2015).</mixed-citation>
</ref>
<ref id="CR126">
<label>126.</label>
<mixed-citation publication-type="other">Grün, F., Rupprecht, C., Navab, N. &amp; Tombari, F. A taxonomy and library for visualizing learned features in convolutional neural networks. In <italic>Proc. 33rd Int. Conference on Machine Learning (ICML) Workshop on Visualization for Deep Learning</italic> (New York, USA, 2016).</mixed-citation>
</ref>
<ref id="CR127">
<label>127.</label>
<mixed-citation publication-type="other">Ribeiro, M. T., Singh, S. &amp; Guestrin, C. Why should I trust you?: Explaining the predictions of any classifier. In <italic>Proc</italic>. <italic>22nd ACM SIGKDD Int. Conference on Knowledge Discovery and Data Mining</italic> 1135–1144 (San Francisco, CA, 2016).</mixed-citation>
</ref>
<ref id="CR128">
<label>128.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhang</surname>
<given-names>QS</given-names>
</name>
<name>
<surname>Zhu</surname>
<given-names>SC</given-names>
</name>
</person-group>
<article-title>Visual interpretability for deep learning: a survey</article-title>
<source/>Front. Inf. Technol. Electron. Eng.
          <year>2018</year>
<volume>19</volume>
<fpage>27</fpage>
<lpage>39</lpage>
</element-citation>
</ref>
<ref id="CR129">
<label>129.</label>
<mixed-citation publication-type="other">Lundberg, S. M. &amp; Lee, S. I. A unified approach to interpreting model predictions. In <italic>Proc</italic>. <italic>31st Conference on Neural Information Processing Systems</italic> 4765–4774 (Long Beach, CA, 2017).</mixed-citation>
</ref>
<ref id="CR130">
<label>130.</label>
<mixed-citation publication-type="other">Shrikumar, A., Greenside, P., Shcherbina, A. &amp; Kundaje, A. Not just a black box: learning important features through propagating activation differences. In <italic>Proc</italic>. <italic>33rd Int. Conference on Machine Learning</italic> (New York, NY, 2016).</mixed-citation>
</ref>
<ref id="CR131">
<label>131.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gawehn</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Hiss</surname>
<given-names>JA</given-names>
</name>
<name>
<surname>Schneider</surname>
<given-names>G</given-names>
</name>
</person-group>
<article-title>Deep learning in drug discovery</article-title>
<source/>Mol. Inform.
          <year>2016</year>
<volume>35</volume>
<fpage>3</fpage>
<lpage>14</lpage>
<pub-id pub-id-type="pmid">27491648</pub-id>
</element-citation>
</ref>
<ref id="CR132">
<label>132.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jerez-Aragonés</surname>
<given-names>JM</given-names>
</name>
<name>
<surname>Gómez-Ruiz</surname>
<given-names>JA</given-names>
</name>
<name>
<surname>Ramos-Jiménez</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Muñoz-Pérez</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Alba-Conejo</surname>
<given-names>E</given-names>
</name>
</person-group>
<article-title>A combined neural network and decision trees model for prognosis of breast cancer relapse</article-title>
<source/>Artif. Intell. Med.
          <year>2003</year>
<volume>27</volume>
<fpage>45</fpage>
<lpage>63</lpage>
<pub-id pub-id-type="pmid">12473391</pub-id>
</element-citation>
</ref>
<ref id="CR133">
<label>133.</label>
<mixed-citation publication-type="other">Zhu, Y., Elemento, O., Pathak, J. &amp; Wang, F. Drug knowledge bases and their applications in biomedical informatics research. <italic>Brief. Bioinformatics</italic><bold>20</bold>, 1308–1321 (2018).</mixed-citation>
</ref>
<ref id="CR134">
<label>134.</label>
<mixed-citation publication-type="other">Su, C., Tong, J., Zhu, Y., Cui, P. &amp; Wang, F. Network embedding in biomedical data science. <italic>Brief. Bioinform</italic>. 10.1093/bib/bby117 (2018).</mixed-citation>
</ref>
<ref id="CR135">
<label>135.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bodenreider</surname>
<given-names>O</given-names>
</name>
</person-group>
<article-title>The unified medical language system (UMLS): integrating biomedical terminology</article-title>
<source/>Nucleic Acids Res.
          <year>2004</year>
<volume>32</volume>
<issue>suppl_1</issue>
<fpage>D267</fpage>
<lpage>D270</lpage>
<pub-id pub-id-type="pmid">14681409</pub-id>
</element-citation>
</ref>
<ref id="CR136">
<label>136.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Szklarczyk</surname>
<given-names>D</given-names>
</name>
<etal></etal>
</person-group>
<article-title>STRING v10: protein–protein interaction networks, integrated over the tree of life</article-title>
<source/>Nucleic Acids Res.
          <year>2014</year>
<volume>43</volume>
<fpage>D447</fpage>
<lpage>D452</lpage>
<pub-id pub-id-type="pmid">25352553</pub-id>
</element-citation>
</ref>
</ref-list>
</back>
</article>
</pmc-articleset>