<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="research-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">Eur Respir J</journal-id>
<journal-id journal-id-type="iso-abbrev">Eur. Respir. J</journal-id>
<journal-id journal-id-type="publisher-id">ERJ</journal-id>
<journal-id journal-id-type="hwp">erj</journal-id>
<journal-title-group>
<journal-title>The European Respiratory Journal</journal-title>
</journal-title-group>
<issn pub-type="ppub">0903-1936</issn>
<issn pub-type="epub">1399-3003</issn>
<publisher>
<publisher-name>European Respiratory Society</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">30635290</article-id>
<article-id pub-id-type="pmc">6437603</article-id>
<article-id pub-id-type="doi">10.1183/13993003.00986-2018</article-id>
<article-id pub-id-type="publisher-id">ERJ-00986-2018</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Original Articles</subject>
<subj-group>
<subject>Lung Cancer and Imaging</subject>
</subj-group>
</subj-group>
<subj-group subj-group-type="hwp-journal-coll">
<subject>6</subject>
<subject>17</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Predicting EGFR mutation status in lung adenocarcinoma on computed tomography image using deep learning</article-title>
<alt-title alt-title-type="short">Predicting EGFR mutation status in lung adenocarcinoma</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Wang</surname>
<given-names>Shuo</given-names>
</name>
<xref ref-type="aff" rid="af1">1</xref>
<xref ref-type="aff" rid="af2">2</xref>
<xref ref-type="aff" rid="af8">8</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Shi</surname>
<given-names>Jingyun</given-names>
</name>
<xref ref-type="aff" rid="af3">3</xref>
<xref ref-type="aff" rid="af8">8</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ye</surname>
<given-names>Zhaoxiang</given-names>
</name>
<xref ref-type="aff" rid="af4">4</xref>
<xref ref-type="aff" rid="af8">8</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dong</surname>
<given-names>Di</given-names>
</name>
<xref ref-type="aff" rid="af1">1</xref>
<xref ref-type="aff" rid="af2">2</xref>
<xref ref-type="aff" rid="af8">8</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Yu</surname>
<given-names>Dongdong</given-names>
</name>
<xref ref-type="aff" rid="af1">1</xref>
<xref ref-type="aff" rid="af2">2</xref>
<xref ref-type="aff" rid="af8">8</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zhou</surname>
<given-names>Mu</given-names>
</name>
<xref ref-type="aff" rid="af5">5</xref>
<xref ref-type="aff" rid="af8">8</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Liu</surname>
<given-names>Ying</given-names>
</name>
<xref ref-type="aff" rid="af4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gevaert</surname>
<given-names>Olivier</given-names>
</name>
<xref ref-type="aff" rid="af5">5</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wang</surname>
<given-names>Kun</given-names>
</name>
<xref ref-type="aff" rid="af1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zhu</surname>
<given-names>Yongbei</given-names>
</name>
<xref ref-type="aff" rid="af1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zhou</surname>
<given-names>Hongyu</given-names>
</name>
<xref ref-type="aff" rid="af6">6</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Liu</surname>
<given-names>Zhenyu</given-names>
</name>
<xref ref-type="aff" rid="af1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Tian</surname>
<given-names>Jie</given-names>
</name>
<xref ref-type="aff" rid="af1">1</xref>
<xref ref-type="aff" rid="af2">2</xref>
<xref ref-type="aff" rid="af7">7</xref>
</contrib>
</contrib-group>
<aff id="af1"><label>1</label>CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing, China</aff>
<aff id="af2"><label>2</label>University of Chinese Academy of Sciences, Beijing, China</aff>
<aff id="af3"><label>3</label>Dept of Respiratory Medicine, Shanghai Pulmonary Hospital, Tongji University School of Medicine, Shanghai, China</aff>
<aff id="af4"><label>4</label>Dept of Radiology, Tianjin Medical University Cancer Institute and Hospital, National Clinical Research Center for Cancer, Tianjin's Clinical Research Center for Cancer, Key Laboratory of Cancer Prevention and Therapy, Tianjin, China</aff>
<aff id="af5"><label>5</label>The Stanford Center for Biomedical Informatics Research, Dept of Medicine, Stanford University, Stanford, CA, USA</aff>
<aff id="af6"><label>6</label>Paul C. Lauterbur Research Center for Biomedical Imaging, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China</aff>
<aff id="af7"><label>7</label>Beijing Advanced Innovation Center for Big Data-Based Precision Medicine, School of Medicine, Beihang University, Beijing, China</aff>
<aff id="af8"><label>8</label>These authors contributed equally to this work</aff>
<author-notes>
<corresp id="cor1">Jie Tian, CAS Key Laboratory of Molecular Imaging, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China. E-mail: <email>jie.tian@ia.ac.cn</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>3</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="epub">
<day>28</day>
<month>3</month>
<year>2019</year>
</pub-date>
<volume>53</volume>
<issue>3</issue>
<elocation-id>1800986</elocation-id>
<history>
<date date-type="received">
<day>30</day>
<month>5</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>31</day>
<month>12</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-statement>Copyright ©ERS 2019</copyright-statement>
<copyright-year>2019</copyright-year>
<license license-type="open-access">
<ali:license_ref specific-use="vor" xmlns:ali="http://www.niso.org/schemas/ali/1.0/">http://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
<license-p>This version is distributed under the terms of the Creative Commons Attribution Non-Commercial Licence 4.0.</license-p>
</license>
</permissions>
<abstract>
<p>Epidermal growth factor receptor (EGFR) genotyping is critical for treatment guidelines such as the use of tyrosine kinase inhibitors in lung adenocarcinoma. Conventional identification of EGFR genotype requires biopsy and sequence testing which is invasive and may suffer from the difficulty of accessing tissue samples. Here, we propose a deep learning model to predict EGFR mutation status in lung adenocarcinoma using non-invasive computed tomography (CT).</p>
<p>We retrospectively collected data from 844 lung adenocarcinoma patients with pre-operative CT images, EGFR mutation and clinical information from two hospitals. An end-to-end deep learning model was proposed to predict the EGFR mutation status by CT scanning.</p>
<p>By training in 14 926 CT images, the deep learning model achieved encouraging predictive performance in both the primary cohort (n=603; AUC 0.85, 95% CI 0.83–0.88) and the independent validation cohort (n=241; AUC 0.81, 95% CI 0.79–0.83), which showed significant improvement over previous studies using hand-crafted CT features or clinical characteristics (p&lt;0.001). The deep learning score demonstrated significant differences in EGFR-mutant and EGFR-wild type tumours (p&lt;0.001).</p>
<p>Since CT is routinely used in lung cancer diagnosis, the deep learning model provides a non-invasive and easy-to-use method for EGFR mutation status prediction.</p>
</abstract>
<abstract abstract-type="short">
<p><bold>Deep learning provides a noninvasive method for EGFR mutation prediction (AUC 0.81) in lung adenocarcinoma, which shows significant improvement over using hand-crafted CT features or clinical characteristics</bold>
<ext-link ext-link-type="uri" xlink:href="http://ow.ly/LtDJ30nhc5Q">http://ow.ly/LtDJ30nhc5Q</ext-link></p>
</abstract>
<funding-group>
<award-group id="funding-1">
<funding-source>Instrument Developing Project of the Chinese Academy of Sciences<named-content content-type="funder-id">http://doi.org/</named-content></funding-source>
<award-id>YZ201502</award-id>
</award-group>
<award-group id="funding-2">
<funding-source>National Key R&amp;D Program of China<named-content content-type="funder-id">http://doi.org/</named-content></funding-source>
<award-id>2016YFC010380</award-id>
<award-id>2017YFA0205200</award-id>
<award-id>2017YFC1308700</award-id>
<award-id>2017YFC1308701</award-id>
<award-id>2017YFC1309100</award-id>
</award-group>
<award-group id="funding-3">
<funding-source>Youth Innovation Promotion Association of the Chinese Academy of Sciences<named-content content-type="funder-id">http://doi.org/10.13039/501100004739</named-content></funding-source>
</award-group>
<award-group id="funding-4">
<funding-source>National Natural Science Foundation of China<named-content content-type="funder-id">http://doi.org/10.13039/501100001809</named-content></funding-source>
<award-id>61231004</award-id>
<award-id>81227901</award-id>
<award-id>81501616</award-id>
<award-id>81527805</award-id>
<award-id>81671851</award-id>
<award-id>81771924</award-id>
</award-group>
<award-group id="funding-5">
<funding-source>Beijing Municipal Science and Technology Commission<named-content content-type="funder-id">http://doi.org/</named-content></funding-source>
<award-id>Z161100002616022</award-id>
<award-id>Z171100000117023</award-id>
</award-group>
<award-group id="funding-6">
<funding-source>National Institute of Biomedical Imaging and Bioengineering<named-content content-type="funder-id">http://doi.org/10.13039/100000070</named-content></funding-source>
<award-id>R01EB020527</award-id>
</award-group>
</funding-group>
</article-meta>
</front>
<body>
<sec id="s1" sec-type="intro">
<title>Introduction</title>
<p>Lung adenocarcinoma is a common histological type of lung cancer and the discovery of epidermal growth factor receptor (EGFR) mutations has revolutionised its treatment [<xref ref-type="bibr" rid="C1">1</xref>, <xref ref-type="bibr" rid="C2">2</xref>]. In first-line treatment, detecting an EGFR mutation is critical since EGFR tyrosine kinase inhibitors can target specific mutations within the EGFR gene, and have resulted in improved outcomes in EGFR-mutant lung adenocarcinoma patients [<xref ref-type="bibr" rid="C3">3</xref>, <xref ref-type="bibr" rid="C4">4</xref>]. Mutational sequencing of biopsies has become the gold standard of EGFR mutation detection. However, biopsy testing for measuring EGFR status probably suffers from having to locate tissue regions because of the extensive heterogeneity of lung tumours [<xref ref-type="bibr" rid="C5">5</xref>, <xref ref-type="bibr" rid="C6">6</xref>]. In addition, biopsy testing raises a potential risk of cancer metastasis [<xref ref-type="bibr" rid="C7">7</xref>]. Furthermore, repeated tumour sampling, difficulty of accessing tissue samples, poor DNA quality [<xref ref-type="bibr" rid="C8">8</xref>] and the relative high costs can limit the applicability of mutational sequencing [<xref ref-type="bibr" rid="C9">9</xref>]. In these situations, a non-invasive and easy-to-use method for predicting EGFR mutation status is necessary.</p>
<p>Computed tomography (CT) as a routinely used technique in cancer diagnosis provides a non-invasive way to analyse lung cancer [<xref ref-type="bibr" rid="C10">10</xref>–<xref ref-type="bibr" rid="C12">12</xref>]. Recent studies revealed that features extracted from lung cancer CT images were related to gene expression patterns [<xref ref-type="bibr" rid="C13">13</xref>–<xref ref-type="bibr" rid="C16">16</xref>] and showed predictive power on EGFR profiles [<xref ref-type="bibr" rid="C17">17</xref>–<xref ref-type="bibr" rid="C19">19</xref>]. Although image assessment cannot replace biopsies, image-driven studies can provide additional information that is complementary to biopsies [<xref ref-type="bibr" rid="C5">5</xref>, <xref ref-type="bibr" rid="C9">9</xref>]. For example, CT imaging provides a complete scope of a tumour and its microenvironment, enabling us to predict EGFR mutation status by considering intra-tumour heterogeneity. In addition, predicting EGFR-mutation status by CT imaging helps us to choose the most suspicious tumour for biopsy if multiple tumours present in a patient. Furthermore, CT imaging is non-invasive and easy to acquire throughout the course of treatment.</p>
<p>Early findings demonstrated that CT semantic features and quantitative “radiomic” features showed predictive value to EGFR mutation status [<xref ref-type="bibr" rid="C9">9</xref>]. However, these methods can only reflect generalised image features which lack specificity to EGFR mutation. In addition, the radiomics methods based on feature engineering rely on precise tumour boundary annotation, which requires human labelling efforts. Since radiomic features are computed only inside the tumour area, the microenvironment and tumour-attached tissues are ignored. In contrast, advanced artificial intelligence models can overcome these problems through a self-learning strategy such as deep learning methods [<xref ref-type="bibr" rid="C20">20</xref>–<xref ref-type="bibr" rid="C22">22</xref>]. Benefiting from a strong feature-learning ability, deep learning models have shown human expert-level performance in classification of skin cancer [<xref ref-type="bibr" rid="C23">23</xref>], diagnosis of eye diseases [<xref ref-type="bibr" rid="C24">24</xref>] and prediction of non-invasive liver fibrosis [<xref ref-type="bibr" rid="C25">25</xref>]. Moreover, deep learning models present a promising performance in assisting lung cancer analysis [<xref ref-type="bibr" rid="C26">26</xref>–<xref ref-type="bibr" rid="C29">29</xref>]. Compared with feature engineering-based radiomic methods, deep learning-based radiomics do not require precise tumour boundary annotation and learn features automatically from image data [<xref ref-type="bibr" rid="C30">30</xref>]. Furthermore, deep learning-based radiomics can extract features that are adaptive to specific clinical outcomes, while feature engineering-based radiomics can only describe general features that may lack specificity for outcome prediction.</p>
<p>In this study, we proposed a deep learning model to mine CT image information that is related to EGFR mutation status. Our method is an end-to-end pipeline that requires only the manually selected tumour region in a CT image without precise tumour boundary segmentation or human-defined features, which is different to conventional radiomic methods based on feature engineering. The proposed model can learn EGFR mutation-related features from CT images automatically and predicts the probability of the tumour being EGFR-mutant. Furthermore, the deep learning model can discover suspicious tumour subregions that are strongly related to EGFR mutation status, aiming to rapidly facilitate clinicians' treatment decision-making for patients. To evaluate the performance of the deep learning model, we collected a large dataset from two independent hospitals (844 patients) and provided independent validation results of the proposed deep learning model.</p>
</sec>
<sec id="s2">
<title>Material and methods</title>
<sec id="s2a">
<title>Patients</title>
<p>The institutional review board of Tianjin Medical University (Tianjin, China) and Shanghai Pulmonary Hospital (Shanghai, China) approved this retrospective study and waived the need to obtain informed consent from the patients. Patients who meet the following inclusion criteria were collected into this study. 1) Histologically confirmed primary lung adenocarcinoma; 2) pathological examination of tumour specimens carried out with proven records of EGFR mutation status; and 3) pre-operative contrast-enhanced CT data obtained. Patients were excluded if 1) clinical data including age, sex and stage was missing; 2) pre-operative treatment was received; or 3) the duration between CT examination and subsequent surgery exceeded 1 month. Finally, 844 patients from two hospitals were used for this study. We allocated the patients into a primary cohort and an independent validation cohort according to the hospital. The primary cohort included 603 patients from Shanghai Pulmonary Hospital between January 2013 and July 2014. The validation cohort included 241 patients from Tianjin Medical University between January 2013 and February 2014. The primary and validation cohorts were used for developing and validating the deep learning model, respectively. CT scanning parameters and detailed descriptions about the datasets are presented in the <ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">supplementary methods</ext-link>.</p>
<p>With regard to molecular profiles, tumour specimens were obtained using surgical resection. EGFR mutations were identified on four tyrosine kinase domains (exons 18–21), which are frequently mutated in lung cancer. The mutation status was determined using an amplification refractory mutation system with a human EGFR gene mutations detection kit (Beijing ACCB Biotech Ltd, Beijing, China). If any exon mutation was detected, the tumour was identified as EGFR-mutant; otherwise, the tumour was identified as EGFR-wild type. In this study, we therefore focused on predicting these binary outcomes (EGFR-mutant and EGFR-wild type) for patients with lung adenocarcinoma.</p>
</sec>
<sec id="s2b">
<title>Development of the deep learning model</title>
<p>Deep learning is a hierarchical neural network that aims at learning the abstract mapping between raw data to the desired label. The computational units in the deep learning model are defined as layers and they are integrated to simulate the analysis process of human brain. The main computational formulas are convolution, pooling, activation and batch normalisation. The terms of the computational process in building the deep learning model are defined in the <ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">supplementary methods</ext-link>.</p>
<p><xref ref-type="fig" rid="F1">Figure 1</xref> illustrates the pipeline of the EGFR mutation status prediction. For applying the deep learning model, a cubic region of interest (ROI) containing the entire tumour was manually selected (by J. Shi and Y. Liu) according to the following rule: the ROI should include the full tumour region, including the edges of tumours. This rule is easy to use in practice since we do not require the tumour to be precisely in the centre of the ROI (<ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">supplementary figure S1</ext-link> illustrates several ROIs selected by users). Afterwards, the ROI was resized to 64×64 pixels by third-order spline interpolation in each CT slice, and fed into the deep learning model. Through a sequential activation of convolution and pooling layers, the deep learning model gave an EGFR-mutant probability for the image. To make a robust prediction, all the CT slices of the tumour were fed into the deep learning model, and the average probability is treated as the EGFR-mutant probability for the tumour. Specifically, all the adjacent three CT slices were combined as a three-channel image and were fed into the deep learning model for prediction (<ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">supplementary figure S2</ext-link>).</p>
<fig id="F1" orientation="portrait" position="float">
<label>FIGURE 1</label>
<caption>
<p>Illustration of the deep learning model. This model is composed of convolutional layers with kernel size 3×3 and 1×1, batch normalisation and pooling layers. Sub-network 1 shares the same structure with the first 20 layers in DenseNet [<xref ref-type="bibr" rid="C31">31</xref>], which was pre-trained using 1.28 million natural images. Sub-network 2 was trained in the epidermal growth factor receptor (EGFR) mutation dataset, aiming at capturing the association between image features to EGFR mutation labels. When we feed a tumour into the deep learning model, it predicts the probability of the tumour being EGFR-mutant. CT: computed tomography.</p>
</caption>
<graphic xlink:href="ERJ-00986-2018.01"></graphic>
</fig>
<p>During model training, we used transfer learning to train the first 20 convolutional layers (sub-network 1 in <xref ref-type="fig" rid="F1">figure 1</xref>) by 1.28 million natural images from the ImageNet dataset [<xref ref-type="bibr" rid="C31">31</xref>]. This transfer learning technique has shown good performance in disease diagnosis since it enlarged the training data [<xref ref-type="bibr" rid="C23">23</xref>, <xref ref-type="bibr" rid="C32">32</xref>]. Afterwards, the last four convolutional layers (sub-network 2 in <xref ref-type="fig" rid="F1">figure 1</xref>) were trained using 14 926 CT images from lung adenocarcinoma tumours in the primary cohort. Details about building the model are presented in the <ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">supplementary methods</ext-link>.</p>
<p>Given the CT image of tumour, the deep learning model predicts a probability of the tumour being EGFR-mutant directly without any pre- or post-processing or image segmentation. The deep learning model generated using the primary cohort of this study is available at <ext-link ext-link-type="uri" xlink:href="http://radiomics.net.cn/post/110">http://radiomics.net.cn/post/110</ext-link>. Part of the CT images from the validation cohort can be downloaded as examples for testing the deep learning model.</p>
</sec>
<sec id="s2c">
<title>Visualisation of the deep learning model</title>
<p>Due to the end-to-end manner of deep learning, the inference process of the deep learning model is not intuitive for users. To further understand the prediction process of the deep learning model, we used visualisation techniques to analyse features learned by the model. The most important component of the deep learning model is the convolutional layer. Therefore, we visualised convolutional layers from two perspectives to understand the inference process of the deep learning model: 1) visualising the feature patterns extracted by convolutional layer; and 2) visualising the response of each convolutional layer to different tumours.</p>
<p>A convolutional layer consists of multiple convolutional filters where each convolutional filter extracts different features. Through a filter-visualising algorithm [<xref ref-type="bibr" rid="C33">33</xref>, <xref ref-type="bibr" rid="C34">34</xref>], we can visualise the feature pattern extracted by a convolutional filter, and we define this feature pattern as a deep learning feature (<ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">supplementary methods</ext-link>).</p>
<p>To further explore the meaning of the deep learning features, we observed the response of each convolutional filter to different tumours. Given a tumour image, each convolutional filter in the deep learning model generates a response map indicating the corresponding feature patterns in the tumour. The average value of the response map is defined as response value. A good convolutional filter should have different response values between EGFR-mutant and EGFR-wild type tumours. Therefore, visualising the response values for a convolutional filter in different tumour groups can help us evaluate the performance of the convolutional filter.</p>
</sec>
<sec id="s2d">
<title>Statistical analysis</title>
<p>Statistical analysis was performed using SPSS Statistics 21 (IBM, Armonk, NY, USA). The independent-samples t-test was adopted to assess the significance of the mean value on ages between the patients in EGFR-mutant and EGFR-wild type groups. The same statistical analysis was performed to assess the difference of deep learning score between the EGFR-mutant and EGFR-wild type groups. The Chi-squared test was used to evaluate the difference of categorical variables such as sex and tumour stage in all the cohorts. In addition, we used the DeLong test to evaluate the difference of the receiver operating characteristic (ROC) curves between various models. A p-value &lt;0.05 was treated as significant. Our implementation of the deep learning model used the Keras toolkit and Python 2.7 (Python Software Foundation; <ext-link ext-link-type="uri" xlink:href="www.python.org/">www.python.org/</ext-link>).</p>
</sec>
</sec>
<sec id="s3" sec-type="results">
<title>Results</title>
<sec id="s3a">
<title>Clinical characteristics of patients</title>
<p>The clinical characteristics of patients are presented in <xref ref-type="table" rid="TB1">table 1</xref>. There was no significant difference between the primary and validation cohorts in terms of age and sex (p=0.083 for age, p=0.321 for sex). The tumour stage showed statistical differences between the two cohorts, probably because of regional differences, since patients in the two cohorts are from two different cities in China. To eliminate this difference, we performed a stratified analysis in the two cohorts to validate the robustness of the deep learning model. Clinical characteristics such as age, sex and stage illustrated difference between EGFR-mutant and EGFR-wild type patients; therefore, these characteristics were used to build a clinical model for comparison to the deep learning model.</p>
<table-wrap id="TB1" orientation="portrait" position="float">
<label>TABLE 1</label>
<caption>
<p>Clinical characteristics of patients in the primary and validation cohorts</p>
</caption>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1"/>
<col align="center" span="1"/>
<col align="center" span="1"/>
<col align="center" span="1"/>
<col align="center" span="1"/>
<col align="center" span="1"/>
<col align="center" span="1"/>
</colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="2"></td>
<td align="center" colspan="2" rowspan="1">
<bold>Primary cohort</bold>
</td>
<td align="center" colspan="1" rowspan="2">
<bold>p-value</bold>
</td>
<td align="center" colspan="2" rowspan="1">
<bold>Validation cohort</bold>
</td>
<td align="center" colspan="1" rowspan="2">
<bold>p-value</bold>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>EGFR-wild type</bold>
</td>
<td align="char" char="(" colspan="1" rowspan="1">
<bold>EGFR-mutant</bold>
</td>
<td align="char" char="(" colspan="1" rowspan="1">
<bold>EGFR-wild type</bold>
</td>
<td align="center" colspan="1" rowspan="1">
<bold>EGFR-mutant</bold>
</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Subjects n</bold>
</td>
<td align="center" colspan="2" rowspan="1">603</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="2" rowspan="1">241</td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Age years</bold>
</td>
<td align="center" colspan="1" rowspan="1">59.50±9.72</td>
<td align="center" colspan="1" rowspan="1">61.36±8.96</td>
<td align="center" colspan="1" rowspan="1">0.016</td>
<td align="center" colspan="1" rowspan="1">59.59±8.83</td>
<td align="center" colspan="1" rowspan="1">59.21±7.28</td>
<td align="center" colspan="1" rowspan="1">0.716</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Sex</bold>
</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1">&lt;0.001</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1">&lt;0.001</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> Female</td>
<td align="center" colspan="1" rowspan="1">99 (39.76)</td>
<td align="center" colspan="1" rowspan="1">206 (58.19)</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1">52 (42.62)</td>
<td align="center" colspan="1" rowspan="1">79 (66.39)</td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> Male</td>
<td align="center" colspan="1" rowspan="1">150 (60.24)</td>
<td align="center" colspan="1" rowspan="1">148 (41.81)</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1">70 (57.38)</td>
<td align="center" colspan="1" rowspan="1">40 (33.61)</td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Stage</bold>
</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1">0.047</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1">0.017</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> I</td>
<td align="center" colspan="1" rowspan="1">181 (72.69)</td>
<td align="center" colspan="1" rowspan="1">240 (67.80)</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1">50 (40.98)</td>
<td align="center" colspan="1" rowspan="1">65 (54.62)</td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> II</td>
<td align="center" colspan="1" rowspan="1">27 (10.84)</td>
<td align="center" colspan="1" rowspan="1">27 (7.63)</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1">22 (18.03)</td>
<td align="center" colspan="1" rowspan="1">8 (6.72)</td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> III</td>
<td align="center" colspan="1" rowspan="1">36 (14.46)</td>
<td align="center" colspan="1" rowspan="1">69 (19.49)</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1">43 (35.25)</td>
<td align="center" colspan="1" rowspan="1">35 (29.41)</td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> IV</td>
<td align="center" colspan="1" rowspan="1">5 (2.01)</td>
<td align="center" colspan="1" rowspan="1">18 (5.08)</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1">7 (5.74)</td>
<td align="center" colspan="1" rowspan="1">11 (9.24)</td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>EGFR mutation</bold>
</td>
<td align="center" colspan="1" rowspan="1">249 (41.29)</td>
<td align="center" colspan="1" rowspan="1">354 (58.71)</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1">122 (50.62)</td>
<td align="center" colspan="1" rowspan="1">119 (49.38)</td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<p>Data are presented as mean±<sc>sd</sc>, or n (%), unless otherwise stated. EGFR: epidermal growth factor receptor.</p>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="s3b">
<title>Diagnostic validation of the deep learning model</title>
<p><xref ref-type="table" rid="TB2">Table 2</xref> lists the predictive performance of the deep learning model where we used area under the ROC curve (AUC), accuracy, sensitivity and specificity as main measurements. In our study, all the results were measured for tumour-level predictions, which are equivalent to reflect subject-level evaluations, since each patient only has﻿ one tumour. In the primary cohort, the deep learning model showed good predictive performance by five-fold cross-validation (AUC 0.85, 95% CI 0.83–0.88). This performance was further confirmed in the independent validation cohort (AUC 0.81, 95% CI 0.79–0.83). The close AUC between the primary and validation cohorts indicated that the deep learning model generalised well on predicting EGFR mutation status of unseen new patients. Benefiting from transfer learning with 1.28 million natural images, the deep learning model did not suffer from over-fitting. The ROC curves of the deep learning model in the two cohorts are presented in <xref ref-type="fig" rid="F2">figure 2a</xref>. Moreover, the deep learning score revealed a significant difference between EGFR-mutant and EGFR-wild type groups in the two cohorts (p&lt;0.001 in both the primary and validation cohorts; <xref ref-type="fig" rid="F2">figure 2b</xref>).</p>
<table-wrap id="TB2" orientation="portrait" position="float">
<label>TABLE 2</label>
<caption>
<p>Predictive performance of various methods in the primary and validation cohorts</p>
</caption>
<table frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1"/>
<col align="char" char="(" span="1"/>
<col align="char" char="(" span="1"/>
<col align="char" char="(" span="1"/>
<col align="char" char="(" span="1"/>
</colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1"></td>
<td align="char" char="(" colspan="1" rowspan="1">
<bold>AUC (95% CI)</bold>
</td>
<td align="char" char="(" colspan="1" rowspan="1">
<bold>Accuracy % (95% CI)</bold>
</td>
<td align="char" char="(" colspan="1" rowspan="1">
<bold>Sensitivity % (95% CI)</bold>
</td>
<td align="char" char="(" colspan="1" rowspan="1">
<bold>Specificity % (95% CI)</bold>
</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Clinical model</bold>
</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> Primary</td>
<td align="center" colspan="1" rowspan="1">0.66 (0.62–0.70)</td>
<td align="center" colspan="1" rowspan="1">61.60 (57.90–65.15)</td>
<td align="center" colspan="1" rowspan="1">64.39 (59.75–68.90)</td>
<td align="center" colspan="1" rowspan="1">56.75 (50.65–62.68)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> Validation</td>
<td align="center" colspan="1" rowspan="1">0.61 (0.58–0.64)</td>
<td align="center" colspan="1" rowspan="1">61.83 (58.88–64.88)</td>
<td align="center" colspan="1" rowspan="1">56.30 (52.41–60.41)</td>
<td align="center" colspan="1" rowspan="1">67.21 (63.20–71.20)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Semantic model</bold>
</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> Primary</td>
<td align="center" colspan="1" rowspan="1">0.76 (0.72–0.80)</td>
<td align="center" colspan="1" rowspan="1">64.77 (61.31–68.22)</td>
<td align="center" colspan="1" rowspan="1">71.49 (67.86–75.09)</td>
<td align="center" colspan="1" rowspan="1">61.22 (57.45–65.12)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> Validation</td>
<td align="center" colspan="1" rowspan="1">0.64 (0.61–0.67)</td>
<td align="center" colspan="1" rowspan="1">62.24 (59.94–64.72)</td>
<td align="center" colspan="1" rowspan="1">63.03 (59.61–66.60)</td>
<td align="center" colspan="1" rowspan="1">61.48 (58.22–64.92)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>Radiomics model</bold>
</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> Primary</td>
<td align="center" colspan="1" rowspan="1">0.70 (0.66–0.74)</td>
<td align="center" colspan="1" rowspan="1">66.27 (62.96–69.83)</td>
<td align="center" colspan="1" rowspan="1"><bold>85.05</bold> (81.81–88.46)</td>
<td align="center" colspan="1" rowspan="1">40.98 (35.82–46.34)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> Validation</td>
<td align="center" colspan="1" rowspan="1">0.64 (0.61–0.67)</td>
<td align="center" colspan="1" rowspan="1">61.47 (58.69–64.69)</td>
<td align="center" colspan="1" rowspan="1">64.04 (60.34–68.34)</td>
<td align="center" colspan="1" rowspan="1">58.97 (55.10–63.10)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<bold>DL model</bold>
</td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
<td align="center" colspan="1" rowspan="1"></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> Primary</td>
<td align="center" colspan="1" rowspan="1"><bold>0.85</bold> (0.83–0.88)</td>
<td align="center" colspan="1" rowspan="1"><bold>77.02</bold> (74.02–79.97)</td>
<td align="center" colspan="1" rowspan="1">76.83 (73.17–80.49)</td>
<td align="center" colspan="1" rowspan="1"><bold>79.03</bold> (74.26–83.61)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> Validation</td>
<td align="center" colspan="1" rowspan="1"><bold>0.81</bold> (0.79–0.83)</td>
<td align="center" colspan="1" rowspan="1"><bold>73.86</bold> (71.82–75.82)</td>
<td align="center" colspan="1" rowspan="1"><bold>72.27</bold> (69.27–75.27)</td>
<td align="center" colspan="1" rowspan="1"><bold>75.41</bold> (72.32–78.32)</td>
</tr>
</tbody>
</table>
<table-wrap-foot>
<p>Data are presented as % (95% CI). All the results in the primary cohort were evaluated by five-fold cross-validation. Bold type represents the best performance. AUC: area under the receiver operating characteristic curve.</p>
</table-wrap-foot>
</table-wrap>
<fig id="F2" orientation="portrait" position="float">
<label>FIGURE 2</label>
<caption>
<p>Predictive performance of the deep learning model. a) Receiver operating characteristic curves of the deep learning (DL) model, radiomics model, semantic model and clinical model in the primary/validation cohorts. b) DL score between epidermal growth factor receptor (EGFR)-mutant and EGFR-wild type groups in the primary and validation cohorts. c) Decision curve of the DL model. The green line represents the benefit of treating all the patients as EGFR-wild type, and the blue line represents the benefit of treating all the patients as EGFR-mutant. The red line shows the benefit of using the DL model.</p>
</caption>
<graphic xlink:href="ERJ-00986-2018.02"></graphic>
</fig>
<p>In addition, we performed a stratified analysis to validate the diagnostic performance of the deep learning model concerning tumour stage. <ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">Supplementary table S1 and supplementary figure S3</ext-link> indicate that the deep learning model achieved good results in all the tumour stages. Moreover, the deep learning score showed a significant difference between EGFR-mutant and EGFR-wild type groups, regardless of tumour stages.</p>
<p><xref ref-type="fig" rid="F2">Figure 2c</xref> plots the decision curve of the deep learning model. This curve shows that if the threshold probability of a patient or doctor is &gt;10%, using the deep learning model to predict EGFR mutation status in lung adenocarcinoma adds more benefit than either the treat-all-patients scheme or the treat-none scheme [<xref ref-type="bibr" rid="C35">35</xref>]. This highlights the clinical use of the deep learning model.</p>
</sec>
<sec id="s3c">
<title>Comparison between the deep learning model and other methods</title>
<p>In early studies, clinical characteristics, semantic features [<xref ref-type="bibr" rid="C17">17</xref>, <xref ref-type="bibr" rid="C36">36</xref>] and quantitative “radiomic” features [<xref ref-type="bibr" rid="C9">9</xref>] were used for EGFR mutation status prediction. Therefore, we built a clinical model, a semantic model and a radiomics model as comparison to the proposed deep learning model. The clinical model involved sex, stage and age as features, and used a support vector machine (SVM) with radius-basis kernel for EGFR mutation prediction. The semantic model used 16 semantic features reported in the previous study and a multivariate logistic regression (details in <ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">supplementary methods and supplementary table S4</ext-link>) [<xref ref-type="bibr" rid="C17">17</xref>]. The radiomics model extracted 1108 features by the PyRadiomics toolkit [<xref ref-type="bibr" rid="C37">37</xref>] and selected eight features using recursive feature elimination (RFE). Finally, a random forest containing 100 trees was built for EGFR mutation prediction in the radiomics model.</p>
<p>The quantitative performance in <xref ref-type="table" rid="TB2">table 2</xref> and the ROC curves in <xref ref-type="fig" rid="F2">figure 2a</xref> indicate that the deep learning model had better performance than the clinical model, with significant difference (AUC 0.66, 95% CI 0.62–0.70 in the primary cohort, p&lt;0.0001; AUC 0.61, 95% CI 0.58–0.64 in the validation cohort, p&lt;0.0001). In addition, a significant improvement over the semantic model was observed in the two cohorts (AUC 0.76, 95% CI 0.72–0.80 in the primary cohort, p&lt;0.0001; AUC 0.64, 95% CI 0.61–0.67 in the validation cohort, p&lt;0.0001). Similar improvement over the radiomics model was confirmed in the two cohorts (AUC 0.70, 95% CI 0.66–0.74 in the primary cohort, p&lt;0.0001; AUC 0.64, 95% CI 0.61–0.67 in the validation cohort, p=0.0002).</p>
</sec>
<sec id="s3d">
<title>Suspicious tumour area discovery</title>
<p>Since deep learning is an end-to-end prediction model that learns abstract mappings between tumour image and EGFR mutation status directly, it is important to explain the predicting process such that we can estimate how reliable the prediction is. We used a deep learning visualisation method [<xref ref-type="bibr" rid="C33">33</xref>, <xref ref-type="bibr" rid="C34">34</xref>] to find the tumour region that was most related to EGFR mutation status (<ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">supplementary methods</ext-link>). This important region was defined as the suspicious area in our study. When the deep learning model predicts an EGFR mutation status, it tells clinicians which area draws the attention of the model at the same time.</p>
<p><xref ref-type="fig" rid="F3">Figure 3</xref> depicts the suspicious areas found by the deep learning model. For a lung adenocarcinoma tumour, the deep learning model generated an attention map indicating the importance of each part in the tumour; we used 0.5 as the cut-off value to reserve the high-response area (suspicious tumour area). These areas were more important than other regions of tumour since they drew the attention of the deep learning model. As shown in the bottom row in <xref ref-type="fig" rid="F3">figure 3</xref>, the suspicious areas found by the deep learning model varied in different tumours. For example, the suspicious area in <xref ref-type="fig" rid="F3">figure 3a</xref> was the tissue between tumour and pleura, whereas the suspicious area in <xref ref-type="fig" rid="F3">figure 3b</xref> was the tumour edge. Based on these observations, the deep learning model interpreted these two tumours as EGFR-mutant. In contrast, the deep learning model focused on the cavitary area in <xref ref-type="fig" rid="F3">figure 3c</xref> and predicted it to be EGFR-wild type. Since the deep learning model required only raw CT image of tumours as input without any tumour segmentation, some normal tissues can be fed into the model. However, the model was capable of finding suspicious areas inside tumours instead of being disturbed by normal tissues. <xref ref-type="fig" rid="F3">Figure 3d</xref> illustrates a tumour adjacent to the mediastinum. In this case, the ROI for the deep learning model included some normal tissues outside the tumour. However, the deep learning model found a suspicious area inside the tumour instead of the normal tissues. The suspicious tumour area was inferred to be strongly related to EGFR mutation status by the deep learning model. Therefore, it can potentially provide a biopsy position for clinicians to avoid false negative diagnoses caused by intra-tumour hetrogeneity. The difference between the suspicious tumour area and other tumour areas may be further explained by combining positron emission tomography–CT data.</p>
<fig id="F3" orientation="portrait" position="float">
<label>FIGURE 3</label>
<caption>
<p>Suspicious tumour area discovery. We used 0.5 as cut-off value to acquire the suspicious areas according to the attention map of the deep learning (DL) model. EGFR: epidermal growth factor receptor.</p>
</caption>
<graphic xlink:href="ERJ-00986-2018.03"></graphic>
</fig>
</sec>
<sec id="s3e">
<title>Deep learning feature analysis</title>
<p>The advantage of deep learning mainly comes from its automatic feature-learning ability. By learning from 14 926 tumour images, the deep learning model detects features that are strongly associated with EGFR mutation status.</p>
<p>For a better understanding of the deep learning feature, we visualised several convolutional filters in the deep learning model (<xref ref-type="fig" rid="F4">figure 4a</xref>). The shallow convolutional layer learned low-level simple features such as horizontal and diagonal edges (Conv_2). A deeper convolutional layer learned more complex features such as tumour shape. For instance, the filters in layer Conv_13 had strong response to circle or arch shapes, because most tumours contain circular or arch-shaped structures. When going deeper, the features became more abstract and were gradually related to EGFR mutation status (Conv_20, Conv_24). In <ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">supplementary figure S4</ext-link>, we compared the convolutional filters before training and after transfer learning (trained in CT data). This figure indicates that the convolutional filters learned various feature patterns that are different with their initial status. Furthermore, transfer learning makes the filters more specific to CT data, especially in deeper network layers.</p>
<fig id="F4" orientation="portrait" position="float">
<label>FIGURE 4</label>
<caption>
<p>Deep learning feature analysis. a) Convolutional filters (Conv_) from the 2nd, 13th, 20th and 24th layers of the deep learning model. Each convolutional layer includes hundreds of filters, and only the first three filters are illustrated in each layer. b) Response of the negative filter and the positive filter in epidermal growth factor receptor (EGFR)-mutant/-wild type tumours. The positive filter has strong response to EGFR-mutant tumours and the negative filter has strong response to EGFR-wild type tumours. All the tumour images are from the validation cohort. c) Response value of the positive and the negative filters in the two cohorts. d) Unsupervised clustering of lung adenocarcinoma patients (n=844) on the vertical axis and deep learning feature expression (feature dimension=32, the Conv_24 layer) on the horizontal axis.</p>
</caption>
<graphic xlink:href="ERJ-00986-2018.04"></graphic>
</fig>
<p>To further demonstrate the association between the deep learning features and EGFR mutation status, we extracted two convolutional filters from the last convolutional layer (the positive and negative filters). These two filters captured different texture patterns (the first column in <xref ref-type="fig" rid="F4">figure 4b</xref>) responding to EGFR-mutant and EGFR-wild type tumours. When we fed EGFR-wild type tumours to the deep learning model, the negative filter generated a strong response, while the positive filter was nearly shut down. Similarly, when we fed EGFR-mutant tumours to the deep learning model, the negative filter was depressed, but the positive filter was strongly activated. As depicted in <xref ref-type="fig" rid="F4">figure 4c</xref>, the response of the positive/negative filters on EGFR-mutant and EGFR-wild type tumours were significantly different in all the cohorts (p&lt;0.001). In <xref ref-type="fig" rid="F4">figure 4d</xref>, the clustering map of deep learning features from the last convolutional layer (Conv_24) in the whole dataset (844 patients) is illustrated. The deep learning features showed obvious clusters that had different responses to EGFR-mutant and EGFR-wild type patients. Meanwhile, tumours of different EGFR mutation status (EGFR-mutant/-wild type) can be roughly separated (vertical axis in <xref ref-type="fig" rid="F4">figure 4d</xref>).</p>
<p>To compare the importance of the deep learning features and the radiomic features, we combined the 32 deep learning features from the Conv_24 layer with the 1108 radiomic features, and used RFE to select the important features. In this step, the RFE used linear SVM and five-fold cross-validation to determine the optimal feature amount using the primary cohort, which is consistent with the RFE settings in building the radiomics model. Finally, 11 features were selected, including eight deep learning features and three radiomic features. This indicates that the deep learning features showed stronger association with EGFR mutation status than radiomic features. In addition, we calculated the univariate AUC for all the deep learning features and the radiomic features. As illustrated in <ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">supplementary figure S5</ext-link>, many of the deep learning features have higher AUCs than the radiomic features.</p>
</sec>
</sec>
<sec id="s4" sec-type="discussion">
<title>Discussion</title>
<p>In this study, we proposed a deep learning model using non-invasive CT images to predict EGFR mutation status for patients with lung adenocarcinoma. We trained the deep learning model in 14 926 CT images from the primary cohort (603 patients), and validated its performance in an independent validation cohort from another hospital (241 patients). The deep learning model showed encouraging results in the primary cohort (AUC 0.85, 95% CI 0.83–0.88) and achieved strong performance in the independent validation cohort (AUC 0.81, 95% CI 0.79–0.83). The deep learning model revealed that there was a significant association between high-dimensional CT image features and EGFR genotype. Our analysis provides an alternative method to non-invasively assess EGFR information for patients, and offers a great supplement to biopsy. Meanwhile, our model can discover the suspicious tumour area that dominates the prediction of EGFR mutation status. This analysis offered visual interpretation to clinicians about understanding the prediction outcomes in CT data. Moreover, the deep learning model requires only the raw tumour image as input and predicts the EGFR mutation status directly without further human assistance, is easy to use and very fast.</p>
<p>Previous studies used clinical factors [<xref ref-type="bibr" rid="C8">8</xref>] and radiomics based on feature engineering [<xref ref-type="bibr" rid="C9">9</xref>, <xref ref-type="bibr" rid="C17">17</xref>, <xref ref-type="bibr" rid="C18">18</xref>] to predict EGFR mutation status. For example, clinical factors such as age, sex, tumour stage and predominant subtype were used to build a nomogram for EGFR mutation status prediction [<xref ref-type="bibr" rid="C8">8</xref>]. In this study, the clinical factors achieved AUC 0.64 in a validation cohort including 464 Asian patients. The clinical model is interpretable, since clinical factors are widely used and the nomogram represents an intuitive linear model. However, clinical features such as stage and predominant subtype require invasive biopsy. In addition, clinical features only reflect few tumour information in pathological level. By contrast, radiomic methods used CT images to quantify tumour information at the macroscopic level, and built the relationship between tumour image and EGFR mutation status. Compared with clinical factors, radiomic analysis provides quantitative features to mine high-dimensional information associated with EGFR genotype. In a cohort including 353 patients, the radiomic method achieved AUC 0.69 by using hand-crafted CT image features [<xref ref-type="bibr" rid="C9">9</xref>]. Despite the advantages of the radiomic method, the hand-crafted feature requires time-consuming tumour boundary segmentation and may lack specificity to EGFR genotype. Consequently, we proposed a deep learning method to learn EGFR-related tumour features automatically and avoid complex tumour boundary segmentation. Furthermore, the deep learning method only requires a user-defined ROI of the tumour instead of four complex procedures in radiomics based on feature engineering (tumour boundary segmentation, feature extraction, feature selection and model building).</p>
<sec id="s4a">
<title>Advantages of deep learning</title>
<p>Previous studies suggested that CT-based semantic features [<xref ref-type="bibr" rid="C18">18</xref>, <xref ref-type="bibr" rid="C19">19</xref>] and quantitative radiomic features [<xref ref-type="bibr" rid="C9">9</xref>, <xref ref-type="bibr" rid="C17">17</xref>] reflected EGFR mutation status. However, they can only reflect low-order visual features or simple high-order features. There are abstract features that can probably be associated with EGFR mutation status; however, they are difficult to represent using hand-crafted feature engineering. In these situations, deep learning demonstrates its advantage since it can mine abstract features that are difficult to formulise but are important for identifying EGFR mutation status.</p>
<p>Compared with previously reported hand-crafted features, the deep learning model has the following advantages. 1) Through a hierarchical neural network structure, the deep learning model extracts multi-level features from visual characteristics to abstract mappings that are directly related to EGFR information; 2) the deep learning model does not require time-consuming tumour boundary annotation, which is a big advantage over hand-crafted feature engineering. Moreover, the microenvironment of tumours and the relationship between tumours and attached tissues (pleura traction, <italic>etc</italic>.) are considered in the deep learning model; 3) the deep learning model is fast and easy to use, requires only the raw CT image as input and predicts the EGFR mutation status directly without further human input.</p>
</sec>
<sec id="s4b">
<title>Clinical utility of the deep learning model</title>
<p>The deep learning model provides potential clinical utility from the following perspectives. 1) The proposed deep learning model provides a non-invasive method to predict EGFR mutation status, which can be used easily in routine CT diagnosis. 2) If the biopsy result of a tumour shows EGFR-wild type, the result may include false negatives because of intra-tumour heterogeneity. At this time, the deep learning model can be seen as an alternative validation tool. If the deep learning model predicts the tumour to be EGFR-mutant, clinicians may need to re-biopsy tissues [<xref ref-type="bibr" rid="C38">38</xref>]. 3) The deep learning model only requires routinely used CT images, without adding cost. Therefore, this model can be used multiple times throughout the course of treatment [<xref ref-type="bibr" rid="C9">9</xref>]. 4) Most importantly, although we studied only adenocarcinoma, the deep learning model shows predictive value in other histological types. This enables the deep learning model to be used directly in CT scans of lung cancer without identifying histological types. To validate this hypothesis, we additionally collected 125 patients with other lung cancer histological types from Shanghai Pulmonary Hospital between January 2013 and July 2014 (clinical characteristics described in <ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">supplementary table S2</ext-link>). Quantitative results in <ext-link ext-link-type="uri" xlink:href="http://erj.ersjournals.com/lookup/doi/10.1183/13993003.00986-2018.figures-only#fig-data-supplementary-materials">supplementary table S3</ext-link> indicate that the deep learning model can achieve AUC 0.77 (95% CI 0.73–0.81) in other histological types of lung cancer. Consequently, even without knowing the histological type of a lung cancer, the deep learning model can achieve AUC 0.81 in adenocarcinoma and AUC 0.77 in other histological types.</p>
<p>Despite the encouraging performance of the deep learning model, this study has several limitations. First, we only examined patients in an Asian population. However, EGFR mutation rate can be affected by race. In future work, populations from multiple sources will be necessary to test whether the deep learning model can be generalised to other populations. Second, although the deep learning model shows better performance than clinical, semantic and radiomics models, the combination of these models is unclear. The predictive performance may be improved if we combine these models together. Third, our study only focused on EGFR mutation status. The relationship between EGFR mutation and other genetic mutations (<italic>e.g.</italic> ROS-1, ALK) can be explored in future work.
</p>
</sec>
</sec>
<sec id="s5" sec-type="supplementary-material">
<title>Supplementary material</title>
<supplementary-material content-type="local-data" id="supplementary">
<object-id pub-id-type="doi">10.1183/13993003.00986-2018.Supp1</object-id>
<p><bold>Please note:</bold> supplementary material is not edited by the Editorial Office, and is uploaded as it has been supplied by the author.</p>
<p>Supplementary material <inline-supplementary-material content-type="local-data" id="SS1" mime-subtype="pdf" mimetype="application" xlink:href="ERJ-00986-2018_Supplement.pdf">ERJ-00986-2018_Supplement</inline-supplementary-material></p>
</supplementary-material>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="supplementary-material">
<p>This article has supplementary material available from <ext-link ext-link-type="uri" xlink:href="erj.ersjournals.com">erj.ersjournals.com</ext-link></p>
</fn>
<fn>
<p>Author contributions: D. Dong, J. Shi, Y. Liu and Z. Ye collected the clinical dataset. Z. Liu, K. Wang and Y. Zhu processed and analysed the data. H. Zhou provided statistical analysis. S. Wang, D. Yu and M. Zhou built the deep learning model and wrote the article. O. Gevaert and J. Tian conceived the project and edited the article.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: S. Wang has nothing to disclose.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: J. Shi has nothing to disclose.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: Z. Ye has nothing to disclose.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: D. Dong has nothing to disclose.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: D. Yu has nothing to disclose.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: M. Zhou has nothing to disclose.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: Y. Liu has nothing to disclose.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: O. Gevaert has nothing to disclose.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: K. Wang has nothing to disclose.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: Y. Zhu has nothing to disclose.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: H. Zhou has nothing to disclose.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: Z. Liu has nothing to disclose.</p>
</fn>
<fn fn-type="COI-statement">
<p>Conflict of interest: J. Tian has nothing to disclose.</p>
</fn>
<fn fn-type="financial-disclosure">
<p>Support statement: This work was supported by the National Key R&amp;D Programme of China (2017YFA0205200, 2017YFC1308700, 2017YFC1309100, and 2016YFC010380), National Natural Science Foundation of China (81227901, 81771924, 81501616, 61231004, 81671851, 81527805), the Beijing Municipal Science and Technology Commission (Z171100000117023, Z161100002616022), the Beijing Natural Science Foundation (L182061), the Bureau of International Cooperation of Chinese Academy of Sciences (173211KYSB20160053), the Instrument Developing Project of the Chinese Academy of Sciences (YZ201502) and the Youth Innovation Promotion Association CAS (2017175). O. Gevaert was supported by the National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health under award number R01EB020527. Funding information for this article has been deposited with the <ext-link ext-link-type="uri" xlink:href="https://www.crossref.org/services/funder-registry/">Crossref Funder Registry</ext-link>.</p>
</fn>
</fn-group>
<ref-list>
<title>References</title>
<ref id="C1">
<label>1</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sequist</surname><given-names>LV</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Yamamoto</surname><given-names>N</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Phase III study of afatinib or cisplatin plus pemetrexed in patients with metastatic lung adenocarcinoma with EGFR mutations</article-title>. <source/>J Clin Oncol
<year>2013</year>; <volume>31</volume>: <fpage>3327</fpage>–<lpage>3334</lpage>.<pub-id pub-id-type="pmid">23816960</pub-id></mixed-citation>
</ref>
<ref id="C2">
<label>2</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Maemondo</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Inoue</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kobayashi</surname><given-names>K</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Gefitinib or chemotherapy for non-small-cell lung cancer with mutated EGFR</article-title>. <source/>N Engl J Med
<year>2010</year>; <volume>362</volume>: <fpage>2380</fpage>–<lpage>2388</lpage>.<pub-id pub-id-type="pmid">20573926</pub-id></mixed-citation>
</ref>
<ref id="C3">
<label>3</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Kung</surname><given-names>H-J</given-names></name>, <name name-style="western"><surname>Mack</surname><given-names>PC</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Genotyping and genomic profiling of non-small-cell lung cancer: implications for current and future therapies</article-title>. <source/>J Clin Oncol
<year>2013</year>; <volume>31</volume>: <fpage>1039</fpage>–<lpage>1049</lpage>.<pub-id pub-id-type="pmid">23401433</pub-id></mixed-citation>
</ref>
<ref id="C4">
<label>4</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>Y-L</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>G</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Erlotinib <italic>versus</italic> chemotherapy as first-line treatment for patients with advanced EGFR mutation-positive non-small-cell lung cancer (OPTIMAL, CTONG-0802): a multicentre, open-label, randomised, phase 3 study</article-title>. <source/>Lancet Oncol
<year>2011</year>; <volume>12</volume>: <fpage>735</fpage>–<lpage>742</lpage>.<pub-id pub-id-type="pmid">21783417</pub-id></mixed-citation>
</ref>
<ref id="C5">
<label>5</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Itakura</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Achrol</surname><given-names>AS</given-names></name>, <name name-style="western"><surname>Mitchell</surname><given-names>LA</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Magnetic resonance image features identify glioblastoma phenotypic subtypes with distinct molecular pathway activities</article-title>. <source/>Sci Transl Med
<year>2015</year>; <volume>7</volume>: <fpage>303ra138</fpage>.</mixed-citation>
</ref>
<ref id="C6">
<label>6</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sacher</surname><given-names>AG</given-names></name>, <name name-style="western"><surname>Dahlberg</surname><given-names>SE</given-names></name>, <name name-style="western"><surname>Heng</surname><given-names>J</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Association between younger age and targetable genomic alterations and prognosis in non-small-cell lung cancer</article-title>. <source/>JAMA Oncol
<year>2016</year>; <volume>2</volume>: <fpage>313</fpage>–<lpage>320</lpage>.<pub-id pub-id-type="pmid">26720421</pub-id></mixed-citation>
</ref>
<ref id="C7">
<label>7</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Loughran</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Keeling</surname><given-names>C</given-names></name></person-group>
<article-title>Seeding of tumour cells following breast biopsy: a literature review</article-title>. <source/>Br J Radiol
<year>2011</year>; <volume>84</volume>: <fpage>869</fpage>–<lpage>874</lpage>.<pub-id pub-id-type="pmid">21933978</pub-id></mixed-citation>
</ref>
<ref id="C8">
<label>8</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Girard</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Sima</surname><given-names>CS</given-names></name>, <name name-style="western"><surname>Jackman</surname><given-names>DM</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Nomogram to predict the presence of EGFR activating mutation in lung adenocarcinoma</article-title>. <source/>Eur Respir J
<year>2012</year>; <volume>39</volume>: <fpage>366</fpage>–<lpage>372</lpage>.<pub-id pub-id-type="pmid">21778168</pub-id></mixed-citation>
</ref>
<ref id="C9">
<label>9</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rios Velazquez</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Parmar</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>Y</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Somatic mutations drive distinct imaging phenotypes in lung cancer</article-title>. <source/>Cancer Res
<year>2017</year>; <volume>77</volume>: <fpage>3922</fpage>–<lpage>3930</lpage>.<pub-id pub-id-type="pmid">28566328</pub-id></mixed-citation>
</ref>
<ref id="C10">
<label>10</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lambin</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Leijenaar</surname><given-names>RT</given-names></name>, <name name-style="western"><surname>Deist</surname><given-names>TM</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Radiomics: the bridge between medical imaging and personalized medicine</article-title>. <source/>Nat Rev Clin Oncol
<year>2017</year>; <volume>14</volume>: <fpage>749</fpage>–<lpage>762</lpage>.<pub-id pub-id-type="pmid">28975929</pub-id></mixed-citation>
</ref>
<ref id="C11">
<label>11</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gillies</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Kinahan</surname><given-names>PE</given-names></name>, <name name-style="western"><surname>Hricak</surname><given-names>H</given-names></name></person-group>
<article-title>Radiomics: images are more than pictures, they are data</article-title>. <source/>Radiology
<year>2016</year>; <volume>278</volume>: <fpage>563</fpage>–<lpage>577</lpage>.<pub-id pub-id-type="pmid">26579733</pub-id></mixed-citation>
</ref>
<ref id="C12">
<label>12</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kauczor</surname><given-names>H-U</given-names></name>, <name name-style="western"><surname>Heussel</surname><given-names>CP</given-names></name>, <name name-style="western"><surname>von Stackelberg</surname><given-names>O</given-names></name></person-group>
<article-title>Time to take CT screening to the next level?</article-title>
<source/>Eur Respir J
<year>2017</year>; <volume>49</volume>: <fpage>1700064</fpage>.<pub-id pub-id-type="pmid">28424364</pub-id></mixed-citation>
</ref>
<ref id="C13">
<label>13</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aerts</surname><given-names>HJ</given-names></name>, <name name-style="western"><surname>Velazquez</surname><given-names>ER</given-names></name>, <name name-style="western"><surname>Leijenaar</surname><given-names>RT</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Decoding tumour phenotype by noninvasive imaging using a quantitative radiomics approach</article-title>. <source/>Nat Commun
<year>2014</year>; <volume>5</volume>: <fpage>4006</fpage>.<pub-id pub-id-type="pmid">24892406</pub-id></mixed-citation>
</ref>
<ref id="C14">
<label>14</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Karlo</surname><given-names>CA</given-names></name>, <name name-style="western"><surname>Di Paolo</surname><given-names>PL</given-names></name>, <name name-style="western"><surname>Chaim</surname><given-names>J</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Radiogenomics of clear cell renal cell carcinoma: associations between CT imaging features and mutations</article-title>. <source/>Radiology
<year>2014</year>; <volume>270</volume>: <fpage>464</fpage>–<lpage>471</lpage>.<pub-id pub-id-type="pmid">24029645</pub-id></mixed-citation>
</ref>
<ref id="C15">
<label>15</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gevaert</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Xu</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Hoang</surname><given-names>CD</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Non-small cell lung cancer: identifying prognostic imaging biomarkers by leveraging public gene expression microarray data – methods and preliminary results</article-title>. <source/>Radiology
<year>2012</year>; <volume>264</volume>: <fpage>387</fpage>–<lpage>396</lpage>.<pub-id pub-id-type="pmid">22723499</pub-id></mixed-citation>
</ref>
<ref id="C16">
<label>16</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Leung</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Echegaray</surname><given-names>S</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Non-small cell lung cancer radiogenomics map identifies relationships between molecular and imaging phenotypes with prognostic implications</article-title>. <source/>Radiology
<year>2018</year>; <volume>286</volume>: <fpage>307</fpage>–<lpage>315</lpage>.<pub-id pub-id-type="pmid">28727543</pub-id></mixed-citation>
</ref>
<ref id="C17">
<label>17</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Qu</surname><given-names>F</given-names></name>, <etal>et al.</etal></person-group>
<article-title>CT features associated with epidermal growth factor receptor mutation status in patients with lung adenocarcinoma</article-title>. <source/>Radiology
<year>2016</year>; <volume>280</volume>: <fpage>271</fpage>–<lpage>280</lpage>.<pub-id pub-id-type="pmid">26937803</pub-id></mixed-citation>
</ref>
<ref id="C18">
<label>18</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yano</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sasaki</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Kobayashi</surname><given-names>Y</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Epidermal growth factor receptor gene mutation and computed tomographic findings in peripheral pulmonary adenocarcinoma</article-title>. <source/>J Thorac Oncol
<year>2006</year>; <volume>1</volume>: <fpage>413</fpage>–<lpage>416</lpage>.<pub-id pub-id-type="pmid">17409892</pub-id></mixed-citation>
</ref>
<ref id="C19">
<label>19</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Zheng</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Yu</surname><given-names>Z</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Comparative analysis of clinicoradiologic characteristics of lung adenocarcinomas with ALK rearrangements or EGFR mutations</article-title>. <source/>Eur Radiol
<year>2015</year>; <volume>25</volume>: <fpage>1257</fpage>–<lpage>1266</lpage>.<pub-id pub-id-type="pmid">25577516</pub-id></mixed-citation>
</ref>
<ref id="C20">
<label>20</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>LeCun</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Bengio</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Hinton</surname><given-names>G</given-names></name></person-group>
<article-title>Deep learning</article-title>. <source/>Nature
<year>2015</year>; <volume>521</volume>: <fpage>436</fpage>–<lpage>444</lpage>.<pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
</ref>
<ref id="C21">
<label>21</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Silver</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Schrittwieser</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Simonyan</surname><given-names>K</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Mastering the game of Go without human knowledge</article-title>. <source/>Nature
<year>2017</year>; <volume>550</volume>: <fpage>354</fpage>–<lpage>359</lpage>.<pub-id pub-id-type="pmid">29052630</pub-id></mixed-citation>
</ref>
<ref id="C22">
<label>22</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hazlett</surname><given-names>HC</given-names></name>, <name name-style="western"><surname>Gu</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Munsell</surname><given-names>BC</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Early brain development in infants at high risk for autism spectrum disorder</article-title>. <source/>Nature
<year>2017</year>; <volume>542</volume>: <fpage>348</fpage>–<lpage>351</lpage>.<pub-id pub-id-type="pmid">28202961</pub-id></mixed-citation>
</ref>
<ref id="C23">
<label>23</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Esteva</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kuprel</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Novoa</surname><given-names>RA</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Dermatologist-level classification of skin cancer with deep neural networks</article-title>. <source/>Nature
<year>2017</year>; <volume>542</volume>: <fpage>115</fpage>–<lpage>118</lpage>.<pub-id pub-id-type="pmid">28117445</pub-id></mixed-citation>
</ref>
<ref id="C24">
<label>24</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ting</surname><given-names>DSW</given-names></name>, <name name-style="western"><surname>Cheung</surname><given-names>CY-L</given-names></name>, <name name-style="western"><surname>Lim</surname><given-names>G</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diabetes</article-title>. <source/>JAMA
<year>2017</year>; <volume>318</volume>: <fpage>2211</fpage>–<lpage>2223</lpage>.<pub-id pub-id-type="pmid">29234807</pub-id></mixed-citation>
</ref>
<ref id="C25">
<label>25</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Lu</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Zhou</surname><given-names>H</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Deep learning radiomics of shear wave elastography significantly improved diagnostic performance for assessing liver fibrosis in chronic hepatitis B: a prospective multicentre study</article-title>. <source/>Gut
<year>2018</year>: <fpage>gutjnl-2018–316204</fpage>.</mixed-citation>
</ref>
<ref id="C26">
<label>26</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lakhani</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Sundaram</surname><given-names>B</given-names></name></person-group>
<article-title>Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks</article-title>. <source/>Radiology
<year>2017</year>; <volume>284</volume>: <fpage>574</fpage>–<lpage>582</lpage>.<pub-id pub-id-type="pmid">28436741</pub-id></mixed-citation>
</ref>
<ref id="C27">
<label>27</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Zhou</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>Z</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Central focused convolutional neural networks: developing a data-driven model for lung nodule segmentation</article-title>. <source/>Med Image Anal
<year>2017</year>; <volume>40</volume>: <fpage>172</fpage>–<lpage>183</lpage>.<pub-id pub-id-type="pmid">28688283</pub-id></mixed-citation>
</ref>
<ref id="C28">
<label>28</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shen</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Zhou</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>F</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Multi-crop convolutional neural networks for lung nodule malignancy suspiciousness classification</article-title>. <source/>Pattern Recognit
<year>2017</year>; <volume>61</volume>: <fpage>663</fpage>–<lpage>673</lpage>.</mixed-citation>
</ref>
<ref id="C29">
<label>29</label>
<mixed-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>X</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Unsupervised deep learning features for lung cancer overall survival analysis</article-title>. In: <conf-name>2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society</conf-name>, <publisher-name>IEEE</publisher-name>, <year>2018</year>; p. <fpage>2583</fpage>–<lpage>2586</lpage>.</mixed-citation>
</ref>
<ref id="C30">
<label>30</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Rong</surname><given-names>Y</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Deep learning provides a new computed tomography-based prognostic biomarker for recurrence prediction in high-grade serous ovarian cancer</article-title>. <source/>Radiother Oncol
<year>2018</year>: <fpage>S0167–8140</fpage>.</mixed-citation>
</ref>
<ref id="C31">
<label>31</label>
<mixed-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Weinberger</surname><given-names>KQ</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Densely connected convolutional networks</article-title>. In: <conf-name>Proceedings of the IEEE conference on computer vision and pattern recognition; 2017</conf-name>, <publisher-name>IEEE</publisher-name>, <year>2017</year>; p. <fpage>3</fpage>.</mixed-citation>
</ref>
<ref id="C32">
<label>32</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kermany</surname><given-names>DS</given-names></name>, <name name-style="western"><surname>Goldbaum</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Cai</surname><given-names>W</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Identifying medical diagnoses and treatable diseases by image-based deep learning</article-title>. <source/>Cell
<year>2018</year>; <volume>172</volume>: <fpage>1122</fpage>–<lpage>1131</lpage>.<pub-id pub-id-type="pmid">29474911</pub-id></mixed-citation>
</ref>
<ref id="C33">
<label>33</label>
<mixed-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Selvaraju</surname><given-names>RR</given-names></name>, <name name-style="western"><surname>Cogswell</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Das</surname><given-names>A</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Grad-CAM: visual explanations from deep networks <italic>via</italic> gradient-based localization</article-title>. In: <conf-name>2017 IEEE International Conference on Computer Vision</conf-name>, <publisher-name>IEEE</publisher-name>, <year>2017</year>; pp. <fpage>618</fpage>–<lpage>626</lpage>.</mixed-citation>
</ref>
<ref id="C34">
<label>34</label>
<mixed-citation publication-type="standard"><person-group person-group-type="author"><name name-style="western"><surname>Kotikalapudi</surname><given-names>R</given-names></name></person-group>
<article-title>keras-vis</article-title>. <ext-link ext-link-type="uri" xlink:href="https://github.com/raghakot/keras-vis">https://github.com/raghakot/keras-vis</ext-link>, <year>2017</year>.</mixed-citation>
</ref>
<ref id="C35">
<label>35</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>Y-Q</given-names></name>, <name name-style="western"><surname>Liang</surname><given-names>C-H</given-names></name>, <name name-style="western"><surname>He</surname><given-names>L</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Development and validation of a radiomics nomogram for preoperative prediction of lymph node metastasis in colorectal cancer</article-title>. <source/>J Clin Oncol
<year>2016</year>; <volume>34</volume>: <fpage>2157</fpage>–<lpage>2164</lpage>.<pub-id pub-id-type="pmid">27138577</pub-id></mixed-citation>
</ref>
<ref id="C36">
<label>36</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gevaert</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Echegaray</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Khuong</surname><given-names>A</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Predictive radiogenomics modeling of EGFR mutation status in lung cancer</article-title>. <source/>Sci Rep
<year>2017</year>; <volume>7</volume>: <fpage>41674</fpage>
<pub-id pub-id-type="doi">10.1038/srep41674</pub-id>.<pub-id pub-id-type="pmid">28139704</pub-id></mixed-citation>
</ref>
<ref id="C37">
<label>37</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>van Griethuysen</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Fedorov</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Parmar</surname><given-names>C</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Computational radiomics system to decode the radiographic phenotype</article-title>. <source/>Cancer Res
<year>2017</year>; <volume>77</volume>: <fpage>e104</fpage>–<lpage>e107</lpage>.<pub-id pub-id-type="pmid">29092951</pub-id></mixed-citation>
</ref>
<ref id="C38">
<label>38</label>
<mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Kim</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Balagurunathan</surname><given-names>Y</given-names></name>, <etal>et al.</etal></person-group>
<article-title>Radiomic features are associated with EGFR mutation status in lung adenocarcinomas</article-title>. <source/>Clin Lung Cancer
<year>2016</year>; <volume>17</volume>: <fpage>441</fpage>–<lpage>448</lpage>.<pub-id pub-id-type="pmid">27017476</pub-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
</pmc-articleset>