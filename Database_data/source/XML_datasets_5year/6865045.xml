<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">

<pmc-articleset><article article-type="review-article" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<?properties open_access?>
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">Genome Med</journal-id>
<journal-id journal-id-type="iso-abbrev">Genome Med</journal-id>
<journal-title-group>
<journal-title>Genome Medicine</journal-title>
</journal-title-group>
<issn pub-type="epub">1756-994X</issn>
<publisher>
<publisher-name>BioMed Central</publisher-name>
<publisher-loc>London</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="pmid">31744524</article-id>
<article-id pub-id-type="pmc">6865045</article-id>
<article-id pub-id-type="publisher-id">689</article-id>
<article-id pub-id-type="doi">10.1186/s13073-019-0689-8</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Review</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Artificial intelligence in clinical and genomic diagnostics</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Dias</surname>
<given-names>Raquel</given-names>
</name>
<xref ref-type="aff" rid="Aff1">1</xref>
<xref ref-type="aff" rid="Aff2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0232-8053</contrib-id>
<name>
<surname>Torkamani</surname>
<given-names>Ali</given-names>
</name>
<address>
<email>atorkama@scripps.edu</email>
</address>
<xref ref-type="aff" rid="Aff1">1</xref>
<xref ref-type="aff" rid="Aff2">2</xref>
</contrib>
<aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000000122199231</institution-id><institution-id institution-id-type="GRID">grid.214007.0</institution-id><institution>The Scripps Translational Science Institute, </institution><institution>The Scripps Research Institute, </institution></institution-wrap>3344 North Torrey Pines Court Suite 300, La Jolla, CA 92037 USA </aff>
<aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000000122199231</institution-id><institution-id institution-id-type="GRID">grid.214007.0</institution-id><institution>Department of Integrative Structural and Computational Biology, </institution><institution>The Scripps Research Institute, </institution></institution-wrap>3344 North Torrey Pines Court Suite 300, La Jolla, CA 92037 USA </aff>
</contrib-group>
<pub-date pub-type="epub">
<day>19</day>
<month>11</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="pmc-release">
<day>19</day>
<month>11</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<year>2019</year>
</pub-date>
<volume>11</volume>
<elocation-id>70</elocation-id>
<history>
<date date-type="received">
<day>10</day>
<month>9</month>
<year>2019</year>
</date>
<date date-type="accepted">
<day>8</day>
<month>11</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-statement>© The Author(s). 2019</copyright-statement>
<license license-type="OpenAccess">
<license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
</license>
</permissions>
<abstract id="Abs1">
<p id="Par1">Artificial intelligence (AI) is the development of computer systems that are able to perform tasks that normally require human intelligence. Advances in AI software and hardware, especially deep learning algorithms and the graphics processing units (GPUs) that power their training, have led to a recent and rapidly increasing interest in medical AI applications. In clinical diagnostics, AI-based computer vision approaches are poised to revolutionize image-based diagnostics, while other AI subtypes have begun to show similar promise in various diagnostic modalities. In some areas, such as clinical genomics, a specific type of AI algorithm known as deep learning is used to process large and complex genomic datasets. In this review, we first summarize the main classes of problems that AI systems are well suited to solve and describe the clinical diagnostic tasks that benefit from these solutions. Next, we focus on emerging methods for specific tasks in clinical genomics, including variant calling, genome annotation and variant classification, and phenotype-to-genotype correspondence. Finally, we end with a discussion on the future potential of AI in individualized medicine applications, especially for risk prediction in common complex diseases, and the challenges, limitations, and biases that must be carefully addressed for the successful deployment of AI in medical applications, particularly those utilizing human genetics and genomics data.</p>
</abstract>
<funding-group>
<award-group>
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006108</institution-id>
<institution>National Center for Advancing Translational Sciences</institution>
</institution-wrap>
</funding-source>
<award-id>TR002306</award-id>
<award-id>RR025774</award-id>
</award-group>
</funding-group>
<funding-group>
<award-group>
<funding-source>
<institution>Stowers Family Foundation</institution>
</funding-source>
<award-id>N/A</award-id>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta>
<meta-name>issue-copyright-statement</meta-name>
<meta-value>© The Author(s) 2019</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="Sec1">
<title>Background</title>
<p id="Par10">Artificial intelligence (AI) is the simulation of intelligence in a non-living agent. In the context of clinical diagnostics, we define AI as any computer system that can correctly interpret health data, especially in its native form as observed by humans. Often, these clinical applications adopt AI frameworks to enable the efficient interpretation of large complex datasets. These AI systems are trained on external health data that have usually been interpreted by humans and that have been minimally processed before exposure to the AI system, for example, clinical images that have been labeled and interpreted by a human expert. The AI system then learns to execute the interpretation task on new health data of the same type, which in clinical diagnostics is often the identification or forecasting of a disease state.</p>
<p id="Par11">AI interpretation tasks can be grouped into problem classes such as computer vision, time series analysis, speech recognition, and natural language processing. Each of these problems is well suited to address specific types of clinical diagnostic tasks [<xref ref-type="bibr" rid="CR1">1</xref>]. For example, computer vision is useful for the interpretation of radiological images, time series analysis is useful for the analysis of continuously streaming health data such as those provided by an electrocardiogram [<xref ref-type="bibr" rid="CR2">2</xref>], speech-recognition techniques can be used for detection of neurological disorders [<xref ref-type="bibr" rid="CR3">3</xref>], and AI-based natural language processing can be helpful in the extraction of meaningful information from electronic health record (EHR) data [<xref ref-type="bibr" rid="CR4">4</xref>]. In some areas, the association between problem classes and diagnostic tasks may not be as obvious; for example, techniques from computer vision are also useful for the identification of functional regulatory elements in the human genome, where they can be used to identify recurrent motifs in DNA sequences in a manner analogous to that in which pixel patterns are detected in images by convolutional neural networks (CNNs; described in the next section) [<xref ref-type="bibr" rid="CR5">5</xref>].</p>
<p id="Par12">Many of these problems have been addressed by a specific group of AI algorithms known as deep learning, which can learn interpretable features from large and complex datasets by using deep neural network architectures. Neural networks are computational systems of artificial neurons (also called ‘nodes’) that transmit signals to one another, often in interconnected layers. The layers that are not the input or output layer are termed the ‘hidden’ layers. A deep neural network consists of many hidden layers of artificial neurons. Neural networks often take as input the fundamental unit of data that it is trained to interpret: for example, pixel intensity in images; diagnostic, prescription, and procedure codes in EHR data; or nucleotide sequence data in genomic applications [<xref ref-type="bibr" rid="CR6">6</xref>]. In other words, unlike most machine-learning approaches, minimal or no human extraction and definition of predictive features are required. A multitude of these simple features are combined in successive layers of the neural network in a variety of ways, as designed by the human neural network architect, in order to represent more sophisticated concepts or features of the input health data. Ultimately, the output of the neural network is the interpretation task that the network has been trained to execute. For example, successive layers of a computer vision algorithm might learn to detect edges in an image, then patterns of edges that represent shapes, then collections of shapes that represent certain objects, and so on. Thus, AI systems synthesize simple features into more complex concepts to derive conclusions about health data in a manner that is analogous to human interpretation, although the complex concepts used by the AI systems are not necessarily recognizable or obvious concepts to humans.</p>
<p id="Par13">In this review, we describe the recent successes and potential future applications of AI, especially deep learning, in clinical diagnostics, with a focus on clinical genomics. We provide a brief overview of AI algorithms and the classes of problems that they are well suited to address. Next, we provide a more detailed review of how AI has been used to accomplish a variety of clinical genomics tasks, including variant calling and annotation, variant impact prediction, and phenotype-to-genotype mapping. Finally, we end by discussing the potential future applications and challenges of AI in genotype-to-phenotype prediction, especially as it relates to common complex diseases and individualized medicine.</p>
</sec>
<sec id="Sec2">
<title>Artificial intelligence and its applications</title>
<p id="Par14">The AI algorithms deployed today for clinical diagnostics are termed ‘narrow’ or ‘weak’ AI. These AI algorithms are trained to perform a single task: for example, to classify images of skin lesions into diagnostic categories or to provide a molecular diagnosis from a combination of genomic and phenotypic data. These algorithms do not display general intelligence and are not flexible enough to address other clinical diagnostic tasks. However, transfer learning approaches can be used to adapt a fully trained AI algorithm to accomplish closely related tasks. This is best exemplified by image-based diagnostic AI algorithms that benefit from advances in computer vision and neural networks trained for general image recognition tasks. Thus, the first step in the design of clinical diagnostic AI algorithms usually involves mapping the specific diagnostic task to a more general problem class. Here, we review these problem classes and briefly highlight the intersection of these techniques with genomics.</p>
<sec id="Sec3">
<title>Computer vision</title>
<p id="Par15">Computer vision is an interdisciplinary field that focuses on acquiring, processing, and analyzing images and/or video. Computer vision algorithms ingest high-dimensional image data and synthesize (or ‘convolute’) it to produce numerical or symbolic representations of concepts that are embedded in the image. This process is thought to mimic the way humans identify patterns and extract meaningful features from images. The main steps in computer vision consist of image acquisition, pre-processing, feature extraction, image pattern detection or segmentation, and classification. Deep-learning algorithms such as CNNs have been designed to perform computer vision tasks. In simplified terms, a typical CNN tiles an input image with small matrices known as kernel nodes or filters. Each filter encodes a pixel intensity pattern that it ‘detects’ as it convolves across the input image. A multitude of filters encoding different pixel intensity patterns convolve across the image to produce two-dimensional activation maps of each filter. The pattern of features detected across the image by these filters may then be used to successively detect the presence of more complex features (Fig. <xref ref-type="fig" rid="Fig1">1</xref>).
<fig id="Fig1"><label>Fig. 1</label><caption><p>Examples of different neural network architectures, their typical workflow, and applications in genomics. <bold>a</bold> Convolutional neural networks break the input image (<italic>top</italic>) or DNA sequence (<italic>bottom</italic>) into subsamples, apply filters or masks to the subsample data, and multiply each feature value by a set of weights. The product then reveals features or patterns (such as conserved motifs) that can be mapped back to the original image. These feature maps can be used to train a classifier (using a feedforward neural network or logistic regression) to predict a given label (for example, whether the conserved motif is a binding target). Masking or filtering out certain base pairs and keeping others in each permutation allows the identification of those elements or motifs that are more important for classifying the sequence correctly. <bold>b</bold> Recurrent neural networks (RNNs) in natural language processing tasks receive a segmented text (<italic>top</italic>) or segmented DNA sequence (<italic>bottom</italic>) and identify connections between input units (<italic>x</italic>) through interconnected hidden states (<italic>h</italic>). Often the hidden states are encoded by unidirectional hidden recurrent nodes that read the input sequence and pass hidden state information in the forward direction only. In this example, we depict a bidirectional RNN that reads the input sequence and passes hidden state information in both forward and backward directions. The context of each input unit is inferred on the basis of its hidden state, which is informed by the hidden state of neighboring input units, and the predicted context labels of the neighboring input units (for example, location versus direction or intron versus exon)</p></caption><graphic id="MO1" xlink:href="13073_2019_689_Fig1_HTML"></graphic></fig></p>
<p id="Par16">Surveillance, image recognition, and autonomous vehicles are some of the major applications of computer vision. In clinical diagnostics, the first applications of AI in healthcare to be cleared by the US Food and Drug Administration (FDA) have been dominated by applications of computer vision to medical scans (for example, magnetic resonance imaging (MRI) or positron emission tomography images), and pathology images (for example, histopathological slides). The first medical imaging applications include the automated quantification of blood flow through the heart via cardiac MRI [<xref ref-type="bibr" rid="CR7">7</xref>], the determination of ejection fraction from echocardiograms [<xref ref-type="bibr" rid="CR8">8</xref>], the detection and volumetric quantification of lung nodules from radiographs [<xref ref-type="bibr" rid="CR7">7</xref>], the detection and quantification of breast densities via mammography [<xref ref-type="bibr" rid="CR9">9</xref>], the detection of stroke, brain bleeds, and other conditions from computerized axial tomography [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR11">11</xref>], and automated screening for diabetic retinopathy from comprehensive dilated eye examination [<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR13">13</xref>]. Imaging applications in pathology include an FDA-cleared system for whole-slide imaging [<xref ref-type="bibr" rid="CR14">14</xref>], and promising approaches to the automated classification of dermatological conditions [<xref ref-type="bibr" rid="CR15">15</xref>], as well as numerous other whole-slide imaging and AI systems in development that are expected to dramatically enhance the efficiency of pathologists [<xref ref-type="bibr" rid="CR16">16</xref>].</p>
<p id="Par17">Computer vision can also inform clinical genomic testing. For example, deep learning of lung cancer histopathological images is able to identify cancer cells, determine their type, and predict what somatic mutations are present in the tumor [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR18">18</xref>]. Similarly, facial image recognition can be used to identify rare genetic disorders and to guide molecular diagnoses [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR20">20</xref>]. Thus, computer vision can extract phenotypic features from medical images in order to provide recommendations for molecular testing in a manner similar to that performed by a skilled pathologist or dysmorphologist. In some cases, AI-based systems have exceeded the capabilities of human experts, for example, by accurately predicting gender from retinal fundus images, a task that human experts would perform no better than random guessing [<xref ref-type="bibr" rid="CR21">21</xref>].</p>
</sec>
<sec id="Sec4">
<title>Time series analysis</title>
<p id="Par18">Time series analysis is the processing of temporal data to forecast future observations, to predict the discrete state producing a sequence of observations (for example, normal heart rhythm versus arrythmia), or to detect anomalies within a sequence of observations. More generally, time series analysis can be applied to any ordered data; for example, to DNA sequence that is ordered but not temporally ordered. Time series analysis algorithms ingest data sequences and are generally tasked to learn sequential dependencies. The primary advantage of AI algorithms in time series analysis is an improved ability to detect non-linear and/or multi-step relationships that are not efficiently interrogated by traditional approaches such as hidden Markov models. Deep-learning algorithms, especially recurrent neural networks (RNNs), have been designed for sequence analysis tasks. A typical RNN includes some form of ‘memory’, in which prior inputs in a sequence influence future output. This is achieved by linking the hidden state of an input to the hidden state of the next input (Fig. <xref ref-type="fig" rid="Fig1">1</xref>). Extensions of this concept, which are implemented in specialized networks such as long short-term memory networks (LSTMs), add network elements that enhance the ability of the network to ‘remember’ long-term dependencies in the input data. CNNs are often applied to time series data when the task is to define the discrete state, or context, that produces the sequential data pattern.</p>
<p id="Par19">Time series analysis has major applications in the forecasting of equity prices, weather conditions, geological events, and essentially any future event of interest. In clinical diagnostics, time series AI algorithms can be applied to medical devices producing continuous output signals, with the application of electrocardiograms being an especially active area of interest. AI applied to electrocardiograms can detect and classify arrythmias [<xref ref-type="bibr" rid="CR22">22</xref>], especially atrial fibrillation [<xref ref-type="bibr" rid="CR23">23</xref>], as well as cardiac contractile dysfunction [<xref ref-type="bibr" rid="CR24">24</xref>], and blood chemistries linked to cardiac rhythm abnormalities [<xref ref-type="bibr" rid="CR25">25</xref>]. When applied to genomic sequence data, AI time series algorithms appear to be especially effective at detecting functional DNA sequence elements that are indicative of gene splicing [<xref ref-type="bibr" rid="CR26">26</xref>, <xref ref-type="bibr" rid="CR27">27</xref>], large-scale regulatory elements [<xref ref-type="bibr" rid="CR28">28</xref>], and gene function [<xref ref-type="bibr" rid="CR29">29</xref>].</p>
</sec>
<sec id="Sec5">
<title>Automatic speech recognition</title>
<p id="Par20">Automatic speech recognition includes a group of methodologies that enable the interpretation of spoken language. Speech-recognition algorithms ingest raw sound waves from human speech and process them to allow the recognition of basic elements of speech including tempo, pitch, timbre, and volume, as well as more complex features of speech including the spoken language, words, and sentences [<xref ref-type="bibr" rid="CR30">30</xref>]. More advanced speech-recognition algorithms can identify sophisticated features from audiological data, such as mood changes or emotional states [<xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR32">32</xref>]. Because of the temporal complexity of speech, traditional speech-recognition algorithms have typically relied on separate models to reassemble meaning from spoken language. These steps include segmenting audio into distinct units of sound (for example, phonemes), connecting those sound units into language units (for example, words), and assembling those language units into more complex language elements (for example, phrases) to extract meaning. Recent advances in AI algorithms that address temporal sequences through sequence-to-sequence attention-based and recurrent neural network transducer-based approaches now allow for these tasks to be executed in a single model with streaming output [<xref ref-type="bibr" rid="CR33">33</xref>, <xref ref-type="bibr" rid="CR34">34</xref>]. In sequence-to-sequence models, for example, a neural network can map the sequences of phonemes produced by an acoustic model into sequences of words, or a sequence of words can be translated into another language. Thus, sequence-to-sequence and other speech-recognition models can also act as powerful tools for the communication of medical and health information across language barriers.</p>
<p id="Par21">Voice command and virtual assistant systems are the major applications of speech recognition. Speech-recognition algorithms have not yet found widespread use in clinical diagnostics but they have shown great promise in the detection of neurological conditions that are often challenging to diagnose with traditional clinical tools. In these clinical applications, the same general speech-recognition strategies are used, but the outcome targeted by the final classification step is a disease phenotype that is typically associated with characteristics of speech (tone, tempo, pitch, and so on) and not necessarily the content of the language. Speech recognition has been successfully applied to the detection of diseases with an obvious influence on speech, notably chronic pharyngitis [<xref ref-type="bibr" rid="CR35">35</xref>], and of diseases with a less obvious influence on speech, including Alzheimer’s disease [<xref ref-type="bibr" rid="CR3">3</xref>], Parkinson’s disease [<xref ref-type="bibr" rid="CR36">36</xref>], major depressive disorder [<xref ref-type="bibr" rid="CR37">37</xref>], posttraumatic stress disorder [<xref ref-type="bibr" rid="CR38">38</xref>], and even coronary artery disease [<xref ref-type="bibr" rid="CR39">39</xref>]. Like imaging, speech recognition can detect potential genetic disorders and inform downstream clinical testing. In addition, speech recognition can be used as a tool to streamline the use of EHRs through automatic transcription, benefitting clinicians and patients and enabling natural language processing (NLP) analysis [<xref ref-type="bibr" rid="CR40">40</xref>, <xref ref-type="bibr" rid="CR41">41</xref>], as described in the next section.</p>
</sec>
<sec id="Sec6">
<title>Natural language processing</title>
<p id="Par22">NLP is the computational extraction of meaning from natural human language. These algorithms take as input a document, or potentially the output from automatic speech recognition, and output a useful transformation of the document. This transformation could be language translation, document classification, summarization, or extraction of higher-level concepts described by the text. Typical NLP algorithms involve syntactic analysis, which involves parsing the written text in a variety of ways to extract useful computational representations of language (by sentence breaking, tagging parts of speech, and standardizing inflected word forms, for example), followed by semantic analysis to extract meaning and/or the identification of named entities from the text. A wide variety of neural network architectures have been developed for NLP depending upon the target outcome, from sequence-to-sequence networks and other RNN variants for language translation [<xref ref-type="bibr" rid="CR42">42</xref>], to CNNs to extract higher-level interpretations of the text [<xref ref-type="bibr" rid="CR43">43</xref>].</p>
<p id="Par23">A major challenge that is addressed by NLP is the variety of synonyms, phrases, and interrelated concepts that can be used to express a singular meaning. This problem is especially pronounced in clinical applications where controlled vocabularies are numerous and in constant flux. Thus, NLP has been effectively used to automatically standardize and synthesize these terms to produce predictions of current and future diagnoses and medical events [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR44">44</xref>]. Similarly, NLP can be used to make health information more accessible by translating educational materials into other languages or by converting medical terms to their lay definitions [<xref ref-type="bibr" rid="CR45">45</xref>]. AI-based chatbots have already been deployed to augment the capabilities of genetic counselors to meet rising demands on their time generated by the rapidly expanding volume of clinical and direct-to-consumer genetic testing [<xref ref-type="bibr" rid="CR46">46</xref>]. In addition, NLP approaches to EHR analysis can overcome the high dimensionality, sparseness, incompleteness, biases, and other confounding factors present in EHR data. For example, NLP has been applied to EHRs to predict patient mortality after hospitalization. In this application, EHR data are converted to a series of patient events streamed into an RNN, which was trained to identify patterns of patient characteristics, diagnoses, demography, medications, and other events that are predictive of near-term patient mortality or hospital readmission [<xref ref-type="bibr" rid="CR4">4</xref>]. Similarly, when combined with other medical data, predictions of disease severity and therapy efficacy can be made [<xref ref-type="bibr" rid="CR47">47</xref>]. When combined with genomic data, NLP-based methods have been used to predict rare disease diagnoses and to drive phenotype-informed genetic analysis, resulting in automated genetic diagnoses with accuracy similar to that of human experts [<xref ref-type="bibr" rid="CR48">48</xref>, <xref ref-type="bibr" rid="CR49">49</xref>].</p>
</sec>
</sec>
<sec id="Sec7">
<title>Artificial intelligence in clinical genomics</title>
<p id="Par24">Mimicking human intelligence is the inspiration for AI algorithms, but AI applications in clinical genomics tend to target tasks that are impractical to perform using human intelligence and error prone when addressed with standard statistical approaches. Many of the techniques described above have been adapted to address the various steps involved in clinical genomic analysis—including variant calling, genome annotation, variant classification, and phenotype-to-genotype correspondence—and perhaps eventually they can also be applied for genotype-to-phenotype predictions. Here, we describe the major classes of problems that have been addressed by AI in clinical genomics.</p>
<sec id="Sec8">
<title>Variant calling</title>
<p id="Par25">The clinical interpretation of genomes is sensitive to the identification of individual genetic variants among the millions populating each genome, necessitating extreme accuracy. Standard variant-calling tools are prone to systematic errors that are associated with the subtleties of sample preparation, sequencing technology, sequence context, and the sometimes unpredictable influence of biology such as somatic mosaicism [<xref ref-type="bibr" rid="CR50">50</xref>]. A mixture of statistical techniques including hand-crafted features such as strand-bias [<xref ref-type="bibr" rid="CR51">51</xref>] or population-level dependencies [<xref ref-type="bibr" rid="CR52">52</xref>] are used to address these issues, resulting in high accuracy but biased errors [<xref ref-type="bibr" rid="CR53">53</xref>]. AI algorithms can learn these biases from a single genome with a known gold standard of reference variant calls and produce superior variant calls. DeepVariant, a CNN-based variant caller trained directly on read alignments without any specialized knowledge about genomics or sequencing platforms, was recently shown to outperform standard tools on some variant-calling tasks [<xref ref-type="bibr" rid="CR54">54</xref>]. The improved accuracy is thought to be due to the ability of CNNs to identify complex dependencies in sequencing data. In addition, recent results suggest that deep learning is poised to revolutionize base calling (and as a result, variant identification) for nanopore-based sequencing technologies, which have historically struggled to compete with established sequencing technology because of the error-prone nature of prior base-calling algorithms [<xref ref-type="bibr" rid="CR55">55</xref>].</p>
</sec>
<sec id="Sec9">
<title>Genome annotation and variant classification</title>
<p id="Par26">After variant calling, the interpretation of human genome data relies on the identification of relevant genetic variants through prior knowledge and inference of the impact of genetic variants on functional genomic elements. AI algorithms can improve the use of prior knowledge by informing phenotype-to-genotype mapping (described in the next section). Here, we describe both genome annotation and variant classification because many of the AI algorithms that are used to predict the presence of a functional element from primary DNA sequence data are also used to predict the impact of a genetic variation on those functional elements.</p>
<sec id="Sec10">
<title>Classification of coding variants</title>
<p id="Par27">Many methods have been developed for the classification of nonsynonymous variants [<xref ref-type="bibr" rid="CR56">56</xref>]. Some of these methods have been integrated into deep-learning-based meta-predictors (models that process and merge the predictions produced by several other predictors) that outperform both their individual predictive components and the combination of those predictive components when integrated using regression or other machine-learning approaches [<xref ref-type="bibr" rid="CR57">57</xref>]. For example, the combined annotation-dependent depletion approach (CADD) [<xref ref-type="bibr" rid="CR58">58</xref>] combines a variety of predictive features in a machine-learning algorithm to predict the deleteriousness of genetic variants. A deep-learning-based extension of CADD, named DANN, demonstrated improved performance using the same set of input features as CADD but combined in a deep neural network [<xref ref-type="bibr" rid="CR57">57</xref>]. This technical extension of CADD suggests that deep learning may be a superior approach for integrating known features that are predictive of deleteriousness. However, the classification accuracies of these tools are not sufficient to drive clinical reporting, although they can be useful for guiding the interpretation of clinical genomic data by prioritizing potential candidate variants for further consideration.</p>
<p id="Par28">More interesting are AI-based methods that make predictions directly from DNA or protein sequence data with minimal hand-crafting of features. One approach, PrimateAI, which used CNNs trained on variants of known pathogenicity with data augmentation using cross-species information, was shown to outperform prior methods when trained directly upon sequence alignments [<xref ref-type="bibr" rid="CR59">59</xref>]. The network was able to learn important protein domains, conserved amino acid positions, and sequence dependencies directly from the training data consisting of about 120,000 human samples. PrimateAI substantially exceeded the performance of other variant pathogenicity prediction tools in differentiating benign and pathogenic de-novo mutations in candidate developmental disorder genes, and in reproducing prior knowledge in Clinvar [<xref ref-type="bibr" rid="CR60">60</xref>]. These results suggest that PrimateAI is an important step forward for variant-classification tools that may lessen the reliance of clinical reporting on prior knowledge. In addition, deep generative models have shown promise for predicting the effects of genetic variants [<xref ref-type="bibr" rid="CR61">61</xref>], and are especially intriguing given their ability to evaluate the joint influence of multiple genetic variants and/or complex indels on protein function, a capability that is largely absent from most pathogenicity prediction tools. Deep generative models are a type of deep neural network that can learn to replicate data distributions and produce examples not previously observed by the model. For example, a deep generative model trained on images of birds could learn to generate novel bird images.</p>
</sec>
<sec id="Sec11">
<title>Classification of non-coding variants</title>
<p id="Par29">The computational identification and prediction of non-coding pathogenic variation is an open challenge in human genomics [<xref ref-type="bibr" rid="CR62">62</xref>]. Recent findings suggest that AI algorithms will substantially improve our ability to understand non-coding genetic variation. Splicing defects in genes are responsible for at least 10% of rare pathogenic genetic variation [<xref ref-type="bibr" rid="CR63">63</xref>], but they can be difficult to identify because of the complexity of intronic and exonic splicing enhancers, silencers, insulators, and other long range and combinatorial DNA interactions that influence gene splicing [<xref ref-type="bibr" rid="CR64">64</xref>]. SpliceAI, a 32-layer deep neural network, is able to predict both canonical and non-canonical splicing directly from exon–intron junction sequence data [<xref ref-type="bibr" rid="CR27">27</xref>]. Remarkably, SpliceAI was able to use long-range sequence information to boost prediction accuracy from 57%, using a short window size (80 nucleotides) typical for many prior splicing prediction tools, to 95% when a 10 kb window size was ingested by the AI algorithm, and was able to identify candidate cryptic splicing variants underlying neurodevelopmental disorders.</p>
<p id="Par30">Deep-learning-based approaches have also substantially improved our ability to detect regulatory elements [<xref ref-type="bibr" rid="CR65">65</xref>, <xref ref-type="bibr" rid="CR66">66</xref>] and to predict the influence of genetic variation on those elements. DeepSEA, a multitask hierarchically structured CNN trained on large-scale functional genomics data [<xref ref-type="bibr" rid="CR67">67</xref>], was able to learn sequence dependencies at multiple scales and simultaneously produce predictions of DNase hypersensitive sites, transcription factor binding sites, histone marks, and the influence of genetic variation on those regulatory elements, with a level of accuracy superior to those of other tools for prioritizing non-coding functional variants [<xref ref-type="bibr" rid="CR68">68</xref>]. As seen for SpliceAI, the ability of DeepSEA to ingest DNA sequences of 1 kb, which is substantially larger than the input to typical motif-based search tools, was critical to this improved performance. Extensions of DeepSEA have been applied to whole-genome sequencing data from families with autism spectrum disorder to reveal several candidate non-coding mutations [<xref ref-type="bibr" rid="CR69">69</xref>]. Further extension to the ExPecto algorithm has demonstrated its ability to predict gene expression levels directly from DNA sequence information [<xref ref-type="bibr" rid="CR70">70</xref>]. Further investigation of these new deep-learning based frameworks for the analysis of non-coding sequence data is likely to provide new insights into the regulatory code of the human genome.</p>
</sec>
</sec>
<sec id="Sec12">
<title>Phenotype-to-genotype mapping</title>
<p id="Par31">Human genomes contain numerous genetic variants that are either previously described as pathogenic or predicted to be pathogenic [<xref ref-type="bibr" rid="CR71">71</xref>], regardless of the individual health status [<xref ref-type="bibr" rid="CR72">72</xref>]. Therefore, the molecular diagnosis of disease often requires both the identification of candidate pathogenic variants and a determination of the correspondence between the diseased individual’s phenotype and those expected to result from each candidate pathogenic variant. AI algorithms can significantly enhance the mapping of phenotype to genotype, especially through the extraction of higher-level diagnostic concepts that are embedded in medical images and EHRs.</p>
<sec id="Sec13">
<title>Image to genetic diagnosis</title>
<p id="Par32">The human phenotype ontology lists 1007 distinct terms defining different abnormalities of the face [<xref ref-type="bibr" rid="CR73">73</xref>]. These abnormalities are associated with 4526 diseases and 2142 genes. A dysmorphologist will often identify these abnormalities individually and synthesize them into a clinical diagnosis. The clinical diagnosis may then inform targeted gene sequencing or phenotype-informed analysis of more comprehensive genetic data. Often the human-provided clinical diagnosis and molecular diagnoses overlap but do not match precisely because of the phenotypic similarity of genetically distinct syndromes. DeepGestalt, a CNN-based facial image analysis algorithm, dramatically outperforms human dysmorphologists in this task and is precise enough to distinguish between molecular diagnoses that are mapped to the same clinical diagnosis (that is, distinct molecular forms of Noonan syndrome) [<xref ref-type="bibr" rid="CR19">19</xref>]. When combined with genomic data, PEDIA, a genome interpretation system incorporating DeepGestalt, was able to use phenotypic features extracted from facial photographs to accurately prioritize candidate pathogenic variants for 105 different monogenic disorders across 679 individuals [<xref ref-type="bibr" rid="CR74">74</xref>]. Deployment of DeepGestalt as a face-scanning app has the potential to both democratize and revolutionize the identification of genetic syndromes [<xref ref-type="bibr" rid="CR20">20</xref>].</p>
<p id="Par33">Genetic syndromes that are identified through facial analysis can be readily confirmed with DNA testing, but adequate material for somatic mutation testing is not always available in some instances of cancer. Nevertheless, knowledge of the genomic underpinnings of a tumor are critical to treatment planning. Here again, AI can bridge the gap between image-derived phenotypes and their probable genetic source. A ‘survival CNN’, which is a combination of a CNN with Cox proportional hazards-based outcomes (a type of statistical survival analysis), was able to learn the histological features of brain tumors that are associated with survival and correlated with somatic mutation status [<xref ref-type="bibr" rid="CR75">75</xref>]. Importantly, this algorithm was not trained to predict genomic aberrations directly. Inspection of the CNN concepts used to make the survival predictions identified novel histological features that are important for prognosis determination. Like the faces of individuals with phenotypically overlapping genetic syndromes, these results suggest that the genomic aberrations underpinning an individual’s tumor could potentially be predicted directly from tumor histology images. More generally, AI-based computer vision systems appear to be capable of predicting the genomic aberrations that are likely to be present in an individual’s genome on the basis of the complex phenotypes embedded in relevant clinical images [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR75">75</xref>].</p>
</sec>
<sec id="Sec14">
<title>EHR to genetic diagnosis</title>
<p id="Par34">Disease phenotypes can be complex and multimodal; captured not only by medical imaging, but also by biochemical and other tests that may be ordered at different times and perhaps by different physicians during the course of a differential diagnosis. These results are documented in an EHR where physicians synthesize these findings to provide diagnoses and inform clinical decision-making. Although human specialists can accomplish this task accurately within their area of expertise, AI-based algorithms can be general EHR pattern recognition experts. In a recent study involving more than 500,000 patients, an AI-based NLP approach was used to extract clinically relevant features from EHR data. A hierarchical statistical model, tiered on the basis of anatomic divisions in a manner meant to mimic the clinical reasoning of a composite of experienced physicians, was trained on the NLP output to generate a diagnostic system [<xref ref-type="bibr" rid="CR48">48</xref>]. Overall, this system was able to differentiate between 55 common pediatric diagnoses with 92% accuracy.</p>
<p id="Par35">When linked with genomic data, an AI-based diagnostic agent coupled with a genome interpretation system can rapidly produce genetic diagnoses. For example, an NLP system was designed to extract phenotypic descriptions automatically from EHR data of pediatric patients with rare diseases, and to rank matches to the expected phenotypic features of candidate pathogenic variants in the patients’ genomes [<xref ref-type="bibr" rid="CR49">49</xref>]. In 101 children with 105 genetic diseases, automated retrospective genomic diagnoses agreed with expert human interpretation at 97% recall and 99% precision. The system was also able to provide automated genomic diagnoses prospectively for three of seven seriously ill ICU infants. Intriguingly, a simpler phenotypic risk score approach, applied to an adult population with EHR and genomic data, was able to identify previously unrecognized monogenic conditions in 18 individuals from a population of 21,701 [<xref ref-type="bibr" rid="CR76">76</xref>]. These results suggest that AI-based phenotype-to-genotype mapping approaches could significantly improve the diagnostic yield of genetic testing and the identification of individuals with unrecognized genetic disorders.</p>
</sec>
</sec>
<sec id="Sec15">
<title>Genotype-to-phenotype prediction</title>
<p id="Par36">Ultimately, the clinical purpose of genetics is to provide diagnoses and forecasts of future disease risk. Relatively simple statistical approaches to polygenic risk prediction allow for personally and clinically useful stratification of risk for some common complex diseases [<xref ref-type="bibr" rid="CR77">77</xref>]. A few studies have attempted genomic prediction of complex human traits using AI algorithms, but most of those reported in the literature to date are probably overfit as they purportedly explain substantially more trait variance than should be possible on the basis of heritability estimates. One application of machine learning to genomic prediction of height was able to provide relatively accurate predictions within expected bounds [<xref ref-type="bibr" rid="CR78">78</xref>], suggesting that AI-based methods can be used to improve upon statistical techniques. However, the true utility of AI-based approaches in genotype-to-phenotype prediction will probably come from the integration of a variety of health data types and risk factors into comprehensive predictors of disease risk.</p>
<p id="Par37">Common diseases are a result of a complex interplay between inherited genetic risk factors, environmental exposures, and behaviors. Genetic risk alone provides a baseline estimate of lifetime risk for disease, but genetic risk combined with other risk factors allows for a narrowing of that probability space into a short-term projection of disease risk. For example, several non-genetic risk factors are associated with breast cancer risk, including mammographic density, age at first birth, age at menarche, and age at menopause. Combining these non-genetic risk factors with genetic data significantly improves the accuracy of breast cancer risk models and can inform risk-based mammographic screening strategies [<xref ref-type="bibr" rid="CR79">79</xref>]. Similarly, significant improvement in risk stratification can be achieved by integrating conventional and genetic risk factors for coronary artery disease [<xref ref-type="bibr" rid="CR80">80</xref>]. Genetic risk score models are more useful than simple pathogenicity assertions in cases where a common disease is the result of a combination of weak effects from multiple loci. However, current models integrate genetic and non-genetic risk factors in simple additive models that probably do not capture the complex causal relationships between these heterogenous risk factors. AI algorithms, given an appropriate volume of data, excel at dissecting this complexity. Unraveling the complex interplay between genetic data, EHR data, digital health monitoring devices, and other sources of health information with AI-based algorithms is a compelling prospect for the future.</p>
</sec>
</sec>
<sec id="Sec16">
<title>Challenges and limitations</title>
<p id="Par38">AI-based algorithms can be superhuman in their ability to interpret complex data. However, their power and complexity can also result in spurious or even unethical and discriminatory conclusions when applied to human health data. Without careful consideration of the methods and biases embedded in a trained AI system, the practical utility of these systems in clinical diagnostics is limited. Thus, we end with a discussion on the challenges and limitations of AI in clinical diagnostics.</p>
<sec id="Sec17">
<title>Regulatory issues</title>
<p id="Par39">A growing number of AI algorithms have been approved by the FDA [<xref ref-type="bibr" rid="CR81">81</xref>]. These algorithms raise a number of regulatory and ethical challenges around the sourcing and privacy of the data used to train the algorithms [<xref ref-type="bibr" rid="CR82">82</xref>], the transparency and generalizability of the underlying algorithms themselves, the regulatory process for refreshing these algorithms as further data become available, and the liability associated with prediction errors [<xref ref-type="bibr" rid="CR83">83</xref>]. Some of these issues can and should be addressed by open sharing of AI models in detail (including source codes, model weights, meta graphs, and so on) with the scientific and medical community to improve transparency. Other issues will need to be addressed by the development of: (i) best practices for the interpretability of predictions to protect patient autonomy and shared decision-making; (ii) fairness standards to minimize disparities induced by machine bias; and (iii) ad hoc guidance to allow for continuous improvement of the algorithms [<xref ref-type="bibr" rid="CR83">83</xref>]. As with most biomedical advances, the cost and expertise necessary to deploy AI algorithms is another concern, although these concerns diminish as interpretability and fairness issues are addressed. We explore these issues in further detail below.</p>
</sec>
<sec id="Sec18">
<title>AI interpretability</title>
<p id="Par40">AI is often criticized for being a ‘black box’: a system that produces an output without any explanation or justification. While this is perfectly acceptable in low-risk situations, clinical decision-making is not a low-risk situation. ‘What?’ may sufficiently encompass the question of interest in a general object-detection task, but ‘why?’ is an inherent part of the question in most clinical diagnostic tasks, because it is often crucial to subsequent clinical decision-making or at least necessary for acceptance of the prediction by both physicians and patients. An ideal AI-based clinical diagnostic system should produce accurate predictions and provide human-interpretable explanations of those predictions. A common approach to answering ‘why?’ in computer vision applications is to generate a visual overlay of the portions of an image that contribute most strongly to an output prediction [<xref ref-type="bibr" rid="CR84">84</xref>, <xref ref-type="bibr" rid="CR85">85</xref>]. This strategy works well for image-based and other CNN-based clinical diagnostic tasks. In fact, many of the AI-based clinical diagnostic methods described in this review include some form of interpretive analysis. Thus, although AI interpretability is an important problem in general, the criticism of ‘black box’ systems in current AI-based clinical diagnostics may be overstated.</p>
<p id="Par41">When complex interdependencies form the basis of a prediction, however, accurate interpretation of AI output becomes quite challenging [<xref ref-type="bibr" rid="CR86">86</xref>]. Interpretable machine-learning methods are an active area of computer science research [<xref ref-type="bibr" rid="CR87">87</xref>], but most interpretable AI approaches involve the production of a simplified and potentially inaccurate approximation of the more complex AI system [<xref ref-type="bibr" rid="CR86">86</xref>]. Recently, a move towards more interactive models of interpretability through ‘dialogue’ with the AI system has been proposed [<xref ref-type="bibr" rid="CR86">86</xref>]. This approach allows the human user to ask contrastive questions of the AI system in order to explore how its output predictions would change if inputs were modified. This approach could also facilitate a dialogue between physician and patient, with the aid of the AI interpretation system, to help them to understand the clinical diagnosis and, in some instances, the risk factors that could be modified to change the predicted outcome. Thus, further improvements to interpretable AI systems could not only substantially enhance the acceptability of AI predictions but also enhance the transparency of health communication between physicians and patients.</p>
</sec>
<sec id="Sec19">
<title>Data and machine bias</title>
<p id="Par42">Interpretative output is not only necessary for acceptance in clinical practice but is also important for unveiling the knowledge discovered by AI systems and for detecting biases that may result in undesirable behavior. There is substructure embedded in genomic and health data. Some substructure is due to truly differing causal relationships between alleged risk factors and health outcomes, whereas other substructure can be attributed to external factors such as socioeconomic status, cultural practices, unequal representation, and other non-causal factors that relate to the delivery and accessibility of medicine and clinical tests rather than to their efficacy [<xref ref-type="bibr" rid="CR88">88</xref>, <xref ref-type="bibr" rid="CR89">89</xref>]. AI systems must be carefully applied to differentiate between these types of bias. When medical AI systems are not inspected for non-causal bias, they can act as propagators of disparity. For example, DeepGestalt, the previously described AI system for facial dysmorphology analysis, displayed poor accuracy for the identification of Down syndrome in individuals of African versus European ancestry (36.8% versus 80%, respectively) [<xref ref-type="bibr" rid="CR90">90</xref>]. Retraining the model with examples of Down syndrome in individuals of African ancestry improved the diagnosis of Down syndrome in individuals of African ancestry to 94.7% [<xref ref-type="bibr" rid="CR90">90</xref>]. Genetic risk prediction is also prone to unequal performance in different population groups because of underrepresentation in the training data [<xref ref-type="bibr" rid="CR91">91</xref>].</p>
<p id="Par43">However, not all machine bias can be resolved by addressing underrepresentation in training data. In some cases, the bias is embedded in ostensibly representative training data. For example, gender bias is common in written documents and can be rapidly incorporated into NLP systems [<xref ref-type="bibr" rid="CR92">92</xref>]. Extensions to these models were required to ‘debias’ word embeddings. In clinical applications, EHR data may be representative overall, but the contents may include biases that result from the delivery of care or physician bias. For example, recent immigrants in Canada are more likely to receive aggressive care and die in intensive care units than are other residents [<xref ref-type="bibr" rid="CR93">93</xref>]. Furthermore, the substructure of genomic data is correlated with population structure, which can lead to the appearance of non-causal trait associations [<xref ref-type="bibr" rid="CR94">94</xref>]. However, tools that will help to address machine bias are being developed, and careful attention to these issues could not only help to resolve machine bias issues but could eventually lead to diagnostic systems that are free from human bias [<xref ref-type="bibr" rid="CR95">95</xref>].</p>
</sec>
</sec>
<sec id="Sec20">
<title>Conclusions and future directions</title>
<p id="Par44">AI systems have surpassed the performance of state-of-the-art methods and have gained FDA clearance for a variety of clinical diagnostics, especially imaging-based diagnostics. The availability of large datasets for training, for example, large collections of annotated medical images or large functional genomics datasets, in conjunction with advances in AI algorithms and in the GPU systems used to train them, is driving this surge of productivity. Currently, the most promising applications of AI in clinical genomics appear to be the AI extraction of deep phenotypic information from images, EHRs, and other medical devices to inform downstream genetic analysis. However, deep-learning algorithms have also shown tremendous promise in a variety of clinical genomics tasks such as variant calling, genome annotation, and functional impact prediction. It is possible that more generalized AI tools will become the standard in these areas, especially for clinical genomics tasks where inference from complex data (that is, variant calling) is a frequently recurring task. These applications have benefited from advances in CNNs and RNNs which appear to be particularly well suited for the analysis of genomic data. Yet, the utility of AI algorithms as the ultimate clinical decision support tool in predicting common complex human phenotypes has not been convincingly demonstrated. The rise of biobank-scale efforts with longitudinal health data collection, such as the UK Biobank [<xref ref-type="bibr" rid="CR96">96</xref>] and All of Us Research Program [<xref ref-type="bibr" rid="CR97">97</xref>], will potentially provide the training datasets necessary to make this goal a reality. Given the reliance of AI on large-scale training datasets, it is likely that the scalable collection of phenotype data, and not genomic data, will be the more difficult barrier to overcome in realizing this ambition. Modern DNA sequencing technology allows for the generation of genomic data uniformly and at scale, but the collection of phenotype data requires numerous data collection modes, and tends to be slow, expensive, and highly variable across collection sites. Finally, the interpretability and identification of machine bias are essential to broad acceptance of AI technology in any clinical diagnostic modality.</p>
</sec>
</body>
<back>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item>
<term>AI</term>
<def>
<p id="Par2">Artificial intelligence</p>
</def>
</def-item>
<def-item>
<term>CADD</term>
<def>
<p id="Par3">Combined annotation-dependent depletion approach</p>
</def>
</def-item>
<def-item>
<term>CNN</term>
<def>
<p id="Par4">Convolutional neural network</p>
</def>
</def-item>
<def-item>
<term>EHR</term>
<def>
<p id="Par5">Electronic health record</p>
</def>
</def-item>
<def-item>
<term>FDA</term>
<def>
<p id="Par6">US Food and Drug Administration</p>
</def>
</def-item>
<def-item>
<term>GPU</term>
<def>
<p id="Par7">Graphics processing unit</p>
</def>
</def-item>
<def-item>
<term>NLP</term>
<def>
<p id="Par8">Natural language processing</p>
</def>
</def-item>
<def-item>
<term>RNN</term>
<def>
<p id="Par9">Recurrent neural network</p>
</def>
</def-item>
</def-list>
</glossary>
<fn-group>
<fn>
<p>
<bold>Publisher’s Note</bold>
</p>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</fn>
</fn-group>
<notes notes-type="author-contribution">
<title>Authors’ contributions</title>
<p>RD and AT wrote the manuscript. Both authors read and approved the final manuscript.</p>
</notes>
<notes notes-type="funding-information">
<title>Funding</title>
<p>This work is supported by an NIH-NCATS Clinical and Translational Science Award (5 UL1 RR025774), a National Center for Data to Health Award (5 U24 TR002306), and the Stowers Foundation.</p>
</notes>
<notes notes-type="COI-statement">
<title>Competing interests</title>
<p id="Par45">The authors declare that they have no competing interests.</p>
</notes>
<ref-list id="Bib1">
<title>References</title>
<ref id="CR1">
<label>1.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Torkamani</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Andersen</surname>
<given-names>KG</given-names>
</name>
<name>
<surname>Steinhubl</surname>
<given-names>SR</given-names>
</name>
<name>
<surname>Topol</surname>
<given-names>EJ</given-names>
</name>
</person-group>
<article-title>High-definition medicine</article-title>
<source/>Cell.
          <year>2017</year>
<volume>170</volume>
<fpage>828</fpage>
<lpage>843</lpage>
<pub-id pub-id-type="doi">10.1016/j.cell.2017.08.007</pub-id>
<pub-id pub-id-type="pmid">28841416</pub-id>
</element-citation>
</ref>
<ref id="CR2">
<label>2.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Esteva</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Robicquet</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Ramsundar</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Kuleshov</surname>
<given-names>V</given-names>
</name>
<name>
<surname>DePristo</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Chou</surname>
<given-names>K</given-names>
</name>
<etal></etal>
</person-group>
<article-title>A guide to deep learning in healthcare</article-title>
<source/>Nat Med
          <year>2019</year>
<volume>25</volume>
<fpage>24</fpage>
<lpage>29</lpage>
<pub-id pub-id-type="doi">10.1038/s41591-018-0316-z</pub-id>
<pub-id pub-id-type="pmid">30617335</pub-id>
</element-citation>
</ref>
<ref id="CR3">
<label>3.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Fraser</surname>
<given-names>KC</given-names>
</name>
<name>
<surname>Meltzer</surname>
<given-names>JA</given-names>
</name>
<name>
<surname>Rudzicz</surname>
<given-names>F</given-names>
</name>
</person-group>
<article-title>Linguistic features identify Alzheimer’s disease in narrative speech</article-title>
<source/>J Alzheimers Dis
          <year>2016</year>
<volume>49</volume>
<fpage>407</fpage>
<lpage>422</lpage>
<pub-id pub-id-type="doi">10.3233/JAD-150520</pub-id>
<pub-id pub-id-type="pmid">26484921</pub-id>
</element-citation>
</ref>
<ref id="CR4">
<label>4.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rajkomar</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Oren</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Dai</surname>
<given-names>AM</given-names>
</name>
<name>
<surname>Hajaj</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>PJ</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Scalable and accurate deep learning for electronic health records</article-title>
<source/>NPJ Digit Med
          <year>2018</year>
<volume>1</volume>
<fpage>18</fpage>
<pub-id pub-id-type="doi">10.1038/s41746-018-0029-1</pub-id>
<pub-id pub-id-type="pmid">31304302</pub-id>
</element-citation>
</ref>
<ref id="CR5">
<label>5.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zou</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Huss</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Abid</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Mohammadi</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Torkamani</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Telenti</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>A primer on deep learning in genomics</article-title>
<source/>Nat Genet
          <year>2019</year>
<volume>51</volume>
<fpage>12</fpage>
<lpage>18</lpage>
<pub-id pub-id-type="doi">10.1038/s41588-018-0295-5</pub-id>
<pub-id pub-id-type="pmid">30478442</pub-id>
</element-citation>
</ref>
<ref id="CR6">
<label>6.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Eraslan</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Avsec</surname>
<given-names>Ž</given-names>
</name>
<name>
<surname>Gagneur</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Theis</surname>
<given-names>FJ</given-names>
</name>
</person-group>
<article-title>Deep learning: new computational modelling techniques for genomics</article-title>
<source/>Nat Rev Genet.
          <year>2019</year>
<volume>20</volume>
<fpage>389</fpage>
<lpage>403</lpage>
<pub-id pub-id-type="doi">10.1038/s41576-019-0122-6</pub-id>
<pub-id pub-id-type="pmid">30971806</pub-id>
</element-citation>
</ref>
<ref id="CR7">
<label>7.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Retson</surname>
<given-names>TA</given-names>
</name>
<name>
<surname>Besser</surname>
<given-names>AH</given-names>
</name>
<name>
<surname>Sall</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Golden</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Hsiao</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Machine learning and deep neural networks in thoracic and cardiovascular imaging</article-title>
<source/>J Thorac Imaging
          <year>2019</year>
<volume>34</volume>
<fpage>192</fpage>
<lpage>201</lpage>
<pub-id pub-id-type="doi">10.1097/RTI.0000000000000385</pub-id>
<pub-id pub-id-type="pmid">31009397</pub-id>
</element-citation>
</ref>
<ref id="CR8">
<label>8.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Asch</surname>
<given-names>FM</given-names>
</name>
<name>
<surname>Abraham</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Jankowski</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Cleve</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Adams</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Romano</surname>
<given-names>N</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Accuracy and reproducibility of a novel artificial intelligence deep learning-based algorithm for automated calculation of ejection fraction in echocardiography</article-title>
<source/>J Am Coll Cardiol
          <year>2019</year>
<volume>73</volume>
<issue>9 Supplement 1</issue>
<fpage>1447</fpage>
<pub-id pub-id-type="doi">10.1016/S0735-1097(19)32053-4</pub-id>
<pub-id pub-id-type="pmid">30922476</pub-id>
</element-citation>
</ref>
<ref id="CR9">
<label>9.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Le</surname>
<given-names>EPV</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Huang</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Hickman</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Gilbert</surname>
<given-names>FJ</given-names>
</name>
</person-group>
<article-title>Artificial intelligence in breast imaging</article-title>
<source/>Clin Radiol
          <year>2019</year>
<volume>74</volume>
<fpage>357</fpage>
<lpage>366</lpage>
<pub-id pub-id-type="doi">10.1016/j.crad.2019.02.006</pub-id>
<pub-id pub-id-type="pmid">30898381</pub-id>
</element-citation>
</ref>
<ref id="CR10">
<label>10.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Majumdar</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Brattain</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Telfer</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Farris</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Scalera</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>Detecting intracranial hemorrhage with deep learning</article-title>
<source/>Conf Proc IEEE Eng Med Biol Soc
          <year>2018</year>
<volume>2018</volume>
<fpage>583</fpage>
<lpage>587</lpage>
<pub-id pub-id-type="pmid">30440464</pub-id>
</element-citation>
</ref>
<ref id="CR11">
<label>11.</label>
<mixed-citation publication-type="other">FDA approves stroke-detecting AI software. Nat Biotechnol. 2018;36:290. 10.1038/nbt0418-290.</mixed-citation>
</ref>
<ref id="CR12">
<label>12.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gulshan</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Peng</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Coram</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Stumpe</surname>
<given-names>MC</given-names>
</name>
<name>
<surname>Wu</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Narayanaswamy</surname>
<given-names>A</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs</article-title>
<source/>JAMA.
          <year>2016</year>
<volume>316</volume>
<fpage>2402</fpage>
<lpage>2410</lpage>
<pub-id pub-id-type="doi">10.1001/jama.2016.17216</pub-id>
<pub-id pub-id-type="pmid">27898976</pub-id>
</element-citation>
</ref>
<ref id="CR13">
<label>13.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>van der Heijden</surname>
<given-names>AA</given-names>
</name>
<name>
<surname>Abramoff</surname>
<given-names>MD</given-names>
</name>
<name>
<surname>Verbraak</surname>
<given-names>F</given-names>
</name>
<name>
<surname>van Hecke</surname>
<given-names>MV</given-names>
</name>
<name>
<surname>Liem</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Nijpels</surname>
<given-names>G</given-names>
</name>
</person-group>
<article-title>Validation of automated screening for referable diabetic retinopathy with the IDx-DR device in the Hoorn diabetes care system</article-title>
<source/>Acta Ophthalmol
          <year>2018</year>
<volume>96</volume>
<fpage>63</fpage>
<lpage>68</lpage>
<pub-id pub-id-type="doi">10.1111/aos.13613</pub-id>
<pub-id pub-id-type="pmid">29178249</pub-id>
</element-citation>
</ref>
<ref id="CR14">
<label>14.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Evans</surname>
<given-names>AJ</given-names>
</name>
<name>
<surname>Bauer</surname>
<given-names>TW</given-names>
</name>
<name>
<surname>Bui</surname>
<given-names>MM</given-names>
</name>
<name>
<surname>Cornish</surname>
<given-names>TC</given-names>
</name>
<name>
<surname>Duncan</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Glassy</surname>
<given-names>EF</given-names>
</name>
<etal></etal>
</person-group>
<article-title>US Food and Drug Administration approval of whole slide imaging for primary diagnosis: a key milestone is reached and new questions are raised</article-title>
<source/>Arch Pathol Lab Med
          <year>2018</year>
<volume>142</volume>
<fpage>1383</fpage>
<lpage>1387</lpage>
<pub-id pub-id-type="doi">10.5858/arpa.2017-0496-CP</pub-id>
<pub-id pub-id-type="pmid">29708429</pub-id>
</element-citation>
</ref>
<ref id="CR15">
<label>15.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Esteva</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Kuprel</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Novoa</surname>
<given-names>RA</given-names>
</name>
<name>
<surname>Ko</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Swetter</surname>
<given-names>SM</given-names>
</name>
<name>
<surname>Blau</surname>
<given-names>HM</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Dermatologist-level classification of skin cancer with deep neural networks</article-title>
<source/>Nature.
          <year>2017</year>
<volume>542</volume>
<fpage>115</fpage>
<lpage>118</lpage>
<pub-id pub-id-type="doi">10.1038/nature21056</pub-id>
<pub-id pub-id-type="pmid">28117445</pub-id>
</element-citation>
</ref>
<ref id="CR16">
<label>16.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Niazi</surname>
<given-names>MKK</given-names>
</name>
<name>
<surname>Parwani</surname>
<given-names>AV</given-names>
</name>
<name>
<surname>Gurcan</surname>
<given-names>MN</given-names>
</name>
</person-group>
<article-title>Digital pathology and artificial intelligence</article-title>
<source/>Lancet Oncol
          <year>2019</year>
<volume>29</volume>
<fpage>e253</fpage>
<lpage>e261</lpage>
<pub-id pub-id-type="doi">10.1016/S1470-2045(19)30154-8</pub-id>
</element-citation>
</ref>
<ref id="CR17">
<label>17.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Rios Velazquez</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Parmar</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Coroller</surname>
<given-names>TP</given-names>
</name>
<name>
<surname>Cruz</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Stringfield</surname>
<given-names>O</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Somatic mutations drive distinct imaging phenotypes in lung cancer</article-title>
<source/>Cancer Res
          <year>2017</year>
<volume>77</volume>
<fpage>3922</fpage>
<lpage>3930</lpage>
<pub-id pub-id-type="doi">10.1158/0008-5472.CAN-17-0122</pub-id>
<pub-id pub-id-type="pmid">28566328</pub-id>
</element-citation>
</ref>
<ref id="CR18">
<label>18.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Coudray</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Ocampo</surname>
<given-names>PS</given-names>
</name>
<name>
<surname>Sakellaropoulos</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Narula</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Snuderl</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Fenyö</surname>
<given-names>D</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Classification and mutation prediction from non-small cell lung cancer histopathology images using deep learning</article-title>
<source/>Nat Med
          <year>2018</year>
<volume>24</volume>
<fpage>1559</fpage>
<lpage>1567</lpage>
<pub-id pub-id-type="doi">10.1038/s41591-018-0177-5</pub-id>
<pub-id pub-id-type="pmid">30224757</pub-id>
</element-citation>
</ref>
<ref id="CR19">
<label>19.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gurovich</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Hanani</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Bar</surname>
<given-names>O</given-names>
</name>
<name>
<surname>Nadav</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Fleischer</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Gelbman</surname>
<given-names>D</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Identifying facial phenotypes of genetic disorders using deep learning</article-title>
<source/>Nat Med
          <year>2019</year>
<volume>25</volume>
<fpage>60</fpage>
<lpage>64</lpage>
<pub-id pub-id-type="doi">10.1038/s41591-018-0279-0</pub-id>
<pub-id pub-id-type="pmid">30617323</pub-id>
</element-citation>
</ref>
<ref id="CR20">
<label>20.</label>
<mixed-citation publication-type="other">Dolgin E. AI face-scanning app spots signs of rare genetic disorders. Nature. 2019. 10.1038/d41586-019-00027-x.</mixed-citation>
</ref>
<ref id="CR21">
<label>21.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Poplin</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Varadarajan</surname>
<given-names>AV</given-names>
</name>
<name>
<surname>Blumer</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>McConnell</surname>
<given-names>MV</given-names>
</name>
<name>
<surname>Corrado</surname>
<given-names>GS</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning</article-title>
<source/>Nat Biomed Eng
          <year>2018</year>
<volume>2</volume>
<fpage>158</fpage>
<lpage>164</lpage>
<pub-id pub-id-type="doi">10.1038/s41551-018-0195-0</pub-id>
<pub-id pub-id-type="pmid">31015713</pub-id>
</element-citation>
</ref>
<ref id="CR22">
<label>22.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hannun</surname>
<given-names>AY</given-names>
</name>
<name>
<surname>Rajpurkar</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Haghpanahi</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Tison</surname>
<given-names>GH</given-names>
</name>
<name>
<surname>Bourn</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Turakhia</surname>
<given-names>MP</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network</article-title>
<source/>Nat Med
          <year>2019</year>
<volume>25</volume>
<fpage>65</fpage>
<lpage>69</lpage>
<pub-id pub-id-type="doi">10.1038/s41591-018-0268-3</pub-id>
<pub-id pub-id-type="pmid">30617320</pub-id>
</element-citation>
</ref>
<ref id="CR23">
<label>23.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Tison</surname>
<given-names>GH</given-names>
</name>
<name>
<surname>Sanchez</surname>
<given-names>JM</given-names>
</name>
<name>
<surname>Ballinger</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Singh</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Olgin</surname>
<given-names>JE</given-names>
</name>
<name>
<surname>Pletcher</surname>
<given-names>MJ</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Passive detection of atrial fibrillation using a commercially available smartwatch</article-title>
<source/>JAMA Cardiol
          <year>2018</year>
<volume>3</volume>
<fpage>409</fpage>
<lpage>416</lpage>
<pub-id pub-id-type="doi">10.1001/jamacardio.2018.0136</pub-id>
<pub-id pub-id-type="pmid">29562087</pub-id>
</element-citation>
</ref>
<ref id="CR24">
<label>24.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Attia</surname>
<given-names>ZI</given-names>
</name>
<name>
<surname>Kapa</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Lopez-Jimenez</surname>
<given-names>F</given-names>
</name>
<name>
<surname>McKie</surname>
<given-names>PM</given-names>
</name>
<name>
<surname>Ladewig</surname>
<given-names>DJ</given-names>
</name>
<name>
<surname>Satam</surname>
<given-names>G</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Screening for cardiac contractile dysfunction using an artificial intelligence-enabled electrocardiogram</article-title>
<source/>Nat Med
          <year>2019</year>
<volume>25</volume>
<fpage>70</fpage>
<lpage>74</lpage>
<pub-id pub-id-type="doi">10.1038/s41591-018-0240-2</pub-id>
<pub-id pub-id-type="pmid">30617318</pub-id>
</element-citation>
</ref>
<ref id="CR25">
<label>25.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Galloway</surname>
<given-names>CD</given-names>
</name>
<name>
<surname>Valys</surname>
<given-names>AV</given-names>
</name>
<name>
<surname>Shreibati</surname>
<given-names>JB</given-names>
</name>
<name>
<surname>Treiman</surname>
<given-names>DL</given-names>
</name>
<name>
<surname>Petterson</surname>
<given-names>FL</given-names>
</name>
<name>
<surname>Gundotra</surname>
<given-names>VP</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Development and validation of a deep-learning model to screen for hyperkalemia from the electrocardiogram</article-title>
<source/>JAMA Cardiol
          <year>2019</year>
<volume>4</volume>
<fpage>428</fpage>
<lpage>436</lpage>
<pub-id pub-id-type="doi">10.1001/jamacardio.2019.0640</pub-id>
<pub-id pub-id-type="pmid">30942845</pub-id>
</element-citation>
</ref>
<ref id="CR26">
<label>26.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Leung</surname>
<given-names>MKK</given-names>
</name>
<name>
<surname>Xiong</surname>
<given-names>HY</given-names>
</name>
<name>
<surname>Lee</surname>
<given-names>LJ</given-names>
</name>
<name>
<surname>Frey</surname>
<given-names>BJ</given-names>
</name>
</person-group>
<article-title>Deep learning of the tissue-regulated splicing code</article-title>
<source/>Bioinformatics.
          <year>2014</year>
<volume>30</volume>
<fpage>i121</fpage>
<lpage>i129</lpage>
<pub-id pub-id-type="doi">10.1093/bioinformatics/btu277</pub-id>
<pub-id pub-id-type="pmid">24931975</pub-id>
</element-citation>
</ref>
<ref id="CR27">
<label>27.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Jaganathan</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Kyriazopoulou Panagiotopoulou</surname>
<given-names>S</given-names>
</name>
<name>
<surname>McRae</surname>
<given-names>JF</given-names>
</name>
<name>
<surname>Darbandi</surname>
<given-names>SF</given-names>
</name>
<name>
<surname>Knowles</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Li</surname>
<given-names>YI</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Predicting splicing from primary sequence with deep learning</article-title>
<source/>Cell
          <year>2019</year>
<volume>176</volume>
<fpage>535</fpage>
<lpage>548</lpage>
<pub-id pub-id-type="doi">10.1016/j.cell.2018.12.015</pub-id>
<pub-id pub-id-type="pmid">30661751</pub-id>
</element-citation>
</ref>
<ref id="CR28">
<label>28.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Quang</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Xie</surname>
<given-names>X</given-names>
</name>
</person-group>
<article-title>DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences</article-title>
<source/>Nucleic Acids Res
          <year>2016</year>
<volume>44</volume>
<fpage>e107</fpage>
<pub-id pub-id-type="doi">10.1093/nar/gkw226</pub-id>
<pub-id pub-id-type="pmid">27084946</pub-id>
</element-citation>
</ref>
<ref id="CR29">
<label>29.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wang</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Cao</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Zhang</surname>
<given-names>JZH</given-names>
</name>
<name>
<surname>Qi</surname>
<given-names>Y</given-names>
</name>
</person-group>
<article-title>Computational protein design with deep learning neural networks</article-title>
<source/>Sci Rep
          <year>2018</year>
<volume>8</volume>
<fpage>6349</fpage>
<pub-id pub-id-type="doi">10.1038/s41598-018-24760-x</pub-id>
<pub-id pub-id-type="pmid">29679026</pub-id>
</element-citation>
</ref>
<ref id="CR30">
<label>30.</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Li</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Deng</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Haeb-Umbach</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Gong</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Li</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Deng</surname>
<given-names>L</given-names>
</name>
<etal></etal>
</person-group>
<person-group person-group-type="editor">
<name>
<surname>Li</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Deng</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Haeb-Umbach</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Gong</surname>
<given-names>Y</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Fundamentals of speech recognition</article-title>
<source/>Robust automatic speech recognition: a bridge to practical applications
          <year>2016</year>
<publisher-loc>Academic Press</publisher-loc>
<publisher-name>New York</publisher-name>
<fpage>9</fpage>
<lpage>40</lpage>
</element-citation>
</ref>
<ref id="CR31">
<label>31.</label>
<mixed-citation publication-type="other">Parthasarathy S, Rozgic V, Sun M, Wang C. Improving emotion classification through variational inference of latent variables. In: International Conference on Acoustics, Speech and Signal Processing (ICASSP)—Proceedings. IEEE. 2019:7410–4 <ext-link ext-link-type="uri" xlink:href="https://ieeexplore.ieee.org/document/8682823">https://ieeexplore.ieee.org/document/8682823</ext-link>. Accessed 31 Oct 2019.</mixed-citation>
</ref>
<ref id="CR32">
<label>32.</label>
<mixed-citation publication-type="other">Trigeorgis G, Ringeval F, Brueckner R, Marchi E, Nicolaou MA, Schuller B, et al. Adieu features? End-to-end speech emotion recognition using a deep convolutional recurrent network. In: International Conference on Acoustics, Speech and Signal Processing (ICASSP)—Proceedings. IEEE. 2016:5200–4 <ext-link ext-link-type="uri" xlink:href="https://ieeexplore.ieee.org/document/7472669">https://ieeexplore.ieee.org/document/7472669</ext-link>. Accessed 31 Oct 2019.</mixed-citation>
</ref>
<ref id="CR33">
<label>33.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hinton</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Deng</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Yu</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Dahl</surname>
<given-names>GE</given-names>
</name>
<name>
<surname>Mohamed</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Jaitly</surname>
<given-names>N</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Deep neural networks for acoustic modeling in speech recognition</article-title>
<source/>IEEE Signal Process Mag
          <year>2012</year>
<volume>29</volume>
<fpage>82</fpage>
<lpage>97</lpage>
<pub-id pub-id-type="doi">10.1109/MSP.2012.2205597</pub-id>
</element-citation>
</ref>
<ref id="CR34">
<label>34.</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Prabhavalkar</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Rao</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Sainath</surname>
<given-names>TN</given-names>
</name>
<name>
<surname>Li</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Johnson</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Jaitly</surname>
<given-names>N</given-names>
</name>
</person-group>
<source/>A Comparison of sequence-to-sequence models for speech recognition. In: Proceedings of the Annual Conference of the International Speech Communication Association, Interspeech
          <year>2017</year>
</element-citation>
</ref>
<ref id="CR35">
<label>35.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Li</surname>
<given-names>Zhichao</given-names>
</name>
<name>
<surname>Huang</surname>
<given-names>Jilin</given-names>
</name>
<name>
<surname>Hu</surname>
<given-names>Zhiping</given-names>
</name>
</person-group>
<article-title>Screening and Diagnosis of Chronic Pharyngitis Based on Deep Learning</article-title>
<source/>International Journal of Environmental Research and Public Health
          <year>2019</year>
<volume>16</volume>
<issue>10</issue>
<fpage>1688</fpage>
<pub-id pub-id-type="doi">10.3390/ijerph16101688</pub-id>
</element-citation>
</ref>
<ref id="CR36">
<label>36.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhan</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Mohan</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Tarolli</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Schneider</surname>
<given-names>RB</given-names>
</name>
<name>
<surname>Adams</surname>
<given-names>JL</given-names>
</name>
<name>
<surname>Sharma</surname>
<given-names>S</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Using smartphones and machine learning to quantify Parkinson disease severity the mobile Parkinson disease score</article-title>
<source/>JAMA Neurol
          <year>2018</year>
<volume>75</volume>
<fpage>876</fpage>
<lpage>880</lpage>
<pub-id pub-id-type="doi">10.1001/jamaneurol.2018.0809</pub-id>
<pub-id pub-id-type="pmid">29582075</pub-id>
</element-citation>
</ref>
<ref id="CR37">
<label>37.</label>
<mixed-citation publication-type="other">Ringeval F, Schuller B, Valstar M, Ni C, Cowie R, Tavabi L, et al. AVEC 2019 workshop and challenge: state-of-mind, detecting depression with AI, and cross-cultural affect recognition. In: Proceedings of the 9th International on Audio/Visual Emotion Challenge and Workshop. Nice; 2019. p. 3–12. 10.1145/3347320.3357688.</mixed-citation>
</ref>
<ref id="CR38">
<label>38.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Marmar</surname>
<given-names>CR</given-names>
</name>
<name>
<surname>Brown</surname>
<given-names>AD</given-names>
</name>
<name>
<surname>Qian</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Laska</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Siegel</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Li</surname>
<given-names>M</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Speech-based markers for posttraumatic stress disorder in US veterans</article-title>
<source/>Depress Anxiety
          <year>2019</year>
<volume>36</volume>
<fpage>607</fpage>
<lpage>616</lpage>
<pub-id pub-id-type="doi">10.1002/da.22890</pub-id>
<pub-id pub-id-type="pmid">31006959</pub-id>
</element-citation>
</ref>
<ref id="CR39">
<label>39.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Maor</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Sara</surname>
<given-names>JD</given-names>
</name>
<name>
<surname>Orbelo</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Lerman</surname>
<given-names>LO</given-names>
</name>
<name>
<surname>Levanon</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Lerman</surname>
<given-names>A</given-names>
</name>
</person-group>
<article-title>Voice signal characteristics are independently associated with coronary artery disease</article-title>
<source/>Mayo Clin Proc
          <year>2018</year>
<volume>93</volume>
<fpage>840</fpage>
<lpage>847</lpage>
<pub-id pub-id-type="doi">10.1016/j.mayocp.2017.12.025</pub-id>
<pub-id pub-id-type="pmid">29656789</pub-id>
</element-citation>
</ref>
<ref id="CR40">
<label>40.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mohr</surname>
<given-names>DN</given-names>
</name>
<name>
<surname>Turner</surname>
<given-names>DW</given-names>
</name>
<name>
<surname>Pond</surname>
<given-names>GR</given-names>
</name>
<name>
<surname>Kamath</surname>
<given-names>JS</given-names>
</name>
<name>
<surname>De Vos</surname>
<given-names>CB</given-names>
</name>
<name>
<surname>Carpenter</surname>
<given-names>PC</given-names>
</name>
</person-group>
<article-title>Speech recognition as a transcription aid: a randomized comparison with standard transcription</article-title>
<source/>J Am Med Informatics Assoc
          <year>2003</year>
<volume>10</volume>
<fpage>85</fpage>
<lpage>93</lpage>
<pub-id pub-id-type="doi">10.1197/jamia.M1130</pub-id>
</element-citation>
</ref>
<ref id="CR41">
<label>41.</label>
<element-citation publication-type="book">
<person-group person-group-type="author">
<name>
<surname>Edwards</surname>
<given-names>Erik</given-names>
</name>
<name>
<surname>Salloum</surname>
<given-names>Wael</given-names>
</name>
<name>
<surname>Finley</surname>
<given-names>Greg P.</given-names>
</name>
<name>
<surname>Fone</surname>
<given-names>James</given-names>
</name>
<name>
<surname>Cardiff</surname>
<given-names>Greg</given-names>
</name>
<name>
<surname>Miller</surname>
<given-names>Mark</given-names>
</name>
<name>
<surname>Suendermann-Oeft</surname>
<given-names>David</given-names>
</name>
</person-group>
<article-title>Medical Speech Recognition: Reaching Parity with Humans</article-title>
<source/>Speech and Computer
          <year>2017</year>
<publisher-loc>Cham</publisher-loc>
<publisher-name>Springer International Publishing</publisher-name>
<fpage>512</fpage>
<lpage>524</lpage>
</element-citation>
</ref>
<ref id="CR42">
<label>42.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wu</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Schuster</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>Z</given-names>
</name>
<name>
<surname>Le</surname>
<given-names>QV</given-names>
</name>
<name>
<surname>Norouzi</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Macherey</surname>
<given-names>W</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Google’s neural machine translation system: bridging the gap between human and machine translation</article-title>
<source/>arXiv
          <year>2016</year>
<volume>arXiv</volume>
<fpage>1609</fpage>
</element-citation>
</ref>
<ref id="CR43">
<label>43.</label>
<mixed-citation publication-type="other">Collobert R, Weston J. A unified architecture for natural language processing: deep neural networks with multitask learning. In: ICML '08. Proceedings of the 25th International Conference on Machine learning. Helsinki; 2008, 2008. p. 160–7. 10.1145/1390156.1390177.</mixed-citation>
</ref>
<ref id="CR44">
<label>44.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Miotto</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Li</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Kidd</surname>
<given-names>BA</given-names>
</name>
<name>
<surname>Dudley</surname>
<given-names>JT</given-names>
</name>
</person-group>
<article-title>Deep patient: an unsupervised representation to predict the future of patients from the electronic health records</article-title>
<source/>Sci Rep
          <year>2016</year>
<volume>6</volume>
<fpage>26094</fpage>
<pub-id pub-id-type="doi">10.1038/srep26094</pub-id>
<pub-id pub-id-type="pmid">27185194</pub-id>
</element-citation>
</ref>
<ref id="CR45">
<label>45.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chen</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Druhl</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Polepalli Ramesh</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Houston</surname>
<given-names>TK</given-names>
</name>
<name>
<surname>Brandt</surname>
<given-names>CA</given-names>
</name>
<name>
<surname>Zulman</surname>
<given-names>DM</given-names>
</name>
<etal></etal>
</person-group>
<article-title>A natural language processing system that links medical terms in electronic health record notes to lay definitions: system development using physician reviews</article-title>
<source/>J Med Internet Res
          <year>2018</year>
<volume>20</volume>
<fpage>e26</fpage>
<pub-id pub-id-type="doi">10.2196/jmir.8669</pub-id>
<pub-id pub-id-type="pmid">29358159</pub-id>
</element-citation>
</ref>
<ref id="CR46">
<label>46.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kohut</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Limb</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Crawford</surname>
<given-names>G</given-names>
</name>
</person-group>
<article-title>The changing role of the genetic counsellor in the genomics era</article-title>
<source/>Curr Genet Med Rep
          <year>2019</year>
<volume>7</volume>
<fpage>75</fpage>
<lpage>84</lpage>
<pub-id pub-id-type="doi">10.1007/s40142-019-00163-w</pub-id>
</element-citation>
</ref>
<ref id="CR47">
<label>47.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Diller</surname>
<given-names>G-P</given-names>
</name>
<name>
<surname>Kempny</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Babu-Narayan</surname>
<given-names>SV</given-names>
</name>
<name>
<surname>Henrichs</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Brida</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Uebing</surname>
<given-names>A</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Machine learning algorithms estimating prognosis and guiding therapy in adult congenital heart disease: data from a single tertiary Centre including 10,019 patients</article-title>
<source/>Eur Heart J
          <year>2019</year>
<volume>40</volume>
<fpage>1069</fpage>
<lpage>1077</lpage>
<pub-id pub-id-type="doi">10.1093/eurheartj/ehy915</pub-id>
<pub-id pub-id-type="pmid">30689812</pub-id>
</element-citation>
</ref>
<ref id="CR48">
<label>48.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Liang</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Tsui</surname>
<given-names>BY</given-names>
</name>
<name>
<surname>Ni</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Valentim</surname>
<given-names>CCS</given-names>
</name>
<name>
<surname>Baxter</surname>
<given-names>SL</given-names>
</name>
<name>
<surname>Liu</surname>
<given-names>G</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence</article-title>
<source/>Nat Med
          <year>2019</year>
<volume>25</volume>
<fpage>433</fpage>
<lpage>438</lpage>
<pub-id pub-id-type="doi">10.1038/s41591-018-0335-9</pub-id>
<pub-id pub-id-type="pmid">30742121</pub-id>
</element-citation>
</ref>
<ref id="CR49">
<label>49.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Clark</surname>
<given-names>MM</given-names>
</name>
<name>
<surname>Hildreth</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Batalov</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Ding</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Chowdhury</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Watkins</surname>
<given-names>K</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Diagnosis of genetic diseases in seriously ill children by rapid whole-genome sequencing and automated phenotyping and interpretation</article-title>
<source/>Sci Transl Med
          <year>2019</year>
<volume>11</volume>
<fpage>eaat6177</fpage>
<pub-id pub-id-type="doi">10.1126/scitranslmed.aat6177</pub-id>
<pub-id pub-id-type="pmid">31019026</pub-id>
</element-citation>
</ref>
<ref id="CR50">
<label>50.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Li</surname>
<given-names>H</given-names>
</name>
</person-group>
<article-title>Toward better understanding of artifacts in variant calling from high-coverage samples</article-title>
<source/>Bioinformatics.
          <year>2014</year>
<volume>30</volume>
<fpage>2843</fpage>
<lpage>2851</lpage>
<pub-id pub-id-type="doi">10.1093/bioinformatics/btu356</pub-id>
<pub-id pub-id-type="pmid">24974202</pub-id>
</element-citation>
</ref>
<ref id="CR51">
<label>51.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>DePristo</surname>
<given-names>MA</given-names>
</name>
<name>
<surname>Banks</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Poplin</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Garimella</surname>
<given-names>KV</given-names>
</name>
<name>
<surname>Maguire</surname>
<given-names>JR</given-names>
</name>
<name>
<surname>Hartl</surname>
<given-names>C</given-names>
</name>
<etal></etal>
</person-group>
<article-title>A framework for variation discovery and genotyping using next-generation DNA sequencing data</article-title>
<source/>Nat Genet
          <year>2011</year>
<volume>43</volume>
<fpage>491</fpage>
<lpage>498</lpage>
<pub-id pub-id-type="doi">10.1038/ng.806</pub-id>
<pub-id pub-id-type="pmid">21478889</pub-id>
</element-citation>
</ref>
<ref id="CR52">
<label>52.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Garrison</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Marth</surname>
<given-names>G</given-names>
</name>
</person-group>
<article-title>Haplotype-based variant detection from short-read sequencing</article-title>
<source/>arXiv
          <year>2012</year>
<volume>arXiv</volume>
<fpage>1207</fpage>
</element-citation>
</ref>
<ref id="CR53">
<label>53.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Hwang</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Kim</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Lee</surname>
<given-names>I</given-names>
</name>
<name>
<surname>Marcotte</surname>
<given-names>EM</given-names>
</name>
</person-group>
<article-title>Systematic comparison of variant calling pipelines using gold standard personal exome variants</article-title>
<source/>Sci Rep
          <year>2015</year>
<volume>5</volume>
<fpage>17875</fpage>
<pub-id pub-id-type="doi">10.1038/srep17875</pub-id>
<pub-id pub-id-type="pmid">26639839</pub-id>
</element-citation>
</ref>
<ref id="CR54">
<label>54.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Poplin</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Chang</surname>
<given-names>PC</given-names>
</name>
<name>
<surname>Alexander</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Schwartz</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Colthurst</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Ku</surname>
<given-names>A</given-names>
</name>
<etal></etal>
</person-group>
<article-title>A universal SNP and small-indel variant caller using deep neural networks</article-title>
<source/>Nat Biotechnol
          <year>2018</year>
<volume>36</volume>
<fpage>983</fpage>
<lpage>987</lpage>
<pub-id pub-id-type="doi">10.1038/nbt.4235</pub-id>
<pub-id pub-id-type="pmid">30247488</pub-id>
</element-citation>
</ref>
<ref id="CR55">
<label>55.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Wick</surname>
<given-names>RR</given-names>
</name>
<name>
<surname>Judd</surname>
<given-names>LM</given-names>
</name>
<name>
<surname>Holt</surname>
<given-names>KE</given-names>
</name>
</person-group>
<article-title>Performance of neural network basecalling tools for Oxford nanopore sequencing</article-title>
<source/>Genome Biol
          <year>2019</year>
<volume>20</volume>
<fpage>129</fpage>
<pub-id pub-id-type="doi">10.1186/s13059-019-1727-y</pub-id>
<pub-id pub-id-type="pmid">31234903</pub-id>
</element-citation>
</ref>
<ref id="CR56">
<label>56.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Tang</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Thomas</surname>
<given-names>PD</given-names>
</name>
</person-group>
<article-title>Tools for predicting the functional impact of nonsynonymous genetic variation</article-title>
<source/>Genetics.
          <year>2016</year>
<volume>203</volume>
<fpage>635</fpage>
<lpage>647</lpage>
<pub-id pub-id-type="doi">10.1534/genetics.116.190033</pub-id>
<pub-id pub-id-type="pmid">27270698</pub-id>
</element-citation>
</ref>
<ref id="CR57">
<label>57.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Quang</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Xie</surname>
<given-names>X</given-names>
</name>
</person-group>
<article-title>DANN: a deep learning approach for annotating the pathogenicity of genetic variants</article-title>
<source/>Bioinformatics.
          <year>2015</year>
<volume>31</volume>
<fpage>761</fpage>
<lpage>763</lpage>
<pub-id pub-id-type="doi">10.1093/bioinformatics/btu703</pub-id>
<pub-id pub-id-type="pmid">25338716</pub-id>
</element-citation>
</ref>
<ref id="CR58">
<label>58.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kircher</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Witten</surname>
<given-names>DM</given-names>
</name>
<name>
<surname>Jain</surname>
<given-names>P</given-names>
</name>
<name>
<surname>O’Roak</surname>
<given-names>BJ</given-names>
</name>
<name>
<surname>Cooper</surname>
<given-names>GM</given-names>
</name>
<name>
<surname>Shendure</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>A general framework for estimating the relative pathogenicity of human genetic variants</article-title>
<source/>Nat Genet
          <year>2014</year>
<volume>46</volume>
<fpage>310</fpage>
<lpage>315</lpage>
<pub-id pub-id-type="doi">10.1038/ng.2892</pub-id>
<pub-id pub-id-type="pmid">24487276</pub-id>
</element-citation>
</ref>
<ref id="CR59">
<label>59.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Sundaram</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Gao</surname>
<given-names>H</given-names>
</name>
<name>
<surname>Padigepati</surname>
<given-names>SR</given-names>
</name>
<name>
<surname>McRae</surname>
<given-names>JF</given-names>
</name>
<name>
<surname>Li</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Kosmicki</surname>
<given-names>JA</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Predicting the clinical impact of human mutation with deep neural networks</article-title>
<source/>Nat Genet
          <year>2018</year>
<volume>50</volume>
<fpage>1161</fpage>
<lpage>1170</lpage>
<pub-id pub-id-type="doi">10.1038/s41588-018-0167-z</pub-id>
<pub-id pub-id-type="pmid">30038395</pub-id>
</element-citation>
</ref>
<ref id="CR60">
<label>60.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Landrum</surname>
<given-names>MJ</given-names>
</name>
<name>
<surname>Lee</surname>
<given-names>JM</given-names>
</name>
<name>
<surname>Benson</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Brown</surname>
<given-names>GR</given-names>
</name>
<name>
<surname>Chao</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Chitipiralla</surname>
<given-names>S</given-names>
</name>
<etal></etal>
</person-group>
<article-title>ClinVar: improving access to variant interpretations and supporting evidence</article-title>
<source/>Nucleic Acids Res
          <year>2018</year>
<volume>46</volume>
<fpage>D1062</fpage>
<lpage>D1067</lpage>
<pub-id pub-id-type="doi">10.1093/nar/gkx1153</pub-id>
<pub-id pub-id-type="pmid">29165669</pub-id>
</element-citation>
</ref>
<ref id="CR61">
<label>61.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Riesselman</surname>
<given-names>AJ</given-names>
</name>
<name>
<surname>Ingraham</surname>
<given-names>JB</given-names>
</name>
<name>
<surname>Marks</surname>
<given-names>DS</given-names>
</name>
</person-group>
<article-title>Deep generative models of genetic variation capture the effects of mutations</article-title>
<source/>Nat Methods
          <year>2018</year>
<volume>15</volume>
<fpage>816</fpage>
<lpage>822</lpage>
<pub-id pub-id-type="doi">10.1038/s41592-018-0138-4</pub-id>
<pub-id pub-id-type="pmid">30250057</pub-id>
</element-citation>
</ref>
<ref id="CR62">
<label>62.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chatterjee</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Ahituv</surname>
<given-names>N</given-names>
</name>
</person-group>
<article-title>Gene regulatory elements, major drivers of human disease</article-title>
<source/>Annu Rev Genomics Hum Genet
          <year>2017</year>
<volume>18</volume>
<fpage>45</fpage>
<lpage>63</lpage>
<pub-id pub-id-type="doi">10.1146/annurev-genom-091416-035537</pub-id>
<pub-id pub-id-type="pmid">28399667</pub-id>
</element-citation>
</ref>
<ref id="CR63">
<label>63.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Soemedi</surname>
<given-names>R</given-names>
</name>
<name>
<surname>Cygan</surname>
<given-names>KJ</given-names>
</name>
<name>
<surname>Rhine</surname>
<given-names>CL</given-names>
</name>
<name>
<surname>Wang</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Bulacan</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Yang</surname>
<given-names>J</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Pathogenic variants that alter protein code often disrupt splicing</article-title>
<source/>Nat Genet
          <year>2017</year>
<volume>49</volume>
<fpage>848</fpage>
<lpage>855</lpage>
<pub-id pub-id-type="doi">10.1038/ng.3837</pub-id>
<pub-id pub-id-type="pmid">28416821</pub-id>
</element-citation>
</ref>
<ref id="CR64">
<label>64.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Baeza-Centurion</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Miñana</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Schmiedel</surname>
<given-names>JM</given-names>
</name>
<name>
<surname>Valcárcel</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Lehner</surname>
<given-names>B</given-names>
</name>
</person-group>
<article-title>Combinatorial genetics reveals a scaling law for the effects of mutations on splicing</article-title>
<source/>Cell.
          <year>2019</year>
<volume>176</volume>
<fpage>549</fpage>
<lpage>563</lpage>
<pub-id pub-id-type="doi">10.1016/j.cell.2018.12.010</pub-id>
<pub-id pub-id-type="pmid">30661752</pub-id>
</element-citation>
</ref>
<ref id="CR65">
<label>65.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Kelley</surname>
<given-names>DR</given-names>
</name>
<name>
<surname>Reshef</surname>
<given-names>YA</given-names>
</name>
<name>
<surname>Bileschi</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Belanger</surname>
<given-names>D</given-names>
</name>
<name>
<surname>McLean</surname>
<given-names>CY</given-names>
</name>
<name>
<surname>Snoek</surname>
<given-names>J</given-names>
</name>
</person-group>
<article-title>Sequential regulatory activity prediction across chromosomes with convolutional neural networks</article-title>
<source/>Genome Res
          <year>2018</year>
<volume>28</volume>
<fpage>739</fpage>
<lpage>750</lpage>
<pub-id pub-id-type="doi">10.1101/gr.227819.117</pub-id>
<pub-id pub-id-type="pmid">29588361</pub-id>
</element-citation>
</ref>
<ref id="CR66">
<label>66.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Alipanahi</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Delong</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Weirauch</surname>
<given-names>MT</given-names>
</name>
<name>
<surname>Frey</surname>
<given-names>BJ</given-names>
</name>
</person-group>
<article-title>Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</article-title>
<source/>Nat Biotechnol
          <year>2015</year>
<volume>33</volume>
<fpage>831</fpage>
<lpage>838</lpage>
<pub-id pub-id-type="doi">10.1038/nbt.3300</pub-id>
<pub-id pub-id-type="pmid">26213851</pub-id>
</element-citation>
</ref>
<ref id="CR67">
<label>67.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bernstein</surname>
<given-names>BE</given-names>
</name>
<name>
<surname>Stamatoyannopoulos</surname>
<given-names>JA</given-names>
</name>
<name>
<surname>Costello</surname>
<given-names>JF</given-names>
</name>
<name>
<surname>Ren</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Milosavljevic</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Meissner</surname>
<given-names>A</given-names>
</name>
<etal></etal>
</person-group>
<article-title>The NIH roadmap epigenomics mapping consortium</article-title>
<source/>Nat Biotechnol
          <year>2010</year>
<volume>28</volume>
<fpage>1045</fpage>
<lpage>1048</lpage>
<pub-id pub-id-type="doi">10.1038/nbt1010-1045</pub-id>
<pub-id pub-id-type="pmid">20944595</pub-id>
</element-citation>
</ref>
<ref id="CR68">
<label>68.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhou</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Troyanskaya</surname>
<given-names>OG</given-names>
</name>
</person-group>
<article-title>Predicting effects of noncoding variants with deep learning-based sequence model</article-title>
<source/>Nat Methods
          <year>2015</year>
<volume>12</volume>
<fpage>931</fpage>
<lpage>934</lpage>
<pub-id pub-id-type="doi">10.1038/nmeth.3547</pub-id>
<pub-id pub-id-type="pmid">26301843</pub-id>
</element-citation>
</ref>
<ref id="CR69">
<label>69.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhou</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Park</surname>
<given-names>CY</given-names>
</name>
<name>
<surname>Theesfeld</surname>
<given-names>CL</given-names>
</name>
<name>
<surname>Wong</surname>
<given-names>AK</given-names>
</name>
<name>
<surname>Yuan</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Scheckel</surname>
<given-names>C</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Whole-genome deep-learning analysis identifies contribution of noncoding mutations to autism risk</article-title>
<source/>Nat Genet
          <year>2019</year>
<volume>51</volume>
<fpage>973</fpage>
<lpage>980</lpage>
<pub-id pub-id-type="doi">10.1038/s41588-019-0420-0</pub-id>
<pub-id pub-id-type="pmid">31133750</pub-id>
</element-citation>
</ref>
<ref id="CR70">
<label>70.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Zhou</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Theesfeld</surname>
<given-names>CL</given-names>
</name>
<name>
<surname>Yao</surname>
<given-names>K</given-names>
</name>
<name>
<surname>Chen</surname>
<given-names>KM</given-names>
</name>
<name>
<surname>Wong</surname>
<given-names>AK</given-names>
</name>
<name>
<surname>Troyanskaya</surname>
<given-names>OG</given-names>
</name>
</person-group>
<article-title>Deep learning sequence-based ab initio prediction of variant effects on expression and disease risk</article-title>
<source/>Nat Genet
          <year>2018</year>
<volume>50</volume>
<fpage>1171</fpage>
<lpage>1179</lpage>
<pub-id pub-id-type="doi">10.1038/s41588-018-0160-6</pub-id>
<pub-id pub-id-type="pmid">30013180</pub-id>
</element-citation>
</ref>
<ref id="CR71">
<label>71.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Telenti</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Pierce</surname>
<given-names>LCT</given-names>
</name>
<name>
<surname>Biggs</surname>
<given-names>WH</given-names>
</name>
<name>
<surname>Di Iulio</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Wong</surname>
<given-names>EHM</given-names>
</name>
<name>
<surname>Fabani</surname>
<given-names>MM</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Deep sequencing of 10,000 human genomes</article-title>
<source/>Proc Natl Acad Sci U S A
          <year>2016</year>
<volume>113</volume>
<fpage>11901</fpage>
<lpage>11906</lpage>
<pub-id pub-id-type="doi">10.1073/pnas.1613365113</pub-id>
<pub-id pub-id-type="pmid">27702888</pub-id>
</element-citation>
</ref>
<ref id="CR72">
<label>72.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Erikson</surname>
<given-names>GA</given-names>
</name>
<name>
<surname>Bodian</surname>
<given-names>DL</given-names>
</name>
<name>
<surname>Rueda</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Molparia</surname>
<given-names>B</given-names>
</name>
<name>
<surname>Scott</surname>
<given-names>ER</given-names>
</name>
<name>
<surname>Scott-Van Zeeland</surname>
<given-names>AA</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Whole-genome sequencing of a healthy aging cohort</article-title>
<source/>Cell.
          <year>2016</year>
<volume>165</volume>
<fpage>1002</fpage>
<lpage>1011</lpage>
<pub-id pub-id-type="doi">10.1016/j.cell.2016.03.022</pub-id>
<pub-id pub-id-type="pmid">27114037</pub-id>
</element-citation>
</ref>
<ref id="CR73">
<label>73.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Köhler</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Carmody</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Vasilevsky</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Jacobsen</surname>
<given-names>JOB</given-names>
</name>
<name>
<surname>Danis</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Gourdine</surname>
<given-names>JP</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Expansion of the human phenotype ontology (HPO) knowledge base and resources</article-title>
<source/>Nucleic Acids Res
          <year>2019</year>
<volume>47</volume>
<fpage>D1018</fpage>
<lpage>D1027</lpage>
<pub-id pub-id-type="doi">10.1093/nar/gky1105</pub-id>
<pub-id pub-id-type="pmid">30476213</pub-id>
</element-citation>
</ref>
<ref id="CR74">
<label>74.</label>
<mixed-citation publication-type="other">Hsieh T-C, Mensah MA, Pantel JT, Aguilar D, Bar O, Bayat A, et al. PEDIA: prioritization of exome data by image analysis. Genet Med. 2019. 10.1038/s41436-019-0566-2.</mixed-citation>
</ref>
<ref id="CR75">
<label>75.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Mobadersany</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Yousefi</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Amgad</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Gutman</surname>
<given-names>DA</given-names>
</name>
<name>
<surname>Barnholtz-Sloan</surname>
<given-names>JS</given-names>
</name>
<name>
<surname>Velázquez Vega</surname>
<given-names>JE</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Predicting cancer outcomes from histology and genomics using convolutional networks</article-title>
<source/>Proc Natl Acad Sci U S A
          <year>2018</year>
<volume>115</volume>
<fpage>E2970</fpage>
<lpage>E2979</lpage>
<pub-id pub-id-type="doi">10.1073/pnas.1717139115</pub-id>
<pub-id pub-id-type="pmid">29531073</pub-id>
</element-citation>
</ref>
<ref id="CR76">
<label>76.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Bastarache</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Hughey</surname>
<given-names>JJ</given-names>
</name>
<name>
<surname>Hebbring</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Marlo</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Zhao</surname>
<given-names>W</given-names>
</name>
<name>
<surname>Ho</surname>
<given-names>WT</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Phenotype risk scores identify patients with unrecognized mendelian disease patterns</article-title>
<source/>Science.
          <year>2018</year>
<volume>359</volume>
<fpage>1233</fpage>
<lpage>1239</lpage>
<pub-id pub-id-type="doi">10.1126/science.aal4043</pub-id>
<pub-id pub-id-type="pmid">29590070</pub-id>
</element-citation>
</ref>
<ref id="CR77">
<label>77.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Torkamani</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Wineinger</surname>
<given-names>NE</given-names>
</name>
<name>
<surname>Topol</surname>
<given-names>EJ</given-names>
</name>
</person-group>
<article-title>The personal and clinical utility of polygenic risk scores</article-title>
<source/>Nat Rev Genet
          <year>2018</year>
<volume>19</volume>
<fpage>581</fpage>
<lpage>590</lpage>
<pub-id pub-id-type="doi">10.1038/s41576-018-0018-x</pub-id>
<pub-id pub-id-type="pmid">29789686</pub-id>
</element-citation>
</ref>
<ref id="CR78">
<label>78.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lello</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Avery</surname>
<given-names>SG</given-names>
</name>
<name>
<surname>Tellier</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Vazquez</surname>
<given-names>AI</given-names>
</name>
</person-group>
<article-title>de los Campos G, Hsu SDH. Accurate genomic prediction of human height</article-title>
<source/>Genetics
          <year>2018</year>
<volume>210</volume>
<fpage>477</fpage>
<lpage>497</lpage>
<pub-id pub-id-type="doi">10.1534/genetics.118.301267</pub-id>
<pub-id pub-id-type="pmid">30150289</pub-id>
</element-citation>
</ref>
<ref id="CR79">
<label>79.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lee</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Mavaddat</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Wilcox</surname>
<given-names>AN</given-names>
</name>
<name>
<surname>Cunningham</surname>
<given-names>AP</given-names>
</name>
<name>
<surname>Carver</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Hartley</surname>
<given-names>S</given-names>
</name>
<etal></etal>
</person-group>
<article-title>BOADICEA: a comprehensive breast cancer risk prediction model incorporating genetic and nongenetic risk factors</article-title>
<source/>Genet Med.
          <year>2019</year>
<volume>21</volume>
<fpage>1708</fpage>
<lpage>1718</lpage>
<pub-id pub-id-type="doi">10.1038/s41436-018-0406-9</pub-id>
<pub-id pub-id-type="pmid">30643217</pub-id>
</element-citation>
</ref>
<ref id="CR80">
<label>80.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Inouye</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Abraham</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Nelson</surname>
<given-names>CP</given-names>
</name>
<name>
<surname>Wood</surname>
<given-names>AM</given-names>
</name>
<name>
<surname>Sweeting</surname>
<given-names>MJ</given-names>
</name>
<name>
<surname>Dudbridge</surname>
<given-names>F</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Genomic risk prediction of coronary artery disease in 480,000 adults</article-title>
<source/>J Am Coll Cardiol
          <year>2018</year>
<volume>72</volume>
<fpage>1883</fpage>
<lpage>1893</lpage>
<pub-id pub-id-type="doi">10.1016/j.jacc.2018.07.079</pub-id>
<pub-id pub-id-type="pmid">30309464</pub-id>
</element-citation>
</ref>
<ref id="CR81">
<label>81.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Topol</surname>
<given-names>EJ</given-names>
</name>
</person-group>
<article-title>High-performance medicine: the convergence of human and artificial intelligence</article-title>
<source/>Nat Med
          <year>2019</year>
<volume>25</volume>
<fpage>44</fpage>
<lpage>56</lpage>
<pub-id pub-id-type="doi">10.1038/s41591-018-0300-7</pub-id>
<pub-id pub-id-type="pmid">30617339</pub-id>
</element-citation>
</ref>
<ref id="CR82">
<label>82.</label>
<mixed-citation publication-type="other">Lomas N. Google has used contract swaps to get bulk access terms to NHS patient data. TechCrunch. 2019; <ext-link ext-link-type="uri" xlink:href="https://techcrunch.com/2019/10/22/google-has-used-contract-swaps-to-get-bulk-access-terms-to-nhs-patient-data/">https://techcrunch.com/2019/10/22/google-has-used-contract-swaps-to-get-bulk-access-terms-to-nhs-patient-data/</ext-link>. Accessed 31 Oct 2019.</mixed-citation>
</ref>
<ref id="CR83">
<label>83.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Vayena</surname>
<given-names>E</given-names>
</name>
<name>
<surname>Blasimme</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Cohen</surname>
<given-names>IG</given-names>
</name>
</person-group>
<article-title>Machine learning in medicine: addressing ethical challenges</article-title>
<source/>PLoS Med
          <year>2018</year>
<volume>15</volume>
<fpage>e1002689</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pmed.1002689</pub-id>
<pub-id pub-id-type="pmid">30399149</pub-id>
</element-citation>
</ref>
<ref id="CR84">
<label>84.</label>
<mixed-citation publication-type="other">Selvaraju RR, Cogswell M, Das A, Vedantam R, Parikh D, Batra D. Grad-CAM: visual explanations from deep networks via gradient-based localization. In: International Conference on Computer Vision (ICCV): IEEE; 2017. p. 618–26. <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/document/8237336/">http://ieeexplore.ieee.org/document/8237336/</ext-link> Accessed 12 Aug 2019.</mixed-citation>
</ref>
<ref id="CR85">
<label>85.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Olah</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Mordvintsev</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Schubert</surname>
<given-names>L</given-names>
</name>
</person-group>
<article-title>Feature visualization: how neural networks build up their understanding of images</article-title>
<source/>Distill.
          <year>2017</year>
<volume>2</volume>
<fpage>e7</fpage>
</element-citation>
</ref>
<ref id="CR86">
<label>86.</label>
<mixed-citation publication-type="other">Mittelstadt B, Russell C, Wachter S. Explaining explanations in AI. In: FAT* 2019. Proceedings of the 2019 Conference on Fairness, Accountability, and Transparency. Atlanta; 2019. p. 29, 279–31, 288. 10.1145/3287560.3287574.</mixed-citation>
</ref>
<ref id="CR87">
<label>87.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Doshi-Velez</surname>
<given-names>F</given-names>
</name>
<name>
<surname>Kim</surname>
<given-names>B</given-names>
</name>
</person-group>
<article-title>Towards a rigorous science of interpretable machine learning</article-title>
<source/>arXiv
          <year>2017</year>
<volume>arXiv</volume>
<fpage>1702</fpage>
</element-citation>
</ref>
<ref id="CR88">
<label>88.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Gianfrancesco</surname>
<given-names>MA</given-names>
</name>
<name>
<surname>Tamang</surname>
<given-names>S</given-names>
</name>
<name>
<surname>Yazdany</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Schmajuk</surname>
<given-names>G</given-names>
</name>
</person-group>
<article-title>Potential biases in machine learning algorithms using electronic health record data</article-title>
<source/>JAMA Intern Med
          <year>2018</year>
<volume>178</volume>
<fpage>1544</fpage>
<lpage>1547</lpage>
<pub-id pub-id-type="doi">10.1001/jamainternmed.2018.3763</pub-id>
<pub-id pub-id-type="pmid">30128552</pub-id>
</element-citation>
</ref>
<ref id="CR89">
<label>89.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Sirugo</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Williams</surname>
<given-names>SM</given-names>
</name>
<name>
<surname>Tishkoff</surname>
<given-names>SA</given-names>
</name>
</person-group>
<article-title>The missing diversity in human genetic studies</article-title>
<source/>Cell
          <year>2019</year>
<volume>177</volume>
<fpage>1080</fpage>
<pub-id pub-id-type="doi">10.1016/j.cell.2019.04.032</pub-id>
<pub-id pub-id-type="pmid">31051100</pub-id>
</element-citation>
</ref>
<ref id="CR90">
<label>90.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Lumaka</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Cosemans</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Lulebo Mampasi</surname>
<given-names>A</given-names>
</name>
<name>
<surname>Mubungu</surname>
<given-names>G</given-names>
</name>
<name>
<surname>Mvuama</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Lubala</surname>
<given-names>T</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Facial dysmorphism is influenced by ethnic background of the patient and of the evaluator</article-title>
<source/>Clin Genet
          <year>2017</year>
<volume>92</volume>
<fpage>166</fpage>
<lpage>171</lpage>
<pub-id pub-id-type="doi">10.1111/cge.12948</pub-id>
<pub-id pub-id-type="pmid">27925162</pub-id>
</element-citation>
</ref>
<ref id="CR91">
<label>91.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Martin</surname>
<given-names>AR</given-names>
</name>
<name>
<surname>Kanai</surname>
<given-names>M</given-names>
</name>
<name>
<surname>Kamatani</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Okada</surname>
<given-names>Y</given-names>
</name>
<name>
<surname>Neale</surname>
<given-names>BM</given-names>
</name>
<name>
<surname>Daly</surname>
<given-names>MJ</given-names>
</name>
</person-group>
<article-title>Clinical use of current polygenic risk scores may exacerbate health disparities</article-title>
<source/>Nat Genet
          <year>2019</year>
<volume>51</volume>
<fpage>584</fpage>
<lpage>591</lpage>
<pub-id pub-id-type="doi">10.1038/s41588-019-0379-x</pub-id>
<pub-id pub-id-type="pmid">30926966</pub-id>
</element-citation>
</ref>
<ref id="CR92">
<label>92.</label>
<mixed-citation publication-type="other">Bolukbasi T, Chang K-W, Zou JY, Saligrama V, Kalai AT. Man is to computer programmer as woman is to homemaker? Debiasing word embeddings. In: Lee DD, Sugiyama M, Luxburg UV, Guyon I, Garnett R, editors. Advances in neural information processing systems 29. Proceedings of the 30th Conference on Neural Information Processing Systems (NIPS 2016). Barcelona. p. 4349–57. <ext-link ext-link-type="uri" xlink:href="https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf">https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf</ext-link> Accessed 31 Oct 2019.</mixed-citation>
</ref>
<ref id="CR93">
<label>93.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Yarnell</surname>
<given-names>CJ</given-names>
</name>
<name>
<surname>Fu</surname>
<given-names>L</given-names>
</name>
<name>
<surname>Manuel</surname>
<given-names>D</given-names>
</name>
<name>
<surname>Tanuseputro</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Stukel</surname>
<given-names>T</given-names>
</name>
<name>
<surname>Pinto</surname>
<given-names>R</given-names>
</name>
<etal></etal>
</person-group>
<article-title>Association between immigrant status and end-of-life care in Ontario, Canada</article-title>
<source/>JAMA
          <year>2017</year>
<volume>318</volume>
<fpage>1479</fpage>
<lpage>1488</lpage>
<pub-id pub-id-type="doi">10.1001/jama.2017.14418</pub-id>
<pub-id pub-id-type="pmid">28973088</pub-id>
</element-citation>
</ref>
<ref id="CR94">
<label>94.</label>
<mixed-citation publication-type="other">Sohail M, Maier RM, Ganna A, Bloemendal A, Martin AR, Turchin MC, et al. Polygenic adaptation on height is overestimated due to uncorrected stratification in genome-wide association studies. Elife. 2019;8. 10.7554/eLife.39702.</mixed-citation>
</ref>
<ref id="CR95">
<label>95.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Chen</surname>
<given-names>IY</given-names>
</name>
<name>
<surname>Szolovits</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Ghassemi</surname>
<given-names>M</given-names>
</name>
</person-group>
<article-title>Can AI help reduce disparities in general medical and mental health care?</article-title>
<source/>AMA J Ethics
          <year>2019</year>
<volume>21</volume>
<fpage>E167</fpage>
<lpage>E179</lpage>
<pub-id pub-id-type="doi">10.1001/amajethics.2019.167</pub-id>
<pub-id pub-id-type="pmid">30794127</pub-id>
</element-citation>
</ref>
<ref id="CR96">
<label>96.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Sudlow</surname>
<given-names>C</given-names>
</name>
<name>
<surname>Gallacher</surname>
<given-names>J</given-names>
</name>
<name>
<surname>Allen</surname>
<given-names>N</given-names>
</name>
<name>
<surname>Beral</surname>
<given-names>V</given-names>
</name>
<name>
<surname>Burton</surname>
<given-names>P</given-names>
</name>
<name>
<surname>Danesh</surname>
<given-names>J</given-names>
</name>
<etal></etal>
</person-group>
<article-title>UK biobank: an open access resource for identifying the causes of a wide range of complex diseases of middle and old age</article-title>
<source/>PLoS Med
          <year>2015</year>
<volume>12</volume>
<fpage>e1001779</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pmed.1001779</pub-id>
<pub-id pub-id-type="pmid">25826379</pub-id>
</element-citation>
</ref>
<ref id="CR97">
<label>97.</label>
<element-citation publication-type="journal">
<person-group person-group-type="author">
<name>
<surname>Sankar</surname>
<given-names>PL</given-names>
</name>
<name>
<surname>Parker</surname>
<given-names>LS</given-names>
</name>
</person-group>
<article-title>The precision medicine initiative’s all of us research program: an agenda for research on its ethical, legal, and social issues</article-title>
<source/>Genet Med
          <year>2017</year>
<volume>19</volume>
<fpage>743</fpage>
<lpage>750</lpage>
<pub-id pub-id-type="doi">10.1038/gim.2016.183</pub-id>
<pub-id pub-id-type="pmid">27929525</pub-id>
</element-citation>
</ref>
</ref-list>
</back>
</article>
</pmc-articleset>