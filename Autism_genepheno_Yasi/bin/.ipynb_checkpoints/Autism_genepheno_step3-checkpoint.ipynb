{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script is used to extract one certain geneâ€™s information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dir\n",
    "\n",
    "# input dir\n",
    "json_path = './Autism_genepheno_results/Extraced_results'             # the output file of step1\n",
    "np_dir = './Autism_genepheno_results/Sum_all/n_p.txt'                # the output file of step1\n",
    "ng_dir = './Autism_genepheno_results/Sum_all/n_g.txt'                # the output file of step1\n",
    "In_Summary_dir='./Autism_genepheno_results/Sum_all/In_Summary.txt'   # the output file of step1\n",
    "NPMI_dir='./Autism_genepheno_results/NPMI_file/NPMI.json'            # the output file of step2\n",
    "\n",
    "# output dir\n",
    "one_information_dir = './Autism_genepheno_results/one_gene_information/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the extracted gene\n",
    "gene_extract = \"SHANK3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = glob.glob(\"{}\\\\*.json\".format(json_path)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dict to store the extracted gene information\n",
    "gene_extract_property_dict = {\"Gene name\":gene_extract,\n",
    "                              \"Gene sfari class\":None,\n",
    "                              'Related sentences':{},\n",
    "                              'Related phenotype NPMI':{},\n",
    "                              'Summary':{\"Paper number\":None, \n",
    "                                         \"Paper list\":[],\n",
    "                                         \"Sentence number\":None,\n",
    "                                         \"Normolized phenotype number\":None}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Autism_genepheno_results/Sum_all/n_p.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f68a5d81c89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mphenotype_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mphenotype_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-f68a5d81c89c>\u001b[0m in \u001b[0;36mread_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# read n_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8-sig'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mphenotype_dict\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Autism_genepheno_results/Sum_all/n_p.txt'"
     ]
    }
   ],
   "source": [
    "# read file in .\\\\Sum_all\n",
    "def read_file():\n",
    "    # read n_p\n",
    "    with open(np_dir, 'r', encoding='utf-8-sig') as o:  \n",
    "        phenotype_dict =  ast.literal_eval(o.read())\n",
    "    \n",
    "            \n",
    "    # read n_g\n",
    "    with open(ng_dir, 'r', encoding='utf-8-sig') as o:  \n",
    "        gene_dict =  ast.literal_eval(o.read())\n",
    "            \n",
    "    # read n_tot\n",
    "    with open(In_Summary_dir, 'r', encoding='utf-8-sig') as o:  \n",
    "        f=o.read()\n",
    "        h = f.find('N_tot = ')\n",
    "        e = f.find('Unique gene list from all papers:')\n",
    "        n_tot = int(f[h+8:e-2])\n",
    "    return phenotype_dict, gene_dict, n_tot\n",
    "\n",
    "phenotype_dict, gene_dict, n_tot = read_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gene_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-688103112b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgene_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphenotype_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgene_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphenotype_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphenotype_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gene_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# get gene_list and phenotype list from gene_dict and phenotype_dict\n",
    "def get_list(gene_dict,phenotype_dict):\n",
    "    gene_list=[]\n",
    "    for key in gene_dict.keys():\n",
    "        gene_list.append(key)\n",
    "    phenotype_list=[]\n",
    "    for key in phenotype_dict.keys():\n",
    "        phenotype_list.append(key)\n",
    "    return gene_list,phenotype_list\n",
    "\n",
    "gene_list,phenotype_list = get_list(gene_dict,phenotype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sentences which contain this gene from results in step 1\n",
    "Sentence_number = 0\n",
    "for index,item in enumerate(jsons) :\n",
    "    with open(item, 'r', encoding='utf-8-sig') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "        for key in json_data['Sentences']:\n",
    "            json_phenotype = json_data['Sentences'][key]['Normolized phenotype']\n",
    "            json_gene = json_data['Sentences'][key]['Gene']\n",
    "            if gene_extract in json_gene:\n",
    "                Sentence_number += 1\n",
    "                gene_extract_property_dict['Related sentences'].update({'Sentence'+str(Sentence_number).zfill(3):{'PMCid':json_data['PMCid'],                                                                         'Title':json_data['Title']}})\n",
    "                gene_extract_property_dict['Related sentences']['Sentence'+str(Sentence_number).zfill(3)].update(json_data['Sentences'][key])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract NPMI information from results in step 2\n",
    "extracted_gene_NPMI_list = []\n",
    "\n",
    "with open(NPMI_dir, 'r', encoding='utf-8-sig') as f:\n",
    "    NPMI_data = json.load(f)\n",
    "\n",
    "    for item in NPMI_data:\n",
    "        if item['gene']==gene_extract:\n",
    "            extracted_gene_NPMI_list.append(item)\n",
    "    extracted_gene_NPMI_list.sort(key=lambda x: -x[\"NPMI\"])\n",
    "\n",
    "    \n",
    "for index, item in enumerate(extracted_gene_NPMI_list):\n",
    "    gene_extract_property_dict['Related phenotype NPMI'][item[\"phenotype\"]] = item[\"NPMI\"]\n",
    "    if index ==0:\n",
    "        gene_extract_property_dict[\"Gene sfari class\"] = item[\"gene_sfari_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary of extracted gene information\n",
    "gene_extract_property_dict['Summary']['Sentence number'] = Sentence_number\n",
    "gene_extract_property_dict['Summary']['Normolized phenotype number'] = len(gene_extract_property_dict['Related phenotype NPMI'])\n",
    "templist = []\n",
    "templist2 = []\n",
    "for sentence in gene_extract_property_dict['Related sentences']:\n",
    "    templist.append(gene_extract_property_dict['Related sentences'][sentence]['PMCid'])\n",
    "    templist2.append(gene_extract_property_dict['Related sentences'][sentence]['Title'])\n",
    "    \n",
    "gene_extract_property_dict['Summary']['Paper list'] = list(set(templist))\n",
    "gene_extract_property_dict['Summary']['Paper name list'] = list(set(templist2))  \n",
    "gene_extract_property_dict['Summary']['Paper number'] = len(gene_extract_property_dict['Summary']['Paper list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the json file\n",
    "with open(one_information_dir+gene_extract+\"_information.json\", 'w', encoding='utf-8-sig') as f:\n",
    "    json.dump(gene_extract_property_dict , f , sort_keys=True, indent=4, separators=(',', ': '))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the summary txt file\n",
    "with open(one_information_dir+gene_extract+\"_summary.txt\", 'w', encoding='utf-8-sig') as f:\n",
    "    f.write(\"Gene name: %s \\n\" % gene_extract)\n",
    "    f.write(\"Paper number: %d \\n\" % gene_extract_property_dict['Summary']['Paper number']) \n",
    "    f.write(\"Paper list: \\n\" )\n",
    "    for paper in gene_extract_property_dict['Summary']['Paper list'] :\n",
    "        f.write(paper)\n",
    "        f.write('\\t')\n",
    "    f.write('\\n')        \n",
    "    f.write(\"Paper name list: \\n\" )\n",
    "    for paper in gene_extract_property_dict['Summary']['Paper name list'] :\n",
    "        f.write(paper)\n",
    "        f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write(\"Sentence number: %d \\n\" % gene_extract_property_dict['Summary']['Sentence number'])\n",
    "    f.write(\"Normolized phenotype number: %d \\n\" % gene_extract_property_dict['Summary']['Normolized phenotype number'])    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
